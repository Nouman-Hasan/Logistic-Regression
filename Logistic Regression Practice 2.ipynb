{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22eafa2b",
   "metadata": {},
   "source": [
    "# Based on the Age and Physical Score(obtained through multiple tests), checking if the individual requires the hearing aid\n",
    "### 1 = Fine,  0 = Requires aid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9efbfe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60708690-4d9e-4fce-8672-cce08caae9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(color_codes=True)\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c267201-bb49-494f-9b06-69da6982958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hearing_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba65562-1f10-4cfb-8333-0cb5f4eec7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>physical_score</th>\n",
       "      <th>test_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  physical_score  test_result\n",
       "0  33.0            40.7            1\n",
       "1  50.0            37.2            1\n",
       "2  52.0            24.7            0\n",
       "3  56.0            31.0            0\n",
       "4  35.0            42.9            1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2be00b9-b0cc-4083-ba91-38317c6cea9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>physical_score</th>\n",
       "      <th>test_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.609000</td>\n",
       "      <td>32.760260</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.287001</td>\n",
       "      <td>8.169802</td>\n",
       "      <td>0.489947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>35.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>38.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age  physical_score  test_result\n",
       "count  5000.000000     5000.000000  5000.000000\n",
       "mean     51.609000       32.760260     0.600000\n",
       "std      11.287001        8.169802     0.489947\n",
       "min      18.000000       -0.000000     0.000000\n",
       "25%      43.000000       26.700000     0.000000\n",
       "50%      51.000000       35.300000     1.000000\n",
       "75%      60.000000       38.900000     1.000000\n",
       "max      90.000000       50.000000     1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87161a70-22c7-4ffb-b989-b8bdaaa98233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='age', ylabel='physical_score'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(data=df,x='age',y='physical_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5133dbf9-e77d-483d-94c1-20b109640fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='age', ylabel='physical_score'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4),dpi=150)\n",
    "sns.scatterplot(data=df,x='age',y='physical_score',hue='test_result',alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7489023-648a-4a65-b695-a2ea50e41af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x1d9c3288880>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 424.425x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(df,hue='test_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28fa348-53a2-467f-8378-56815a5e6100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD/CAYAAAAT87ocAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzsUlEQVR4nO3dd7xcVb3+8c8h9BqFAAkQwXvlAUQJEJAuXMqVIqAgKCAgQog0oyCgtABSFAIRpP3oHZFeAqLUiCAihkh7RHooosC59JLk/P5Ya2BnMifZM2fOyTDn+76ved3Za69d5kj22qt9V0dXVxchhBD6t9lm9Q2EEEKY9aIwCCGEEIVBCCGEKAxCCCEQhUEIIQSiMAghhADM3pcXk7QDcCgwBzDW9ml9ef0QQpiVyj4DJV0E3GH7grw9FLgEWBQwsKPttyUNBC4FPg/8G9jO9iuN3Fuf1QwkLQEcA6wDDANGSFqhr64fQgizUplnoKQhkm4Etq06/HTgdNvLAQ8Ch+X0nwPjbS8PnA38qtH768tmoo1IJd3rtt8BrmL6HxxCCO2qzDNwR+B64MpKgqQ5gPVyfoALgG/l75uTagYAlwOb5vx168tmoiHAy4Xtl4HV+/D6IYTQdLmpZmCNXZ22OwvbM30G2j4hn3OdQvIiwJu2JxeOW7L6nLYnS3oTGAS8VO/v6MvCYDagGPuiA5ha5sAHl9w6YmaEEEoZPum6jp6e46P/PF3PM+dI4Ihu0kcXtht9BlYfR+G46t9a+rla6yJ9ZRIwuLC9OA2UXiGE0OumTin/gbHAMjU+Y6vO2ugz8FVgIUkD8vbgwnEv5vMgaXZgAeC1+n5s0pc1gz8AoyUNAt4BtgFG9OH1QwihnK7yL9e5KaizRNaGnoG2P5I0HtgeuAzYGbgl7x6Xt4/N+8fb/qj0zRf0Wc3A9ovAIcCdwATgMtsP9NX1QwihtKlTy39K6u4ZKGmcpOEzOXwv0uijx4B1ScNTIY0qWkPSoznP3vX90E90fBpCWEefQQihrGb0GXz40qOlnzlzDvlij6/XCvp00lkIIXwqTJk88zxtJgqDEEKoljqG+5UoDEIIoVodHcjtokeFgaQjgO3y5s22D5S0JnAyaYjTRGAX2x8Wjtkc+LXtZXpy7RBC6DV1dAy3i4ZHE0naCNgEWJkUZ2NVSbsA1wAjbH8xZ/1+4ZjFgBOZfqJECCG0jK6uqaU/7aInNYOXgf0rb/2SHgeWBu6zPTHn2bfqGueQZuUd34PrhhBC7+qHNYOGCwPbj1a+S/oCqbloDPC2pCuA5YB7gf1znv2Ah4D7e3LDIYTQ66Y0NG/rU63Hk84kfRH4PfATUuHyv8BPgVWB+YCDJa1Imm13dE+vF0IIva5ravlPm+hRYSBpbeB24GDbFwKvAPfbfsb2FFIY1tVJ4VYHk+JwjwOG5OnVIYTQenphBnKr60kH8lLAdcAOtq/IybeROpKXyttbAH+1fYTtZW0PAzYDXrK9buO3HUIIvagf1gx60oF8ADA3cJKkStqZwJ7AjZLmJsXfOKAnNxhCCH2ujd74y4rYRCGEttKM2ETvT7ip9DNn7mFbtMVQ+ZiBHEII1fphzSAKgxBCqNZGfQFl9TQcxZ3AokBlUO6ewErAfqRl2h4E9rT9oaRVgLOAOYEXgJ2q1gcNIYTW0A8D1fVkNFEHsCywku1heaTQG6T5BmsBX87nryy28CvgcNsrASY6lkMIrSpGE9WlMoToNkkLA2cDNwJ72X4TQNLfgaE53wBgwfx9XuD1Hlw7hBB6T/QZ1OUzpAln+wJzAHcBtv17gLzO5z7Arjn/j0kFx1jS+p9f6cG1Qwih98TiNuXZvg+4r7It6VzShLLfS1qCtGDzubbvkjQPcC6wUV7z88fARcDmPbr7EELoDb1UM5C0A2n94jmAsbZPq9o/jBTQc0HgHmAk8FnShN6KhYBBtueX9FVSpOgX8r6/2f5eI/fWcGEgaR1gLtu356QO4CNJywG/A06xPSbvWxF4z/YDefssIk5RCKFFdXU1vwM5vyQfQ4rb9gHwJ0l32n6skO0SYHfb9+cX7D1sn0FaJgBJs5FaZA7J+YcDJ9o+rqf315PYRAOBEyTNLWkBYBdSn8FtwKGFggDgn8BS+mSq8lbAX3pw7RBC6D29E5toI+AO26/bfge4Cti2slPS54B5bFciO19AiutW9D3gXduX5e3VgE0kTZR0QyEUUN160kx0k6SvAH8jdQ6fRiqlFgP2l7R/znqD7cMl7QpcmUchvUr6USGE0HrqGCUkaSDp5bhaZ9Xw+SGkdWAqXiYF8pzR/iUL1xlAqhFsVbwGcKXtaySNBK4A1i598wU9mmdg+zDgsKrkk7vJewupHyGEEFpbfW/8o4AjaqQfCYwubM9Gmn9V0QFMrWP/14Anbf+9kmB7ZOH7mZKOl7SQ7f+r5wdAzEAOIYTp1TeaaCypSadaZ9X2JKAYrXlx4KWq/YNnsH9r0ps/8HH/wU+B4/OSARUNDYWKwiCEEKrV0UyUm4I6S2T9AzA6D7t/h7Tg14jCeZ6T9L6ktW3fC3yXaVtT1gR+Ucg/VdI3gCdJTfA7A3/O/RF16/FKZyGE0HZ6oQPZ9oukNv87SeH9L8tD7cdJGp6z7QicLOkJYH7glMIpPk+qPRTtAoyS9CipH3b3Rn4u9CCEtaTdSZPKKpYBLibFIzoQmALcAexve7KkrUhtaB3AM8D3bL9R5loRwjqEUFYzQli/d/PY0s+ceTYf1RYhrBuuGdg+pxCTaEfSCKGLgZ8DG9r+EmlixX6SFgTOADbPsYkmMm3HSgghtI5+GJuoWc1EZwA/I8Uhus92ZXjUTaROjzmAvXM1CVJhMLT6JCGE0BKmTC7/aRM97kCWtBFposRvJS1LWgZzKVIv+LbA4rZfA67N+ecBDgZO7em1QwihV/TDQHXNqBnsCZwEYPsfpAf9DcB4Ug3gw0pGSQsBNwMP276wCdcOIYTmi2ai+kiaE/gq6eGPpLmBB2yvbHst4EXgqbxvMJ8UEA33eIcQQq/rnXAULa2nzURfBv5RGNc6H3C7pC+SAjHtC5yZp1HfSJo2/fMeXjOEEHpXGz3ky+ppM9E0415z38CRwP3AI6SgTJcBWwKrANtKmpA/5/Tw2iGE0Du6usp/2kTD8wz6UswzCCGU1ZR5BpceVn6ewY5Ht8U8gwhHEUII1dqoY7isKAxCCKFaP+wzKFUY5BnEfwK2sP1snltwEjAP8Bvbh+Z8RwC7AZUwE2fbPi2PJDqHFK/7XWBH28829ZeEEEKzfAqaz5ttph3IeQGbPwLL5u15gPNICywsD6wmadOcfTjw7UqYisL6nhcDN9peOX//BSGE0KpiaGlNewB7kx7ikFbmedL2MwCSLiEtzXYLqTD4WV6+7R7gAFLkvZWAjfPx55PW8AwhhNbURg/5smZaM7C9u+3xhaSaS7NJmp+0BOZPSMNIB5JWQfsv4HlgjKS/kNb9/JAQQmhRXVOmlP60i0bmGdRcms3227Y3s/2E7cnAGGAzUu1jZdKcg9WA64EIRRFCaF39sJmokcKg5tJskoZK2q2Q3gF8BLwCvGX7ppx+GdMuAh1CCK0lYhOV8mdAkv47h5nYgdRf8B7wS0nLSOog9TNca/spYFKhk/nrwF+bcO8hhNA7pnaV/7SJugsD2+8DuwJXA48BTwBX2f43KYLpjYBJNYMx+bBvAgdJegT4IWn4aQghtKZ+2EwU4ShCCG2lGeEo3h27Z+lnzryjzopwFCGE0JZ66Y1f0g7AoaTVH8cW5mJV9g8jTdBdkDQ8f2ReQ34X4HjgXznrzbYPkTQQuJQUNPTfwHa2X2nk3pq17GUIIbSPXugzkLQEcAywDjAMGCFphapslwD72F6W1NS+R04fDvy4MKH3kJz+c2C87eWBs4FfNfqTo2YQQgjV6hgllN/OB9bY1Wm7s7C9EWmI/ev5uKtISwMflbc/R1pC+P6c/wLSkgBnAKsBX5D0M+BhYF/bbwCbA+vl/JcDp0maw/ZHpX9A1mhsoh8A+5BKrpuBA213Sdoq33wH8AzwPdtvSBpKKvEWJXUu72j77XpvNoQQ+kR9o4RGAUfUSD8SGF3YrjVhd/WZ7F+y8P1E0nP4WODXwI7FY3Jz0pvAINIa9HVpJDbRMsCP84/4ErAWsHEuMM4ANre9Eml5y9H5NKcDp9teDniQNDM5hBBaUtfUqaU/wFhgmRqfsVWnrTlht8x+29+wfa/tLuCXwKaFPNQ6pl51xyay/YykFWx/JGlhYCGgk9QhsrftF/NxE4EdJc1BqsZsndMvAO4GDmrkhkMIodfVEWYiNwV1lsg6CVi3sL04077BdzehdyFgN9sn5/QOYHL+/mLON0nS7MACwGulb76gkdhE5IJgD+BpUhVlgu3XbF8LH0c2PRi4DlgEeDOHqIBpqz4hhNB6emfS2R+ADSUNkjQvsA1wa2Wn7eeA9yWtnZO+S5rQ+zZwYG6lgdREf23+Pg7YOX/fntSZXHd/AfRgNJHts4GFSeEmRlfScyl2M/Cw7QuZvuoDDVZjQgihT/TCpLPcanIIcCcwAbjM9gOSxkkanrPtCJws6QlSxOdTbE8BtgPOkPQ4sCpwYM5/GLCGpEeBvUitOA2pezSRpKWAobn9arKkK4Af5H2Dgd8BdwA/yoe8CiwkaUD+UYNpoHMjhBD6TC+FmbB9GSk+WzFts8L3h6kRuy23zqxSI/11YMtm3FsjNYOFgEslDcwxiLYF/pjjFN0IXGl7VO7oIFdZxpOqMJCqNLf0/NZDCKGX9MNAdXXXDGw/Iuk40hCnyaQH/RhS6bQKMLukbXP2B23vTqq+XCjpUNLaBt9pxs2HEEKvaKMAdGVFbKIQQltpRmyitw/6Zulnzvy/uCZiE4UQQlvqhzWDKAxCCKFaG/UFlNVoOIrzScGW3slZjrR9raRVgLOAOYEXgJ2KsTkkrQzcb3uuJv6GEEJorqgZTC9PdDibHI4iGw6sZ/vlquy/Ag63fYukMcABpHCt5EkWp5IKihBCaFld/bAwKDO0tBKO4iX4+KE+FDhP0kRJR0qqnGcAKQ43wLykpTArxjB9rI4QQmg9k6eU/7SJRsJRLE6aVLYbsAYp1sb3874fA2dLehnYGDgTQNKWwLy2r2rivYcQQu/oh2sgNzLP4GngG5VtSacCO0u6BDgX2ChPsf4xcJGk75OaijZq0j2HEELvaqOHfFl1z0CW9CVJ2xSSOoCPgBWB92w/kNPPAtYHtiDFMLpH0oR8jgmSFujBfYcQQq/p6uoq/WkXjQwt7QDGSrqDFE1vBHAh8E9gKUmybWAr4C+2zyGt6QmApC7bw3p85yGE0Fv6Yc2gkWaiiTkcxb2kNQyutn05gKRdgStzzKJXge818V5DCKFv9MPCIMJRhBDaSjPCUfzfLhuWfuYsdOHtEY4ihBDaUv+bgByFQQghVOuPk86iMAghhGpRGNRWIzbRJsAJpBnHDwG72/6wkH9z4Ne2l8nbSwMXkWYndwK75PU+Qwih9UQz0fS6iU10LrCJ7cclXUVaveycnH8x4ETSENSKo4HLbZ8haV/gGGCn5vyEEEJort5qJpK0A2kS7hzAWNunVe0fRnqWLgjcA4zMywuvDZxMiu32GrCb7eckfRW4hhQYFOBvthsaxVl3bKJsALBgXupybqaNQXQOcGTVOYoxi+aryh9CCC2la3JX6U9ZkpYgvQivAwwDRkhaoSrbJcA+tpclvVDvkdMvJbXADMvfT8npw4ETbQ/Ln4aH88+0ZpCXrURSMXkv4C7gTeAZ4KqcZz9Ss9H9Vac5DPhT3j8nsGajNxxCCL2ujmYiSQOBgTV2dRZD+JNC8tyRF7Ent6psCxyVtz8HzGO78vy8ADhS0nnAobYn5vSJwL75+2rAYpK+AzwL7G27UkuoSyPhKBYHjieFnxhMevCfJGlFYBtSk1C1C4ERtpcARgLX5olpIYTQcmqte9/dBxhFeimu/oyqOu0QoBj2/2VgyZntt/2B7UsAcoTo0cB1OU8ncKrtLwPjgCsa/c2NjCZaF3jE9lP55s4GrgT+QyocHiS9/Q+RNB74JrCc7esBbF8t6UxgEeDfjd54CCH0mvo6kMeS3uKrdVZtzwYU25U6qq40w/2S5iS9WM8OHAtge2Rlv+0zJR0vaSHb/1fXL6CxwuARYIykxWz/i09iEB0BHJFvemngLtvr5hrA+5LWtT0+d4S8ZTsKghBCS6pn1cvcFNRZIusk0st0xeJM2xc7ifRCPd1+SfMDN5A6j7ey/VGuJfwUON52cWGFyeXv/hN1NxPZfpzUB3CnpImkDowDZpC/i1Q7ODHn/yWpOSmEEFpS1+Tynzr8AdhQ0qC8SNg2wK2VnXm4/fv5hRngu8At+fslpGCg29v+IOefSlpOYBsASTsDf7ZdWY64LhGbKITQVpoRm+jVDb9a+pmz6O13l75eHlr6M1JT+jm2fylpHGm54AclrUQayr8gaTDO94AV8vfHSMsFALxkezNJX8z5FyIFB9250Q7kKAxCCG2lGYXBvzYoXxgsdmf5wqCVRTiKEEKo1tUWz/e6lA1HcQSwXd682faBOX0OUpvX0bbvKuQ/Gphie3TeXp608tmCpAlnP7A9oTk/IYQQmqueDuR2USYcxUbAJsDKpGFPt0r6Bqn96jxglULehYCTgO+QOoorzgaOs32zpP8hDY9aqVk/IoQQmqlratQMankZ2L8SiE7S48BQ0iziE5h2YsVWwJPAmKpznMMnveYT8/EhhNCSpk6JwmA6th+tfJf0BVJz0dq2n8xpowp5L8ppo6vOcUFh8yg+mT0XQggtJ5qJZiAPYboZ+EmlIKhHnnx2ArAGsEG9x4cQQl+JZqJu5EkQVwOjbNcd+0LS7KT1DJYANmhkqnQIIfSVT8GI+6Yr04G8FKlZZ3vbdzR4nRNJI4k2qcyeCyGEVhU1g9oOIK1ZcFIhjPWZts8scwFJg4B9SFH8/lw5R47LHUIILac/diDHDOQQQltpxgzkp7+0Selnzuf/fltblBwxAzmEEKp0xQzkEEIIMbQ0hBACU6NmUFut2ESSfkDqGO4gzT84kBRi4oLCoYOAN2yvKGkwaSbyEOBdYEfbzzbjR4QQQjNFM1EN3cQm+hGwFzAMeB+4B9jY9m05jbx4wwOkNY8BLgauykuzjQR+AWzfzB8TQgjN0B9HEzUam2gqsEJeem1h0sIKnVXH/RS42/YfJS1CqjVsnPedD9zehPsPIYSmi3kGNcwgNtFHkvYgTSh7AJhQyLcQMAL4Uk76L+B50trJ6wKvkJqYQgih5fTHPoPSayDn2ES/pxCbyPbZwMKkh/voQvadgOtsv5q3Zyc1M91hezXgelIY6xBCaDldXR2lP+2iodhEOUTFUNv32p4s6QrgB4VDtgaOLWy/Arxl+6a8fRlwSo/vPoQQekFvzcXNayAfCswBjLV9WtX+YaSBNguS+mJH5mfsUOASYFHApAE4b0saCFwKfB74N7Cd7VcaubeZ1gwKsYl2KASpWwi4VNLAHI10W+CPOX8HsCpwX+Uctp8CJknaNCd9HfhrIzccQgi9bWpXR+lPWZKWAI4B1iENtBkhaYWqbJcA+9heljRSc4+cfjpwuu3lgAeBw3L6z4HxtpcnLSL2q8Z+cblmomJsogmSJuQfcxzwJ+Bh0lDRyoI2g4APbb9fdZ5vAgdJegT4IbBbozcdQgi9aerUjtKfOmxEaip/3fY7wFWkF2kAJH0OmMf2/TnpAuBbeXnh9XL+j9Pz981JNQOAy4FNc/66lelA/iHp4V3LWTXyvwosXiPdwPp13l8IIfS5Ot/4BwIDa+zqtN1Z2B5CGp1Z8TKw+kz2LwksArxpe3JV+jTH5OakN0kv5C+V/gFZ6Q7kEELoL+rsQB5Fispc/RlVddrZSHO1KjpIw/Rntr86ncJx1aVW9TlLi3AUIYRQpc6hpWOZNvJCRWfV9iRg3cL24kz7Bj8JGFxj/6vAQpIG2J6S81SOezHnm5QXEVsAeK2em6/oSTiKNYGT88UnArtUJqblYzYHfm17mbxdsze8kZsOIYTeVM9gotwU1Fki6x+A0XmNl3eAbUjzsSrneU7S+5LWtn0v8F3gljynazwpYsNlwM7ALfmwcXn72Lx/vO2P6rj9j5UZTVQMRzEMWFXSLsA1wAjbX8xZv184ZjHSZLRi8dpdb3gIIbSUKVNnK/0py/aLwCHAnaRJupfZfkDSOEnDc7YdgZMlPQHMzydD8PcijT56jFS7ODSnHwasIenRnGfvRn9zo+Eolgbusz0x59m36lznAEcCx+djKr3hW+f9FwB3Awc1euMhhNBbeiuCte3LSG/3xbTNCt8fZtpO5Ur6c9QYgGP7dWDLZtxbo+EoxgBv58lmywH3AvvnPPsBDwH3F04zo97wEEJoKV3T9cu2v4bCUZAKkf8lBaNbFZgPOFjSiqR2sKNrXKe73vAQQmgpU7vKf9pFqcIgh6O4HTjY9oWk8BL3234m925fSarafIvU0/0gqWNjSO74+Lg3PJ+y2BseQggtZSodpT/totFwFLeROpKXyttbAH+1fYTtZW0PAzYDXrK9bu7drvSGw7S94SGE0FK66Cj9aRdlOpCL4SgqaWcCewI3Spqb1DN+wEzOsxdwoaRDSeGsv9PIDYcQQm+b0kYP+bI6unorPF8TPbjk1q1/kyGEljB80nU9fpLfuti3Sz9zvvavK9qi5IgZyCGEUKU/jm6JwiCEEKq0U19AWVEYhBBClX64BHKPYhPtChwITAHuIM1SntzdSj2Fc61MGpY6V9N+RQghNFE7DRktq9HYRAeRVtjZ0PaXSEu47ZcP6W6lHiTNC5wKzNnE3xBCCE01pY5Puygz6ezj2ER5vsDjpKGm99muLMRwE7B1dyv1FM41hhTuNYQQWtbUjo7Sn3bRaGyidYE/5ElnL5GWbluc7lfqQdKWwLy2ryrMVwghhJbTH8eyNxSbKC9heTBwA2lm8UTgQ7pZqUfS4qSQq/s26b5DCKHXTK3j0y7KdiCvDVwNjLJ9RZ51/IDtlfP+bwFP0f1KPVsACwP3VGoFkiYA69p+qzk/JYQQmiNGE9VQiE20ve07cvJ8wO25tvAB6Y3/zBms1HMOaYRR5ZxdOX5RCCG0nP4YjqInsYmOJK1ZMAdpxZ7Kgg07AmdLWpC0rsEphBDCp0h/rBlEbKIQQltpRmyiC5bYqfQzZ9cXL2mLoiNmIIcQQpW+fPuUNJQ0P2tRwMCOtt+uyjMncC4wHHiPtKTAE5LmB84jrTjZARxTWWpA0tPAm4XTfN32C93dRxQGIYRQpY+biU4HTs+Dcw4jLXJfvT78fsA7tpeXtB5pDtcapFGdz9veTtKiwARJdwKTgQ/r6ZstO5roKNJcgi7gXNsn5fQ5gFuBo23fldMEnAV8hrQi2rdtvyFpaeAiUpiKTmCXvMhzCCG0lL4aMpqfoesBW+ekC4C7mb4w2Bw4HMD2PZIG5RrF3aTaBLZflfQ6aRTnYKBD0r3APMBxtn87o3spM5roq8D/AF8mdRY/JunmvPs8YJVC3g7S3IMf2r5V0vGkkusg0rrIl9s+Q9K+wDHATjO7fggh9LUpddQMJA0EBtbY1Wm7cyaHLwK8WYjf9vFE3So1J/Ta/n3hPrYD5gIeBZYBfkd69i4GjJf0iO3Hu7uRMjOQ75a0QQ5Ct0Q+5h1SteUEYFQh+yqkqsyteftYPvkjDSDVCiANTX1vZtcOIYRZoc6awSjgiBrpRwKjKxt5PtbJVXmeZPouilqXrzmht+rcvwK+lguW6/IH4FlJ15BizDVeGADY/kjSkaRhpr8FXrR9YL6JUYWs/w28IulcUmC7x/lk1vFhwJ8k7UcKVLdmmWuHEEJfq7MwGEtq3qnWWdzIzTTTNNXkZqLXJA2wPYXUvPNSjXNVJvQ+lbcrE3rJLS0/ATax/fectgXwiu0Hc/4O4KMZ/YjS4ShsHwEMApaiEIm0yuzA+sAZtlcBngZOyvsuBEbYXgIYCVybm5VCCKGldNXxsd1p+9kan86ZXScH/xwPbJ+TdgZuqZF1XN6HpHWA920/L2lr4EfA2pWCIFsaOELSbJIWA7YEbmYGyoSwXi6vUYDtd4FrSP0HtbwCPFkojS4HVpc0CFjO9vX5PFeTSrZFZnb9EELoa1M7yn+aYC9ghKTHSEFADwWQNDIP3oEU+n8uSY+SJvJ+N6cfSeogvlHShPwZTpoY/DLwCLlDemYDdso0E30eODKXRl3AVqSO41r+BAyStJLth4GvA38F/gO8L2ld2+NzrKO3bP+7xPVDCKFP9WUAuvyQXr9G+pmF7+8Du9TIs9IMTj2invuYac3A9jhS9eJvpAf7nyqTGmrkfQ/4BikcxaOkUUj72+4CvgmcKGki8Etgm3puNIQQ+kp/XNwmwlGEENpKM8JR/PJz5cNRHPhchKMIIYS21E7rFJQVhUEIIVTpj00RPQpHkfftA2xre/28/Q1SD/cA4C+k4aQf5k7jk0lzDF4DdotwFCGEVjS1HxYHZYaWFsNRDAf2zfGHkLQCKdxEJe98wK+BjW1/kbQOwq5596XA7jlw0qXEOgchhBbVHzuQy4wmuhvYIE9xXpQcjkLSXKSAdIcX8r4DLG37X5LmzfnfyHkPtT0xZ50IDG3uTwkhhOboj2sgl5qBXAhH8RhwO/AicBxpvsHTNfJuCrxAmlR2m+0PbF8CIGk2UryO65r0G0IIoan6eNJZS2g0HMUIYKjt87vJe4vthYGbgDMq6XmBhktJtYtje3DfIYTQa6bSVfrTLhoNR/EV4IuSJpAWuh8u6TeSPitpk8Lhl5JDV+QVeW4lFQRb5ZgcIYTQcuqJTdQuytQMPk+aUTxXfrPfitT0s3zuDN4deND29qTIeJfkRRcAvgX8MX+/BPgnsL3tD5r5I0IIoZmiz6CGOsNRvEZqQrpJ0sOAgIMkrUwqRNYGHsrBlMY16TeEEEJTTaGr9KddRDiKEEJbaUY4igOW/k7pZ86Jz17eFt3IMQM5hBCqtFPHcFlRGIQQQpX+VxREYRBCCNNpp47hshqOTSRpTVKsoQVIM4p3yTGINgV+kQ/9O7Cn7bclDSYNQx0CvAvsaPvZpv6aEEJognbqGC6r0dhEK5HmG4zIMYgAvi9pIGmt42/b/jLwMJ9MLrsYuNH2yvn7LwghhBbUHyedzbRmYPtuSRvYnixpiXzMMOC+QqyhfXP6F4DnbD+W028Cbs01i5WAjXP6+aSwFiGE0HL68hGf52VdQorlZlKrydtVeeYEziW9kL8H7GD7CUlzkKJAF8MCrWp7iqT9gT1IL/0H275mRvfRaGyixYG3JV2RZyEfCXQCTwJL5ZoDwHY5738BzwNjJP0FuAr4sMy1Qwihr/VxzeB04HTbywEPAofVyLMf8I7t5YFRwAU5/cukF/Nhhc8USasBO5Fe3NcBTpD02RndRKOxieYG/hf4KbAqMB+p5OkEdgb+X37ov0R66M8OrAzcYXs14HpSc1IIIbScvpqBnN/s1yO9IEN6yH+rRtbNSeF9sH0PMCjXKFbL3x+UdH9u1gfYDLjG9vu2XwXuAraY0b3MtJlI0nLA3LYn2H5X0jXAiaSQFM/kPFcC+0gaAEyy/ZWcvhrwFPAK8Jbtm/JpLyPWMwghtKiuOt74c1/pwBq7OvML8owsAryZlwgAeBlYska+IXkfVfm6SBGgjwNWBG6RtGLO/5ca+btVZjTR54EjJa2TL7wVKeTEcZKWsv0CqcT5a95/m6SvkGoFPwZ+Y/spSZMkbWr7FuDrOX8IIbScOkcTjQKOqJF+JClcPwCSvkUagVn0JNN3UdSqcMxWla8DmGr7rELa3yT9mRT2p2b+bn8B5TqQx0lanRSbaApwte2LJb0O3ChpbmACcIDtqZL2JEUnnQv4A3BCPtU3gbMknQC8Cewys2uHEMKsUGfzz1g+acMv6ixu2P4t8NtiWqUDWNIA21OAwaQX6WqT8r6n8vbiwEuSvkuKF1dJ7wA+KuSnkN8z+hGl5hnYHk2hhMtpN5MC2FXn7S7dwPplrhdCCLPS1DpituWmoM5GrpMH54wHtic1n+8M3FIj67i874+5leZ928/nwTprAnvl5YhXBsYD/yG9fJ9E6tPdkMKqlLXEDOQQQqjSx7MH9gIulHQoadTldwAkjQSG2D4cOJX0cH8U+AD4bj72KOA8SY/k297Z9lvAA5IuIfUbzA4cZvvFGd1ERC0NIbSVZkQt3eFz3yj9zLnsuWv7T9TSbsJR7AocSOpHuAPYP09ME3AW8BnSKKJv236jzMSKEEJoBfWMJmoXjYajEPBzYEPbXwLmAPaT1AHcABxveyVSp/PB+VRlJlaEEMIsN5mu0p92UWals7uBDfI42EVJtYnVSbPeKuNebwK2BlYhzZK7NacfC5xWx8SKEEKY5brq+L92UXY0USUcxQGkoVEPAMdKWoo0DGpb0tCl/wZekXQuqVf7cVLcorITK0IIYZbrjyGsGw1H8VVS888NpGFME/kk7MT6wBm2VyEFTzqJ6SdAQP/8e4cQPgW6urpKf9pFmT6D5SQNA7D9Lil09erAA7ZXtr0W8CKfhJ140vaD+fDLc95XgYVyuArofmJFCCHMcv0xhHWZmsHngbMlzZXDqG4F3AncLmmBnLYv8BvgT6SgSZWopV8H/mr7I1INYvuc3t3EihBCmOWm0FX60y4aDUdxaQ5DcT9pJNFlti8DkPQNUuExH2lKdGVyRM2JFSGE0Gra6Y2/rJh0FkJoK82YdLbpUpuWfubc8sIt/WfSWQgh9Cf9cXRLFAYhhFClneYPlBWFQQghVOmPfQalCwNJJwKL2N5V0gjSmpxdpNASe9r+UNJWpAUdOoBngO/ZfqNwjpWB+23P1cwfEUIIzTSlq/81FJWadCZpQ/JiNJKWBX4CrEWKVzQbsLekBYEzgM1zXKKJTLvKz7ykMKxzNvH+Qwih6fpjOIoyk84+CxxDijMEKZb2XrbftN0F/B0YShpiunchZvbEnF4xhrQiUAghtLSpXV2lP+2iTDPRWcAhpDAU2H4OeA5A0iBgH2BX268B1+b0eUjhKk7N21sC89q+KgU8DSGE1tU+j/jyZlgzkLQ78ILt22vsWwK4nbS+wV2F9IVIy14+bPtCSYsDh5JmKYcQQsvrj+EoZlYz2B4YLGkC8Flgfkknk2oLvwNOsT2mklnS4Jx+B/CjnLwFsDBwT6VWkM+3bl6eLYQQWko7PeTLmmFhYHvjyve8stn6pEWVHwUOsX1xYf8A4EbgSts/L5zjHOCcQr4u28Oac/shhNB8fTmaqMwqkDkG3LmkBcbeA3aw/YSkM4E1Clm/BGyfm+SfBt4s7Pu67Re6u49G5hnsDiwG7C9p/5x2Ayl20SrA7JK2zekP2t69gWuEEMIs08ejhCqrQF4h6TDSKpAHVeXZj7Rw2PKS1iMtELaG7ZGVDJJ2A7YDrpa0MPBhPS/epQsD2xfkGwA4uZtsZVZOa4s4HiGE9tVXMdsKq0BunZMuAO5m+sJgc1KrDLbvkTRI0lDbz+fzLAwcBaxtu0vSakCHpHuBeYDjbP92RvcSM5BDCKFKPX0GkgYCA2vs6rTdOZPDy64COSTvoyrf83n7R8AVebQnwNyk/tuDSC054yU9Yvvx7m4kCoMQQqhSZ81gFHBEjfQjmXbi7beYvlXlScqtAlm9WmRHJZ+k2YDdSAuJAWD7OuC6vPmspGuATUhLEdfUUDiKQto+wLa218/bq5BGGs0JvADsZLtT0tLARcCCQCewS6EECyGEljKlvrilY/mkCb2os7iRm2mmaarJzUSvSRpgewrdrwI5Ke97Km8vXsi3JmmFyUmF824BvFJYdbID+GhGP6LucBSFtBVIE8uKfgUcnsNRGDggpx8NXJ47M64mzWgOIYSWVM8MZNudtp+t8emc2XXqWAVyXN6HpHWA9yv9BaTCYHxV/qWBIyTNJmkxYEvS/K9uNRKOAklzkWoAh1dlH0B6+weYlzQEqjp9vkJ6CCG0nD6OTbQXMELSY8C6pEm6SBop6aic51RgLkmPAqfwyQqSkJYmnsS0ziT1KzxC7pCeWWtM3eEosuOA80iRSYt+DNwmaSzwDvCVnH4Y8CdJ+5GakNYscd0QQpgl+jLmUH5Ir18j/czC9/epap0p7NurRtpkYEQ991F3OApJGwNDbZ9flXce0qSIjWwPJo2dvSjvvhAYYXsJYCRwraQYYhpCaEn9MWrpDNdAlvR7UqfFZHI4CuB60oy3D/L24qS2qBOBM2wPz8fOB7xKart63PYihfP+G1jB9r/L3GSsgRxCKKsZayAvO2h46WfOP/79YFu82NYdjsL29wpp6wOjbW8v6TPAUpJk28BWwF+A/wDvS1rX9nhJawNvlS0IQgihr/XHxW2aNs/A9hu5wLgyNwG9SlrprEvSN4FTc1PSW8A2zbpuCCE0Wzs1/5Q1w2aiVhHNRCGEsprRTLTMwiuVfuY889rD7d9MFEII/VGEsA4hhNBngepaSRQGIYRQJWoGM1CJTQRcSWE2MrAE8GfbW0g6ghQw6Y2872zbp+URRCeTJpy9BuwWsYlCCK1qytQYTVRTITbRzbbHkeJkkNc3vpdPlrgcDnzb9n1Vp7gU2NL2xLwAwymkoachhNBy+uNoopkWBlWxiVaq2n0CcKbtJ/P2cOBnkj4H3EMKVNcFHGp7Ys4zEdi3CfceQgi9oj/2GZSJWlqJTfRGMVHSF0jxNE7J2/OTlr78CWn5y4HAYbY/sH1JzjMbKb73dc24+RBC6A1T6Sr9aRd1xyYqGEFat/MDANtv297M9hM5SNIYYLPCueYkNRfNzrR9DiGE0FK6urpKf9rFzGoG2wObSJpAWl9zS0mVlXq2Bq6oZJQ0NPcHVHy8mEKuNdxKKgi2yjG8QwihJU2ZOrX0p100EpvoR5IWAeaxXQxh/R7wS0l3As8CewPX5n2XAP8ERtpun79eCKEttVPzT1mlVjqrYbrFFHLguT2BG0mrnHUAYyStTBo5tDbwkKQJksY1fsshhNC7+mMzUcQmCiG0lWbEJpp/3mVKP3PefveZiE0UQgjtKOYZhBBC6NNlL1tFFAYhhFBlah8ubiNpKGmQzaKk/tYdbb/dTd6NgYNtb5i3O0iTf7cApgJ72L4379sf2IPUN3yw7WtmdB+NdiCHEELb6uMO5NNJc7aWAx4EDqvOIGm2/HC/AhhQ2LUNsDywAmm4/wWSZpe0GrATMAxYBzghR5PoVtQMQgihSj0PeUkDSREXqnXa7pzJsXMA65Ee5AAXAHcDB1VlXT5/9gD2K6RvDlyRh+z/Q9LzwFrABsA1tt8nLTt8F6n2cFF39/KpKAyaMToghBDK+ujDF0s/cySNBo6osetIUvidGVkEeDNHbQB4GViyOpPtR4Hd87rzRUPyMRWV44eQ1qCvTu/Wp6IwCCGEFjaW9EZfrbO4IelbpFD+RU/CdEOX6umwmK3q+I58fHfp3YrCIIQQeiA3BXWWyPdb4LfFtNxM9JqkAbanAIOBl+q4/KR8TMXi+fha6Z7RiaIDOYQQZpEcp208KQ4cwM7ALXWcYhywo6QBkv4bWJbUPHQLsI2keSUNAjYEagUc/VjUDEIIYdbaC7hQ0qHA88B3ACSNBIbYPnwGx14FfIW0TgzA922/Bzwg6RJSwTA7aTmBF2d0E5+KcBQhhBB6VzQThRBCiMIghBBCFAYhhBCIwiCEEAJRGIQekrS0pGd7eI4hjS54JClGQITQBFEYhFnO9ku2N5vV9/FpI2khSdfOPOd0x20h6ce9cU8lrt2V///qkn4xK+4h1BbzDBogaXbgDGBFYDHSGN/vkIJI7UuajfgE8JTt0ZK+BhwFzAE8Qwoz+9osuPUeyXFRDgM+ApYBHgB+Dswj6QrS3+MNUtCtrYH/sb1jPnY0aZ3sB4FfkqbKv0H6u80P3GV7aUmfA84nhfN9F9jd9kRJx5AmznyWNMNye9v/KnHPXwb+H+m/9feB79l+UtIOwKH5Pv5C+t9uDuBsYCXS1P0TbV+U1//ehRRH5kbgV8BZwFI5309t/6GuP2ZzfAZYuYHjhjf7RhqwAunfTmgRURg0Zi3gQ9trSpoNuAM4ENgBWBX4ELgLeCrP/jse2MD2G5L2BH4B7D5L7rzn1iKFxf0HcCUpauIg4CTbD0i6Cvg2cCFwrKQFbL9FeuhvAFwKjLT9F0kHAqvkc1WcDlxt+zRJmwGHSvoZsBywlu2pki4ihecdU+J+fwSMsf1bSbsAa0h6lxQjZlXbkyRdnH/HWsBrtleUtAhp4s6EfJ4lgeVtT84F33m2b5A0GPijpGH5d/alU4AhuXZwLTCKVNv/K7A3MAU4j1RIQ/rb3guMBJD0nO3za524bAEoaUNmULjnc40GsD06bw8kvRzNL+kQ28f0/E8ReiqaiRpg+x7gdEl7k/6RfCHvusn2mzls7OU57SvAUODO/GDZp5D/0+geJ13AxcD/AC/ZfiDvfxRYJC/OMQ74pqR1gadtvwTcAFwr6dfA32zfVnX+r+bzYnuc7e1s/xPYnxS1cQywJumBU8bNwK8lnQv8H3BZPv5e25Pydb5r+7r8W87Naf8BrgfWz+d5qBBZciPgqPy/5y2kGsV/lbyfZtqPVEs6lFSzWcv2MOBV4ABS4fZZ2yuTCrt1bT8GnAmc2V1BULAksLLtn5H+Oz/P9qrAlsBZkhbI1x5pezjwe1LhPkM5ls/hwA1RELSOqBk0QNKWpDebX5GaNBYhNQ0NrJF9APBH21vmY+em/IOsFU0ufJ8tbxfTukgREiG9lR4KPE2O6mj7ZEk3kmKr/zLXJC4tHP9R5UtexWl5YB5S4XoSafr9lMI1Zsj2VZLuy9f7EemheBOFiI659lb5PUUdfPJv5L1C+gBSE9jr+fjBpAfwrLIB6QXjfkkAcwIPkZoyJel3pIL5J3Wet7oAXE7SUXm7UgBWCvfrgOtt/17S0j34LWEWiZpBYzYCrsxvVp2kf4wAm0laUNKcpBWIuoA/A2tKWjbnOQw4sY/vt5nWkbREbh6bYVAt2+NJb5cbANcBSPozsIDtsaSmmuo3yXtIzUyQ/s7/j1RbuMv2maQmpS2YdrWnbkn6DbCa7bNIf/tVSH0Ea0haPGc7GdiK1Nz3/XzcIqR+j7tqnPYOUjwZJK0APALMW+Z+eskA0n+Pw3LNYHVgn9wv9UXgVEDAQ7mJpqxaBWDlGl8B/m77ZFLt6Z+kwv0Qpn0hgFRwhBYXhUFjzga+I+nvpJC095LazU8B7iNFIXwLeM/2K8BuwJU5/yqkJo9Pq5dIqyU9BrwIzKzj9BrgDtsf5O2fkZbm+yvpwXtwVf59SNEWJ5AWBxkB/AZYKf/97iJ1Qi9T8n6PBQ6R9BCpbfsHubnqh8DvJD1CeuidT6rtfTZf5x7gGNsP1TjnvqTCZGK+t51mQX8BpBrZ7KS/yTckLZprU2cAo3IN9mJSU9l+wNukNv/KcfWoWQB2U7h3kv6OgyTNBXxtBvceWkQEqmuS/Oa/eX5TQtL1wDm2b5y1d9Y8eTTRaNvrl8jbQWqu+D0wqpuHauiBHAv/buADUlPbKNIL3gTSC8gU4BxgNdJIqmttHy1pPVIH/0m2T+3m3LsC69veNW8PIdXShpLe+g+0fUvuQD6J9HB/mzT660lJh5EK+xdIBce/8si6Ltsd+d/LOOAq29UvBGEWiMKgSfIb0PnAl0nV5N8BP8kdrW2hzsJgMKn2cLbtA3v5vrYHflprX27SCCHMRBQGIfRTUYiGoigMQgghRAdyCCGEKAxCCCEQhUEIIQSiMAghhEAUBiGEEID/D89XwXeYu2F3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2b57d7c-e15d-486e-94a8-71d8a0364e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "marker": {
          "color": "rgba(255, 153, 51, 0.6)",
          "line": {
           "color": "rgba(255, 153, 51, 1.0)",
           "width": 1
          }
         },
         "name": "test_result",
         "orientation": "v",
         "text": "",
         "type": "bar",
         "x": [
          "age",
          "physical_score"
         ],
         "y": [
          -0.6831706796301815,
          0.7927158178562347
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"9fd45c34-b7e4-4731-b3b9-71de7b05326f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';                                    if (document.getElementById(\"9fd45c34-b7e4-4731-b3b9-71de7b05326f\")) {                    Plotly.newPlot(                        \"9fd45c34-b7e4-4731-b3b9-71de7b05326f\",                        [{\"marker\":{\"color\":\"rgba(255, 153, 51, 0.6)\",\"line\":{\"color\":\"rgba(255, 153, 51, 1.0)\",\"width\":1}},\"name\":\"test_result\",\"orientation\":\"v\",\"text\":\"\",\"x\":[\"age\",\"physical_score\"],\"y\":[-0.6831706796301815,0.7927158178562347],\"type\":\"bar\"}],                        {\"legend\":{\"bgcolor\":\"#F5F6F9\",\"font\":{\"color\":\"#4D5663\"}},\"paper_bgcolor\":\"#F5F6F9\",\"plot_bgcolor\":\"#F5F6F9\",\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"color\":\"#4D5663\"}},\"xaxis\":{\"gridcolor\":\"#E1E5ED\",\"showgrid\":true,\"tickfont\":{\"color\":\"#4D5663\"},\"title\":{\"font\":{\"color\":\"#4D5663\"},\"text\":\"\"},\"zerolinecolor\":\"#E1E5ED\"},\"yaxis\":{\"gridcolor\":\"#E1E5ED\",\"showgrid\":true,\"tickfont\":{\"color\":\"#4D5663\"},\"title\":{\"font\":{\"color\":\"#4D5663\"},\"text\":\"\"},\"zerolinecolor\":\"#E1E5ED\"}},                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('9fd45c34-b7e4-4731-b3b9-71de7b05326f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.corr()['test_result'][:-1].sort_values().iplot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2491415-fe8b-4879-80f1-ffd98bc45d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74d8f72f-8b49-4eae-a6c0-0633c515e3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "age=%{x}<br>physical_score=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          33,
          50,
          52,
          56,
          35,
          58,
          66,
          38,
          53,
          43,
          39,
          58,
          45,
          52,
          36,
          83,
          57,
          39,
          58,
          54,
          65,
          69,
          41,
          43,
          64,
          55,
          46,
          40,
          70,
          36,
          62,
          71,
          38,
          67,
          50,
          68,
          58,
          63,
          60,
          24,
          44,
          55,
          42,
          61,
          49,
          66,
          51,
          65,
          53,
          52,
          60,
          46,
          69,
          62,
          64,
          72,
          66,
          32,
          54,
          59,
          74,
          37,
          32,
          68,
          62,
          58,
          54,
          75,
          48,
          54,
          57,
          31,
          74,
          40,
          54,
          82,
          48,
          53,
          61,
          27,
          62,
          66,
          39,
          51,
          41,
          52,
          46,
          57,
          47,
          82,
          43,
          55,
          57,
          46,
          56,
          49,
          52,
          46,
          56,
          60,
          49,
          67,
          39,
          59,
          67,
          55,
          68,
          44,
          47,
          45,
          70,
          62,
          68,
          46,
          74,
          60,
          52,
          58,
          42,
          50,
          43,
          57,
          51,
          49,
          46,
          47,
          40,
          66,
          48,
          45,
          39,
          47,
          54,
          55,
          66,
          47,
          62,
          51,
          70,
          51,
          48,
          32,
          60,
          50,
          48,
          42,
          51,
          44,
          71,
          57,
          34,
          58,
          31,
          71,
          46,
          69,
          82,
          54,
          59,
          47,
          56,
          54,
          42,
          53,
          77,
          37,
          68,
          66,
          62,
          43,
          48,
          44,
          54,
          39,
          65,
          51,
          30,
          53,
          48,
          51,
          64,
          34,
          43,
          67,
          46,
          46,
          44,
          79,
          59,
          69,
          35,
          49,
          32,
          60,
          41,
          38,
          40,
          35,
          56,
          48,
          36,
          51,
          43,
          52,
          41,
          67,
          61,
          34,
          63,
          62,
          64,
          45,
          53,
          46,
          51,
          51,
          33,
          48,
          50,
          63,
          48,
          51,
          34,
          46,
          56,
          54,
          46,
          66,
          57,
          38,
          34,
          55,
          41,
          49,
          60,
          56,
          66,
          65,
          56,
          52,
          48,
          71,
          54,
          52,
          57,
          38,
          58,
          56,
          46,
          56,
          53,
          61,
          45,
          53,
          46,
          64,
          47,
          46,
          68,
          70,
          41,
          50,
          62,
          43,
          53,
          46,
          52,
          53,
          34,
          40,
          43,
          40,
          50,
          58,
          48,
          39,
          49,
          51,
          47,
          59,
          42,
          44,
          65,
          40,
          43,
          65,
          50,
          49,
          70,
          49,
          52,
          39,
          31,
          64,
          44,
          46,
          32,
          36,
          30,
          68,
          49,
          50,
          35,
          37,
          65,
          61,
          37,
          76,
          48,
          36,
          55,
          65,
          39,
          34,
          25,
          59,
          42,
          54,
          51,
          49,
          59,
          72,
          61,
          41,
          50,
          52,
          34,
          66,
          40,
          37,
          58,
          58,
          50,
          52,
          55,
          36,
          45,
          31,
          57,
          49,
          52,
          75,
          57,
          57,
          38,
          56,
          56,
          60,
          47,
          57,
          59,
          61,
          48,
          78,
          46,
          72,
          48,
          44,
          52,
          76,
          72,
          53,
          47,
          44,
          34,
          45,
          64,
          59,
          68,
          62,
          49,
          40,
          59,
          48,
          40,
          48,
          39,
          51,
          40,
          55,
          41,
          38,
          42,
          66,
          66,
          58,
          43,
          46,
          55,
          54,
          43,
          57,
          40,
          42,
          64,
          72,
          39,
          52,
          43,
          62,
          43,
          77,
          58,
          49,
          44,
          49,
          58,
          40,
          74,
          73,
          44,
          43,
          45,
          40,
          65,
          55,
          55,
          52,
          68,
          56,
          53,
          43,
          64,
          55,
          76,
          46,
          56,
          44,
          38,
          43,
          53,
          81,
          50,
          63,
          30,
          47,
          25,
          55,
          48,
          48,
          50,
          37,
          72,
          47,
          65,
          53,
          82,
          35,
          38,
          37,
          47,
          54,
          39,
          59,
          22,
          56,
          56,
          42,
          58,
          64,
          62,
          64,
          50,
          58,
          52,
          60,
          31,
          42,
          38,
          57,
          41,
          39,
          40,
          56,
          68,
          48,
          66,
          41,
          63,
          49,
          41,
          40,
          55,
          55,
          48,
          41,
          50,
          41,
          32,
          59,
          42,
          54,
          48,
          49,
          60,
          43,
          39,
          48,
          46,
          45,
          53,
          39,
          52,
          33,
          53,
          42,
          67,
          50,
          78,
          58,
          43,
          43,
          46,
          56,
          62,
          35,
          60,
          77,
          58,
          39,
          39,
          48,
          44,
          48,
          74,
          67,
          33,
          41,
          45,
          62,
          65,
          39,
          77,
          63,
          71,
          44,
          58,
          69,
          48,
          64,
          62,
          40,
          69,
          40,
          44,
          48,
          60,
          61,
          40,
          57,
          54,
          63,
          42,
          59,
          41,
          66,
          53,
          36,
          46,
          51,
          45,
          33,
          46,
          75,
          47,
          48,
          47,
          51,
          48,
          38,
          40,
          67,
          72,
          52,
          51,
          63,
          35,
          33,
          62,
          43,
          47,
          70,
          51,
          40,
          39,
          32,
          60,
          33,
          57,
          68,
          69,
          54,
          60,
          57,
          18,
          55,
          46,
          54,
          46,
          54,
          47,
          35,
          48,
          45,
          47,
          41,
          42,
          41,
          41,
          52,
          31,
          41,
          55,
          73,
          64,
          29,
          63,
          54,
          63,
          45,
          65,
          47,
          49,
          57,
          44,
          53,
          29,
          56,
          52,
          44,
          25,
          54,
          40,
          46,
          67,
          45,
          45,
          47,
          65,
          54,
          41,
          43,
          54,
          52,
          68,
          82,
          42,
          75,
          74,
          43,
          65,
          35,
          42,
          55,
          42,
          51,
          71,
          41,
          47,
          28,
          42,
          55,
          70,
          67,
          49,
          55,
          37,
          48,
          37,
          46,
          34,
          63,
          53,
          54,
          76,
          50,
          69,
          48,
          45,
          42,
          39,
          55,
          43,
          38,
          51,
          60,
          70,
          71,
          62,
          69,
          34,
          52,
          56,
          37,
          43,
          67,
          53,
          49,
          44,
          51,
          60,
          37,
          50,
          31,
          45,
          53,
          45,
          66,
          68,
          44,
          50,
          51,
          66,
          48,
          45,
          61,
          43,
          47,
          58,
          33,
          55,
          56,
          54,
          52,
          52,
          64,
          39,
          56,
          73,
          56,
          64,
          43,
          39,
          59,
          52,
          43,
          48,
          48,
          46,
          53,
          59,
          49,
          31,
          72,
          76,
          54,
          39,
          60,
          59,
          42,
          49,
          32,
          41,
          68,
          60,
          76,
          43,
          42,
          74,
          68,
          43,
          53,
          71,
          48,
          37,
          78,
          42,
          47,
          60,
          50,
          41,
          77,
          67,
          64,
          49,
          62,
          46,
          48,
          34,
          66,
          50,
          47,
          71,
          51,
          44,
          64,
          55,
          65,
          62,
          54,
          51,
          57,
          39,
          50,
          52,
          40,
          42,
          46,
          47,
          53,
          51,
          52,
          44,
          43,
          52,
          49,
          53,
          48,
          50,
          71,
          43,
          53,
          53,
          61,
          56,
          47,
          68,
          32,
          40,
          46,
          73,
          56,
          74,
          55,
          74,
          50,
          66,
          42,
          41,
          51,
          42,
          46,
          38,
          46,
          41,
          59,
          62,
          64,
          54,
          54,
          61,
          62,
          38,
          48,
          56,
          73,
          26,
          34,
          50,
          44,
          62,
          32,
          44,
          68,
          45,
          74,
          47,
          36,
          48,
          66,
          56,
          64,
          61,
          49,
          57,
          54,
          66,
          47,
          65,
          63,
          44,
          53,
          35,
          62,
          49,
          64,
          39,
          55,
          67,
          54,
          41,
          57,
          67,
          59,
          38,
          36,
          28,
          31,
          72,
          52,
          49,
          50,
          43,
          49,
          58,
          68,
          49,
          39,
          54,
          63,
          51,
          61,
          62,
          77,
          31,
          70,
          42,
          55,
          42,
          38,
          52,
          55,
          46,
          56,
          71,
          48,
          38,
          50,
          76,
          60,
          68,
          73,
          36,
          66,
          43,
          42,
          61,
          53,
          28,
          34,
          55,
          41,
          44,
          34,
          55,
          63,
          51,
          44,
          45,
          48,
          45,
          46,
          40,
          39,
          51,
          43,
          41,
          67,
          63,
          46,
          78,
          58,
          51,
          62,
          42,
          36,
          70,
          41,
          65,
          44,
          39,
          50,
          47,
          41,
          48,
          74,
          48,
          49,
          58,
          49,
          61,
          61,
          51,
          37,
          49,
          63,
          54,
          50,
          46,
          60,
          50,
          67,
          67,
          47,
          57,
          30,
          62,
          47,
          48,
          42,
          42,
          35,
          54,
          49,
          46,
          61,
          69,
          40,
          30,
          46,
          47,
          77,
          54,
          50,
          51,
          26,
          39,
          52,
          49,
          52,
          27,
          45,
          55,
          67,
          41,
          56,
          66,
          67,
          52,
          57,
          73,
          60,
          44,
          45,
          66,
          60,
          69,
          50,
          78,
          46,
          48,
          41,
          60,
          39,
          64,
          46,
          43,
          37,
          42,
          44,
          40,
          58,
          46,
          57,
          54,
          36,
          66,
          30,
          37,
          58,
          56,
          47,
          61,
          51,
          24,
          35,
          60,
          64,
          40,
          57,
          53,
          50,
          53,
          38,
          56,
          59,
          57,
          39,
          45,
          69,
          49,
          42,
          58,
          50,
          68,
          71,
          44,
          34,
          41,
          48,
          68,
          48,
          55,
          49,
          63,
          37,
          44,
          63,
          42,
          44,
          65,
          44,
          63,
          55,
          47,
          55,
          51,
          54,
          52,
          60,
          71,
          44,
          38,
          41,
          44,
          55,
          42,
          41,
          38,
          58,
          39,
          46,
          39,
          60,
          41,
          44,
          60,
          62,
          64,
          60,
          59,
          65,
          50,
          61,
          44,
          40,
          58,
          46,
          54,
          63,
          37,
          45,
          41,
          58,
          65,
          56,
          44,
          63,
          55,
          47,
          47,
          39,
          52,
          32,
          41,
          48,
          41,
          46,
          55,
          48,
          47,
          38,
          69,
          70,
          60,
          45,
          50,
          44,
          44,
          50,
          49,
          72,
          37,
          68,
          46,
          57,
          54,
          36,
          78,
          52,
          40,
          49,
          81,
          64,
          44,
          43,
          50,
          69,
          54,
          62,
          64,
          46,
          57,
          40,
          52,
          34,
          50,
          21,
          43,
          46,
          41,
          74,
          50,
          38,
          39,
          76,
          60,
          37,
          56,
          66,
          68,
          49,
          39,
          56,
          47,
          65,
          42,
          36,
          57,
          57,
          37,
          54,
          32,
          54,
          54,
          62,
          68,
          37,
          42,
          48,
          66,
          43,
          59,
          59,
          54,
          50,
          52,
          33,
          44,
          53,
          42,
          74,
          54,
          46,
          52,
          52,
          43,
          33,
          60,
          61,
          54,
          57,
          62,
          60,
          64,
          69,
          73,
          47,
          44,
          47,
          44,
          58,
          65,
          32,
          46,
          52,
          58,
          62,
          66,
          77,
          35,
          52,
          40,
          72,
          46,
          51,
          48,
          43,
          65,
          49,
          48,
          38,
          45,
          58,
          62,
          48,
          34,
          38,
          40,
          50,
          59,
          56,
          51,
          80,
          39,
          55,
          46,
          45,
          48,
          68,
          53,
          42,
          34,
          44,
          59,
          45,
          66,
          57,
          44,
          53,
          83,
          72,
          69,
          62,
          50,
          48,
          60,
          63,
          66,
          53,
          80,
          68,
          36,
          32,
          59,
          69,
          51,
          50,
          51,
          44,
          50,
          57,
          44,
          52,
          43,
          33,
          41,
          30,
          61,
          59,
          61,
          49,
          57,
          64,
          47,
          54,
          48,
          47,
          45,
          65,
          49,
          76,
          67,
          56,
          42,
          48,
          58,
          51,
          68,
          54,
          65,
          67,
          46,
          62,
          55,
          57,
          47,
          36,
          57,
          52,
          68,
          65,
          63,
          54,
          43,
          35,
          36,
          74,
          41,
          42,
          39,
          64,
          28,
          52,
          52,
          46,
          58,
          70,
          48,
          57,
          54,
          54,
          68,
          54,
          38,
          74,
          35,
          49,
          59,
          40,
          41,
          62,
          66,
          65,
          71,
          47,
          47,
          65,
          49,
          61,
          81,
          60,
          47,
          69,
          34,
          78,
          34,
          59,
          42,
          46,
          46,
          55,
          31,
          47,
          45,
          50,
          55,
          54,
          62,
          50,
          34,
          62,
          42,
          49,
          42,
          47,
          56,
          49,
          73,
          47,
          53,
          58,
          61,
          49,
          38,
          33,
          57,
          71,
          55,
          43,
          63,
          42,
          60,
          62,
          55,
          55,
          56,
          65,
          50,
          47,
          63,
          46,
          39,
          29,
          45,
          50,
          62,
          38,
          47,
          54,
          49,
          63,
          51,
          43,
          42,
          45,
          54,
          55,
          35,
          30,
          50,
          40,
          43,
          43,
          38,
          57,
          50,
          49,
          58,
          44,
          58,
          53,
          46,
          47,
          44,
          38,
          42,
          56,
          40,
          60,
          31,
          53,
          62,
          37,
          77,
          56,
          55,
          24,
          50,
          55,
          68,
          55,
          58,
          37,
          51,
          40,
          47,
          64,
          51,
          61,
          53,
          64,
          32,
          46,
          68,
          36,
          54,
          46,
          51,
          64,
          30,
          51,
          56,
          43,
          54,
          46,
          44,
          34,
          63,
          61,
          42,
          63,
          57,
          66,
          37,
          59,
          42,
          48,
          60,
          39,
          59,
          36,
          43,
          54,
          57,
          47,
          41,
          83,
          43,
          53,
          70,
          60,
          42,
          48,
          34,
          68,
          44,
          61,
          55,
          71,
          54,
          38,
          49,
          52,
          60,
          70,
          55,
          40,
          36,
          70,
          47,
          57,
          42,
          51,
          44,
          66,
          82,
          48,
          53,
          61,
          54,
          48,
          37,
          84,
          47,
          33,
          63,
          60,
          44,
          37,
          36,
          42,
          61,
          46,
          60,
          37,
          41,
          68,
          54,
          66,
          69,
          68,
          72,
          48,
          62,
          42,
          56,
          51,
          36,
          56,
          43,
          49,
          46,
          69,
          40,
          39,
          52,
          46,
          55,
          41,
          48,
          58,
          71,
          46,
          58,
          71,
          79,
          33,
          46,
          46,
          65,
          57,
          38,
          70,
          46,
          62,
          31,
          42,
          57,
          54,
          56,
          67,
          51,
          49,
          37,
          49,
          42,
          58,
          62,
          60,
          54,
          40,
          51,
          58,
          43,
          33,
          62,
          59,
          49,
          50,
          42,
          56,
          35,
          45,
          44,
          67,
          52,
          52,
          62,
          71,
          54,
          47,
          49,
          54,
          52,
          39,
          51,
          49,
          65,
          55,
          44,
          51,
          59,
          70,
          53,
          49,
          45,
          41,
          55,
          43,
          51,
          59,
          60,
          68,
          60,
          45,
          51,
          37,
          60,
          52,
          50,
          46,
          50,
          64,
          45,
          41,
          54,
          40,
          55,
          38,
          40,
          70,
          60,
          43,
          59,
          40,
          55,
          81,
          39,
          53,
          80,
          61,
          53,
          54,
          63,
          58,
          46,
          38,
          55,
          63,
          43,
          68,
          50,
          50,
          59,
          57,
          55,
          50,
          61,
          55,
          63,
          49,
          56,
          71,
          40,
          84,
          43,
          61,
          46,
          55,
          33,
          65,
          68,
          57,
          76,
          58,
          56,
          39,
          29,
          54,
          47,
          62,
          52,
          47,
          64,
          34,
          59,
          71,
          47,
          67,
          59,
          57,
          58,
          39,
          41,
          41,
          52,
          55,
          46,
          73,
          59,
          39,
          49,
          43,
          47,
          64,
          46,
          46,
          62,
          47,
          32,
          61,
          68,
          66,
          46,
          35,
          45,
          32,
          41,
          29,
          65,
          43,
          43,
          59,
          70,
          41,
          39,
          41,
          45,
          53,
          44,
          52,
          47,
          62,
          50,
          63,
          56,
          45,
          42,
          59,
          39,
          47,
          84,
          52,
          49,
          63,
          38,
          53,
          65,
          45,
          42,
          43,
          44,
          40,
          49,
          37,
          54,
          44,
          63,
          34,
          50,
          55,
          67,
          40,
          48,
          50,
          49,
          64,
          50,
          42,
          40,
          51,
          60,
          70,
          31,
          57,
          38,
          44,
          64,
          38,
          48,
          43,
          43,
          69,
          66,
          47,
          67,
          42,
          64,
          66,
          43,
          41,
          42,
          76,
          46,
          53,
          64,
          49,
          48,
          37,
          39,
          37,
          57,
          40,
          62,
          50,
          54,
          46,
          39,
          45,
          67,
          62,
          44,
          56,
          31,
          48,
          63,
          50,
          37,
          56,
          62,
          53,
          37,
          36,
          47,
          51,
          57,
          59,
          46,
          38,
          39,
          42,
          38,
          47,
          40,
          42,
          57,
          45,
          48,
          66,
          53,
          58,
          49,
          42,
          47,
          51,
          44,
          55,
          48,
          57,
          37,
          42,
          52,
          41,
          48,
          52,
          52,
          48,
          71,
          43,
          41,
          60,
          75,
          40,
          67,
          66,
          68,
          54,
          52,
          45,
          29,
          54,
          59,
          53,
          64,
          53,
          41,
          52,
          57,
          51,
          54,
          51,
          47,
          57,
          51,
          68,
          46,
          41,
          68,
          33,
          45,
          29,
          64,
          58,
          42,
          48,
          36,
          37,
          51,
          67,
          46,
          56,
          66,
          55,
          55,
          53,
          52,
          39,
          49,
          39,
          34,
          40,
          60,
          28,
          58,
          59,
          41,
          63,
          42,
          45,
          53,
          57,
          74,
          41,
          42,
          24,
          65,
          56,
          49,
          60,
          71,
          55,
          47,
          58,
          58,
          55,
          39,
          70,
          69,
          43,
          49,
          48,
          56,
          47,
          41,
          56,
          33,
          60,
          48,
          66,
          70,
          52,
          56,
          37,
          38,
          58,
          49,
          79,
          54,
          67,
          61,
          42,
          44,
          48,
          47,
          65,
          37,
          36,
          48,
          42,
          38,
          46,
          74,
          53,
          64,
          70,
          33,
          39,
          53,
          58,
          58,
          57,
          34,
          40,
          53,
          39,
          46,
          46,
          43,
          68,
          41,
          38,
          46,
          58,
          35,
          60,
          63,
          41,
          49,
          47,
          59,
          45,
          50,
          39,
          66,
          47,
          59,
          80,
          59,
          77,
          33,
          42,
          43,
          37,
          56,
          69,
          46,
          69,
          38,
          64,
          56,
          48,
          56,
          57,
          83,
          36,
          71,
          56,
          48,
          29,
          73,
          38,
          67,
          35,
          47,
          53,
          32,
          47,
          56,
          50,
          50,
          69,
          42,
          39,
          61,
          56,
          44,
          45,
          43,
          54,
          42,
          41,
          53,
          55,
          43,
          47,
          35,
          38,
          46,
          56,
          55,
          40,
          60,
          49,
          63,
          65,
          40,
          36,
          45,
          46,
          61,
          68,
          47,
          47,
          48,
          37,
          45,
          38,
          39,
          56,
          77,
          53,
          34,
          44,
          52,
          45,
          49,
          68,
          39,
          46,
          49,
          64,
          51,
          43,
          28,
          52,
          61,
          37,
          56,
          74,
          70,
          51,
          37,
          53,
          63,
          61,
          44,
          63,
          42,
          48,
          51,
          55,
          57,
          59,
          73,
          49,
          69,
          66,
          42,
          58,
          49,
          63,
          82,
          45,
          51,
          60,
          78,
          37,
          45,
          66,
          37,
          67,
          38,
          47,
          47,
          22,
          44,
          50,
          35,
          67,
          56,
          44,
          61,
          41,
          45,
          64,
          50,
          57,
          53,
          45,
          62,
          41,
          51,
          31,
          42,
          47,
          71,
          47,
          63,
          65,
          43,
          79,
          66,
          45,
          48,
          39,
          66,
          60,
          39,
          73,
          42,
          48,
          46,
          54,
          52,
          52,
          38,
          55,
          50,
          59,
          71,
          54,
          47,
          32,
          54,
          37,
          50,
          56,
          22,
          36,
          41,
          53,
          41,
          44,
          40,
          54,
          40,
          47,
          83,
          36,
          47,
          43,
          41,
          54,
          55,
          49,
          35,
          47,
          37,
          58,
          36,
          47,
          59,
          64,
          55,
          30,
          50,
          40,
          55,
          57,
          80,
          62,
          34,
          56,
          67,
          35,
          55,
          58,
          37,
          68,
          57,
          66,
          47,
          51,
          41,
          37,
          35,
          55,
          44,
          47,
          51,
          54,
          61,
          33,
          60,
          55,
          46,
          34,
          41,
          60,
          39,
          38,
          36,
          45,
          53,
          39,
          48,
          58,
          62,
          55,
          56,
          29,
          35,
          77,
          71,
          57,
          57,
          53,
          43,
          59,
          60,
          34,
          51,
          48,
          50,
          49,
          57,
          66,
          60,
          66,
          44,
          39,
          53,
          32,
          51,
          52,
          71,
          47,
          39,
          57,
          49,
          46,
          57,
          43,
          53,
          38,
          47,
          44,
          45,
          60,
          47,
          45,
          50,
          39,
          52,
          35,
          52,
          54,
          66,
          30,
          38,
          39,
          52,
          52,
          43,
          49,
          58,
          39,
          59,
          60,
          63,
          38,
          61,
          70,
          45,
          44,
          52,
          58,
          45,
          40,
          75,
          44,
          37,
          53,
          54,
          58,
          52,
          58,
          34,
          56,
          60,
          68,
          68,
          60,
          43,
          44,
          75,
          50,
          45,
          60,
          51,
          64,
          45,
          62,
          55,
          71,
          38,
          72,
          67,
          55,
          56,
          52,
          38,
          43,
          48,
          69,
          37,
          63,
          71,
          44,
          67,
          48,
          61,
          44,
          62,
          68,
          36,
          62,
          44,
          60,
          62,
          75,
          33,
          56,
          40,
          46,
          43,
          64,
          51,
          63,
          59,
          41,
          40,
          47,
          45,
          41,
          53,
          58,
          40,
          69,
          46,
          65,
          48,
          41,
          42,
          71,
          65,
          56,
          33,
          68,
          47,
          43,
          53,
          56,
          60,
          54,
          49,
          38,
          38,
          44,
          28,
          54,
          39,
          48,
          50,
          41,
          33,
          50,
          41,
          45,
          52,
          45,
          47,
          38,
          51,
          56,
          44,
          48,
          46,
          60,
          41,
          40,
          59,
          61,
          52,
          53,
          65,
          35,
          62,
          46,
          42,
          44,
          63,
          40,
          36,
          52,
          32,
          79,
          48,
          49,
          37,
          52,
          43,
          50,
          41,
          49,
          42,
          45,
          55,
          71,
          61,
          54,
          43,
          65,
          45,
          40,
          38,
          53,
          62,
          58,
          64,
          62,
          52,
          32,
          35,
          39,
          50,
          51,
          50,
          49,
          51,
          50,
          53,
          44,
          54,
          54,
          54,
          53,
          53,
          63,
          39,
          50,
          56,
          42,
          58,
          44,
          59,
          54,
          41,
          63,
          52,
          63,
          50,
          36,
          42,
          57,
          47,
          71,
          56,
          62,
          77,
          72,
          64,
          58,
          71,
          42,
          46,
          40,
          63,
          76,
          41,
          49,
          51,
          44,
          44,
          62,
          40,
          60,
          44,
          53,
          22,
          55,
          67,
          60,
          51,
          46,
          55,
          52,
          81,
          55,
          74,
          54,
          76,
          41,
          33,
          67,
          40,
          46,
          53,
          59,
          63,
          60,
          55,
          48,
          65,
          52,
          43,
          67,
          53,
          44,
          48,
          31,
          54,
          42,
          52,
          45,
          37,
          36,
          70,
          49,
          45,
          46,
          46,
          53,
          55,
          46,
          63,
          35,
          36,
          61,
          50,
          48,
          80,
          34,
          47,
          65,
          31,
          61,
          58,
          40,
          49,
          46,
          67,
          47,
          77,
          40,
          43,
          58,
          56,
          53,
          56,
          59,
          71,
          73,
          54,
          54,
          46,
          69,
          45,
          31,
          39,
          51,
          37,
          61,
          50,
          60,
          34,
          41,
          57,
          63,
          35,
          74,
          64,
          35,
          54,
          36,
          49,
          39,
          47,
          47,
          46,
          43,
          48,
          72,
          57,
          28,
          47,
          53,
          66,
          67,
          64,
          60,
          59,
          66,
          65,
          68,
          51,
          52,
          44,
          43,
          53,
          53,
          45,
          62,
          72,
          47,
          48,
          49,
          51,
          67,
          37,
          50,
          46,
          41,
          45,
          68,
          42,
          31,
          55,
          37,
          42,
          46,
          32,
          50,
          43,
          25,
          42,
          41,
          44,
          39,
          49,
          58,
          35,
          45,
          64,
          61,
          42,
          52,
          69,
          44,
          58,
          51,
          55,
          70,
          59,
          39,
          46,
          68,
          49,
          42,
          46,
          47,
          57,
          46,
          67,
          39,
          35,
          46,
          64,
          60,
          48,
          41,
          41,
          57,
          61,
          45,
          30,
          52,
          28,
          50,
          61,
          31,
          34,
          41,
          68,
          43,
          42,
          45,
          57,
          40,
          65,
          53,
          41,
          66,
          57,
          25,
          43,
          51,
          58,
          52,
          44,
          58,
          65,
          34,
          48,
          62,
          41,
          75,
          39,
          51,
          45,
          64,
          73,
          56,
          77,
          68,
          62,
          48,
          48,
          45,
          32,
          48,
          56,
          51,
          48,
          48,
          41,
          53,
          48,
          64,
          49,
          58,
          70,
          62,
          44,
          52,
          53,
          40,
          46,
          58,
          50,
          53,
          57,
          49,
          55,
          42,
          59,
          27,
          40,
          69,
          38,
          38,
          70,
          57,
          54,
          66,
          49,
          53,
          38,
          45,
          48,
          63,
          55,
          45,
          56,
          52,
          66,
          45,
          48,
          41,
          51,
          45,
          48,
          52,
          48,
          54,
          35,
          41,
          59,
          53,
          59,
          43,
          66,
          52,
          42,
          56,
          57,
          47,
          76,
          58,
          35,
          40,
          32,
          63,
          48,
          32,
          69,
          41,
          59,
          54,
          43,
          69,
          60,
          54,
          57,
          53,
          39,
          43,
          56,
          50,
          31,
          28,
          53,
          43,
          48,
          44,
          58,
          52,
          62,
          44,
          53,
          38,
          39,
          37,
          68,
          66,
          70,
          49,
          35,
          49,
          44,
          41,
          57,
          41,
          35,
          43,
          65,
          61,
          48,
          38,
          42,
          50,
          57,
          63,
          64,
          70,
          57,
          55,
          34,
          37,
          54,
          39,
          55,
          53,
          38,
          37,
          50,
          70,
          34,
          40,
          46,
          45,
          61,
          69,
          44,
          54,
          58,
          60,
          50,
          42,
          63,
          47,
          49,
          43,
          48,
          45,
          66,
          34,
          48,
          55,
          50,
          36,
          44,
          54,
          45,
          58,
          55,
          63,
          39,
          52,
          44,
          58,
          42,
          59,
          32,
          53,
          58,
          49,
          62,
          48,
          31,
          67,
          44,
          29,
          70,
          36,
          49,
          43,
          62,
          64,
          56,
          29,
          72,
          47,
          60,
          42,
          56,
          42,
          52,
          59,
          45,
          55,
          65,
          69,
          43,
          56,
          44,
          59,
          69,
          57,
          30,
          41,
          41,
          50,
          45,
          62,
          60,
          48,
          66,
          48,
          58,
          37,
          62,
          34,
          32,
          48,
          74,
          35,
          61,
          56,
          41,
          65,
          70,
          64,
          62,
          53,
          63,
          57,
          59,
          59,
          52,
          49,
          72,
          40,
          61,
          52,
          62,
          46,
          46,
          55,
          68,
          43,
          71,
          51,
          52,
          41,
          64,
          58,
          63,
          47,
          50,
          69,
          43,
          65,
          52,
          54,
          47,
          53,
          47,
          38,
          75,
          47,
          46,
          54,
          42,
          50,
          61,
          40,
          64,
          50,
          62,
          62,
          49,
          68,
          37,
          45,
          33,
          51,
          47,
          42,
          76,
          65,
          40,
          32,
          47,
          63,
          46,
          38,
          43,
          63,
          55,
          56,
          36,
          45,
          42,
          60,
          36,
          36,
          46,
          63,
          48,
          50,
          44,
          61,
          51,
          42,
          44,
          35,
          47,
          62,
          55,
          32,
          60,
          48,
          43,
          41,
          60,
          46,
          36,
          46,
          52,
          44,
          51,
          49,
          68,
          47,
          48,
          60,
          70,
          50,
          54,
          54,
          56,
          55,
          44,
          49,
          21,
          66,
          62,
          62,
          60,
          46,
          45,
          48,
          55,
          49,
          61,
          41,
          48,
          61,
          53,
          49,
          41,
          33,
          52,
          49,
          56,
          39,
          48,
          69,
          36,
          69,
          48,
          69,
          67,
          42,
          45,
          60,
          38,
          52,
          67,
          38,
          50,
          52,
          24,
          36,
          41,
          45,
          47,
          73,
          60,
          44,
          66,
          54,
          44,
          25,
          50,
          37,
          69,
          58,
          37,
          42,
          71,
          61,
          65,
          52,
          65,
          54,
          61,
          55,
          32,
          57,
          56,
          44,
          47,
          56,
          37,
          31,
          29,
          45,
          44,
          53,
          34,
          40,
          63,
          52,
          59,
          51,
          69,
          46,
          57,
          27,
          66,
          51,
          38,
          54,
          45,
          68,
          52,
          41,
          67,
          52,
          42,
          44,
          58,
          63,
          35,
          47,
          54,
          44,
          44,
          49,
          47,
          50,
          45,
          39,
          42,
          43,
          54,
          40,
          47,
          59,
          60,
          52,
          61,
          46,
          53,
          45,
          80,
          32,
          53,
          75,
          44,
          62,
          50,
          44,
          46,
          66,
          49,
          57,
          57,
          56,
          64,
          53,
          58,
          54,
          46,
          37,
          33,
          67,
          55,
          44,
          66,
          54,
          55,
          59,
          68,
          49,
          49,
          64,
          40,
          61,
          70,
          57,
          73,
          46,
          48,
          63,
          49,
          57,
          59,
          50,
          39,
          50,
          50,
          50,
          44,
          48,
          45,
          36,
          39,
          56,
          51,
          47,
          40,
          72,
          54,
          30,
          45,
          60,
          44,
          39,
          67,
          68,
          55,
          55,
          42,
          47,
          74,
          57,
          59,
          39,
          41,
          61,
          28,
          79,
          68,
          34,
          37,
          37,
          36,
          60,
          44,
          49,
          28,
          38,
          43,
          68,
          50,
          48,
          44,
          37,
          40,
          61,
          41,
          70,
          53,
          59,
          53,
          46,
          80,
          45,
          59,
          41,
          38,
          50,
          48,
          60,
          45,
          65,
          66,
          62,
          68,
          54,
          45,
          70,
          66,
          57,
          50,
          51,
          36,
          68,
          51,
          64,
          44,
          50,
          43,
          51,
          50,
          75,
          31,
          58,
          57,
          57,
          47,
          68,
          38,
          65,
          42,
          54,
          55,
          45,
          42,
          33,
          61,
          48,
          45,
          36,
          57,
          63,
          64,
          38,
          37,
          46,
          28,
          51,
          68,
          79,
          51,
          43,
          63,
          44,
          55,
          38,
          36,
          58,
          39,
          59,
          47,
          49,
          70,
          51,
          57,
          44,
          55,
          52,
          53,
          70,
          53,
          60,
          56,
          45,
          64,
          66,
          38,
          38,
          57,
          55,
          51,
          72,
          70,
          54,
          55,
          38,
          66,
          38,
          66,
          43,
          46,
          40,
          50,
          38,
          52,
          60,
          54,
          62,
          72,
          84,
          44,
          66,
          41,
          47,
          44,
          67,
          36,
          48,
          62,
          30,
          42,
          51,
          44,
          45,
          72,
          62,
          57,
          47,
          60,
          54,
          43,
          36,
          37,
          38,
          49,
          55,
          64,
          66,
          46,
          49,
          36,
          45,
          30,
          52,
          53,
          64,
          67,
          61,
          54,
          45,
          61,
          56,
          35,
          38,
          30,
          49,
          38,
          42,
          42,
          55,
          53,
          36,
          58,
          29,
          42,
          47,
          41,
          39,
          49,
          35,
          45,
          73,
          39,
          53,
          38,
          38,
          44,
          61,
          41,
          58,
          39,
          50,
          44,
          56,
          64,
          37,
          66,
          53,
          54,
          53,
          73,
          33,
          57,
          49,
          47,
          56,
          32,
          61,
          52,
          43,
          65,
          39,
          68,
          48,
          44,
          50,
          43,
          61,
          56,
          49,
          39,
          36,
          45,
          45,
          53,
          40,
          45,
          32,
          61,
          30,
          47,
          67,
          46,
          30,
          47,
          55,
          39,
          44,
          71,
          45,
          51,
          56,
          40,
          51,
          46,
          55,
          76,
          56,
          58,
          74,
          56,
          56,
          27,
          44,
          54,
          62,
          55,
          65,
          49,
          39,
          56,
          62,
          66,
          53,
          51,
          42,
          42,
          51,
          70,
          46,
          42,
          58,
          55,
          39,
          59,
          58,
          53,
          47,
          34,
          43,
          72,
          79,
          34,
          46,
          58,
          71,
          65,
          49,
          70,
          59,
          39,
          38,
          43,
          37,
          61,
          39,
          38,
          73,
          63,
          46,
          41,
          51,
          59,
          50,
          59,
          80,
          48,
          67,
          42,
          64,
          35,
          46,
          51,
          60,
          45,
          58,
          52,
          29,
          63,
          43,
          72,
          29,
          57,
          57,
          29,
          46,
          29,
          48,
          52,
          61,
          58,
          42,
          55,
          59,
          49,
          77,
          39,
          70,
          56,
          24,
          64,
          37,
          49,
          65,
          57,
          51,
          49,
          57,
          51,
          60,
          66,
          41,
          55,
          75,
          38,
          44,
          51,
          25,
          58,
          44,
          63,
          44,
          29,
          35,
          38,
          54,
          70,
          54,
          48,
          43,
          52,
          58,
          61,
          45,
          65,
          49,
          36,
          55,
          54,
          68,
          36,
          34,
          62,
          48,
          60,
          44,
          49,
          63,
          61,
          52,
          47,
          57,
          72,
          68,
          42,
          52,
          61,
          47,
          44,
          41,
          49,
          57,
          46,
          76,
          55,
          43,
          46,
          44,
          45,
          45,
          46,
          60,
          67,
          34,
          38,
          44,
          57,
          65,
          50,
          40,
          66,
          27,
          64,
          45,
          58,
          78,
          57,
          77,
          60,
          68,
          46,
          53,
          40,
          48,
          62,
          54,
          36,
          40,
          69,
          36,
          49,
          48,
          28,
          68,
          41,
          35,
          70,
          46,
          50,
          77,
          60,
          47,
          69,
          67,
          60,
          46,
          39,
          41,
          42,
          53,
          46,
          47,
          37,
          49,
          52,
          43,
          73,
          63,
          42,
          54,
          58,
          66,
          60,
          90,
          42,
          65,
          45,
          48,
          40,
          43,
          61,
          43,
          48,
          36,
          54,
          45,
          54,
          68,
          56,
          51,
          35,
          46,
          71,
          64,
          49,
          43,
          60,
          66,
          64,
          56,
          56,
          70,
          40,
          41,
          54,
          51,
          43,
          66,
          58,
          48,
          36,
          49,
          50,
          51,
          30,
          46,
          52,
          68,
          34,
          77,
          58,
          50,
          49,
          49,
          64,
          52,
          41,
          56,
          48,
          58,
          51,
          63,
          50,
          54,
          61,
          39,
          63,
          37,
          46,
          49,
          53,
          57,
          69,
          45,
          71,
          48,
          43,
          43,
          41,
          35,
          53,
          49,
          52,
          38,
          53,
          55,
          55,
          48,
          47,
          71,
          37,
          59,
          51,
          40,
          36,
          54,
          58,
          59,
          45,
          38,
          45,
          69,
          57,
          42,
          55,
          38,
          60,
          37,
          53,
          46,
          51,
          57,
          49,
          40,
          64,
          45,
          43,
          49,
          42,
          61,
          74,
          60,
          29,
          67,
          69,
          41,
          59,
          51,
          46,
          49,
          55,
          55,
          33,
          65,
          58,
          39,
          64,
          67,
          53,
          45,
          49,
          49,
          51,
          51,
          54,
          49,
          53,
          45,
          50,
          37,
          51,
          67,
          56,
          52,
          36,
          65,
          30,
          69,
          33,
          55,
          50,
          63,
          54,
          50,
          48,
          38,
          74,
          57,
          58,
          61,
          55,
          55,
          56,
          73,
          55,
          40,
          54,
          61,
          33,
          50,
          48,
          48,
          41,
          35,
          68,
          42,
          49,
          50,
          63,
          56,
          55,
          41,
          37,
          47,
          50,
          64,
          44,
          41,
          47,
          39,
          41,
          41,
          75,
          37,
          58,
          30,
          36,
          60,
          49,
          52,
          35,
          54,
          38,
          49,
          51,
          60,
          54,
          39,
          41,
          36,
          39,
          47,
          33,
          62,
          73,
          49,
          48,
          36,
          50,
          62,
          46,
          44,
          48,
          42,
          61,
          55,
          71,
          34,
          40,
          41,
          39,
          54,
          50,
          43,
          56,
          43,
          38,
          50,
          28,
          57,
          58,
          72,
          47,
          87,
          62,
          52,
          67,
          50,
          54,
          51,
          53,
          56,
          54,
          55,
          41,
          65,
          37,
          46,
          37,
          60,
          60,
          42,
          47,
          49,
          49,
          66,
          41,
          59,
          58,
          44,
          46,
          53,
          43,
          32,
          33,
          40,
          50,
          48,
          53,
          54,
          53,
          57,
          36,
          71,
          52,
          43,
          29,
          61,
          35,
          49,
          48,
          55,
          70,
          43,
          42,
          47,
          59,
          44,
          57,
          36,
          34,
          53,
          73,
          45,
          59,
          43,
          68,
          45,
          64,
          59,
          57,
          57,
          67,
          60,
          65,
          59,
          52,
          47,
          71,
          60,
          68,
          67,
          55,
          38,
          55,
          63,
          40,
          46,
          49,
          45,
          41,
          71,
          72,
          41,
          64,
          32,
          51,
          48,
          57,
          39,
          49,
          81,
          57,
          64,
          46,
          62,
          42,
          40,
          45,
          65,
          59,
          55,
          53,
          67,
          48,
          41,
          59,
          57,
          69,
          64,
          49,
          64,
          37,
          49,
          40,
          41,
          58,
          56,
          54,
          37,
          42,
          63,
          54,
          55,
          50,
          55,
          52,
          31,
          44,
          71,
          40,
          42,
          52,
          62,
          31,
          58,
          43,
          58,
          68,
          38,
          43,
          57,
          71,
          36,
          46,
          42,
          63,
          50,
          38,
          48,
          63,
          63,
          55,
          60,
          63,
          52,
          55,
          48,
          42,
          61,
          36,
          60,
          69,
          46,
          51,
          56,
          42,
          54,
          60,
          62,
          59,
          42,
          67,
          55,
          31,
          44,
          52,
          29,
          38,
          57,
          47,
          39,
          63,
          64,
          63,
          49,
          64,
          81,
          55,
          46,
          41,
          60,
          50,
          58,
          47,
          58,
          58,
          42,
          39,
          53,
          61,
          52,
          31,
          40,
          45,
          64,
          58,
          61,
          62,
          42,
          35,
          70,
          38,
          42,
          44,
          53,
          36,
          42,
          57,
          65,
          47,
          49,
          41,
          52,
          57,
          62,
          67,
          60,
          53,
          59,
          52,
          50,
          67,
          62,
          66,
          48,
          39,
          40,
          41,
          63,
          36,
          59,
          58,
          48,
          38,
          48,
          60,
          50,
          37,
          62,
          63,
          50,
          56,
          44,
          43,
          66,
          65,
          49,
          34,
          42,
          54,
          62,
          59,
          69,
          57,
          70,
          56,
          46,
          31,
          70,
          49,
          56,
          60,
          55,
          52,
          61,
          69,
          44,
          49,
          47,
          36,
          51,
          42,
          42,
          34,
          48,
          48,
          51,
          72,
          71,
          69,
          50,
          65,
          48,
          66,
          36,
          45,
          43,
          75,
          53,
          50,
          55,
          50,
          51,
          49,
          64,
          23,
          48,
          75,
          47,
          62,
          33,
          56,
          53,
          38,
          63,
          64,
          63,
          64,
          45,
          47,
          76,
          69,
          50,
          44,
          45,
          53,
          43,
          62,
          61,
          41,
          43,
          62,
          58,
          42,
          48,
          50,
          64,
          78,
          52,
          44,
          61,
          63,
          42,
          45,
          62,
          62,
          55,
          47,
          58,
          61,
          50,
          46,
          63,
          40,
          62,
          74,
          35,
          67,
          48,
          61,
          36,
          65,
          56,
          44,
          60,
          73,
          68,
          62,
          38,
          28,
          64,
          34,
          48,
          42,
          50,
          53,
          60,
          56,
          57,
          48,
          38,
          59,
          67,
          59,
          62,
          64,
          50,
          40,
          71,
          69,
          63,
          53,
          44,
          45,
          59,
          54,
          51,
          51,
          59,
          74,
          38,
          48,
          35,
          64,
          58,
          54,
          44,
          46,
          29,
          58,
          69,
          64,
          63,
          76,
          53,
          45,
          50,
          64,
          39,
          65,
          50,
          52,
          54,
          58,
          40,
          63,
          60,
          70,
          59,
          61,
          48,
          60,
          50,
          46,
          60,
          48,
          61,
          61,
          55,
          33,
          58,
          63,
          44,
          44,
          58,
          70,
          46,
          37,
          57,
          56,
          39,
          53,
          63,
          41,
          48,
          50,
          61,
          48,
          64,
          46,
          35,
          36,
          35,
          69,
          43,
          44,
          48,
          48,
          54,
          43,
          46,
          51,
          40,
          61,
          47,
          44,
          66,
          45,
          56,
          52,
          58,
          50,
          47,
          55,
          45,
          54,
          29,
          39,
          58,
          45,
          74,
          53,
          53,
          66,
          46,
          65,
          76,
          48,
          49,
          60,
          47,
          53,
          41,
          53,
          35,
          57,
          43,
          49,
          66,
          45,
          47,
          58,
          37,
          83,
          47,
          45,
          58,
          57,
          63,
          52,
          61,
          55,
          52,
          44,
          63,
          55,
          59,
          39,
          75,
          42,
          65,
          66,
          48,
          49,
          70,
          66,
          34,
          58,
          56,
          49,
          50,
          65,
          62,
          47,
          85,
          61,
          62,
          72,
          55,
          61,
          46,
          46,
          75,
          63,
          59,
          69,
          61,
          57,
          49,
          61,
          53,
          49,
          32,
          52,
          42,
          46,
          78,
          60,
          61,
          41,
          52,
          40,
          63,
          66,
          51,
          57,
          63,
          51,
          27,
          31,
          37,
          35,
          66,
          71,
          31,
          52,
          41,
          54,
          39,
          43,
          43,
          57,
          36,
          51,
          44,
          41,
          74,
          42,
          48,
          50,
          44,
          56,
          52,
          61,
          47,
          61,
          41,
          39,
          75,
          37,
          54,
          47,
          76,
          43,
          49,
          45,
          62,
          41,
          60,
          77,
          56,
          63,
          68,
          36,
          49,
          47,
          71,
          68,
          43,
          51,
          47,
          46,
          46,
          45,
          42,
          41,
          51,
          48,
          42,
          35,
          39,
          49,
          65,
          46,
          50,
          52,
          51,
          66,
          58,
          45,
          55,
          44,
          72,
          57,
          45,
          60,
          42,
          57,
          44,
          50,
          50,
          39,
          57,
          61,
          58,
          77,
          37,
          68,
          67,
          62,
          62,
          47,
          52,
          47,
          40,
          41,
          41,
          59,
          31,
          60,
          52,
          66,
          52,
          55,
          60,
          31,
          60,
          68,
          27,
          39,
          60,
          61,
          70,
          42,
          56,
          46,
          57,
          57,
          65,
          29,
          53,
          59,
          53,
          51,
          46,
          64,
          55,
          54,
          43,
          49,
          68,
          57,
          44,
          49,
          51,
          53,
          53,
          55,
          41,
          32,
          49,
          58,
          61,
          57,
          65,
          66,
          59,
          49,
          47,
          57,
          64,
          38,
          64,
          70,
          37,
          49,
          59,
          63,
          55,
          50,
          79,
          65,
          50,
          62,
          64,
          53,
          46,
          40,
          53,
          55,
          37,
          39,
          57,
          30,
          44,
          55,
          42,
          51,
          35,
          53,
          66,
          47,
          74,
          54,
          47,
          48,
          45,
          44,
          75,
          58,
          43,
          34,
          69,
          62,
          49,
          41,
          52,
          36,
          65,
          46,
          77,
          68,
          60,
          47,
          44,
          58,
          46,
          49,
          61,
          86,
          41,
          53,
          59,
          61,
          47,
          78,
          31,
          45,
          56,
          54,
          66,
          33,
          51,
          54,
          44,
          51,
          50,
          61,
          50,
          45,
          47,
          42,
          36,
          48,
          46,
          38,
          70,
          62,
          50,
          59,
          30,
          43,
          76,
          53,
          76,
          50,
          63,
          40,
          45,
          39,
          42,
          54,
          49,
          55,
          51,
          70,
          47,
          83,
          62,
          36,
          59,
          59,
          59,
          46,
          55,
          56,
          40,
          59,
          53,
          36,
          50,
          57,
          50,
          53,
          62,
          41,
          73,
          57,
          49,
          38,
          48
         ],
         "xaxis": "x",
         "y": [
          40.7,
          37.2,
          24.700000000000003,
          31,
          42.900000000000006,
          23,
          28.90000000000001,
          41.1,
          32,
          41.5,
          42.1,
          31.3,
          39.8,
          34.599999999999994,
          43,
          10.700000000000005,
          32.900000000000006,
          40.7,
          26.8,
          36.2,
          20.8,
          25.8,
          41.5,
          39.1,
          22.90000000000001,
          20.5,
          35.900000000000006,
          41,
          25.40000000000001,
          39.900000000000006,
          19,
          18.700000000000003,
          44.6,
          32.900000000000006,
          28.700000000000003,
          23.3,
          28.599999999999994,
          30.3,
          31.90000000000001,
          46.900000000000006,
          35.900000000000006,
          36.5,
          39.3,
          27.40000000000001,
          24.700000000000003,
          20.700000000000003,
          35.099999999999994,
          25.200000000000003,
          34.5,
          35.400000000000006,
          16.799999999999997,
          37.2,
          17.599999999999994,
          34.900000000000006,
          25.40000000000001,
          20.40000000000001,
          34.099999999999994,
          44.6,
          30.8,
          29.8,
          25.8,
          39.1,
          44.400000000000006,
          24.3,
          20,
          22.5,
          32.3,
          6.400000000000006,
          30.599999999999994,
          37.3,
          23.700000000000003,
          40.1,
          19.099999999999994,
          42.5,
          36.8,
          19.40000000000001,
          36.5,
          23,
          26.200000000000003,
          45.8,
          22.8,
          31.5,
          39.1,
          35.5,
          42.1,
          34.8,
          40,
          27.700000000000003,
          35.7,
          14.099999999999994,
          40.2,
          36.5,
          34.5,
          36.5,
          22.099999999999994,
          21.200000000000003,
          24.90000000000001,
          41.5,
          35.7,
          32.900000000000006,
          22.90000000000001,
          24.200000000000003,
          41.3,
          34.3,
          33.400000000000006,
          34.5,
          32.2,
          39.8,
          37.6,
          41.6,
          20.099999999999994,
          30,
          23,
          37.400000000000006,
          13.099999999999994,
          29.599999999999994,
          36.3,
          32.400000000000006,
          37.8,
          40,
          42.8,
          33.099999999999994,
          33.5,
          50,
          35.099999999999994,
          34.2,
          39,
          30.5,
          34.900000000000006,
          40.6,
          38.8,
          34.400000000000006,
          27.90000000000001,
          31.90000000000001,
          14.700000000000005,
          37.900000000000006,
          30.40000000000001,
          16.599999999999994,
          16.799999999999997,
          36.1,
          40.1,
          43,
          21.700000000000003,
          37.400000000000006,
          34.400000000000006,
          40.5,
          34.900000000000006,
          39.1,
          24.8,
          37.1,
          44.2,
          22.099999999999994,
          44.3,
          16.700000000000003,
          33.3,
          31.700000000000003,
          19.599999999999994,
          24.40000000000001,
          31.3,
          37.8,
          24.90000000000001,
          34.400000000000006,
          39.6,
          34.400000000000006,
          17.799999999999997,
          43.400000000000006,
          8.799999999999997,
          24,
          32.599999999999994,
          43.400000000000006,
          37.9,
          28.3,
          32.5,
          36.900000000000006,
          23.3,
          15.799999999999995,
          42.2,
          32.900000000000006,
          36.400000000000006,
          33.2,
          15.900000000000006,
          45.5,
          38.400000000000006,
          18.90000000000001,
          36.900000000000006,
          41.2,
          40,
          26.8,
          36.5,
          28.90000000000001,
          41.8,
          12.099999999999994,
          42.6,
          40.5,
          38.1,
          41.1,
          38.8,
          38.1,
          27.90000000000001,
          24.200000000000003,
          40.900000000000006,
          35.099999999999994,
          40.400000000000006,
          33.900000000000006,
          44.6,
          13.799999999999995,
          24,
          41.400000000000006,
          27.40000000000001,
          28.099999999999994,
          36.6,
          32.400000000000006,
          33.8,
          41,
          39.2,
          37.3,
          44.3,
          34.7,
          37.6,
          30,
          35.599999999999994,
          34,
          40.5,
          40.5,
          27.200000000000003,
          22.599999999999994,
          35.2,
          16.700000000000003,
          24.599999999999994,
          41,
          48.3,
          31.599999999999994,
          31.90000000000001,
          40.1,
          20.700000000000003,
          26.099999999999994,
          21.3,
          22.700000000000003,
          24.40000000000001,
          40.1,
          35.8,
          22.5,
          38.1,
          34.7,
          33.099999999999994,
          40.2,
          17.599999999999994,
          33,
          37,
          33.099999999999994,
          21.700000000000003,
          33.599999999999994,
          36.5,
          32.2,
          39.1,
          32.5,
          32.099999999999994,
          38.3,
          22.8,
          23.5,
          38.5,
          35.7,
          15.799999999999995,
          38.7,
          33.400000000000006,
          22.700000000000003,
          38,
          26.5,
          38.7,
          40.1,
          40.5,
          36.5,
          35.2,
          36.8,
          35.7,
          40.900000000000006,
          34.7,
          33.400000000000006,
          39.3,
          23.599999999999994,
          41.5,
          38.8,
          37.1,
          45,
          38.8,
          23.5,
          35.400000000000006,
          39.5,
          20.599999999999994,
          35.2,
          35.5,
          38.900000000000006,
          42.5,
          21.5,
          36.7,
          39.3,
          41.1,
          38.6,
          42.8,
          23.599999999999994,
          35.2,
          29.90000000000001,
          41.1,
          41.7,
          22.90000000000001,
          34.099999999999994,
          38.7,
          11.5,
          36.8,
          36.1,
          33.400000000000006,
          21.700000000000003,
          43.8,
          43.2,
          44.8,
          32.400000000000006,
          38.400000000000006,
          36.6,
          38.8,
          35.599999999999994,
          34,
          16.099999999999994,
          26,
          38.7,
          45,
          25.099999999999994,
          42.2,
          29.3,
          40.6,
          42.1,
          22.599999999999994,
          29.3,
          33.8,
          9.5,
          28.599999999999994,
          40.1,
          36.900000000000006,
          43.400000000000006,
          22.599999999999994,
          38.900000000000006,
          35.099999999999994,
          14.799999999999995,
          32.8,
          24.40000000000001,
          42.900000000000006,
          21.8,
          19.599999999999994,
          27.200000000000003,
          34,
          22.5,
          29.5,
          19.599999999999994,
          36.400000000000006,
          14.799999999999995,
          39.3,
          12.799999999999995,
          38,
          37.1,
          37.2,
          24.200000000000003,
          24.90000000000001,
          31.700000000000003,
          36.400000000000006,
          34.400000000000006,
          40.6,
          39,
          24.200000000000003,
          22.599999999999994,
          16.5,
          30.700000000000003,
          38.1,
          36.400000000000006,
          24.599999999999994,
          42,
          39.3,
          36.6,
          37.6,
          28.099999999999994,
          39.3,
          37.8,
          41.1,
          42.400000000000006,
          38.5,
          29.599999999999994,
          26.5,
          38.900000000000006,
          38.1,
          36.3,
          19.90000000000001,
          33.099999999999994,
          37.5,
          21.5,
          37.8,
          38.2,
          18.40000000000001,
          18.40000000000001,
          37.900000000000006,
          26.200000000000003,
          36,
          22.200000000000003,
          39.400000000000006,
          27.90000000000001,
          28.40000000000001,
          34.900000000000006,
          35.3,
          37.900000000000006,
          18.3,
          40.400000000000006,
          24.599999999999994,
          20.599999999999994,
          36.6,
          47.3,
          39.1,
          36.400000000000006,
          35.099999999999994,
          25.3,
          25.40000000000001,
          32.099999999999994,
          20.5,
          38.3,
          38.6,
          28.8,
          12.900000000000006,
          36.3,
          21.200000000000003,
          37.7,
          24.700000000000003,
          39.6,
          42.1,
          41.400000000000006,
          35.900000000000006,
          23.90000000000001,
          40.7,
          28.200000000000003,
          41.8,
          40.7,
          45.1,
          35.5,
          39.900000000000006,
          36.8,
          34.900000000000006,
          35.400000000000006,
          25,
          38.900000000000006,
          22.8,
          36.6,
          19.40000000000001,
          42.8,
          43,
          39.8,
          37.1,
          30.200000000000003,
          42.1,
          39.400000000000006,
          49.5,
          36.1,
          37.900000000000006,
          43.6,
          32.8,
          28.8,
          31,
          22.099999999999994,
          34.2,
          27.700000000000003,
          28.90000000000001,
          34.400000000000006,
          43.2,
          39.400000000000006,
          41.8,
          38.2,
          35.900000000000006,
          42,
          44.1,
          34.599999999999994,
          26.099999999999994,
          39,
          24.90000000000001,
          38.1,
          24.5,
          36.7,
          28.599999999999994,
          39.6,
          22.5,
          37.1,
          35.5,
          39.6,
          30.099999999999994,
          35.099999999999994,
          39.2,
          32,
          37.5,
          21.599999999999994,
          23.5,
          26.200000000000003,
          33.3,
          40.6,
          38.900000000000006,
          35.099999999999994,
          40.1,
          35.599999999999994,
          33.2,
          45.7,
          27.90000000000001,
          39.400000000000006,
          36.8,
          41.2,
          30.5,
          37.1,
          21.8,
          30.599999999999994,
          37.900000000000006,
          37.6,
          23.099999999999994,
          28.599999999999994,
          20.40000000000001,
          39.3,
          17.400000000000006,
          29.3,
          33.400000000000006,
          42.2,
          32.2,
          39.3,
          39.7,
          39.8,
          19.099999999999994,
          23.8,
          41.1,
          37.7,
          38.8,
          23.700000000000003,
          26.8,
          40.1,
          27.700000000000003,
          25.5,
          20.099999999999994,
          39.8,
          23.40000000000001,
          20.599999999999994,
          38.1,
          20,
          28.5,
          37,
          17.200000000000003,
          40.400000000000006,
          37.400000000000006,
          35.400000000000006,
          20.8,
          37.900000000000006,
          40.900000000000006,
          7.799999999999997,
          32,
          26.200000000000003,
          37.900000000000006,
          30.8,
          42.2,
          27.40000000000001,
          35.8,
          41.900000000000006,
          39,
          23.599999999999994,
          37.400000000000006,
          40.1,
          39.6,
          21.3,
          38.6,
          38,
          36,
          33.2,
          37.8,
          40.400000000000006,
          43.2,
          16.200000000000003,
          20.200000000000003,
          35.2,
          19.3,
          30.5,
          40.900000000000006,
          43.5,
          27.5,
          39.400000000000006,
          37.2,
          28.099999999999994,
          43.2,
          40.5,
          38.2,
          39.7,
          33.099999999999994,
          45.6,
          12.900000000000006,
          20.200000000000003,
          20.099999999999994,
          36,
          22.8,
          29.5,
          48.2,
          22.40000000000001,
          37.1,
          34.8,
          36.1,
          35.7,
          36.6,
          34.599999999999994,
          40.1,
          36.1,
          33.900000000000006,
          39.2,
          37.2,
          38.6,
          37.8,
          38,
          36.3,
          38.8,
          33.7,
          18.90000000000001,
          29.200000000000003,
          42.400000000000006,
          25.3,
          23.90000000000001,
          33.400000000000006,
          41.400000000000006,
          30.40000000000001,
          37.400000000000006,
          38.8,
          33.400000000000006,
          41.5,
          34.2,
          44.5,
          34.2,
          39.5,
          39.7,
          47.2,
          33.3,
          37.3,
          36.7,
          25,
          36.3,
          35.3,
          33.7,
          27.700000000000003,
          39.3,
          38,
          28.3,
          34.7,
          37.6,
          23.700000000000003,
          12,
          38.900000000000006,
          14.299999999999995,
          16.299999999999997,
          40.2,
          17.700000000000003,
          40.400000000000006,
          41.6,
          16,
          40.1,
          33.2,
          15.599999999999994,
          41.7,
          35.2,
          47.8,
          36.3,
          31.3,
          33.5,
          26.200000000000003,
          36.7,
          33,
          41.2,
          34.099999999999994,
          44.8,
          37.6,
          38.7,
          22.700000000000003,
          31.8,
          12.400000000000006,
          25,
          28.90000000000001,
          27.099999999999994,
          39.7,
          36.5,
          42,
          43,
          35.8,
          36.2,
          43.900000000000006,
          24,
          27.3,
          28.099999999999994,
          28.700000000000003,
          24.700000000000003,
          31.90000000000001,
          43.1,
          39.7,
          33.7,
          42,
          44.5,
          20.099999999999994,
          36.900000000000006,
          34.400000000000006,
          41.1,
          35.7,
          24.200000000000003,
          42.3,
          39.400000000000006,
          47.5,
          38.2,
          26.3,
          37.2,
          30.599999999999994,
          22.8,
          26.3,
          28.8,
          33.099999999999994,
          30,
          36.8,
          36.3,
          18,
          38.2,
          36.400000000000006,
          35.599999999999994,
          43.5,
          23.200000000000003,
          34.7,
          40,
          39.400000000000006,
          32.5,
          20.5,
          40.8,
          20.90000000000001,
          28.5,
          25.5,
          19.700000000000003,
          40.6,
          40.2,
          23.200000000000003,
          35.900000000000006,
          41.5,
          41.5,
          37,
          39,
          34.8,
          38.9,
          35.099999999999994,
          43.8,
          14.599999999999994,
          4.5,
          35.900000000000006,
          37.7,
          25.40000000000001,
          33,
          38.5,
          34.099999999999994,
          41.7,
          22.700000000000003,
          20.5,
          26.8,
          28.5,
          36.5,
          35.3,
          25.3,
          23.90000000000001,
          42.2,
          37.1,
          27.90000000000001,
          36.7,
          37.8,
          15.700000000000005,
          35.2,
          37.2,
          27.099999999999994,
          40.1,
          41.8,
          16.700000000000003,
          26,
          25.700000000000003,
          34.3,
          19.40000000000001,
          35.599999999999994,
          38.6,
          44.3,
          22.5,
          38.900000000000006,
          37.8,
          23,
          34.900000000000006,
          37.1,
          26.3,
          28.700000000000003,
          23.099999999999994,
          27.40000000000001,
          33.900000000000006,
          36.8,
          16.099999999999994,
          41,
          36.3,
          37.8,
          39.400000000000006,
          38.1,
          39.6,
          38.400000000000006,
          30.40000000000001,
          27.8,
          31.599999999999994,
          34.599999999999994,
          41.3,
          22.099999999999994,
          38.8,
          36.2,
          37.7,
          35.599999999999994,
          21.40000000000001,
          29.8,
          25,
          35.400000000000006,
          14.299999999999995,
          36.7,
          37.900000000000006,
          31.3,
          43.6,
          39.5,
          36.900000000000006,
          25.599999999999994,
          35,
          11.099999999999994,
          18.599999999999994,
          12.200000000000005,
          33.7,
          18.200000000000003,
          38.6,
          41.400000000000006,
          31,
          39.5,
          41.400000000000006,
          39.3,
          35.900000000000006,
          35.7,
          32.7,
          32.599999999999994,
          22.90000000000001,
          33.2,
          35.8,
          22.099999999999994,
          19.200000000000003,
          41.1,
          39,
          32.599999999999994,
          20.5,
          41.7,
          43.900000000000006,
          21.599999999999994,
          41.3,
          13.700000000000005,
          38,
          36,
          28.700000000000003,
          40.7,
          15.700000000000005,
          38.2,
          42.2,
          36.8,
          27,
          35.8,
          36.6,
          17.799999999999997,
          26,
          24.40000000000001,
          30.599999999999994,
          23.90000000000001,
          40.6,
          16.200000000000003,
          30,
          39.3,
          36.2,
          42,
          23.5,
          37.400000000000006,
          23.3,
          40.6,
          37,
          24.099999999999994,
          30.90000000000001,
          40.8,
          22.90000000000001,
          23.90000000000001,
          24.200000000000003,
          44.1,
          38.900000000000006,
          46.7,
          42.7,
          12.099999999999994,
          32.2,
          37.2,
          36.900000000000006,
          38.8,
          31.3,
          25.3,
          34.099999999999994,
          35.599999999999994,
          37.8,
          30.5,
          13.900000000000006,
          31.5,
          25,
          25,
          21,
          46.3,
          20.5,
          37.900000000000006,
          31.599999999999994,
          10.400000000000006,
          40.8,
          35.3,
          24.40000000000001,
          40.7,
          26.3,
          24.3,
          39.3,
          41.6,
          34.5,
          21,
          31.700000000000003,
          17.799999999999997,
          17.400000000000006,
          39,
          20,
          37.5,
          38.3,
          32.400000000000006,
          36.3,
          41,
          42,
          36.5,
          37,
          36.6,
          36.1,
          32.2,
          18.90000000000001,
          33.599999999999994,
          43.6,
          40.900000000000006,
          35.599999999999994,
          39,
          38.3,
          36.400000000000006,
          37.6,
          38,
          38,
          39.1,
          26.3,
          38.6,
          38.7,
          10.299999999999995,
          22.40000000000001,
          35.099999999999994,
          18,
          35,
          42.7,
          27.700000000000003,
          42.8,
          15,
          36.8,
          42.400000000000006,
          34.7,
          36.2,
          38.900000000000006,
          38.8,
          14.599999999999994,
          36.3,
          37.1,
          17.200000000000003,
          32.2,
          31.200000000000003,
          18.40000000000001,
          37,
          41.7,
          37.8,
          23.200000000000003,
          22.099999999999994,
          39.3,
          37.400000000000006,
          32.5,
          34.3,
          15.599999999999994,
          26.8,
          40.900000000000006,
          18.5,
          44.1,
          29.5,
          22.90000000000001,
          35.599999999999994,
          41.2,
          39.1,
          41,
          25.700000000000003,
          38.900000000000006,
          37.1,
          22.90000000000001,
          16.700000000000003,
          39.7,
          44.7,
          33.900000000000006,
          35.2,
          18.3,
          33.400000000000006,
          37.2,
          24.099999999999994,
          43.2,
          38,
          29.3,
          29.40000000000001,
          34.900000000000006,
          43.400000000000006,
          23.40000000000001,
          34.599999999999994,
          26.40000000000001,
          44.900000000000006,
          38.5,
          31.8,
          22.599999999999994,
          37.2,
          33,
          22.3,
          16.200000000000003,
          37.6,
          36.7,
          31.200000000000003,
          35.7,
          13.299999999999995,
          35,
          21.200000000000003,
          37.2,
          38,
          37.5,
          28.90000000000001,
          38.2,
          30.40000000000001,
          30.8,
          38.6,
          40.1,
          41.900000000000006,
          43.2,
          38.6,
          32.900000000000006,
          37.6,
          30.8,
          36,
          42.6,
          23.8,
          40.5,
          40.2,
          31.599999999999994,
          30.099999999999994,
          36.5,
          24.8,
          37.6,
          47.7,
          41.3,
          32.5,
          22.5,
          40.8,
          31.700000000000003,
          37,
          33.099999999999994,
          33.7,
          42,
          36.1,
          22.5,
          31.200000000000003,
          41.3,
          40.8,
          14,
          33.8,
          38.1,
          29,
          36.5,
          16,
          28.40000000000001,
          40.5,
          41.1,
          38.8,
          34.7,
          29.40000000000001,
          33.900000000000006,
          27.5,
          38.2,
          32.400000000000006,
          42.5,
          37.900000000000006,
          30.3,
          35.3,
          37.2,
          32.8,
          37.900000000000006,
          15.299999999999995,
          20.599999999999994,
          33.8,
          36.400000000000006,
          20.5,
          21.200000000000003,
          31.200000000000003,
          18.599999999999994,
          28.90000000000001,
          37.2,
          38.5,
          36.400000000000006,
          37.8,
          25.40000000000001,
          35.7,
          41.6,
          39.8,
          22.8,
          39.2,
          37.3,
          42.7,
          36.4,
          43.400000000000006,
          38.6,
          14.700000000000005,
          25.200000000000003,
          29.200000000000003,
          19.90000000000001,
          25.40000000000001,
          20.099999999999994,
          35.7,
          11.599999999999994,
          36.6,
          39.8,
          36.3,
          19.40000000000001,
          36.5,
          18.200000000000003,
          44.900000000000006,
          42.3,
          38.1,
          31.700000000000003,
          19.3,
          35,
          40.1,
          29.200000000000003,
          31.200000000000003,
          38.2,
          39.6,
          35.099999999999994,
          32.3,
          43.7,
          43.5,
          34.7,
          39.400000000000006,
          35.5,
          37.400000000000006,
          35.900000000000006,
          34.599999999999994,
          41.8,
          23.200000000000003,
          12.700000000000005,
          20.200000000000003,
          33.2,
          39.6,
          37.2,
          38.6,
          40,
          36.8,
          22.90000000000001,
          41.1,
          24.200000000000003,
          40.1,
          34.599999999999994,
          37.400000000000006,
          41.3,
          17.5,
          36.400000000000006,
          39.2,
          37.3,
          15.900000000000006,
          24.90000000000001,
          38.900000000000006,
          36.900000000000006,
          38.2,
          13.200000000000005,
          30.90000000000001,
          23.40000000000001,
          34.2,
          38.1,
          32.8,
          38.2,
          34.400000000000006,
          40.400000000000006,
          36.900000000000006,
          46.5,
          38.5,
          31.40000000000001,
          34.900000000000006,
          26.200000000000003,
          31,
          39.2,
          39.400000000000006,
          27.3,
          23.5,
          38.400000000000006,
          24.5,
          21,
          28.3,
          31.8,
          38.900000000000006,
          10.900000000000006,
          37.400000000000006,
          19.200000000000003,
          41.6,
          40.8,
          29.40000000000001,
          30.5,
          39.1,
          19.700000000000003,
          42.7,
          35.400000000000006,
          34.900000000000006,
          24.40000000000001,
          22.700000000000003,
          42.7,
          41.3,
          36.2,
          0,
          33.3,
          21.5,
          34.3,
          33.2,
          35,
          38.2,
          38.8,
          35.8,
          37,
          39.3,
          28,
          37.7,
          37.8,
          21.099999999999994,
          37.1,
          42.6,
          41.3,
          35.5,
          28.599999999999994,
          38.2,
          28.8,
          25,
          11.400000000000006,
          19.3,
          19,
          21.5,
          35.099999999999994,
          38.7,
          39.8,
          42.3,
          14.900000000000006,
          14.099999999999994,
          42.1,
          38.2,
          36.2,
          25.599999999999994,
          33.900000000000006,
          17.900000000000006,
          11.400000000000006,
          43.8,
          35.2,
          37.900000000000006,
          18.099999999999994,
          34.099999999999994,
          33.400000000000006,
          42,
          38.7,
          28.8,
          31.8,
          39.1,
          42.2,
          38.1,
          34.599999999999994,
          23.599999999999994,
          33.099999999999994,
          35.2,
          42.900000000000006,
          39.6,
          32.8,
          17.700000000000003,
          35.7,
          33.3,
          23,
          36.400000000000006,
          28.40000000000001,
          36.8,
          37.8,
          37,
          25.200000000000003,
          24.5,
          38.5,
          38.900000000000006,
          39.400000000000006,
          33.400000000000006,
          34.3,
          13.700000000000005,
          32.3,
          37.3,
          38.8,
          17.200000000000003,
          22,
          24.599999999999994,
          16.700000000000003,
          34.2,
          33.2,
          22.5,
          18.5,
          22.5,
          35.5,
          13.799999999999995,
          19.099999999999994,
          41.400000000000006,
          38.400000000000006,
          21,
          27.5,
          39,
          38.400000000000006,
          34.7,
          34.8,
          35.8,
          30.700000000000003,
          39.3,
          32.900000000000006,
          36.400000000000006,
          40.1,
          33.2,
          45.6,
          37.3,
          33.900000000000006,
          29.5,
          37.7,
          23,
          11.099999999999994,
          35.5,
          29.40000000000001,
          39.2,
          37.900000000000006,
          39.2,
          26.8,
          36,
          19.700000000000003,
          29.90000000000001,
          20.200000000000003,
          36.900000000000006,
          39.1,
          36.900000000000006,
          35.599999999999994,
          17.200000000000003,
          37.8,
          19.200000000000003,
          17.900000000000006,
          25.099999999999994,
          27.099999999999994,
          34.3,
          30.5,
          37.8,
          39.900000000000006,
          32.3,
          37,
          33.400000000000006,
          21.200000000000003,
          30.700000000000003,
          36.6,
          41.2,
          41.6,
          41.3,
          26.40000000000001,
          38.7,
          35.8,
          38.6,
          24.3,
          41.2,
          37.1,
          20.200000000000003,
          36.7,
          32.8,
          32,
          36.2,
          32.599999999999994,
          23.90000000000001,
          23.3,
          24.5,
          33.900000000000006,
          43.2,
          17.599999999999994,
          40.400000000000006,
          35.400000000000006,
          28.200000000000003,
          38.5,
          36.7,
          25.200000000000003,
          26.3,
          16.299999999999997,
          22.200000000000003,
          38.400000000000006,
          36.6,
          24.099999999999994,
          36.2,
          26.90000000000001,
          17.799999999999997,
          28.599999999999994,
          40.5,
          23.200000000000003,
          45,
          15.799999999999995,
          43.900000000000006,
          15.200000000000005,
          43.1,
          37.7,
          36,
          27.200000000000003,
          41.6,
          35.099999999999994,
          30.90000000000001,
          35.599999999999994,
          17.700000000000003,
          32.3,
          35.900000000000006,
          37,
          41.6,
          23.099999999999994,
          38.2,
          38.1,
          38.5,
          30,
          28.099999999999994,
          37.1,
          30.200000000000003,
          34.5,
          35.599999999999994,
          22,
          29.700000000000003,
          38.2,
          39.3,
          40.7,
          34.8,
          18.90000000000001,
          19.5,
          39,
          27,
          40.1,
          17.599999999999994,
          26.40000000000001,
          36.900000000000006,
          30.5,
          32.2,
          28.40000000000001,
          26.3,
          35,
          32.400000000000006,
          40.2,
          37.400000000000006,
          46.7,
          42.900000000000006,
          38,
          22.90000000000001,
          39.2,
          37,
          35.099999999999994,
          36.7,
          29.90000000000001,
          34,
          37.8,
          37.400000000000006,
          35.5,
          23,
          29.3,
          36.6,
          43.1,
          40.3,
          41.1,
          42.5,
          37.5,
          40.1,
          36.3,
          37.8,
          34.900000000000006,
          19.599999999999994,
          33.5,
          20.700000000000003,
          18.599999999999994,
          39.8,
          38.3,
          32.2,
          41.1,
          41.1,
          30.5,
          40.8,
          31,
          42.400000000000006,
          26.099999999999994,
          28.90000000000001,
          39.8,
          15.400000000000006,
          35.5,
          35.599999999999994,
          45.6,
          25.5,
          13.400000000000006,
          34.3,
          39.7,
          31.099999999999994,
          36.8,
          40,
          40.8,
          31.5,
          15.5,
          38.3,
          25,
          16.799999999999997,
          19.90000000000001,
          40.900000000000006,
          32.8,
          23.099999999999994,
          39,
          33.900000000000006,
          23.599999999999994,
          27.40000000000001,
          28.8,
          40.5,
          30,
          14.400000000000006,
          41.5,
          24.700000000000003,
          30.700000000000003,
          35.400000000000006,
          38.8,
          43.2,
          26.8,
          43.400000000000006,
          20.40000000000001,
          34.599999999999994,
          14.5,
          38.8,
          35.3,
          41.3,
          37.5,
          26.8,
          41.8,
          24.700000000000003,
          42.1,
          34.5,
          30.200000000000003,
          18.3,
          41.6,
          41,
          24.099999999999994,
          41.8,
          38.400000000000006,
          17.900000000000006,
          33.3,
          23.40000000000001,
          34.7,
          41.900000000000006,
          13.5,
          36.900000000000006,
          31.599999999999994,
          31.8,
          22.099999999999994,
          38.3,
          38.3,
          35.3,
          40.1,
          23.599999999999994,
          15.599999999999994,
          26.5,
          42.7,
          40,
          19.8,
          40.5,
          35.400000000000006,
          37.6,
          33.400000000000006,
          38,
          13.700000000000005,
          7.799999999999997,
          42.400000000000006,
          39.400000000000006,
          34.099999999999994,
          36.2,
          40.1,
          40.900000000000006,
          19.3,
          37.400000000000006,
          42.3,
          23.90000000000001,
          27.40000000000001,
          41.5,
          44.8,
          40.5,
          40.8,
          17.400000000000006,
          39.8,
          35,
          42,
          38.5,
          25.700000000000003,
          25.700000000000003,
          19.90000000000001,
          21.8,
          17.700000000000003,
          17.400000000000006,
          36.900000000000006,
          30.700000000000003,
          36.400000000000006,
          34.099999999999994,
          27.200000000000003,
          36.900000000000006,
          30.099999999999994,
          31.200000000000003,
          36.6,
          42.1,
          32.599999999999994,
          36.3,
          38.7,
          37.4,
          35.8,
          33.5,
          39.3,
          34.099999999999994,
          27.700000000000003,
          9.599999999999994,
          33,
          30.599999999999994,
          21.5,
          25,
          40.3,
          41,
          37.900000000000006,
          20.3,
          29.90000000000001,
          39.6,
          24.5,
          37.8,
          33.400000000000006,
          44.1,
          37.1,
          29.200000000000003,
          35.099999999999994,
          38.6,
          21.099999999999994,
          36.1,
          37.400000000000006,
          42.3,
          36.5,
          37.6,
          26.700000000000003,
          17.299999999999997,
          21.40000000000001,
          34,
          44,
          36.3,
          30.599999999999994,
          44.7,
          43.5,
          20.099999999999994,
          22,
          29.8,
          24.3,
          35.7,
          34.3,
          42.8,
          39.6,
          27.3,
          19.8,
          35.8,
          37.7,
          31.099999999999994,
          23.5,
          20.599999999999994,
          24,
          39.6,
          22.099999999999994,
          29.700000000000003,
          37.6,
          37.3,
          39.900000000000006,
          31.200000000000003,
          24.40000000000001,
          41.6,
          36.6,
          34.5,
          21.40000000000001,
          36,
          35.5,
          42.6,
          39.6,
          39.400000000000006,
          39.2,
          38.8,
          24.40000000000001,
          13.900000000000006,
          23.099999999999994,
          22.200000000000003,
          37.6,
          35.900000000000006,
          41.7,
          26.8,
          35.599999999999994,
          35.900000000000006,
          38.8,
          39.6,
          40.3,
          36.900000000000006,
          36.7,
          23.8,
          31.8,
          34.8,
          37.3,
          42.1,
          24.40000000000001,
          34.900000000000006,
          40.5,
          26.90000000000001,
          43.3,
          33.599999999999994,
          22,
          37.8,
          25.90000000000001,
          21.099999999999994,
          22.200000000000003,
          38.400000000000006,
          33.900000000000006,
          30.099999999999994,
          24.200000000000003,
          36.7,
          40,
          23.599999999999994,
          33.8,
          38.900000000000006,
          17.700000000000003,
          37.7,
          36.400000000000006,
          33.099999999999994,
          21.599999999999994,
          30,
          37.8,
          25.5,
          34.400000000000006,
          25.8,
          42,
          36.6,
          20.5,
          37.2,
          25.8,
          39.1,
          33,
          40.2,
          31.40000000000001,
          43.2,
          23.5,
          19.3,
          16.299999999999997,
          21.90000000000001,
          25,
          29.5,
          36.6,
          43,
          37.2,
          39,
          16.200000000000003,
          38.2,
          34.3,
          17,
          44.5,
          33.599999999999994,
          25.5,
          34.8,
          25.40000000000001,
          19.8,
          29,
          35.5,
          37.7,
          42.3,
          42.3,
          25.90000000000001,
          30.3,
          30.8,
          9.900000000000006,
          34,
          44,
          35.099999999999994,
          37.8,
          31.3,
          21.700000000000003,
          38.6,
          34.3,
          30,
          21.099999999999994,
          38.8,
          20.8,
          21.40000000000001,
          21.3,
          37.6,
          41.400000000000006,
          34.2,
          46.400000000000006,
          39.900000000000006,
          43.900000000000006,
          33.2,
          38.5,
          37.6,
          20.8,
          20.3,
          37.400000000000006,
          41.2,
          41.6,
          35.599999999999994,
          37.400000000000006,
          36.7,
          38.900000000000006,
          38.5,
          31.099999999999994,
          38.5,
          20.200000000000003,
          33.3,
          41.1,
          33.7,
          33.3,
          41.3,
          38.900000000000006,
          6.5,
          31.599999999999994,
          40.400000000000006,
          23.3,
          43.6,
          27.3,
          26,
          34.3,
          39.5,
          38.3,
          42.6,
          40.5,
          30.700000000000003,
          38,
          37.6,
          40.2,
          29.099999999999994,
          41,
          25.90000000000001,
          34.400000000000006,
          17.5,
          38.2,
          39.8,
          31.90000000000001,
          39.6,
          29.90000000000001,
          34.099999999999994,
          39.3,
          40.2,
          36.1,
          28.700000000000003,
          34,
          42.3,
          11,
          40,
          41.1,
          24.599999999999994,
          37.5,
          34.099999999999994,
          35.900000000000006,
          39.7,
          11.599999999999994,
          26.200000000000003,
          38.400000000000006,
          21.3,
          37.2,
          27.599999999999994,
          29.90000000000001,
          38.5,
          39,
          39.400000000000006,
          19.40000000000001,
          36.5,
          36.5,
          28,
          37.8,
          38.400000000000006,
          40.5,
          41.8,
          44.900000000000006,
          31.5,
          39.2,
          26.099999999999994,
          37.5,
          36,
          35.099999999999994,
          41,
          36,
          23,
          34,
          38,
          36.8,
          42,
          39.6,
          20.599999999999994,
          26.3,
          37.900000000000006,
          29.40000000000001,
          27,
          13.200000000000005,
          40.1,
          39.1,
          40,
          35.900000000000006,
          22.3,
          28,
          34.099999999999994,
          38.5,
          38,
          32.900000000000006,
          44.400000000000006,
          36.2,
          39.3,
          40.8,
          29.40000000000001,
          37.3,
          38.8,
          17.599999999999994,
          28.8,
          29.3,
          35.599999999999994,
          41.8,
          41,
          33.7,
          35.2,
          33.5,
          22.5,
          25.599999999999994,
          42.400000000000006,
          39.6,
          38,
          45.2,
          37,
          38.2,
          34.099999999999994,
          26.5,
          26.700000000000003,
          39.8,
          37.900000000000006,
          15,
          17.299999999999997,
          39.7,
          9.200000000000005,
          15.099999999999994,
          24.3,
          34,
          35.3,
          37.400000000000006,
          43,
          32.099999999999994,
          20.599999999999994,
          36.8,
          17.700000000000003,
          33,
          40.8,
          36.5,
          24.3,
          36,
          28,
          36.400000000000006,
          40.5,
          32.900000000000006,
          36.900000000000006,
          20,
          37.2,
          39.7,
          19.700000000000003,
          39.1,
          35.7,
          43.3,
          20.8,
          29.099999999999994,
          37.5,
          39.6,
          45.3,
          38.6,
          35.8,
          21.3,
          38.7,
          26.200000000000003,
          34.3,
          24.40000000000001,
          32.099999999999994,
          34.5,
          24.40000000000001,
          40.1,
          39,
          39.5,
          39.7,
          39.1,
          32,
          44.7,
          34.2,
          34.3,
          38.7,
          20.8,
          41.5,
          35.5,
          33.400000000000006,
          36.2,
          29.200000000000003,
          37.3,
          36.8,
          45.400000000000006,
          18,
          35.900000000000006,
          34.5,
          30.599999999999994,
          25.700000000000003,
          24.90000000000001,
          35,
          34,
          34.400000000000006,
          33.3,
          43.3,
          28.099999999999994,
          17.900000000000006,
          39.5,
          34.099999999999994,
          37.1,
          25.3,
          36.8,
          39.5,
          33.5,
          44.7,
          21.3,
          39.5,
          27.200000000000003,
          17.200000000000003,
          35.3,
          25.8,
          43.8,
          38.3,
          38.7,
          37.900000000000006,
          23.3,
          31.8,
          22.099999999999994,
          32.599999999999994,
          38,
          34.8,
          38.400000000000006,
          37.2,
          19.8,
          42.1,
          43.8,
          38.6,
          36.6,
          39.7,
          36.2,
          21.8,
          37.2,
          25.099999999999994,
          22.8,
          43.400000000000006,
          40.8,
          33,
          34.400000000000006,
          22.40000000000001,
          27.40000000000001,
          43.1,
          40.900000000000006,
          36.900000000000006,
          40,
          34.400000000000006,
          40.400000000000006,
          38,
          15.799999999999995,
          34.7,
          40.8,
          34.599999999999994,
          28.3,
          41.2,
          27.200000000000003,
          31.200000000000003,
          34.900000000000006,
          37.900000000000006,
          38.7,
          21.3,
          35.900000000000006,
          40.1,
          39.6,
          19.200000000000003,
          36,
          35.7,
          26.099999999999994,
          34.099999999999994,
          24.200000000000003,
          40.8,
          37.7,
          40.1,
          39.5,
          34.3,
          21.3,
          39.5,
          27.099999999999994,
          42.400000000000006,
          25.099999999999994,
          22.3,
          32.3,
          31.40000000000001,
          35,
          8.599999999999994,
          39.400000000000006,
          26.8,
          33.7,
          43,
          39.7,
          24.200000000000003,
          37,
          25,
          37.8,
          39.2,
          33.099999999999994,
          37.7,
          35.099999999999994,
          22.5,
          36,
          13.599999999999994,
          12.599999999999994,
          35.7,
          42.400000000000006,
          39.4,
          35.900000000000006,
          37.3,
          38.5,
          40.3,
          33,
          35.3,
          39.6,
          27.40000000000001,
          25,
          40.400000000000006,
          37.5,
          40.400000000000006,
          37.8,
          23.5,
          31.90000000000001,
          22,
          41.7,
          19.599999999999994,
          28.90000000000001,
          20,
          35.2,
          41.3,
          40.400000000000006,
          39.7,
          35.3,
          22.5,
          20.90000000000001,
          34,
          36.8,
          26.599999999999994,
          33.3,
          38.2,
          41.3,
          41.5,
          25.3,
          32,
          35.3,
          41.1,
          37.6,
          34.7,
          38.400000000000006,
          31.40000000000001,
          36,
          37.400000000000006,
          40.8,
          33.599999999999994,
          23,
          25,
          37.3,
          42.7,
          34.8,
          34.8,
          34.400000000000006,
          21.8,
          21.5,
          24.8,
          35,
          41,
          31.099999999999994,
          32.7,
          32.8,
          37.3,
          25.099999999999994,
          37.6,
          37.6,
          34.599999999999994,
          24.200000000000003,
          25,
          19.099999999999994,
          15.700000000000005,
          35.5,
          17.799999999999997,
          20.700000000000003,
          41,
          25.40000000000001,
          36,
          19.3,
          25,
          33.900000000000006,
          12.400000000000006,
          29.200000000000003,
          16.299999999999997,
          39.3,
          39.8,
          25.90000000000001,
          40.6,
          25.8,
          36.1,
          38.7,
          29,
          46.900000000000006,
          34.5,
          38,
          38.7,
          34.900000000000006,
          21,
          39.1,
          30.700000000000003,
          39.3,
          36.400000000000006,
          21.8,
          36.5,
          45.5,
          34.599999999999994,
          36.7,
          27.3,
          35.5,
          35.900000000000006,
          41.900000000000006,
          37.900000000000006,
          38.5,
          21.700000000000003,
          39.400000000000006,
          22,
          25.5,
          35.8,
          16.200000000000003,
          24.599999999999994,
          39.7,
          37.3,
          38.3,
          26.599999999999994,
          16.200000000000003,
          35.099999999999994,
          10.5,
          40.1,
          35.599999999999994,
          41.8,
          33.7,
          37.8,
          31,
          46,
          37,
          37,
          13.799999999999995,
          30.200000000000003,
          38.7,
          38.6,
          46.400000000000006,
          21.40000000000001,
          39.7,
          34.5,
          31.099999999999994,
          41.8,
          41.3,
          40.2,
          38.2,
          41.1,
          39.7,
          35.400000000000006,
          42,
          39.7,
          40.3,
          22.3,
          38.400000000000006,
          38.1,
          39,
          39.8,
          25.5,
          36,
          35.400000000000006,
          41.6,
          37.3,
          43,
          21.90000000000001,
          42.2,
          37.5,
          33.3,
          33,
          23.099999999999994,
          41.6,
          33.400000000000006,
          37.5,
          37.400000000000006,
          45.6,
          18.3,
          25.5,
          38.7,
          32.3,
          27.3,
          39,
          38.1,
          31.099999999999994,
          41.5,
          23.90000000000001,
          39.1,
          17.400000000000006,
          35.8,
          38.7,
          39.6,
          45.7,
          41.400000000000006,
          22.40000000000001,
          43.900000000000006,
          38.8,
          21.40000000000001,
          33.5,
          17.900000000000006,
          40.900000000000006,
          35.400000000000006,
          31.099999999999994,
          36.6,
          42.5,
          36.2,
          33.5,
          40.900000000000006,
          42.2,
          40.400000000000006,
          39,
          32.7,
          33.7,
          39.1,
          21.599999999999994,
          31.3,
          27.200000000000003,
          37.1,
          41.2,
          43.8,
          17,
          9.900000000000006,
          35.099999999999994,
          35.099999999999994,
          37.7,
          42.1,
          33.3,
          24.90000000000001,
          42.6,
          31.700000000000003,
          17.099999999999994,
          39.3,
          33.3,
          29.40000000000001,
          31,
          15.799999999999995,
          23.90000000000001,
          39.1,
          38.1,
          36.6,
          45.6,
          17.700000000000003,
          35.900000000000006,
          13.200000000000005,
          22.3,
          37.8,
          27.3,
          36.9,
          36.4,
          28.700000000000003,
          42.3,
          26.3,
          40,
          37.6,
          40.900000000000006,
          38.900000000000006,
          32.599999999999994,
          36.7,
          35.599999999999994,
          35.5,
          37.900000000000006,
          35.5,
          42.8,
          36.2,
          25.700000000000003,
          24.099999999999994,
          39.3,
          40.1,
          39.3,
          24.8,
          27.40000000000001,
          35.7,
          39.900000000000006,
          30.90000000000001,
          40.8,
          30.099999999999994,
          14.799999999999995,
          19.5,
          43.7,
          33.7,
          19.3,
          32.400000000000006,
          34,
          30.599999999999994,
          33.5,
          36.1,
          36.900000000000006,
          19.90000000000001,
          40.400000000000006,
          38.2,
          35.3,
          34.3,
          33.099999999999994,
          36.3,
          31.40000000000001,
          40.400000000000006,
          37.3,
          32.5,
          25.099999999999994,
          26.700000000000003,
          33.599999999999994,
          41,
          39.3,
          15.400000000000006,
          37.400000000000006,
          39.6,
          17.099999999999994,
          37.2,
          36.1,
          28.90000000000001,
          25.099999999999994,
          38.6,
          27.5,
          41.5,
          17.799999999999997,
          20.40000000000001,
          36,
          18.8,
          32.400000000000006,
          42.1,
          37.7,
          39.1,
          7.200000000000003,
          37.2,
          28.599999999999994,
          20.3,
          37.400000000000006,
          15.299999999999995,
          34.8,
          33.599999999999994,
          36.400000000000006,
          30,
          27.5,
          37,
          25.5,
          30.200000000000003,
          23.700000000000003,
          20.099999999999994,
          20.8,
          41.5,
          34.900000000000006,
          30.40000000000001,
          37,
          41.3,
          22.200000000000003,
          35.5,
          23,
          25.8,
          37.400000000000006,
          42.1,
          36.3,
          36.6,
          44.1,
          37.5,
          33,
          39.900000000000006,
          23,
          39.6,
          32.8,
          35.400000000000006,
          37.8,
          41.8,
          19.90000000000001,
          18.700000000000003,
          36.3,
          39.2,
          20.40000000000001,
          38.900000000000006,
          39.900000000000006,
          35.5,
          33.7,
          28.3,
          36.1,
          37.3,
          45.3,
          37.900000000000006,
          35.8,
          43,
          34.099999999999994,
          41.7,
          34.7,
          39.2,
          39.7,
          43.2,
          40.6,
          40.7,
          40.5,
          29.90000000000001,
          38.7,
          36.5,
          40.6,
          24.40000000000001,
          28.8,
          40.3,
          36.400000000000006,
          37.3,
          31.5,
          37.7,
          44,
          30.3,
          36,
          33.7,
          30.599999999999994,
          21.099999999999994,
          41.6,
          36.3,
          37.6,
          40.7,
          37.3,
          23.700000000000003,
          38.5,
          41.8,
          35.099999999999994,
          47.8,
          10.200000000000005,
          34.2,
          41.1,
          41.1,
          37.7,
          38,
          34.599999999999994,
          39.900000000000006,
          38.1,
          41.900000000000006,
          38.400000000000006,
          23.700000000000003,
          20.200000000000003,
          21.5,
          31.099999999999994,
          38.6,
          33.5,
          33.3,
          40.900000000000006,
          38.7,
          34.099999999999994,
          22.200000000000003,
          27.200000000000003,
          19.8,
          33.099999999999994,
          35.900000000000006,
          40.400000000000006,
          45.900000000000006,
          39.1,
          34.7,
          23.8,
          30.3,
          35.3,
          36.6,
          40.1,
          38.8,
          36,
          25,
          36.400000000000006,
          31.5,
          24.8,
          32.900000000000006,
          20,
          43.1,
          26.700000000000003,
          29.3,
          39.2,
          26.8,
          38,
          24.3,
          39.2,
          41.900000000000006,
          29.099999999999994,
          38,
          21.8,
          35.8,
          38.5,
          35.2,
          36.2,
          33.400000000000006,
          18.099999999999994,
          35.900000000000006,
          24.3,
          18.90000000000001,
          14.900000000000006,
          29,
          20.40000000000001,
          18.5,
          39.400000000000006,
          37.2,
          40.3,
          32,
          24.099999999999994,
          40.3,
          26.8,
          29.40000000000001,
          40.400000000000006,
          37.3,
          13.299999999999995,
          38.5,
          34.5,
          42.5,
          20.8,
          45.3,
          35.099999999999994,
          29,
          35,
          24.200000000000003,
          35.8,
          30,
          35.2,
          22.40000000000001,
          37.1,
          25,
          29.3,
          19,
          35.599999999999994,
          40.900000000000006,
          35.7,
          38.900000000000006,
          39,
          29.5,
          16,
          27.5,
          20.099999999999994,
          28.5,
          28.3,
          24,
          37.3,
          40.1,
          27.099999999999994,
          37.1,
          22.8,
          39.2,
          40.8,
          31.700000000000003,
          37.6,
          27.3,
          43.2,
          40.5,
          41.1,
          17.400000000000006,
          30.8,
          37.6,
          40.7,
          37.7,
          29.90000000000001,
          37.1,
          25.3,
          28.5,
          42.400000000000006,
          41.2,
          29.5,
          38.6,
          38.8,
          12.799999999999995,
          40.2,
          33.5,
          15.5,
          44.5,
          18,
          34.5,
          38.1,
          39.1,
          36.7,
          16.799999999999997,
          43.3,
          22.90000000000001,
          39,
          36.400000000000006,
          29.90000000000001,
          16,
          36.7,
          22.8,
          13.299999999999995,
          24.200000000000003,
          22.90000000000001,
          30.90000000000001,
          34.7,
          32.400000000000006,
          17.599999999999994,
          38.2,
          45.400000000000006,
          42,
          41.5,
          39.8,
          17.5,
          33.2,
          20.700000000000003,
          40.400000000000006,
          36.400000000000006,
          33.599999999999994,
          27.5,
          37.8,
          24.5,
          23.90000000000001,
          44.400000000000006,
          38.1,
          43,
          35.099999999999994,
          38.5,
          36.400000000000006,
          40.400000000000006,
          38.5,
          38.3,
          37.8,
          16.700000000000003,
          26.40000000000001,
          44.900000000000006,
          41,
          35.3,
          23,
          24.700000000000003,
          26.5,
          20.200000000000003,
          36.900000000000006,
          30.5,
          26.3,
          26.099999999999994,
          34.900000000000006,
          34.599999999999994,
          43.2,
          42,
          37.1,
          34.7,
          41.5,
          22.90000000000001,
          17.900000000000006,
          43.2,
          38.400000000000006,
          41,
          36.8,
          13.200000000000005,
          37.900000000000006,
          36.7,
          40,
          36.3,
          39.8,
          18.8,
          39,
          39.400000000000006,
          26.5,
          39.900000000000006,
          36.5,
          41.1,
          41.3,
          21.8,
          36.6,
          43.900000000000006,
          38.900000000000006,
          37,
          39,
          39.1,
          37.6,
          32,
          43.2,
          41.1,
          28.700000000000003,
          33.099999999999994,
          39.5,
          27.599999999999994,
          17.099999999999994,
          36,
          34,
          39.1,
          33.099999999999994,
          26.099999999999994,
          20.700000000000003,
          42.1,
          40.400000000000006,
          23.8,
          38.5,
          39.2,
          38.6,
          39.2,
          33.099999999999994,
          38.400000000000006,
          39.8,
          42.900000000000006,
          40,
          37,
          24.8,
          21.200000000000003,
          36,
          39.900000000000006,
          40.3,
          37.400000000000006,
          11.900000000000006,
          39.1,
          41.400000000000006,
          38.3,
          44.3,
          38,
          26.599999999999994,
          43.900000000000006,
          37.7,
          41.8,
          35.099999999999994,
          41.400000000000006,
          37.6,
          37,
          21.90000000000001,
          38,
          26.700000000000003,
          37.900000000000006,
          36.2,
          22,
          19.700000000000003,
          45.7,
          39.8,
          30,
          27.099999999999994,
          24.40000000000001,
          28.5,
          36.6,
          24.90000000000001,
          43.900000000000006,
          32.5,
          27.8,
          37.6,
          22,
          43.5,
          23.599999999999994,
          41.2,
          21.099999999999994,
          24.099999999999994,
          32.5,
          18.599999999999994,
          35.3,
          13.700000000000005,
          37.2,
          37.6,
          37.6,
          35.8,
          39.1,
          25.90000000000001,
          41.2,
          37.6,
          38.5,
          41.6,
          33.599999999999994,
          34.7,
          29.599999999999994,
          38,
          22.90000000000001,
          16,
          23.200000000000003,
          39.8,
          35.099999999999994,
          21.099999999999994,
          39.3,
          38.6,
          33.5,
          37.6,
          22.90000000000001,
          35.7,
          37.900000000000006,
          36.8,
          36.6,
          32.900000000000006,
          44.2,
          38.2,
          26.5,
          40.400000000000006,
          44.8,
          26.40000000000001,
          32,
          24.700000000000003,
          32.400000000000006,
          40.5,
          39.4,
          38,
          28,
          40.5,
          31.599999999999994,
          35.599999999999994,
          38.7,
          32.8,
          40.5,
          24,
          36.3,
          34.8,
          41.1,
          26.5,
          39.400000000000006,
          36,
          37.1,
          40.2,
          34.3,
          41.1,
          35.5,
          23.200000000000003,
          20.8,
          27.90000000000001,
          34.8,
          9.799999999999995,
          36.3,
          43.3,
          23.40000000000001,
          35.900000000000006,
          36.2,
          17.400000000000006,
          25.3,
          42.8,
          36.8,
          41.2,
          18.40000000000001,
          37.400000000000006,
          40.1,
          8.099999999999994,
          38.3,
          35,
          35.599999999999994,
          41.900000000000006,
          16.900000000000006,
          31.3,
          35.5,
          21.5,
          28.700000000000003,
          38.5,
          41.3,
          32.5,
          33.8,
          40.6,
          40.400000000000006,
          36.3,
          38,
          38.2,
          34.2,
          36,
          29.099999999999994,
          30.90000000000001,
          38.1,
          33.099999999999994,
          39.3,
          38.6,
          38.400000000000006,
          22.3,
          20.3,
          13.299999999999995,
          35.5,
          45.900000000000006,
          33.2,
          39.900000000000006,
          42.1,
          22.8,
          37.7,
          41.6,
          37.6,
          39.5,
          22.8,
          34.8,
          40,
          39.900000000000006,
          40,
          28.700000000000003,
          19.599999999999994,
          17.599999999999994,
          21.700000000000003,
          34.7,
          30.90000000000001,
          43.5,
          40.6,
          19.5,
          40.7,
          35.400000000000006,
          35,
          40.7,
          41.3,
          35.2,
          13.299999999999995,
          38.2,
          39,
          36.1,
          37.7,
          23.099999999999994,
          26.099999999999994,
          42.1,
          20.90000000000001,
          25,
          32.599999999999994,
          34.5,
          42.5,
          34,
          36.2,
          39.3,
          24.8,
          35.8,
          41.5,
          30.8,
          42.5,
          37.3,
          29.599999999999994,
          22.90000000000001,
          39.3,
          35.2,
          36.1,
          38.1,
          30.200000000000003,
          30.200000000000003,
          14.900000000000006,
          42.2,
          26.8,
          37.2,
          36.5,
          40,
          34.3,
          38.400000000000006,
          27.40000000000001,
          33.8,
          32.099999999999994,
          22.700000000000003,
          38.400000000000006,
          42.7,
          19,
          38.3,
          43.1,
          22.099999999999994,
          41.6,
          38.900000000000006,
          38.2,
          38.3,
          17.799999999999997,
          35.7,
          39.6,
          23.40000000000001,
          37.400000000000006,
          23.700000000000003,
          37.6,
          35.3,
          36.3,
          36.4,
          24.90000000000001,
          24,
          29.8,
          20.90000000000001,
          10.799999999999995,
          41.2,
          34.900000000000006,
          35.7,
          27.200000000000003,
          30,
          30.3,
          42.8,
          39.6,
          42.1,
          38.8,
          39,
          37.9,
          36,
          38.5,
          21.5,
          39.8,
          41.6,
          42.2,
          26.3,
          40,
          42.8,
          33,
          19.90000000000001,
          45.6,
          37.7,
          30.599999999999994,
          38.2,
          27.700000000000003,
          24.8,
          20.700000000000003,
          17.400000000000006,
          30,
          25.90000000000001,
          16.299999999999997,
          17.200000000000003,
          34.400000000000006,
          36.400000000000006,
          36.2,
          18.40000000000001,
          42.3,
          32.7,
          19.3,
          30.099999999999994,
          35.3,
          37.900000000000006,
          26.599999999999994,
          28.700000000000003,
          42.400000000000006,
          13.900000000000006,
          34.7,
          22.40000000000001,
          38.8,
          18.5,
          32.400000000000006,
          27.599999999999994,
          35.7,
          32.599999999999994,
          18.5,
          38.1,
          16,
          37.6,
          37.400000000000006,
          39.1,
          23.5,
          38.1,
          39.7,
          26,
          38.1,
          28.40000000000001,
          36.5,
          41.5,
          37.3,
          22.5,
          39.7,
          15.900000000000006,
          35.5,
          17.700000000000003,
          31.200000000000003,
          34.5,
          32.7,
          44.6,
          39,
          38.6,
          26.8,
          39.8,
          44.1,
          21.200000000000003,
          13.099999999999994,
          40.6,
          41.7,
          34.8,
          16,
          40.3,
          42.5,
          40.5,
          20,
          34.7,
          36.3,
          43.5,
          39.400000000000006,
          38.1,
          27.099999999999994,
          42.2,
          39.1,
          39.8,
          18.700000000000003,
          39.8,
          34.7,
          37.5,
          23.40000000000001,
          36.3,
          42.2,
          39.1,
          39.5,
          23.8,
          29.40000000000001,
          24.90000000000001,
          45,
          28.5,
          28.099999999999994,
          36.900000000000006,
          40.400000000000006,
          26.099999999999994,
          40.400000000000006,
          43.3,
          41.5,
          29.90000000000001,
          40.6,
          40,
          35.599999999999994,
          22.40000000000001,
          36.7,
          33.3,
          34,
          24.599999999999994,
          37.1,
          27.599999999999994,
          23.8,
          17,
          31.099999999999994,
          32.900000000000006,
          41.5,
          46.3,
          27.099999999999994,
          16.200000000000003,
          30.599999999999994,
          32.900000000000006,
          40,
          38.8,
          20.099999999999994,
          12,
          37,
          32.7,
          34.900000000000006,
          24.700000000000003,
          32.599999999999994,
          36.8,
          27,
          42.1,
          40.7,
          35.900000000000006,
          37.3,
          20.40000000000001,
          29.700000000000003,
          36.8,
          19.40000000000001,
          42.400000000000006,
          27.200000000000003,
          41.5,
          23.5,
          19.599999999999994,
          38.1,
          20.5,
          20.5,
          41.5,
          32.7,
          23.5,
          40.8,
          24,
          37.1,
          48.8,
          43.3,
          39.3,
          39.3,
          36.2,
          24,
          28.90000000000001,
          39.3,
          31.200000000000003,
          34.599999999999994,
          32.3,
          43.6,
          37.5,
          37.3,
          18.8,
          33.7,
          36.2,
          39.2,
          24.90000000000001,
          25.200000000000003,
          17.299999999999997,
          20.3,
          26.8,
          40,
          15.700000000000005,
          43.1,
          42.1,
          32.5,
          21.8,
          36.400000000000006,
          38.3,
          37,
          41.1,
          44,
          43.900000000000006,
          36,
          40,
          34.5,
          40.8,
          42.6,
          28.8,
          35.5,
          32,
          35.099999999999994,
          23.5,
          37.7,
          34.900000000000006,
          46.400000000000006,
          23.200000000000003,
          31.599999999999994,
          42.3,
          34.099999999999994,
          34.7,
          21,
          37.400000000000006,
          38.900000000000006,
          39.7,
          37.3,
          33.2,
          38.3,
          36.900000000000006,
          23.5,
          38.7,
          39,
          35.8,
          39.5,
          36.7,
          34.400000000000006,
          37.900000000000006,
          30.8,
          39.3,
          39.8,
          38.6,
          40.900000000000006,
          17.299999999999997,
          36,
          37.6,
          31.099999999999994,
          31.099999999999994,
          34.900000000000006,
          16,
          41,
          31.200000000000003,
          40.7,
          8.700000000000003,
          38.7,
          41.5,
          16.700000000000003,
          41.2,
          35.900000000000006,
          38.3,
          36.900000000000006,
          37,
          32.2,
          37,
          27,
          37,
          5.599999999999994,
          26.700000000000003,
          33.7,
          30.599999999999994,
          22.8,
          41,
          44.3,
          41,
          23.700000000000003,
          23.099999999999994,
          36.1,
          26.40000000000001,
          34.900000000000006,
          35.8,
          33.400000000000006,
          25.8,
          36.900000000000006,
          39.7,
          27.90000000000001,
          41.2,
          27.40000000000001,
          13,
          26.5,
          23.8,
          38.6,
          37.7,
          31.099999999999994,
          35,
          32.7,
          26.3,
          39.6,
          38.8,
          37.6,
          38.3,
          27.200000000000003,
          37.8,
          37.8,
          19.599999999999994,
          39,
          38.1,
          29.099999999999994,
          36.7,
          37.8,
          42.7,
          17.200000000000003,
          41.6,
          43.6,
          30.90000000000001,
          31.099999999999994,
          39.400000000000006,
          39.1,
          13.599999999999994,
          12.700000000000005,
          24.200000000000003,
          28,
          39.400000000000006,
          35.900000000000006,
          13.400000000000006,
          35.3,
          30.599999999999994,
          41.5,
          41.2,
          32.900000000000006,
          43.5,
          17.799999999999997,
          17.5,
          44.3,
          41.7,
          39.8,
          42.7,
          33.3,
          40.400000000000006,
          34.8,
          43,
          40.7,
          36.1,
          33,
          35,
          34.3,
          39.1,
          36.7,
          42.2,
          26.099999999999994,
          41.900000000000006,
          20.40000000000001,
          40.8,
          14.400000000000006,
          26.200000000000003,
          35.099999999999994,
          11.900000000000006,
          38.8,
          15.200000000000005,
          38.8,
          37.5,
          37.400000000000006,
          36.7,
          18.3,
          35.900000000000006,
          31.200000000000003,
          31,
          30,
          27.599999999999994,
          36.3,
          34.7,
          25.200000000000003,
          24.90000000000001,
          39.3,
          19.599999999999994,
          33,
          42.6,
          22.200000000000003,
          24.700000000000003,
          27,
          45.5,
          37.8,
          38.1,
          37.8,
          38,
          13.599999999999994,
          43.5,
          21.40000000000001,
          19,
          32.099999999999994,
          34.400000000000006,
          34.900000000000006,
          40.7,
          26.90000000000001,
          35.900000000000006,
          31.099999999999994,
          34.2,
          33.599999999999994,
          38.1,
          39,
          13.400000000000006,
          38.900000000000006,
          39.400000000000006,
          42.3,
          14.099999999999994,
          31.3,
          33.400000000000006,
          40.7,
          41.900000000000006,
          40.7,
          39.7,
          37.7,
          35.900000000000006,
          14.400000000000006,
          31,
          39.8,
          14.900000000000006,
          38.6,
          34.8,
          36.900000000000006,
          40.8,
          15.099999999999994,
          34,
          25.3,
          34.7,
          38.900000000000006,
          18.700000000000003,
          40.2,
          19.200000000000003,
          40,
          34.8,
          37.7,
          37.6,
          19.90000000000001,
          38.3,
          24.40000000000001,
          36,
          40.400000000000006,
          29.200000000000003,
          15.200000000000005,
          40.7,
          40.8,
          32.2,
          35.099999999999994,
          28.599999999999994,
          10.5,
          26.90000000000001,
          31.90000000000001,
          24.40000000000001,
          37.8,
          20.5,
          43.7,
          31.3,
          39,
          33.900000000000006,
          42.3,
          37.3,
          37.400000000000006,
          28.200000000000003,
          23.700000000000003,
          34.599999999999994,
          31,
          22.200000000000003,
          11.900000000000006,
          38.2,
          25.8,
          41.900000000000006,
          37.8,
          37.7,
          15.299999999999995,
          40.900000000000006,
          36.6,
          23.200000000000003,
          40.1,
          39,
          38.5,
          37.900000000000006,
          39.400000000000006,
          10.099999999999994,
          17,
          27.90000000000001,
          33.5,
          37.1,
          35.3,
          37.8,
          39,
          43.400000000000006,
          39.2,
          34.900000000000006,
          35.2,
          22,
          33,
          40.3,
          39.900000000000006,
          38.2,
          37.900000000000006,
          41.5,
          34.900000000000006,
          25.099999999999994,
          33.5,
          18.200000000000003,
          28.8,
          34.599999999999994,
          39.7,
          33.099999999999994,
          34.3,
          41.900000000000006,
          39.400000000000006,
          44.2,
          24,
          40.1,
          39.1,
          38.400000000000006,
          28.700000000000003,
          34.3,
          38.900000000000006,
          24.40000000000001,
          45.3,
          38.400000000000006,
          37.7,
          36.900000000000006,
          39.1,
          41.2,
          43,
          38.1,
          22.099999999999994,
          41.400000000000006,
          33.900000000000006,
          39.3,
          41.2,
          38.5,
          20.200000000000003,
          38.6,
          33.099999999999994,
          40.5,
          36.5,
          43.1,
          34.099999999999994,
          21.40000000000001,
          40.3,
          25.099999999999994,
          24,
          36.7,
          28.90000000000001,
          33.900000000000006,
          40.900000000000006,
          19.700000000000003,
          37.2,
          28.099999999999994,
          33.2,
          42,
          33.2,
          33.400000000000006,
          41,
          19.3,
          39.6,
          29.90000000000001,
          39.3,
          44,
          35.900000000000006,
          42,
          34,
          31.8,
          36.6,
          36.1,
          41.900000000000006,
          36.1,
          36.900000000000006,
          36.5,
          44.8,
          39,
          39.400000000000006,
          32.5,
          43,
          34.7,
          17.700000000000003,
          40,
          41.5,
          38,
          24.200000000000003,
          35.8,
          37,
          18,
          39.6,
          37.7,
          36.400000000000006,
          43.6,
          36.400000000000006,
          36.8,
          31.200000000000003,
          12.599999999999994,
          35.8,
          36.8,
          23.40000000000001,
          29.3,
          29.40000000000001,
          43,
          38.5,
          34.7,
          37.9,
          23.700000000000003,
          13.900000000000006,
          37,
          39.8,
          38.5,
          29.700000000000003,
          19.599999999999994,
          37.3,
          23.40000000000001,
          39.1,
          38.7,
          37.2,
          18.40000000000001,
          28.40000000000001,
          42.8,
          19.700000000000003,
          27,
          37.1,
          25.200000000000003,
          37.400000000000006,
          37.7,
          36.5,
          41.3,
          39.6,
          27.5,
          23.3,
          42.5,
          37.6,
          29.8,
          31.90000000000001,
          25.90000000000001,
          34.7,
          25.599999999999994,
          38.1,
          43,
          43.3,
          38.400000000000006,
          40.8,
          31,
          41.3,
          36.3,
          13.799999999999995,
          23.200000000000003,
          39.7,
          35.8,
          34.2,
          32,
          31.3,
          18.90000000000001,
          19.200000000000003,
          35.7,
          25.599999999999994,
          36.6,
          24.3,
          40.8,
          24,
          35.900000000000006,
          20.3,
          40.6,
          34.099999999999994,
          33.2,
          45.2,
          29.90000000000001,
          39.900000000000006,
          22.5,
          46.1,
          18.700000000000003,
          31.90000000000001,
          43.5,
          36.900000000000006,
          41,
          33.2,
          36.2,
          23.3,
          24.8,
          37.400000000000006,
          36.6,
          25.700000000000003,
          37.7,
          17.700000000000003,
          36.1,
          32.900000000000006,
          31.5,
          45.900000000000006,
          29,
          38.7,
          32.7,
          19.200000000000003,
          23.8,
          32.599999999999994,
          38,
          34.900000000000006,
          27.40000000000001,
          30.90000000000001,
          22.3,
          40,
          33.099999999999994,
          18.90000000000001,
          38.1,
          38.1,
          36.5,
          37.8,
          32.8,
          36,
          21.5,
          36.3,
          48.5,
          47.5,
          38.900000000000006,
          36.3,
          29.5,
          26.099999999999994,
          34.599999999999994,
          39,
          23.5,
          19.200000000000003,
          28.099999999999994,
          27.8,
          32.900000000000006,
          36.5,
          40.900000000000006,
          39.2,
          36.5,
          25,
          39.8,
          43,
          29.599999999999994,
          38.8,
          20.700000000000003,
          41.8,
          28,
          23.200000000000003,
          21.200000000000003,
          37.6,
          38.900000000000006,
          33.2,
          25.5,
          23,
          24.8,
          35.8,
          23.200000000000003,
          26.099999999999994,
          38.2,
          39.7,
          37.900000000000006,
          24.099999999999994,
          38.7,
          27.8,
          25.099999999999994,
          39.3,
          36.9,
          40.400000000000006,
          39,
          39.7,
          37.8,
          21.700000000000003,
          20.5,
          42.2,
          41,
          37.8,
          36.400000000000006,
          19,
          29.599999999999994,
          36.400000000000006,
          20.90000000000001,
          42.7,
          25.099999999999994,
          39.7,
          30.90000000000001,
          15.099999999999994,
          35.400000000000006,
          12.099999999999994,
          34.900000000000006,
          26,
          34.8,
          32,
          40.900000000000006,
          35.099999999999994,
          29,
          34.7,
          41.900000000000006,
          39,
          37.5,
          42.7,
          37.8,
          34.599999999999994,
          48.2,
          16.599999999999994,
          38.400000000000006,
          42.3,
          22.200000000000003,
          35.599999999999994,
          36.7,
          12.5,
          20.5,
          36.3,
          14.900000000000006,
          29.5,
          26.40000000000001,
          39,
          26.700000000000003,
          41.400000000000006,
          39.1,
          22.5,
          35.8,
          37.7,
          39.7,
          30.099999999999994,
          36.5,
          39.2,
          16.200000000000003,
          29.8,
          31.099999999999994,
          22.099999999999994,
          37.2,
          26.200000000000003,
          31.599999999999994,
          12.700000000000005,
          42,
          18.200000000000003,
          39.1,
          38.900000000000006,
          40.400000000000006,
          42.6,
          23.3,
          37.8,
          38.6,
          44.900000000000006,
          35.400000000000006,
          35.400000000000006,
          25.8,
          28.599999999999994,
          34.7,
          27.200000000000003,
          39.8,
          34.900000000000006,
          23.3,
          30.700000000000003,
          35.900000000000006,
          40.5,
          24.90000000000001,
          33.099999999999994,
          18.700000000000003,
          27.200000000000003,
          25.40000000000001,
          21.700000000000003,
          38.8,
          30.40000000000001,
          36.900000000000006,
          39.6,
          31.700000000000003,
          13.700000000000005,
          36.2,
          33.400000000000006,
          40.7,
          39.6,
          37.6,
          38.5,
          41.3,
          31.599999999999994,
          25.700000000000003,
          34.099999999999994,
          43.6,
          16.799999999999997,
          31.099999999999994,
          32.599999999999994,
          40,
          38.8,
          21.40000000000001,
          30.8,
          42.3,
          31.8,
          36.8,
          33.5,
          38.400000000000006,
          33.400000000000006,
          38.1,
          29.8,
          30.200000000000003,
          37.2,
          22.8,
          36.5,
          37,
          36.3,
          16.299999999999997,
          31.40000000000001,
          12.599999999999994,
          35.3,
          19.599999999999994,
          38.900000000000006,
          41.2,
          39.2,
          40.7,
          39.1,
          32.5,
          39.2,
          36.2,
          39.900000000000006,
          36.8,
          34,
          21.3,
          34.5,
          36.1,
          23.5,
          41.2,
          24.599999999999994,
          37.8,
          40.3,
          39,
          22.099999999999994,
          24.8,
          19.3,
          33.599999999999994,
          40.6,
          35.099999999999994,
          24.5,
          35.2,
          38,
          33.8,
          41,
          27.700000000000003,
          39.1,
          33.7,
          36.1,
          26.599999999999994,
          28.200000000000003,
          22.5,
          38.3,
          32.5,
          38.7,
          36.8,
          40.9,
          39.8,
          25.3,
          19,
          26.200000000000003,
          42.8,
          14.799999999999995,
          20.3,
          31.200000000000003,
          32.5,
          35.2,
          42.7,
          33.2,
          35.2,
          37.8,
          40.3,
          26.8,
          33.900000000000006,
          43.400000000000006,
          34.400000000000006,
          26.700000000000003,
          35.3,
          39.2,
          34.5,
          37.400000000000006,
          36.8,
          38,
          37.400000000000006,
          38.2,
          38.1,
          39.3,
          34.5,
          42.900000000000006,
          35.099999999999994,
          17.400000000000006,
          25.599999999999994,
          32.099999999999994,
          42.5,
          25,
          40.3,
          23.90000000000001,
          41,
          32.099999999999994,
          18.700000000000003,
          27.90000000000001,
          36,
          37.2,
          39.8,
          38.7,
          28.099999999999994,
          31.599999999999994,
          30.8,
          16.900000000000006,
          35.7,
          36.400000000000006,
          34.400000000000006,
          23.700000000000003,
          23.099999999999994,
          38.6,
          37.8,
          38.3,
          43.6,
          37,
          35.099999999999994,
          37.400000000000006,
          43.2,
          38.8,
          26.40000000000001,
          39.2,
          36.6,
          35.5,
          25.099999999999994,
          36.2,
          36.900000000000006,
          41.400000000000006,
          43.2,
          41.8,
          35.599999999999994,
          25.3,
          38.5,
          37.7,
          38,
          37.8,
          38.1,
          34.599999999999994,
          13.799999999999995,
          40.400000000000006,
          16.700000000000003,
          44.2,
          40.8,
          25.599999999999994,
          35,
          35,
          39.8,
          13.400000000000006,
          40.5,
          35.099999999999994,
          33.2,
          28.8,
          33,
          40.3,
          36.8,
          36.7,
          40.3,
          38.3,
          41.1,
          22.3,
          14.200000000000005,
          20.700000000000003,
          36.7,
          39,
          36,
          12.299999999999995,
          33.900000000000006,
          41.3,
          33.900000000000006,
          34.2,
          39.6,
          35.599999999999994,
          11.099999999999994,
          38.7,
          40.400000000000006,
          41.400000000000006,
          40.7,
          26.5,
          35.5,
          36.2,
          21.90000000000001,
          38.8,
          41.3,
          36.1,
          43.8,
          31.40000000000001,
          30.8,
          12.200000000000005,
          38,
          12.200000000000005,
          27.40000000000001,
          37.400000000000006,
          26.90000000000001,
          34.8,
          37.3,
          42.7,
          33.8,
          19,
          35.400000000000006,
          33.8,
          39.900000000000006,
          19.40000000000001,
          42,
          34.099999999999994,
          41.7,
          23,
          36.900000000000006,
          27.8,
          39.7,
          34.7,
          33,
          23,
          42.5,
          36.3,
          23.8,
          43.1,
          38.1,
          35.2,
          39.900000000000006,
          38.900000000000006,
          40.5,
          39.3,
          35.3,
          38.2,
          37.7,
          23,
          36.1,
          37,
          42,
          16.400000000000006,
          34.099999999999994,
          37.8,
          43.7,
          24.40000000000001,
          42,
          38.1,
          38.3,
          26.3,
          23,
          39.900000000000006,
          39.3,
          35.900000000000006,
          27.599999999999994,
          38.7,
          31,
          42,
          44.400000000000006,
          35.599999999999994,
          19.40000000000001,
          35.5,
          28.40000000000001,
          38.6,
          25.700000000000003,
          40,
          38.6,
          24.599999999999994,
          24.200000000000003,
          33.2,
          20.099999999999994,
          31.40000000000001,
          21.3,
          28.40000000000001,
          37.1,
          37.1,
          25.3,
          27.5,
          17.400000000000006,
          25.90000000000001,
          32.7,
          36.7,
          23.200000000000003,
          29.200000000000003,
          39,
          33.099999999999994,
          38,
          39.6,
          41.1,
          28.700000000000003,
          20.3,
          40.1,
          19.599999999999994,
          45.3,
          30,
          39.1,
          20,
          40.3,
          38.400000000000006,
          30.8,
          33.7,
          23.90000000000001,
          43.6,
          24.90000000000001,
          38.400000000000006,
          40.900000000000006,
          40.1,
          26.099999999999994,
          34.8,
          15.099999999999994,
          30.599999999999994,
          30.3,
          35.7,
          39.2,
          35.400000000000006,
          28.5,
          19.3,
          22.200000000000003,
          37.2,
          20.099999999999994,
          40.3,
          35.599999999999994,
          38.1,
          40.1,
          32.5,
          11.700000000000005,
          37.7,
          39.7,
          37.2,
          14,
          27.5,
          40.3,
          28.099999999999994,
          34,
          31.200000000000003,
          41.1,
          36.900000000000006,
          22.3,
          37.3,
          39.3,
          37.5,
          32.400000000000006,
          40.7,
          33.900000000000006,
          36.5,
          25.700000000000003,
          19.099999999999994,
          40.8,
          39.7,
          33.099999999999994,
          16.5,
          39.400000000000006,
          38.6,
          35.8,
          17.400000000000006,
          33.099999999999994,
          21.90000000000001,
          41.1,
          23,
          28.90000000000001,
          40.1,
          30.8,
          34.400000000000006,
          27.90000000000001,
          36.900000000000006,
          38,
          40.400000000000006,
          24.3,
          41.900000000000006,
          31.8,
          23.599999999999994,
          37.8,
          37.6,
          34.5,
          39.8,
          36.6,
          35.400000000000006,
          27.200000000000003,
          16.700000000000003,
          36.1,
          21,
          36.8,
          47.1,
          39.7,
          36.5,
          41.2,
          40.1,
          24.8,
          43.400000000000006,
          37.6,
          20.3,
          30.90000000000001,
          22.8,
          33.2,
          28,
          19.599999999999994,
          26.90000000000001,
          41.5,
          35.900000000000006,
          25.8,
          38.5,
          29.599999999999994,
          37.5,
          32.5,
          29.099999999999994,
          36.1,
          38.400000000000006,
          35.2,
          22.40000000000001,
          34.400000000000006,
          43.6,
          36.1,
          35.400000000000006,
          17.5,
          18.599999999999994,
          29.099999999999994,
          23.8,
          35.7,
          40.3,
          15.200000000000005,
          41.5,
          38.6,
          38.3,
          37.5,
          39.1,
          42.3,
          36.900000000000006,
          15.299999999999995,
          31.8,
          37.400000000000006,
          44.8,
          35.2,
          29.40000000000001,
          16.400000000000006,
          20.099999999999994,
          13.099999999999994,
          34.099999999999994,
          33.8,
          37.6,
          34.7,
          22.599999999999994,
          24.8,
          18.8,
          25.5,
          40,
          38.7,
          42.8,
          24.700000000000003,
          40.2,
          34.2,
          30.700000000000003,
          41.5,
          41.900000000000006,
          37,
          34.400000000000006,
          31.3,
          38.6,
          31.3,
          29.099999999999994,
          33.8,
          22.700000000000003,
          39.400000000000006,
          40.1,
          14.400000000000006,
          23.90000000000001,
          33.2,
          41.5,
          36.900000000000006,
          35.400000000000006,
          33.3,
          7.099999999999994,
          17.799999999999997,
          30.599999999999994,
          28,
          23,
          38,
          41.1,
          20.5,
          31,
          32.2,
          28.599999999999994,
          30.700000000000003,
          32.5,
          27.5,
          30.099999999999994,
          40.400000000000006,
          34.2,
          41.3,
          39.5,
          38.1,
          39.1,
          38.5,
          36.7,
          36,
          38.1,
          38,
          20.3,
          26.5,
          30.90000000000001,
          40.8,
          22.90000000000001,
          23,
          22,
          45.1,
          38.6,
          38.900000000000006,
          19.599999999999994,
          34.599999999999994,
          30.5,
          33.2,
          37.5,
          21.200000000000003,
          34.3,
          19.40000000000001,
          44.2,
          40.5,
          17.099999999999994,
          38,
          35.8,
          43.2,
          39.6,
          37.1,
          43.6,
          12.900000000000006,
          24.3,
          19.700000000000003,
          24.8,
          42.2,
          38.3,
          27.40000000000001,
          25.5,
          40.3,
          33.400000000000006,
          40.8,
          26.90000000000001,
          38,
          28.8,
          32.7,
          41.1,
          32.3,
          33.599999999999994,
          28.8,
          40.7,
          33.099999999999994,
          38,
          34.599999999999994,
          19.099999999999994,
          43.7,
          38.400000000000006,
          34.400000000000006,
          24.40000000000001,
          39.400000000000006,
          38.5,
          30.40000000000001,
          30.700000000000003,
          28.200000000000003,
          37.3,
          32.2,
          38.8,
          37,
          37.900000000000006,
          34.900000000000006,
          34.7,
          19.40000000000001,
          14.900000000000006,
          38.8,
          24.099999999999994,
          37.1,
          31.700000000000003,
          38.6,
          8.900000000000006,
          32.099999999999994,
          39.7,
          30.90000000000001,
          24.40000000000001,
          29.200000000000003,
          27.099999999999994,
          40.400000000000006,
          43.2,
          29.5,
          43,
          24.700000000000003,
          33.7,
          41.6,
          35.5,
          14.5,
          34.900000000000006,
          23.599999999999994,
          36.8,
          39.1,
          36,
          21.5,
          37,
          26,
          20.200000000000003,
          35.900000000000006,
          38.6,
          13,
          20.90000000000001,
          23.3,
          33.2,
          37.8,
          42.2,
          17.799999999999997,
          32.7,
          38.8,
          35.099999999999994,
          24.40000000000001,
          12.099999999999994,
          40.7,
          31.3,
          39.900000000000006,
          26.3,
          33.8,
          34.2,
          34.8,
          37.400000000000006,
          41.400000000000006,
          15,
          16.099999999999994,
          29.8,
          21.90000000000001,
          22.3,
          31.200000000000003,
          41.5,
          31,
          24.40000000000001,
          42.3,
          19.200000000000003,
          30.5,
          23.3,
          16.400000000000006,
          32.900000000000006,
          41.900000000000006,
          24.099999999999994,
          31,
          18.40000000000001,
          20,
          26.700000000000003,
          39.400000000000006,
          18.8,
          36.5,
          39.8,
          20.90000000000001,
          41.6,
          16,
          30.40000000000001,
          36.1,
          40.2,
          23.3,
          21.3,
          37.8,
          33.400000000000006,
          20.5,
          31.3,
          35.2,
          41.6,
          25.200000000000003,
          18.700000000000003,
          40.6,
          42.3,
          17.5,
          35.599999999999994,
          35.099999999999994,
          33.599999999999994,
          38.6,
          20.8,
          14.400000000000006,
          36.1,
          39.400000000000006,
          41.2,
          43.7,
          19.40000000000001,
          36.5,
          41.1,
          39.7,
          36.2,
          26.599999999999994,
          40.7,
          24.3,
          33.099999999999994,
          36,
          27.599999999999994,
          27.8,
          38.400000000000006,
          32.599999999999994,
          41.6,
          33.8,
          36.1,
          14.599999999999994,
          38.5,
          37.5,
          37,
          36.5,
          34,
          44.5,
          45.3,
          23.099999999999994,
          39.5,
          21.8,
          30.700000000000003,
          21,
          21.8,
          40.5,
          17.400000000000006,
          19.40000000000001,
          38.2,
          39.1,
          35.900000000000006,
          37.8,
          33.599999999999994,
          40.3,
          35.599999999999994,
          40.5,
          19.5,
          36.1,
          37.5,
          30,
          35.900000000000006,
          32,
          19.099999999999994,
          42.7,
          15.299999999999995,
          38.6,
          40.400000000000006,
          32.599999999999994,
          24.40000000000001,
          32.900000000000006,
          32.7,
          35.3,
          33.7,
          31.5,
          39.1,
          28.3,
          31.40000000000001,
          27.5,
          39.6,
          14.400000000000006,
          41.2,
          30.599999999999994,
          25.599999999999994,
          34.3,
          37.900000000000006,
          18.90000000000001,
          24.5,
          41.900000000000006,
          32.8,
          31.099999999999994,
          31.8,
          38.2,
          15.799999999999995,
          30.90000000000001,
          28.3,
          24.90000000000001,
          21.200000000000003,
          29.3,
          9.099999999999994,
          25.90000000000001,
          23.200000000000003,
          35.5,
          25.8,
          14.200000000000005,
          28.8,
          19.700000000000003,
          19.8,
          28.40000000000001,
          36.900000000000006,
          26.90000000000001,
          20.599999999999994,
          28.5,
          41.3,
          44.7,
          35.8,
          41.6,
          37.6,
          10.700000000000005,
          33.400000000000006,
          26,
          41.5,
          38,
          39.2,
          33.900000000000006,
          28.700000000000003,
          35.2,
          34.3,
          19.40000000000001,
          32.400000000000006,
          42.8,
          42.3,
          40.900000000000006,
          40.2,
          22.200000000000003,
          20.200000000000003,
          43.5,
          37.8,
          42.2,
          35,
          34.8,
          39.7,
          37.2,
          33.5,
          38.400000000000006,
          35.400000000000006,
          36.6,
          38.900000000000006,
          23.8,
          22.099999999999994,
          38.2,
          33.3,
          38.900000000000006,
          24.599999999999994,
          38.2,
          28.8,
          36.5,
          34.3,
          37.5,
          39.5,
          21.40000000000001,
          37.3,
          38.7,
          38.3,
          27.5,
          37.400000000000006,
          38.4,
          39.2,
          27.700000000000003,
          38.900000000000006,
          27.90000000000001,
          34.5,
          27.8,
          12.599999999999994,
          27.40000000000001,
          37.3,
          34.900000000000006,
          37.900000000000006,
          17.299999999999997,
          24.3,
          36.7,
          28.5,
          37.1,
          37.7,
          38.8,
          33.8,
          38.8,
          40.2,
          37.7,
          37.900000000000006,
          41.3,
          39.400000000000006,
          42.7,
          28.5,
          22.200000000000003,
          39.7,
          34.3,
          25.200000000000003,
          37.400000000000006,
          24,
          24.599999999999994,
          36.900000000000006,
          32.3,
          38.3,
          23.40000000000001,
          28.200000000000003,
          36.1,
          31.599999999999994,
          34.900000000000006,
          38.3,
          41.6,
          18,
          38.6,
          41.1,
          20.90000000000001,
          29.200000000000003,
          24.599999999999994,
          18.599999999999994,
          44.1,
          27.8,
          29.5,
          33.5,
          26.200000000000003,
          38.400000000000006,
          36.400000000000006,
          34.8,
          37.7,
          38.1,
          36.900000000000006,
          26.599999999999994,
          43.7,
          25.099999999999994,
          22.3,
          18.8,
          30.5,
          22.599999999999994,
          20.3,
          43.2,
          36.2,
          2.299999999999997,
          42.1,
          41.400000000000006,
          24.90000000000001,
          21.200000000000003,
          21.599999999999994,
          38.900000000000006,
          23.599999999999994,
          39.7,
          28.5,
          24.200000000000003,
          17,
          41.2,
          35.900000000000006,
          15.200000000000005,
          38.7,
          36,
          40.3,
          26.8,
          35.2,
          35.099999999999994,
          39.3,
          23.099999999999994,
          23.700000000000003,
          35.900000000000006,
          34.3,
          34.3,
          38.5,
          27.8,
          37.1,
          32.099999999999994,
          38.7,
          36.400000000000006,
          22.700000000000003,
          18.700000000000003,
          27.8,
          32.099999999999994,
          37.3,
          23.40000000000001,
          19.90000000000001,
          37.400000000000006,
          38.900000000000006,
          27.200000000000003,
          18,
          40.5,
          31.3,
          30.200000000000003,
          37.400000000000006,
          37.5,
          37.900000000000006,
          17.700000000000003,
          35.400000000000006,
          34.599999999999994,
          14.299999999999995,
          37.4,
          36.7,
          15,
          16.299999999999997,
          36,
          37,
          49.1,
          26.700000000000003,
          26,
          43.400000000000006,
          38,
          35.2,
          45.6,
          38.7,
          25.5,
          42,
          34.8,
          39,
          31.700000000000003,
          32.599999999999994,
          38.8,
          14.200000000000005,
          35.900000000000006,
          39.7,
          39,
          38.6,
          41.1,
          22.700000000000003,
          15.200000000000005,
          40.7,
          39.6,
          32,
          21.90000000000001,
          37.6,
          38.2,
          38.1,
          39.7,
          30.3,
          41.3,
          14.400000000000006,
          31.700000000000003,
          24.5,
          35.2,
          38.7,
          41,
          32.900000000000006,
          38.8,
          19.200000000000003,
          21.700000000000003,
          39.2,
          37.400000000000006,
          24.40000000000001,
          30,
          37.900000000000006,
          21.5,
          43.1,
          42.1,
          39.6,
          30.599999999999994,
          24.40000000000001,
          43.400000000000006,
          33.2,
          34.7,
          42.400000000000006,
          36.1,
          15.099999999999994,
          21,
          38,
          35.599999999999994,
          24.40000000000001,
          36.8,
          38.900000000000006,
          37.2,
          36.2,
          43,
          20.599999999999994,
          21.200000000000003,
          39.3,
          30.40000000000001,
          42.3,
          34.3,
          23.700000000000003,
          22.5,
          33.099999999999994,
          42,
          19.3,
          43,
          38,
          38.6,
          40.400000000000006,
          34.599999999999994,
          36.3,
          35,
          35.900000000000006,
          24.700000000000003,
          38.900000000000006,
          16,
          27,
          37,
          23.8,
          16,
          25.700000000000003,
          35.3,
          26,
          29.099999999999994,
          37.2,
          21.599999999999994,
          29.200000000000003,
          41.400000000000006,
          40.5,
          23.599999999999994,
          36.6,
          25.8,
          33,
          39.900000000000006,
          3.9000000000000057,
          33.900000000000006,
          34.5,
          46.400000000000006,
          38.5
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "age"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "physical_score"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"3b0bcfbe-06bb-4706-8dae-afba33796a4f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3b0bcfbe-06bb-4706-8dae-afba33796a4f\")) {                    Plotly.newPlot(                        \"3b0bcfbe-06bb-4706-8dae-afba33796a4f\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"age=%{x}<br>physical_score=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[33.0,50.0,52.0,56.0,35.0,58.0,66.0,38.0,53.0,43.0,39.0,58.0,45.0,52.0,36.0,83.0,57.0,39.0,58.0,54.0,65.0,69.0,41.0,43.0,64.0,55.0,46.0,40.0,70.0,36.0,62.0,71.0,38.0,67.0,50.0,68.0,58.0,63.0,60.0,24.0,44.0,55.0,42.0,61.0,49.0,66.0,51.0,65.0,53.0,52.0,60.0,46.0,69.0,62.0,64.0,72.0,66.0,32.0,54.0,59.0,74.0,37.0,32.0,68.0,62.0,58.0,54.0,75.0,48.0,54.0,57.0,31.0,74.0,40.0,54.0,82.0,48.0,53.0,61.0,27.0,62.0,66.0,39.0,51.0,41.0,52.0,46.0,57.0,47.0,82.0,43.0,55.0,57.0,46.0,56.0,49.0,52.0,46.0,56.0,60.0,49.0,67.0,39.0,59.0,67.0,55.0,68.0,44.0,47.0,45.0,70.0,62.0,68.0,46.0,74.0,60.0,52.0,58.0,42.0,50.0,43.0,57.0,51.0,49.0,46.0,47.0,40.0,66.0,48.0,45.0,39.0,47.0,54.0,55.0,66.0,47.0,62.0,51.0,70.0,51.0,48.0,32.0,60.0,50.0,48.0,42.0,51.0,44.0,71.0,57.0,34.0,58.0,31.0,71.0,46.0,69.0,82.0,54.0,59.0,47.0,56.0,54.0,42.0,53.0,77.0,37.0,68.0,66.0,62.0,43.0,48.0,44.0,54.0,39.0,65.0,51.0,30.0,53.0,48.0,51.0,64.0,34.0,43.0,67.0,46.0,46.0,44.0,79.0,59.0,69.0,35.0,49.0,32.0,60.0,41.0,38.0,40.0,35.0,56.0,48.0,36.0,51.0,43.0,52.0,41.0,67.0,61.0,34.0,63.0,62.0,64.0,45.0,53.0,46.0,51.0,51.0,33.0,48.0,50.0,63.0,48.0,51.0,34.0,46.0,56.0,54.0,46.0,66.0,57.0,38.0,34.0,55.0,41.0,49.0,60.0,56.0,66.0,65.0,56.0,52.0,48.0,71.0,54.0,52.0,57.0,38.0,58.0,56.0,46.0,56.0,53.0,61.0,45.0,53.0,46.0,64.0,47.0,46.0,68.0,70.0,41.0,50.0,62.0,43.0,53.0,46.0,52.0,53.0,34.0,40.0,43.0,40.0,50.0,58.0,48.0,39.0,49.0,51.0,47.0,59.0,42.0,44.0,65.0,40.0,43.0,65.0,50.0,49.0,70.0,49.0,52.0,39.0,31.0,64.0,44.0,46.0,32.0,36.0,30.0,68.0,49.0,50.0,35.0,37.0,65.0,61.0,37.0,76.0,48.0,36.0,55.0,65.0,39.0,34.0,25.0,59.0,42.0,54.0,51.0,49.0,59.0,72.0,61.0,41.0,50.0,52.0,34.0,66.0,40.0,37.0,58.0,58.0,50.0,52.0,55.0,36.0,45.0,31.0,57.0,49.0,52.0,75.0,57.0,57.0,38.0,56.0,56.0,60.0,47.0,57.0,59.0,61.0,48.0,78.0,46.0,72.0,48.0,44.0,52.0,76.0,72.0,53.0,47.0,44.0,34.0,45.0,64.0,59.0,68.0,62.0,49.0,40.0,59.0,48.0,40.0,48.0,39.0,51.0,40.0,55.0,41.0,38.0,42.0,66.0,66.0,58.0,43.0,46.0,55.0,54.0,43.0,57.0,40.0,42.0,64.0,72.0,39.0,52.0,43.0,62.0,43.0,77.0,58.0,49.0,44.0,49.0,58.0,40.0,74.0,73.0,44.0,43.0,45.0,40.0,65.0,55.0,55.0,52.0,68.0,56.0,53.0,43.0,64.0,55.0,76.0,46.0,56.0,44.0,38.0,43.0,53.0,81.0,50.0,63.0,30.0,47.0,25.0,55.0,48.0,48.0,50.0,37.0,72.0,47.0,65.0,53.0,82.0,35.0,38.0,37.0,47.0,54.0,39.0,59.0,22.0,56.0,56.0,42.0,58.0,64.0,62.0,64.0,50.0,58.0,52.0,60.0,31.0,42.0,38.0,57.0,41.0,39.0,40.0,56.0,68.0,48.0,66.0,41.0,63.0,49.0,41.0,40.0,55.0,55.0,48.0,41.0,50.0,41.0,32.0,59.0,42.0,54.0,48.0,49.0,60.0,43.0,39.0,48.0,46.0,45.0,53.0,39.0,52.0,33.0,53.0,42.0,67.0,50.0,78.0,58.0,43.0,43.0,46.0,56.0,62.0,35.0,60.0,77.0,58.0,39.0,39.0,48.0,44.0,48.0,74.0,67.0,33.0,41.0,45.0,62.0,65.0,39.0,77.0,63.0,71.0,44.0,58.0,69.0,48.0,64.0,62.0,40.0,69.0,40.0,44.0,48.0,60.0,61.0,40.0,57.0,54.0,63.0,42.0,59.0,41.0,66.0,53.0,36.0,46.0,51.0,45.0,33.0,46.0,75.0,47.0,48.0,47.0,51.0,48.0,38.0,40.0,67.0,72.0,52.0,51.0,63.0,35.0,33.0,62.0,43.0,47.0,70.0,51.0,40.0,39.0,32.0,60.0,33.0,57.0,68.0,69.0,54.0,60.0,57.0,18.0,55.0,46.0,54.0,46.0,54.0,47.0,35.0,48.0,45.0,47.0,41.0,42.0,41.0,41.0,52.0,31.0,41.0,55.0,73.0,64.0,29.0,63.0,54.0,63.0,45.0,65.0,47.0,49.0,57.0,44.0,53.0,29.0,56.0,52.0,44.0,25.0,54.0,40.0,46.0,67.0,45.0,45.0,47.0,65.0,54.0,41.0,43.0,54.0,52.0,68.0,82.0,42.0,75.0,74.0,43.0,65.0,35.0,42.0,55.0,42.0,51.0,71.0,41.0,47.0,28.0,42.0,55.0,70.0,67.0,49.0,55.0,37.0,48.0,37.0,46.0,34.0,63.0,53.0,54.0,76.0,50.0,69.0,48.0,45.0,42.0,39.0,55.0,43.0,38.0,51.0,60.0,70.0,71.0,62.0,69.0,34.0,52.0,56.0,37.0,43.0,67.0,53.0,49.0,44.0,51.0,60.0,37.0,50.0,31.0,45.0,53.0,45.0,66.0,68.0,44.0,50.0,51.0,66.0,48.0,45.0,61.0,43.0,47.0,58.0,33.0,55.0,56.0,54.0,52.0,52.0,64.0,39.0,56.0,73.0,56.0,64.0,43.0,39.0,59.0,52.0,43.0,48.0,48.0,46.0,53.0,59.0,49.0,31.0,72.0,76.0,54.0,39.0,60.0,59.0,42.0,49.0,32.0,41.0,68.0,60.0,76.0,43.0,42.0,74.0,68.0,43.0,53.0,71.0,48.0,37.0,78.0,42.0,47.0,60.0,50.0,41.0,77.0,67.0,64.0,49.0,62.0,46.0,48.0,34.0,66.0,50.0,47.0,71.0,51.0,44.0,64.0,55.0,65.0,62.0,54.0,51.0,57.0,39.0,50.0,52.0,40.0,42.0,46.0,47.0,53.0,51.0,52.0,44.0,43.0,52.0,49.0,53.0,48.0,50.0,71.0,43.0,53.0,53.0,61.0,56.0,47.0,68.0,32.0,40.0,46.0,73.0,56.0,74.0,55.0,74.0,50.0,66.0,42.0,41.0,51.0,42.0,46.0,38.0,46.0,41.0,59.0,62.0,64.0,54.0,54.0,61.0,62.0,38.0,48.0,56.0,73.0,26.0,34.0,50.0,44.0,62.0,32.0,44.0,68.0,45.0,74.0,47.0,36.0,48.0,66.0,56.0,64.0,61.0,49.0,57.0,54.0,66.0,47.0,65.0,63.0,44.0,53.0,35.0,62.0,49.0,64.0,39.0,55.0,67.0,54.0,41.0,57.0,67.0,59.0,38.0,36.0,28.0,31.0,72.0,52.0,49.0,50.0,43.0,49.0,58.0,68.0,49.0,39.0,54.0,63.0,51.0,61.0,62.0,77.0,31.0,70.0,42.0,55.0,42.0,38.0,52.0,55.0,46.0,56.0,71.0,48.0,38.0,50.0,76.0,60.0,68.0,73.0,36.0,66.0,43.0,42.0,61.0,53.0,28.0,34.0,55.0,41.0,44.0,34.0,55.0,63.0,51.0,44.0,45.0,48.0,45.0,46.0,40.0,39.0,51.0,43.0,41.0,67.0,63.0,46.0,78.0,58.0,51.0,62.0,42.0,36.0,70.0,41.0,65.0,44.0,39.0,50.0,47.0,41.0,48.0,74.0,48.0,49.0,58.0,49.0,61.0,61.0,51.0,37.0,49.0,63.0,54.0,50.0,46.0,60.0,50.0,67.0,67.0,47.0,57.0,30.0,62.0,47.0,48.0,42.0,42.0,35.0,54.0,49.0,46.0,61.0,69.0,40.0,30.0,46.0,47.0,77.0,54.0,50.0,51.0,26.0,39.0,52.0,49.0,52.0,27.0,45.0,55.0,67.0,41.0,56.0,66.0,67.0,52.0,57.0,73.0,60.0,44.0,45.0,66.0,60.0,69.0,50.0,78.0,46.0,48.0,41.0,60.0,39.0,64.0,46.0,43.0,37.0,42.0,44.0,40.0,58.0,46.0,57.0,54.0,36.0,66.0,30.0,37.0,58.0,56.0,47.0,61.0,51.0,24.0,35.0,60.0,64.0,40.0,57.0,53.0,50.0,53.0,38.0,56.0,59.0,57.0,39.0,45.0,69.0,49.0,42.0,58.0,50.0,68.0,71.0,44.0,34.0,41.0,48.0,68.0,48.0,55.0,49.0,63.0,37.0,44.0,63.0,42.0,44.0,65.0,44.0,63.0,55.0,47.0,55.0,51.0,54.0,52.0,60.0,71.0,44.0,38.0,41.0,44.0,55.0,42.0,41.0,38.0,58.0,39.0,46.0,39.0,60.0,41.0,44.0,60.0,62.0,64.0,60.0,59.0,65.0,50.0,61.0,44.0,40.0,58.0,46.0,54.0,63.0,37.0,45.0,41.0,58.0,65.0,56.0,44.0,63.0,55.0,47.0,47.0,39.0,52.0,32.0,41.0,48.0,41.0,46.0,55.0,48.0,47.0,38.0,69.0,70.0,60.0,45.0,50.0,44.0,44.0,50.0,49.0,72.0,37.0,68.0,46.0,57.0,54.0,36.0,78.0,52.0,40.0,49.0,81.0,64.0,44.0,43.0,50.0,69.0,54.0,62.0,64.0,46.0,57.0,40.0,52.0,34.0,50.0,21.0,43.0,46.0,41.0,74.0,50.0,38.0,39.0,76.0,60.0,37.0,56.0,66.0,68.0,49.0,39.0,56.0,47.0,65.0,42.0,36.0,57.0,57.0,37.0,54.0,32.0,54.0,54.0,62.0,68.0,37.0,42.0,48.0,66.0,43.0,59.0,59.0,54.0,50.0,52.0,33.0,44.0,53.0,42.0,74.0,54.0,46.0,52.0,52.0,43.0,33.0,60.0,61.0,54.0,57.0,62.0,60.0,64.0,69.0,73.0,47.0,44.0,47.0,44.0,58.0,65.0,32.0,46.0,52.0,58.0,62.0,66.0,77.0,35.0,52.0,40.0,72.0,46.0,51.0,48.0,43.0,65.0,49.0,48.0,38.0,45.0,58.0,62.0,48.0,34.0,38.0,40.0,50.0,59.0,56.0,51.0,80.0,39.0,55.0,46.0,45.0,48.0,68.0,53.0,42.0,34.0,44.0,59.0,45.0,66.0,57.0,44.0,53.0,83.0,72.0,69.0,62.0,50.0,48.0,60.0,63.0,66.0,53.0,80.0,68.0,36.0,32.0,59.0,69.0,51.0,50.0,51.0,44.0,50.0,57.0,44.0,52.0,43.0,33.0,41.0,30.0,61.0,59.0,61.0,49.0,57.0,64.0,47.0,54.0,48.0,47.0,45.0,65.0,49.0,76.0,67.0,56.0,42.0,48.0,58.0,51.0,68.0,54.0,65.0,67.0,46.0,62.0,55.0,57.0,47.0,36.0,57.0,52.0,68.0,65.0,63.0,54.0,43.0,35.0,36.0,74.0,41.0,42.0,39.0,64.0,28.0,52.0,52.0,46.0,58.0,70.0,48.0,57.0,54.0,54.0,68.0,54.0,38.0,74.0,35.0,49.0,59.0,40.0,41.0,62.0,66.0,65.0,71.0,47.0,47.0,65.0,49.0,61.0,81.0,60.0,47.0,69.0,34.0,78.0,34.0,59.0,42.0,46.0,46.0,55.0,31.0,47.0,45.0,50.0,55.0,54.0,62.0,50.0,34.0,62.0,42.0,49.0,42.0,47.0,56.0,49.0,73.0,47.0,53.0,58.0,61.0,49.0,38.0,33.0,57.0,71.0,55.0,43.0,63.0,42.0,60.0,62.0,55.0,55.0,56.0,65.0,50.0,47.0,63.0,46.0,39.0,29.0,45.0,50.0,62.0,38.0,47.0,54.0,49.0,63.0,51.0,43.0,42.0,45.0,54.0,55.0,35.0,30.0,50.0,40.0,43.0,43.0,38.0,57.0,50.0,49.0,58.0,44.0,58.0,53.0,46.0,47.0,44.0,38.0,42.0,56.0,40.0,60.0,31.0,53.0,62.0,37.0,77.0,56.0,55.0,24.0,50.0,55.0,68.0,55.0,58.0,37.0,51.0,40.0,47.0,64.0,51.0,61.0,53.0,64.0,32.0,46.0,68.0,36.0,54.0,46.0,51.0,64.0,30.0,51.0,56.0,43.0,54.0,46.0,44.0,34.0,63.0,61.0,42.0,63.0,57.0,66.0,37.0,59.0,42.0,48.0,60.0,39.0,59.0,36.0,43.0,54.0,57.0,47.0,41.0,83.0,43.0,53.0,70.0,60.0,42.0,48.0,34.0,68.0,44.0,61.0,55.0,71.0,54.0,38.0,49.0,52.0,60.0,70.0,55.0,40.0,36.0,70.0,47.0,57.0,42.0,51.0,44.0,66.0,82.0,48.0,53.0,61.0,54.0,48.0,37.0,84.0,47.0,33.0,63.0,60.0,44.0,37.0,36.0,42.0,61.0,46.0,60.0,37.0,41.0,68.0,54.0,66.0,69.0,68.0,72.0,48.0,62.0,42.0,56.0,51.0,36.0,56.0,43.0,49.0,46.0,69.0,40.0,39.0,52.0,46.0,55.0,41.0,48.0,58.0,71.0,46.0,58.0,71.0,79.0,33.0,46.0,46.0,65.0,57.0,38.0,70.0,46.0,62.0,31.0,42.0,57.0,54.0,56.0,67.0,51.0,49.0,37.0,49.0,42.0,58.0,62.0,60.0,54.0,40.0,51.0,58.0,43.0,33.0,62.0,59.0,49.0,50.0,42.0,56.0,35.0,45.0,44.0,67.0,52.0,52.0,62.0,71.0,54.0,47.0,49.0,54.0,52.0,39.0,51.0,49.0,65.0,55.0,44.0,51.0,59.0,70.0,53.0,49.0,45.0,41.0,55.0,43.0,51.0,59.0,60.0,68.0,60.0,45.0,51.0,37.0,60.0,52.0,50.0,46.0,50.0,64.0,45.0,41.0,54.0,40.0,55.0,38.0,40.0,70.0,60.0,43.0,59.0,40.0,55.0,81.0,39.0,53.0,80.0,61.0,53.0,54.0,63.0,58.0,46.0,38.0,55.0,63.0,43.0,68.0,50.0,50.0,59.0,57.0,55.0,50.0,61.0,55.0,63.0,49.0,56.0,71.0,40.0,84.0,43.0,61.0,46.0,55.0,33.0,65.0,68.0,57.0,76.0,58.0,56.0,39.0,29.0,54.0,47.0,62.0,52.0,47.0,64.0,34.0,59.0,71.0,47.0,67.0,59.0,57.0,58.0,39.0,41.0,41.0,52.0,55.0,46.0,73.0,59.0,39.0,49.0,43.0,47.0,64.0,46.0,46.0,62.0,47.0,32.0,61.0,68.0,66.0,46.0,35.0,45.0,32.0,41.0,29.0,65.0,43.0,43.0,59.0,70.0,41.0,39.0,41.0,45.0,53.0,44.0,52.0,47.0,62.0,50.0,63.0,56.0,45.0,42.0,59.0,39.0,47.0,84.0,52.0,49.0,63.0,38.0,53.0,65.0,45.0,42.0,43.0,44.0,40.0,49.0,37.0,54.0,44.0,63.0,34.0,50.0,55.0,67.0,40.0,48.0,50.0,49.0,64.0,50.0,42.0,40.0,51.0,60.0,70.0,31.0,57.0,38.0,44.0,64.0,38.0,48.0,43.0,43.0,69.0,66.0,47.0,67.0,42.0,64.0,66.0,43.0,41.0,42.0,76.0,46.0,53.0,64.0,49.0,48.0,37.0,39.0,37.0,57.0,40.0,62.0,50.0,54.0,46.0,39.0,45.0,67.0,62.0,44.0,56.0,31.0,48.0,63.0,50.0,37.0,56.0,62.0,53.0,37.0,36.0,47.0,51.0,57.0,59.0,46.0,38.0,39.0,42.0,38.0,47.0,40.0,42.0,57.0,45.0,48.0,66.0,53.0,58.0,49.0,42.0,47.0,51.0,44.0,55.0,48.0,57.0,37.0,42.0,52.0,41.0,48.0,52.0,52.0,48.0,71.0,43.0,41.0,60.0,75.0,40.0,67.0,66.0,68.0,54.0,52.0,45.0,29.0,54.0,59.0,53.0,64.0,53.0,41.0,52.0,57.0,51.0,54.0,51.0,47.0,57.0,51.0,68.0,46.0,41.0,68.0,33.0,45.0,29.0,64.0,58.0,42.0,48.0,36.0,37.0,51.0,67.0,46.0,56.0,66.0,55.0,55.0,53.0,52.0,39.0,49.0,39.0,34.0,40.0,60.0,28.0,58.0,59.0,41.0,63.0,42.0,45.0,53.0,57.0,74.0,41.0,42.0,24.0,65.0,56.0,49.0,60.0,71.0,55.0,47.0,58.0,58.0,55.0,39.0,70.0,69.0,43.0,49.0,48.0,56.0,47.0,41.0,56.0,33.0,60.0,48.0,66.0,70.0,52.0,56.0,37.0,38.0,58.0,49.0,79.0,54.0,67.0,61.0,42.0,44.0,48.0,47.0,65.0,37.0,36.0,48.0,42.0,38.0,46.0,74.0,53.0,64.0,70.0,33.0,39.0,53.0,58.0,58.0,57.0,34.0,40.0,53.0,39.0,46.0,46.0,43.0,68.0,41.0,38.0,46.0,58.0,35.0,60.0,63.0,41.0,49.0,47.0,59.0,45.0,50.0,39.0,66.0,47.0,59.0,80.0,59.0,77.0,33.0,42.0,43.0,37.0,56.0,69.0,46.0,69.0,38.0,64.0,56.0,48.0,56.0,57.0,83.0,36.0,71.0,56.0,48.0,29.0,73.0,38.0,67.0,35.0,47.0,53.0,32.0,47.0,56.0,50.0,50.0,69.0,42.0,39.0,61.0,56.0,44.0,45.0,43.0,54.0,42.0,41.0,53.0,55.0,43.0,47.0,35.0,38.0,46.0,56.0,55.0,40.0,60.0,49.0,63.0,65.0,40.0,36.0,45.0,46.0,61.0,68.0,47.0,47.0,48.0,37.0,45.0,38.0,39.0,56.0,77.0,53.0,34.0,44.0,52.0,45.0,49.0,68.0,39.0,46.0,49.0,64.0,51.0,43.0,28.0,52.0,61.0,37.0,56.0,74.0,70.0,51.0,37.0,53.0,63.0,61.0,44.0,63.0,42.0,48.0,51.0,55.0,57.0,59.0,73.0,49.0,69.0,66.0,42.0,58.0,49.0,63.0,82.0,45.0,51.0,60.0,78.0,37.0,45.0,66.0,37.0,67.0,38.0,47.0,47.0,22.0,44.0,50.0,35.0,67.0,56.0,44.0,61.0,41.0,45.0,64.0,50.0,57.0,53.0,45.0,62.0,41.0,51.0,31.0,42.0,47.0,71.0,47.0,63.0,65.0,43.0,79.0,66.0,45.0,48.0,39.0,66.0,60.0,39.0,73.0,42.0,48.0,46.0,54.0,52.0,52.0,38.0,55.0,50.0,59.0,71.0,54.0,47.0,32.0,54.0,37.0,50.0,56.0,22.0,36.0,41.0,53.0,41.0,44.0,40.0,54.0,40.0,47.0,83.0,36.0,47.0,43.0,41.0,54.0,55.0,49.0,35.0,47.0,37.0,58.0,36.0,47.0,59.0,64.0,55.0,30.0,50.0,40.0,55.0,57.0,80.0,62.0,34.0,56.0,67.0,35.0,55.0,58.0,37.0,68.0,57.0,66.0,47.0,51.0,41.0,37.0,35.0,55.0,44.0,47.0,51.0,54.0,61.0,33.0,60.0,55.0,46.0,34.0,41.0,60.0,39.0,38.0,36.0,45.0,53.0,39.0,48.0,58.0,62.0,55.0,56.0,29.0,35.0,77.0,71.0,57.0,57.0,53.0,43.0,59.0,60.0,34.0,51.0,48.0,50.0,49.0,57.0,66.0,60.0,66.0,44.0,39.0,53.0,32.0,51.0,52.0,71.0,47.0,39.0,57.0,49.0,46.0,57.0,43.0,53.0,38.0,47.0,44.0,45.0,60.0,47.0,45.0,50.0,39.0,52.0,35.0,52.0,54.0,66.0,30.0,38.0,39.0,52.0,52.0,43.0,49.0,58.0,39.0,59.0,60.0,63.0,38.0,61.0,70.0,45.0,44.0,52.0,58.0,45.0,40.0,75.0,44.0,37.0,53.0,54.0,58.0,52.0,58.0,34.0,56.0,60.0,68.0,68.0,60.0,43.0,44.0,75.0,50.0,45.0,60.0,51.0,64.0,45.0,62.0,55.0,71.0,38.0,72.0,67.0,55.0,56.0,52.0,38.0,43.0,48.0,69.0,37.0,63.0,71.0,44.0,67.0,48.0,61.0,44.0,62.0,68.0,36.0,62.0,44.0,60.0,62.0,75.0,33.0,56.0,40.0,46.0,43.0,64.0,51.0,63.0,59.0,41.0,40.0,47.0,45.0,41.0,53.0,58.0,40.0,69.0,46.0,65.0,48.0,41.0,42.0,71.0,65.0,56.0,33.0,68.0,47.0,43.0,53.0,56.0,60.0,54.0,49.0,38.0,38.0,44.0,28.0,54.0,39.0,48.0,50.0,41.0,33.0,50.0,41.0,45.0,52.0,45.0,47.0,38.0,51.0,56.0,44.0,48.0,46.0,60.0,41.0,40.0,59.0,61.0,52.0,53.0,65.0,35.0,62.0,46.0,42.0,44.0,63.0,40.0,36.0,52.0,32.0,79.0,48.0,49.0,37.0,52.0,43.0,50.0,41.0,49.0,42.0,45.0,55.0,71.0,61.0,54.0,43.0,65.0,45.0,40.0,38.0,53.0,62.0,58.0,64.0,62.0,52.0,32.0,35.0,39.0,50.0,51.0,50.0,49.0,51.0,50.0,53.0,44.0,54.0,54.0,54.0,53.0,53.0,63.0,39.0,50.0,56.0,42.0,58.0,44.0,59.0,54.0,41.0,63.0,52.0,63.0,50.0,36.0,42.0,57.0,47.0,71.0,56.0,62.0,77.0,72.0,64.0,58.0,71.0,42.0,46.0,40.0,63.0,76.0,41.0,49.0,51.0,44.0,44.0,62.0,40.0,60.0,44.0,53.0,22.0,55.0,67.0,60.0,51.0,46.0,55.0,52.0,81.0,55.0,74.0,54.0,76.0,41.0,33.0,67.0,40.0,46.0,53.0,59.0,63.0,60.0,55.0,48.0,65.0,52.0,43.0,67.0,53.0,44.0,48.0,31.0,54.0,42.0,52.0,45.0,37.0,36.0,70.0,49.0,45.0,46.0,46.0,53.0,55.0,46.0,63.0,35.0,36.0,61.0,50.0,48.0,80.0,34.0,47.0,65.0,31.0,61.0,58.0,40.0,49.0,46.0,67.0,47.0,77.0,40.0,43.0,58.0,56.0,53.0,56.0,59.0,71.0,73.0,54.0,54.0,46.0,69.0,45.0,31.0,39.0,51.0,37.0,61.0,50.0,60.0,34.0,41.0,57.0,63.0,35.0,74.0,64.0,35.0,54.0,36.0,49.0,39.0,47.0,47.0,46.0,43.0,48.0,72.0,57.0,28.0,47.0,53.0,66.0,67.0,64.0,60.0,59.0,66.0,65.0,68.0,51.0,52.0,44.0,43.0,53.0,53.0,45.0,62.0,72.0,47.0,48.0,49.0,51.0,67.0,37.0,50.0,46.0,41.0,45.0,68.0,42.0,31.0,55.0,37.0,42.0,46.0,32.0,50.0,43.0,25.0,42.0,41.0,44.0,39.0,49.0,58.0,35.0,45.0,64.0,61.0,42.0,52.0,69.0,44.0,58.0,51.0,55.0,70.0,59.0,39.0,46.0,68.0,49.0,42.0,46.0,47.0,57.0,46.0,67.0,39.0,35.0,46.0,64.0,60.0,48.0,41.0,41.0,57.0,61.0,45.0,30.0,52.0,28.0,50.0,61.0,31.0,34.0,41.0,68.0,43.0,42.0,45.0,57.0,40.0,65.0,53.0,41.0,66.0,57.0,25.0,43.0,51.0,58.0,52.0,44.0,58.0,65.0,34.0,48.0,62.0,41.0,75.0,39.0,51.0,45.0,64.0,73.0,56.0,77.0,68.0,62.0,48.0,48.0,45.0,32.0,48.0,56.0,51.0,48.0,48.0,41.0,53.0,48.0,64.0,49.0,58.0,70.0,62.0,44.0,52.0,53.0,40.0,46.0,58.0,50.0,53.0,57.0,49.0,55.0,42.0,59.0,27.0,40.0,69.0,38.0,38.0,70.0,57.0,54.0,66.0,49.0,53.0,38.0,45.0,48.0,63.0,55.0,45.0,56.0,52.0,66.0,45.0,48.0,41.0,51.0,45.0,48.0,52.0,48.0,54.0,35.0,41.0,59.0,53.0,59.0,43.0,66.0,52.0,42.0,56.0,57.0,47.0,76.0,58.0,35.0,40.0,32.0,63.0,48.0,32.0,69.0,41.0,59.0,54.0,43.0,69.0,60.0,54.0,57.0,53.0,39.0,43.0,56.0,50.0,31.0,28.0,53.0,43.0,48.0,44.0,58.0,52.0,62.0,44.0,53.0,38.0,39.0,37.0,68.0,66.0,70.0,49.0,35.0,49.0,44.0,41.0,57.0,41.0,35.0,43.0,65.0,61.0,48.0,38.0,42.0,50.0,57.0,63.0,64.0,70.0,57.0,55.0,34.0,37.0,54.0,39.0,55.0,53.0,38.0,37.0,50.0,70.0,34.0,40.0,46.0,45.0,61.0,69.0,44.0,54.0,58.0,60.0,50.0,42.0,63.0,47.0,49.0,43.0,48.0,45.0,66.0,34.0,48.0,55.0,50.0,36.0,44.0,54.0,45.0,58.0,55.0,63.0,39.0,52.0,44.0,58.0,42.0,59.0,32.0,53.0,58.0,49.0,62.0,48.0,31.0,67.0,44.0,29.0,70.0,36.0,49.0,43.0,62.0,64.0,56.0,29.0,72.0,47.0,60.0,42.0,56.0,42.0,52.0,59.0,45.0,55.0,65.0,69.0,43.0,56.0,44.0,59.0,69.0,57.0,30.0,41.0,41.0,50.0,45.0,62.0,60.0,48.0,66.0,48.0,58.0,37.0,62.0,34.0,32.0,48.0,74.0,35.0,61.0,56.0,41.0,65.0,70.0,64.0,62.0,53.0,63.0,57.0,59.0,59.0,52.0,49.0,72.0,40.0,61.0,52.0,62.0,46.0,46.0,55.0,68.0,43.0,71.0,51.0,52.0,41.0,64.0,58.0,63.0,47.0,50.0,69.0,43.0,65.0,52.0,54.0,47.0,53.0,47.0,38.0,75.0,47.0,46.0,54.0,42.0,50.0,61.0,40.0,64.0,50.0,62.0,62.0,49.0,68.0,37.0,45.0,33.0,51.0,47.0,42.0,76.0,65.0,40.0,32.0,47.0,63.0,46.0,38.0,43.0,63.0,55.0,56.0,36.0,45.0,42.0,60.0,36.0,36.0,46.0,63.0,48.0,50.0,44.0,61.0,51.0,42.0,44.0,35.0,47.0,62.0,55.0,32.0,60.0,48.0,43.0,41.0,60.0,46.0,36.0,46.0,52.0,44.0,51.0,49.0,68.0,47.0,48.0,60.0,70.0,50.0,54.0,54.0,56.0,55.0,44.0,49.0,21.0,66.0,62.0,62.0,60.0,46.0,45.0,48.0,55.0,49.0,61.0,41.0,48.0,61.0,53.0,49.0,41.0,33.0,52.0,49.0,56.0,39.0,48.0,69.0,36.0,69.0,48.0,69.0,67.0,42.0,45.0,60.0,38.0,52.0,67.0,38.0,50.0,52.0,24.0,36.0,41.0,45.0,47.0,73.0,60.0,44.0,66.0,54.0,44.0,25.0,50.0,37.0,69.0,58.0,37.0,42.0,71.0,61.0,65.0,52.0,65.0,54.0,61.0,55.0,32.0,57.0,56.0,44.0,47.0,56.0,37.0,31.0,29.0,45.0,44.0,53.0,34.0,40.0,63.0,52.0,59.0,51.0,69.0,46.0,57.0,27.0,66.0,51.0,38.0,54.0,45.0,68.0,52.0,41.0,67.0,52.0,42.0,44.0,58.0,63.0,35.0,47.0,54.0,44.0,44.0,49.0,47.0,50.0,45.0,39.0,42.0,43.0,54.0,40.0,47.0,59.0,60.0,52.0,61.0,46.0,53.0,45.0,80.0,32.0,53.0,75.0,44.0,62.0,50.0,44.0,46.0,66.0,49.0,57.0,57.0,56.0,64.0,53.0,58.0,54.0,46.0,37.0,33.0,67.0,55.0,44.0,66.0,54.0,55.0,59.0,68.0,49.0,49.0,64.0,40.0,61.0,70.0,57.0,73.0,46.0,48.0,63.0,49.0,57.0,59.0,50.0,39.0,50.0,50.0,50.0,44.0,48.0,45.0,36.0,39.0,56.0,51.0,47.0,40.0,72.0,54.0,30.0,45.0,60.0,44.0,39.0,67.0,68.0,55.0,55.0,42.0,47.0,74.0,57.0,59.0,39.0,41.0,61.0,28.0,79.0,68.0,34.0,37.0,37.0,36.0,60.0,44.0,49.0,28.0,38.0,43.0,68.0,50.0,48.0,44.0,37.0,40.0,61.0,41.0,70.0,53.0,59.0,53.0,46.0,80.0,45.0,59.0,41.0,38.0,50.0,48.0,60.0,45.0,65.0,66.0,62.0,68.0,54.0,45.0,70.0,66.0,57.0,50.0,51.0,36.0,68.0,51.0,64.0,44.0,50.0,43.0,51.0,50.0,75.0,31.0,58.0,57.0,57.0,47.0,68.0,38.0,65.0,42.0,54.0,55.0,45.0,42.0,33.0,61.0,48.0,45.0,36.0,57.0,63.0,64.0,38.0,37.0,46.0,28.0,51.0,68.0,79.0,51.0,43.0,63.0,44.0,55.0,38.0,36.0,58.0,39.0,59.0,47.0,49.0,70.0,51.0,57.0,44.0,55.0,52.0,53.0,70.0,53.0,60.0,56.0,45.0,64.0,66.0,38.0,38.0,57.0,55.0,51.0,72.0,70.0,54.0,55.0,38.0,66.0,38.0,66.0,43.0,46.0,40.0,50.0,38.0,52.0,60.0,54.0,62.0,72.0,84.0,44.0,66.0,41.0,47.0,44.0,67.0,36.0,48.0,62.0,30.0,42.0,51.0,44.0,45.0,72.0,62.0,57.0,47.0,60.0,54.0,43.0,36.0,37.0,38.0,49.0,55.0,64.0,66.0,46.0,49.0,36.0,45.0,30.0,52.0,53.0,64.0,67.0,61.0,54.0,45.0,61.0,56.0,35.0,38.0,30.0,49.0,38.0,42.0,42.0,55.0,53.0,36.0,58.0,29.0,42.0,47.0,41.0,39.0,49.0,35.0,45.0,73.0,39.0,53.0,38.0,38.0,44.0,61.0,41.0,58.0,39.0,50.0,44.0,56.0,64.0,37.0,66.0,53.0,54.0,53.0,73.0,33.0,57.0,49.0,47.0,56.0,32.0,61.0,52.0,43.0,65.0,39.0,68.0,48.0,44.0,50.0,43.0,61.0,56.0,49.0,39.0,36.0,45.0,45.0,53.0,40.0,45.0,32.0,61.0,30.0,47.0,67.0,46.0,30.0,47.0,55.0,39.0,44.0,71.0,45.0,51.0,56.0,40.0,51.0,46.0,55.0,76.0,56.0,58.0,74.0,56.0,56.0,27.0,44.0,54.0,62.0,55.0,65.0,49.0,39.0,56.0,62.0,66.0,53.0,51.0,42.0,42.0,51.0,70.0,46.0,42.0,58.0,55.0,39.0,59.0,58.0,53.0,47.0,34.0,43.0,72.0,79.0,34.0,46.0,58.0,71.0,65.0,49.0,70.0,59.0,39.0,38.0,43.0,37.0,61.0,39.0,38.0,73.0,63.0,46.0,41.0,51.0,59.0,50.0,59.0,80.0,48.0,67.0,42.0,64.0,35.0,46.0,51.0,60.0,45.0,58.0,52.0,29.0,63.0,43.0,72.0,29.0,57.0,57.0,29.0,46.0,29.0,48.0,52.0,61.0,58.0,42.0,55.0,59.0,49.0,77.0,39.0,70.0,56.0,24.0,64.0,37.0,49.0,65.0,57.0,51.0,49.0,57.0,51.0,60.0,66.0,41.0,55.0,75.0,38.0,44.0,51.0,25.0,58.0,44.0,63.0,44.0,29.0,35.0,38.0,54.0,70.0,54.0,48.0,43.0,52.0,58.0,61.0,45.0,65.0,49.0,36.0,55.0,54.0,68.0,36.0,34.0,62.0,48.0,60.0,44.0,49.0,63.0,61.0,52.0,47.0,57.0,72.0,68.0,42.0,52.0,61.0,47.0,44.0,41.0,49.0,57.0,46.0,76.0,55.0,43.0,46.0,44.0,45.0,45.0,46.0,60.0,67.0,34.0,38.0,44.0,57.0,65.0,50.0,40.0,66.0,27.0,64.0,45.0,58.0,78.0,57.0,77.0,60.0,68.0,46.0,53.0,40.0,48.0,62.0,54.0,36.0,40.0,69.0,36.0,49.0,48.0,28.0,68.0,41.0,35.0,70.0,46.0,50.0,77.0,60.0,47.0,69.0,67.0,60.0,46.0,39.0,41.0,42.0,53.0,46.0,47.0,37.0,49.0,52.0,43.0,73.0,63.0,42.0,54.0,58.0,66.0,60.0,90.0,42.0,65.0,45.0,48.0,40.0,43.0,61.0,43.0,48.0,36.0,54.0,45.0,54.0,68.0,56.0,51.0,35.0,46.0,71.0,64.0,49.0,43.0,60.0,66.0,64.0,56.0,56.0,70.0,40.0,41.0,54.0,51.0,43.0,66.0,58.0,48.0,36.0,49.0,50.0,51.0,30.0,46.0,52.0,68.0,34.0,77.0,58.0,50.0,49.0,49.0,64.0,52.0,41.0,56.0,48.0,58.0,51.0,63.0,50.0,54.0,61.0,39.0,63.0,37.0,46.0,49.0,53.0,57.0,69.0,45.0,71.0,48.0,43.0,43.0,41.0,35.0,53.0,49.0,52.0,38.0,53.0,55.0,55.0,48.0,47.0,71.0,37.0,59.0,51.0,40.0,36.0,54.0,58.0,59.0,45.0,38.0,45.0,69.0,57.0,42.0,55.0,38.0,60.0,37.0,53.0,46.0,51.0,57.0,49.0,40.0,64.0,45.0,43.0,49.0,42.0,61.0,74.0,60.0,29.0,67.0,69.0,41.0,59.0,51.0,46.0,49.0,55.0,55.0,33.0,65.0,58.0,39.0,64.0,67.0,53.0,45.0,49.0,49.0,51.0,51.0,54.0,49.0,53.0,45.0,50.0,37.0,51.0,67.0,56.0,52.0,36.0,65.0,30.0,69.0,33.0,55.0,50.0,63.0,54.0,50.0,48.0,38.0,74.0,57.0,58.0,61.0,55.0,55.0,56.0,73.0,55.0,40.0,54.0,61.0,33.0,50.0,48.0,48.0,41.0,35.0,68.0,42.0,49.0,50.0,63.0,56.0,55.0,41.0,37.0,47.0,50.0,64.0,44.0,41.0,47.0,39.0,41.0,41.0,75.0,37.0,58.0,30.0,36.0,60.0,49.0,52.0,35.0,54.0,38.0,49.0,51.0,60.0,54.0,39.0,41.0,36.0,39.0,47.0,33.0,62.0,73.0,49.0,48.0,36.0,50.0,62.0,46.0,44.0,48.0,42.0,61.0,55.0,71.0,34.0,40.0,41.0,39.0,54.0,50.0,43.0,56.0,43.0,38.0,50.0,28.0,57.0,58.0,72.0,47.0,87.0,62.0,52.0,67.0,50.0,54.0,51.0,53.0,56.0,54.0,55.0,41.0,65.0,37.0,46.0,37.0,60.0,60.0,42.0,47.0,49.0,49.0,66.0,41.0,59.0,58.0,44.0,46.0,53.0,43.0,32.0,33.0,40.0,50.0,48.0,53.0,54.0,53.0,57.0,36.0,71.0,52.0,43.0,29.0,61.0,35.0,49.0,48.0,55.0,70.0,43.0,42.0,47.0,59.0,44.0,57.0,36.0,34.0,53.0,73.0,45.0,59.0,43.0,68.0,45.0,64.0,59.0,57.0,57.0,67.0,60.0,65.0,59.0,52.0,47.0,71.0,60.0,68.0,67.0,55.0,38.0,55.0,63.0,40.0,46.0,49.0,45.0,41.0,71.0,72.0,41.0,64.0,32.0,51.0,48.0,57.0,39.0,49.0,81.0,57.0,64.0,46.0,62.0,42.0,40.0,45.0,65.0,59.0,55.0,53.0,67.0,48.0,41.0,59.0,57.0,69.0,64.0,49.0,64.0,37.0,49.0,40.0,41.0,58.0,56.0,54.0,37.0,42.0,63.0,54.0,55.0,50.0,55.0,52.0,31.0,44.0,71.0,40.0,42.0,52.0,62.0,31.0,58.0,43.0,58.0,68.0,38.0,43.0,57.0,71.0,36.0,46.0,42.0,63.0,50.0,38.0,48.0,63.0,63.0,55.0,60.0,63.0,52.0,55.0,48.0,42.0,61.0,36.0,60.0,69.0,46.0,51.0,56.0,42.0,54.0,60.0,62.0,59.0,42.0,67.0,55.0,31.0,44.0,52.0,29.0,38.0,57.0,47.0,39.0,63.0,64.0,63.0,49.0,64.0,81.0,55.0,46.0,41.0,60.0,50.0,58.0,47.0,58.0,58.0,42.0,39.0,53.0,61.0,52.0,31.0,40.0,45.0,64.0,58.0,61.0,62.0,42.0,35.0,70.0,38.0,42.0,44.0,53.0,36.0,42.0,57.0,65.0,47.0,49.0,41.0,52.0,57.0,62.0,67.0,60.0,53.0,59.0,52.0,50.0,67.0,62.0,66.0,48.0,39.0,40.0,41.0,63.0,36.0,59.0,58.0,48.0,38.0,48.0,60.0,50.0,37.0,62.0,63.0,50.0,56.0,44.0,43.0,66.0,65.0,49.0,34.0,42.0,54.0,62.0,59.0,69.0,57.0,70.0,56.0,46.0,31.0,70.0,49.0,56.0,60.0,55.0,52.0,61.0,69.0,44.0,49.0,47.0,36.0,51.0,42.0,42.0,34.0,48.0,48.0,51.0,72.0,71.0,69.0,50.0,65.0,48.0,66.0,36.0,45.0,43.0,75.0,53.0,50.0,55.0,50.0,51.0,49.0,64.0,23.0,48.0,75.0,47.0,62.0,33.0,56.0,53.0,38.0,63.0,64.0,63.0,64.0,45.0,47.0,76.0,69.0,50.0,44.0,45.0,53.0,43.0,62.0,61.0,41.0,43.0,62.0,58.0,42.0,48.0,50.0,64.0,78.0,52.0,44.0,61.0,63.0,42.0,45.0,62.0,62.0,55.0,47.0,58.0,61.0,50.0,46.0,63.0,40.0,62.0,74.0,35.0,67.0,48.0,61.0,36.0,65.0,56.0,44.0,60.0,73.0,68.0,62.0,38.0,28.0,64.0,34.0,48.0,42.0,50.0,53.0,60.0,56.0,57.0,48.0,38.0,59.0,67.0,59.0,62.0,64.0,50.0,40.0,71.0,69.0,63.0,53.0,44.0,45.0,59.0,54.0,51.0,51.0,59.0,74.0,38.0,48.0,35.0,64.0,58.0,54.0,44.0,46.0,29.0,58.0,69.0,64.0,63.0,76.0,53.0,45.0,50.0,64.0,39.0,65.0,50.0,52.0,54.0,58.0,40.0,63.0,60.0,70.0,59.0,61.0,48.0,60.0,50.0,46.0,60.0,48.0,61.0,61.0,55.0,33.0,58.0,63.0,44.0,44.0,58.0,70.0,46.0,37.0,57.0,56.0,39.0,53.0,63.0,41.0,48.0,50.0,61.0,48.0,64.0,46.0,35.0,36.0,35.0,69.0,43.0,44.0,48.0,48.0,54.0,43.0,46.0,51.0,40.0,61.0,47.0,44.0,66.0,45.0,56.0,52.0,58.0,50.0,47.0,55.0,45.0,54.0,29.0,39.0,58.0,45.0,74.0,53.0,53.0,66.0,46.0,65.0,76.0,48.0,49.0,60.0,47.0,53.0,41.0,53.0,35.0,57.0,43.0,49.0,66.0,45.0,47.0,58.0,37.0,83.0,47.0,45.0,58.0,57.0,63.0,52.0,61.0,55.0,52.0,44.0,63.0,55.0,59.0,39.0,75.0,42.0,65.0,66.0,48.0,49.0,70.0,66.0,34.0,58.0,56.0,49.0,50.0,65.0,62.0,47.0,85.0,61.0,62.0,72.0,55.0,61.0,46.0,46.0,75.0,63.0,59.0,69.0,61.0,57.0,49.0,61.0,53.0,49.0,32.0,52.0,42.0,46.0,78.0,60.0,61.0,41.0,52.0,40.0,63.0,66.0,51.0,57.0,63.0,51.0,27.0,31.0,37.0,35.0,66.0,71.0,31.0,52.0,41.0,54.0,39.0,43.0,43.0,57.0,36.0,51.0,44.0,41.0,74.0,42.0,48.0,50.0,44.0,56.0,52.0,61.0,47.0,61.0,41.0,39.0,75.0,37.0,54.0,47.0,76.0,43.0,49.0,45.0,62.0,41.0,60.0,77.0,56.0,63.0,68.0,36.0,49.0,47.0,71.0,68.0,43.0,51.0,47.0,46.0,46.0,45.0,42.0,41.0,51.0,48.0,42.0,35.0,39.0,49.0,65.0,46.0,50.0,52.0,51.0,66.0,58.0,45.0,55.0,44.0,72.0,57.0,45.0,60.0,42.0,57.0,44.0,50.0,50.0,39.0,57.0,61.0,58.0,77.0,37.0,68.0,67.0,62.0,62.0,47.0,52.0,47.0,40.0,41.0,41.0,59.0,31.0,60.0,52.0,66.0,52.0,55.0,60.0,31.0,60.0,68.0,27.0,39.0,60.0,61.0,70.0,42.0,56.0,46.0,57.0,57.0,65.0,29.0,53.0,59.0,53.0,51.0,46.0,64.0,55.0,54.0,43.0,49.0,68.0,57.0,44.0,49.0,51.0,53.0,53.0,55.0,41.0,32.0,49.0,58.0,61.0,57.0,65.0,66.0,59.0,49.0,47.0,57.0,64.0,38.0,64.0,70.0,37.0,49.0,59.0,63.0,55.0,50.0,79.0,65.0,50.0,62.0,64.0,53.0,46.0,40.0,53.0,55.0,37.0,39.0,57.0,30.0,44.0,55.0,42.0,51.0,35.0,53.0,66.0,47.0,74.0,54.0,47.0,48.0,45.0,44.0,75.0,58.0,43.0,34.0,69.0,62.0,49.0,41.0,52.0,36.0,65.0,46.0,77.0,68.0,60.0,47.0,44.0,58.0,46.0,49.0,61.0,86.0,41.0,53.0,59.0,61.0,47.0,78.0,31.0,45.0,56.0,54.0,66.0,33.0,51.0,54.0,44.0,51.0,50.0,61.0,50.0,45.0,47.0,42.0,36.0,48.0,46.0,38.0,70.0,62.0,50.0,59.0,30.0,43.0,76.0,53.0,76.0,50.0,63.0,40.0,45.0,39.0,42.0,54.0,49.0,55.0,51.0,70.0,47.0,83.0,62.0,36.0,59.0,59.0,59.0,46.0,55.0,56.0,40.0,59.0,53.0,36.0,50.0,57.0,50.0,53.0,62.0,41.0,73.0,57.0,49.0,38.0,48.0],\"xaxis\":\"x\",\"y\":[40.7,37.2,24.700000000000003,31.0,42.900000000000006,23.0,28.90000000000001,41.1,32.0,41.5,42.1,31.3,39.8,34.599999999999994,43.0,10.700000000000005,32.900000000000006,40.7,26.8,36.2,20.8,25.8,41.5,39.1,22.90000000000001,20.5,35.900000000000006,41.0,25.40000000000001,39.900000000000006,19.0,18.700000000000003,44.6,32.900000000000006,28.700000000000003,23.3,28.599999999999994,30.3,31.90000000000001,46.900000000000006,35.900000000000006,36.5,39.3,27.40000000000001,24.700000000000003,20.700000000000003,35.099999999999994,25.200000000000003,34.5,35.400000000000006,16.799999999999997,37.2,17.599999999999994,34.900000000000006,25.40000000000001,20.40000000000001,34.099999999999994,44.6,30.8,29.8,25.8,39.1,44.400000000000006,24.3,20.0,22.5,32.3,6.400000000000006,30.599999999999994,37.3,23.700000000000003,40.1,19.099999999999994,42.5,36.8,19.40000000000001,36.5,23.0,26.200000000000003,45.8,22.8,31.5,39.1,35.5,42.1,34.8,40.0,27.700000000000003,35.7,14.099999999999994,40.2,36.5,34.5,36.5,22.099999999999994,21.200000000000003,24.90000000000001,41.5,35.7,32.900000000000006,22.90000000000001,24.200000000000003,41.3,34.3,33.400000000000006,34.5,32.2,39.8,37.6,41.6,20.099999999999994,30.0,23.0,37.400000000000006,13.099999999999994,29.599999999999994,36.3,32.400000000000006,37.8,40.0,42.8,33.099999999999994,33.5,50.0,35.099999999999994,34.2,39.0,30.5,34.900000000000006,40.6,38.8,34.400000000000006,27.90000000000001,31.90000000000001,14.700000000000005,37.900000000000006,30.40000000000001,16.599999999999994,16.799999999999997,36.1,40.1,43.0,21.700000000000003,37.400000000000006,34.400000000000006,40.5,34.900000000000006,39.1,24.8,37.1,44.2,22.099999999999994,44.3,16.700000000000003,33.3,31.700000000000003,19.599999999999994,24.40000000000001,31.3,37.8,24.90000000000001,34.400000000000006,39.6,34.400000000000006,17.799999999999997,43.400000000000006,8.799999999999997,24.0,32.599999999999994,43.400000000000006,37.9,28.3,32.5,36.900000000000006,23.3,15.799999999999995,42.2,32.900000000000006,36.400000000000006,33.2,15.900000000000006,45.5,38.400000000000006,18.90000000000001,36.900000000000006,41.2,40.0,26.8,36.5,28.90000000000001,41.8,12.099999999999994,42.6,40.5,38.1,41.1,38.8,38.1,27.90000000000001,24.200000000000003,40.900000000000006,35.099999999999994,40.400000000000006,33.900000000000006,44.6,13.799999999999995,24.0,41.400000000000006,27.40000000000001,28.099999999999994,36.6,32.400000000000006,33.8,41.0,39.2,37.3,44.3,34.7,37.6,30.0,35.599999999999994,34.0,40.5,40.5,27.200000000000003,22.599999999999994,35.2,16.700000000000003,24.599999999999994,41.0,48.3,31.599999999999994,31.90000000000001,40.1,20.700000000000003,26.099999999999994,21.3,22.700000000000003,24.40000000000001,40.1,35.8,22.5,38.1,34.7,33.099999999999994,40.2,17.599999999999994,33.0,37.0,33.099999999999994,21.700000000000003,33.599999999999994,36.5,32.2,39.1,32.5,32.099999999999994,38.3,22.8,23.5,38.5,35.7,15.799999999999995,38.7,33.400000000000006,22.700000000000003,38.0,26.5,38.7,40.1,40.5,36.5,35.2,36.8,35.7,40.900000000000006,34.7,33.400000000000006,39.3,23.599999999999994,41.5,38.8,37.1,45.0,38.8,23.5,35.400000000000006,39.5,20.599999999999994,35.2,35.5,38.900000000000006,42.5,21.5,36.7,39.3,41.1,38.6,42.8,23.599999999999994,35.2,29.90000000000001,41.1,41.7,22.90000000000001,34.099999999999994,38.7,11.5,36.8,36.1,33.400000000000006,21.700000000000003,43.8,43.2,44.8,32.400000000000006,38.400000000000006,36.6,38.8,35.599999999999994,34.0,16.099999999999994,26.0,38.7,45.0,25.099999999999994,42.2,29.3,40.6,42.1,22.599999999999994,29.3,33.8,9.5,28.599999999999994,40.1,36.900000000000006,43.400000000000006,22.599999999999994,38.900000000000006,35.099999999999994,14.799999999999995,32.8,24.40000000000001,42.900000000000006,21.8,19.599999999999994,27.200000000000003,34.0,22.5,29.5,19.599999999999994,36.400000000000006,14.799999999999995,39.3,12.799999999999995,38.0,37.1,37.2,24.200000000000003,24.90000000000001,31.700000000000003,36.400000000000006,34.400000000000006,40.6,39.0,24.200000000000003,22.599999999999994,16.5,30.700000000000003,38.1,36.400000000000006,24.599999999999994,42.0,39.3,36.6,37.6,28.099999999999994,39.3,37.8,41.1,42.400000000000006,38.5,29.599999999999994,26.5,38.900000000000006,38.1,36.3,19.90000000000001,33.099999999999994,37.5,21.5,37.8,38.2,18.40000000000001,18.40000000000001,37.900000000000006,26.200000000000003,36.0,22.200000000000003,39.400000000000006,27.90000000000001,28.40000000000001,34.900000000000006,35.3,37.900000000000006,18.3,40.400000000000006,24.599999999999994,20.599999999999994,36.6,47.3,39.1,36.400000000000006,35.099999999999994,25.3,25.40000000000001,32.099999999999994,20.5,38.3,38.6,28.8,12.900000000000006,36.3,21.200000000000003,37.7,24.700000000000003,39.6,42.1,41.400000000000006,35.900000000000006,23.90000000000001,40.7,28.200000000000003,41.8,40.7,45.1,35.5,39.900000000000006,36.8,34.900000000000006,35.400000000000006,25.0,38.900000000000006,22.8,36.6,19.40000000000001,42.8,43.0,39.8,37.1,30.200000000000003,42.1,39.400000000000006,49.5,36.1,37.900000000000006,43.6,32.8,28.8,31.0,22.099999999999994,34.2,27.700000000000003,28.90000000000001,34.400000000000006,43.2,39.400000000000006,41.8,38.2,35.900000000000006,42.0,44.1,34.599999999999994,26.099999999999994,39.0,24.90000000000001,38.1,24.5,36.7,28.599999999999994,39.6,22.5,37.1,35.5,39.6,30.099999999999994,35.099999999999994,39.2,32.0,37.5,21.599999999999994,23.5,26.200000000000003,33.3,40.6,38.900000000000006,35.099999999999994,40.1,35.599999999999994,33.2,45.7,27.90000000000001,39.400000000000006,36.8,41.2,30.5,37.1,21.8,30.599999999999994,37.900000000000006,37.6,23.099999999999994,28.599999999999994,20.40000000000001,39.3,17.400000000000006,29.3,33.400000000000006,42.2,32.2,39.3,39.7,39.8,19.099999999999994,23.8,41.1,37.7,38.8,23.700000000000003,26.8,40.1,27.700000000000003,25.5,20.099999999999994,39.8,23.40000000000001,20.599999999999994,38.1,20.0,28.5,37.0,17.200000000000003,40.400000000000006,37.400000000000006,35.400000000000006,20.8,37.900000000000006,40.900000000000006,7.799999999999997,32.0,26.200000000000003,37.900000000000006,30.8,42.2,27.40000000000001,35.8,41.900000000000006,39.0,23.599999999999994,37.400000000000006,40.1,39.6,21.3,38.6,38.0,36.0,33.2,37.8,40.400000000000006,43.2,16.200000000000003,20.200000000000003,35.2,19.3,30.5,40.900000000000006,43.5,27.5,39.400000000000006,37.2,28.099999999999994,43.2,40.5,38.2,39.7,33.099999999999994,45.6,12.900000000000006,20.200000000000003,20.099999999999994,36.0,22.8,29.5,48.2,22.40000000000001,37.1,34.8,36.1,35.7,36.6,34.599999999999994,40.1,36.1,33.900000000000006,39.2,37.2,38.6,37.8,38.0,36.3,38.8,33.7,18.90000000000001,29.200000000000003,42.400000000000006,25.3,23.90000000000001,33.400000000000006,41.400000000000006,30.40000000000001,37.400000000000006,38.8,33.400000000000006,41.5,34.2,44.5,34.2,39.5,39.7,47.2,33.3,37.3,36.7,25.0,36.3,35.3,33.7,27.700000000000003,39.3,38.0,28.3,34.7,37.6,23.700000000000003,12.0,38.900000000000006,14.299999999999995,16.299999999999997,40.2,17.700000000000003,40.400000000000006,41.6,16.0,40.1,33.2,15.599999999999994,41.7,35.2,47.8,36.3,31.3,33.5,26.200000000000003,36.7,33.0,41.2,34.099999999999994,44.8,37.6,38.7,22.700000000000003,31.8,12.400000000000006,25.0,28.90000000000001,27.099999999999994,39.7,36.5,42.0,43.0,35.8,36.2,43.900000000000006,24.0,27.3,28.099999999999994,28.700000000000003,24.700000000000003,31.90000000000001,43.1,39.7,33.7,42.0,44.5,20.099999999999994,36.900000000000006,34.400000000000006,41.1,35.7,24.200000000000003,42.3,39.400000000000006,47.5,38.2,26.3,37.2,30.599999999999994,22.8,26.3,28.8,33.099999999999994,30.0,36.8,36.3,18.0,38.2,36.400000000000006,35.599999999999994,43.5,23.200000000000003,34.7,40.0,39.400000000000006,32.5,20.5,40.8,20.90000000000001,28.5,25.5,19.700000000000003,40.6,40.2,23.200000000000003,35.900000000000006,41.5,41.5,37.0,39.0,34.8,38.9,35.099999999999994,43.8,14.599999999999994,4.5,35.900000000000006,37.7,25.40000000000001,33.0,38.5,34.099999999999994,41.7,22.700000000000003,20.5,26.8,28.5,36.5,35.3,25.3,23.90000000000001,42.2,37.1,27.90000000000001,36.7,37.8,15.700000000000005,35.2,37.2,27.099999999999994,40.1,41.8,16.700000000000003,26.0,25.700000000000003,34.3,19.40000000000001,35.599999999999994,38.6,44.3,22.5,38.900000000000006,37.8,23.0,34.900000000000006,37.1,26.3,28.700000000000003,23.099999999999994,27.40000000000001,33.900000000000006,36.8,16.099999999999994,41.0,36.3,37.8,39.400000000000006,38.1,39.6,38.400000000000006,30.40000000000001,27.8,31.599999999999994,34.599999999999994,41.3,22.099999999999994,38.8,36.2,37.7,35.599999999999994,21.40000000000001,29.8,25.0,35.400000000000006,14.299999999999995,36.7,37.900000000000006,31.3,43.6,39.5,36.900000000000006,25.599999999999994,35.0,11.099999999999994,18.599999999999994,12.200000000000005,33.7,18.200000000000003,38.6,41.400000000000006,31.0,39.5,41.400000000000006,39.3,35.900000000000006,35.7,32.7,32.599999999999994,22.90000000000001,33.2,35.8,22.099999999999994,19.200000000000003,41.1,39.0,32.599999999999994,20.5,41.7,43.900000000000006,21.599999999999994,41.3,13.700000000000005,38.0,36.0,28.700000000000003,40.7,15.700000000000005,38.2,42.2,36.8,27.0,35.8,36.6,17.799999999999997,26.0,24.40000000000001,30.599999999999994,23.90000000000001,40.6,16.200000000000003,30.0,39.3,36.2,42.0,23.5,37.400000000000006,23.3,40.6,37.0,24.099999999999994,30.90000000000001,40.8,22.90000000000001,23.90000000000001,24.200000000000003,44.1,38.900000000000006,46.7,42.7,12.099999999999994,32.2,37.2,36.900000000000006,38.8,31.3,25.3,34.099999999999994,35.599999999999994,37.8,30.5,13.900000000000006,31.5,25.0,25.0,21.0,46.3,20.5,37.900000000000006,31.599999999999994,10.400000000000006,40.8,35.3,24.40000000000001,40.7,26.3,24.3,39.3,41.6,34.5,21.0,31.700000000000003,17.799999999999997,17.400000000000006,39.0,20.0,37.5,38.3,32.400000000000006,36.3,41.0,42.0,36.5,37.0,36.6,36.1,32.2,18.90000000000001,33.599999999999994,43.6,40.900000000000006,35.599999999999994,39.0,38.3,36.400000000000006,37.6,38.0,38.0,39.1,26.3,38.6,38.7,10.299999999999995,22.40000000000001,35.099999999999994,18.0,35.0,42.7,27.700000000000003,42.8,15.0,36.8,42.400000000000006,34.7,36.2,38.900000000000006,38.8,14.599999999999994,36.3,37.1,17.200000000000003,32.2,31.200000000000003,18.40000000000001,37.0,41.7,37.8,23.200000000000003,22.099999999999994,39.3,37.400000000000006,32.5,34.3,15.599999999999994,26.8,40.900000000000006,18.5,44.1,29.5,22.90000000000001,35.599999999999994,41.2,39.1,41.0,25.700000000000003,38.900000000000006,37.1,22.90000000000001,16.700000000000003,39.7,44.7,33.900000000000006,35.2,18.3,33.400000000000006,37.2,24.099999999999994,43.2,38.0,29.3,29.40000000000001,34.900000000000006,43.400000000000006,23.40000000000001,34.599999999999994,26.40000000000001,44.900000000000006,38.5,31.8,22.599999999999994,37.2,33.0,22.3,16.200000000000003,37.6,36.7,31.200000000000003,35.7,13.299999999999995,35.0,21.200000000000003,37.2,38.0,37.5,28.90000000000001,38.2,30.40000000000001,30.8,38.6,40.1,41.900000000000006,43.2,38.6,32.900000000000006,37.6,30.8,36.0,42.6,23.8,40.5,40.2,31.599999999999994,30.099999999999994,36.5,24.8,37.6,47.7,41.3,32.5,22.5,40.8,31.700000000000003,37.0,33.099999999999994,33.7,42.0,36.1,22.5,31.200000000000003,41.3,40.8,14.0,33.8,38.1,29.0,36.5,16.0,28.40000000000001,40.5,41.1,38.8,34.7,29.40000000000001,33.900000000000006,27.5,38.2,32.400000000000006,42.5,37.900000000000006,30.3,35.3,37.2,32.8,37.900000000000006,15.299999999999995,20.599999999999994,33.8,36.400000000000006,20.5,21.200000000000003,31.200000000000003,18.599999999999994,28.90000000000001,37.2,38.5,36.400000000000006,37.8,25.40000000000001,35.7,41.6,39.8,22.8,39.2,37.3,42.7,36.4,43.400000000000006,38.6,14.700000000000005,25.200000000000003,29.200000000000003,19.90000000000001,25.40000000000001,20.099999999999994,35.7,11.599999999999994,36.6,39.8,36.3,19.40000000000001,36.5,18.200000000000003,44.900000000000006,42.3,38.1,31.700000000000003,19.3,35.0,40.1,29.200000000000003,31.200000000000003,38.2,39.6,35.099999999999994,32.3,43.7,43.5,34.7,39.400000000000006,35.5,37.400000000000006,35.900000000000006,34.599999999999994,41.8,23.200000000000003,12.700000000000005,20.200000000000003,33.2,39.6,37.2,38.6,40.0,36.8,22.90000000000001,41.1,24.200000000000003,40.1,34.599999999999994,37.400000000000006,41.3,17.5,36.400000000000006,39.2,37.3,15.900000000000006,24.90000000000001,38.900000000000006,36.900000000000006,38.2,13.200000000000005,30.90000000000001,23.40000000000001,34.2,38.1,32.8,38.2,34.400000000000006,40.400000000000006,36.900000000000006,46.5,38.5,31.40000000000001,34.900000000000006,26.200000000000003,31.0,39.2,39.400000000000006,27.3,23.5,38.400000000000006,24.5,21.0,28.3,31.8,38.900000000000006,10.900000000000006,37.400000000000006,19.200000000000003,41.6,40.8,29.40000000000001,30.5,39.1,19.700000000000003,42.7,35.400000000000006,34.900000000000006,24.40000000000001,22.700000000000003,42.7,41.3,36.2,-0.0,33.3,21.5,34.3,33.2,35.0,38.2,38.8,35.8,37.0,39.3,28.0,37.7,37.8,21.099999999999994,37.1,42.6,41.3,35.5,28.599999999999994,38.2,28.8,25.0,11.400000000000006,19.3,19.0,21.5,35.099999999999994,38.7,39.8,42.3,14.900000000000006,14.099999999999994,42.1,38.2,36.2,25.599999999999994,33.900000000000006,17.900000000000006,11.400000000000006,43.8,35.2,37.900000000000006,18.099999999999994,34.099999999999994,33.400000000000006,42.0,38.7,28.8,31.8,39.1,42.2,38.1,34.599999999999994,23.599999999999994,33.099999999999994,35.2,42.900000000000006,39.6,32.8,17.700000000000003,35.7,33.3,23.0,36.400000000000006,28.40000000000001,36.8,37.8,37.0,25.200000000000003,24.5,38.5,38.900000000000006,39.400000000000006,33.400000000000006,34.3,13.700000000000005,32.3,37.3,38.8,17.200000000000003,22.0,24.599999999999994,16.700000000000003,34.2,33.2,22.5,18.5,22.5,35.5,13.799999999999995,19.099999999999994,41.400000000000006,38.400000000000006,21.0,27.5,39.0,38.400000000000006,34.7,34.8,35.8,30.700000000000003,39.3,32.900000000000006,36.400000000000006,40.1,33.2,45.6,37.3,33.900000000000006,29.5,37.7,23.0,11.099999999999994,35.5,29.40000000000001,39.2,37.900000000000006,39.2,26.8,36.0,19.700000000000003,29.90000000000001,20.200000000000003,36.900000000000006,39.1,36.900000000000006,35.599999999999994,17.200000000000003,37.8,19.200000000000003,17.900000000000006,25.099999999999994,27.099999999999994,34.3,30.5,37.8,39.900000000000006,32.3,37.0,33.400000000000006,21.200000000000003,30.700000000000003,36.6,41.2,41.6,41.3,26.40000000000001,38.7,35.8,38.6,24.3,41.2,37.1,20.200000000000003,36.7,32.8,32.0,36.2,32.599999999999994,23.90000000000001,23.3,24.5,33.900000000000006,43.2,17.599999999999994,40.400000000000006,35.400000000000006,28.200000000000003,38.5,36.7,25.200000000000003,26.3,16.299999999999997,22.200000000000003,38.400000000000006,36.6,24.099999999999994,36.2,26.90000000000001,17.799999999999997,28.599999999999994,40.5,23.200000000000003,45.0,15.799999999999995,43.900000000000006,15.200000000000005,43.1,37.7,36.0,27.200000000000003,41.6,35.099999999999994,30.90000000000001,35.599999999999994,17.700000000000003,32.3,35.900000000000006,37.0,41.6,23.099999999999994,38.2,38.1,38.5,30.0,28.099999999999994,37.1,30.200000000000003,34.5,35.599999999999994,22.0,29.700000000000003,38.2,39.3,40.7,34.8,18.90000000000001,19.5,39.0,27.0,40.1,17.599999999999994,26.40000000000001,36.900000000000006,30.5,32.2,28.40000000000001,26.3,35.0,32.400000000000006,40.2,37.400000000000006,46.7,42.900000000000006,38.0,22.90000000000001,39.2,37.0,35.099999999999994,36.7,29.90000000000001,34.0,37.8,37.400000000000006,35.5,23.0,29.3,36.6,43.1,40.3,41.1,42.5,37.5,40.1,36.3,37.8,34.900000000000006,19.599999999999994,33.5,20.700000000000003,18.599999999999994,39.8,38.3,32.2,41.1,41.1,30.5,40.8,31.0,42.400000000000006,26.099999999999994,28.90000000000001,39.8,15.400000000000006,35.5,35.599999999999994,45.6,25.5,13.400000000000006,34.3,39.7,31.099999999999994,36.8,40.0,40.8,31.5,15.5,38.3,25.0,16.799999999999997,19.90000000000001,40.900000000000006,32.8,23.099999999999994,39.0,33.900000000000006,23.599999999999994,27.40000000000001,28.8,40.5,30.0,14.400000000000006,41.5,24.700000000000003,30.700000000000003,35.400000000000006,38.8,43.2,26.8,43.400000000000006,20.40000000000001,34.599999999999994,14.5,38.8,35.3,41.3,37.5,26.8,41.8,24.700000000000003,42.1,34.5,30.200000000000003,18.3,41.6,41.0,24.099999999999994,41.8,38.400000000000006,17.900000000000006,33.3,23.40000000000001,34.7,41.900000000000006,13.5,36.900000000000006,31.599999999999994,31.8,22.099999999999994,38.3,38.3,35.3,40.1,23.599999999999994,15.599999999999994,26.5,42.7,40.0,19.8,40.5,35.400000000000006,37.6,33.400000000000006,38.0,13.700000000000005,7.799999999999997,42.400000000000006,39.400000000000006,34.099999999999994,36.2,40.1,40.900000000000006,19.3,37.400000000000006,42.3,23.90000000000001,27.40000000000001,41.5,44.8,40.5,40.8,17.400000000000006,39.8,35.0,42.0,38.5,25.700000000000003,25.700000000000003,19.90000000000001,21.8,17.700000000000003,17.400000000000006,36.900000000000006,30.700000000000003,36.400000000000006,34.099999999999994,27.200000000000003,36.900000000000006,30.099999999999994,31.200000000000003,36.6,42.1,32.599999999999994,36.3,38.7,37.4,35.8,33.5,39.3,34.099999999999994,27.700000000000003,9.599999999999994,33.0,30.599999999999994,21.5,25.0,40.3,41.0,37.900000000000006,20.3,29.90000000000001,39.6,24.5,37.8,33.400000000000006,44.1,37.1,29.200000000000003,35.099999999999994,38.6,21.099999999999994,36.1,37.400000000000006,42.3,36.5,37.6,26.700000000000003,17.299999999999997,21.40000000000001,34.0,44.0,36.3,30.599999999999994,44.7,43.5,20.099999999999994,22.0,29.8,24.3,35.7,34.3,42.8,39.6,27.3,19.8,35.8,37.7,31.099999999999994,23.5,20.599999999999994,24.0,39.6,22.099999999999994,29.700000000000003,37.6,37.3,39.900000000000006,31.200000000000003,24.40000000000001,41.6,36.6,34.5,21.40000000000001,36.0,35.5,42.6,39.6,39.400000000000006,39.2,38.8,24.40000000000001,13.900000000000006,23.099999999999994,22.200000000000003,37.6,35.900000000000006,41.7,26.8,35.599999999999994,35.900000000000006,38.8,39.6,40.3,36.900000000000006,36.7,23.8,31.8,34.8,37.3,42.1,24.40000000000001,34.900000000000006,40.5,26.90000000000001,43.3,33.599999999999994,22.0,37.8,25.90000000000001,21.099999999999994,22.200000000000003,38.400000000000006,33.900000000000006,30.099999999999994,24.200000000000003,36.7,40.0,23.599999999999994,33.8,38.900000000000006,17.700000000000003,37.7,36.400000000000006,33.099999999999994,21.599999999999994,30.0,37.8,25.5,34.400000000000006,25.8,42.0,36.6,20.5,37.2,25.8,39.1,33.0,40.2,31.40000000000001,43.2,23.5,19.3,16.299999999999997,21.90000000000001,25.0,29.5,36.6,43.0,37.2,39.0,16.200000000000003,38.2,34.3,17.0,44.5,33.599999999999994,25.5,34.8,25.40000000000001,19.8,29.0,35.5,37.7,42.3,42.3,25.90000000000001,30.3,30.8,9.900000000000006,34.0,44.0,35.099999999999994,37.8,31.3,21.700000000000003,38.6,34.3,30.0,21.099999999999994,38.8,20.8,21.40000000000001,21.3,37.6,41.400000000000006,34.2,46.400000000000006,39.900000000000006,43.900000000000006,33.2,38.5,37.6,20.8,20.3,37.400000000000006,41.2,41.6,35.599999999999994,37.400000000000006,36.7,38.900000000000006,38.5,31.099999999999994,38.5,20.200000000000003,33.3,41.1,33.7,33.3,41.3,38.900000000000006,6.5,31.599999999999994,40.400000000000006,23.3,43.6,27.3,26.0,34.3,39.5,38.3,42.6,40.5,30.700000000000003,38.0,37.6,40.2,29.099999999999994,41.0,25.90000000000001,34.400000000000006,17.5,38.2,39.8,31.90000000000001,39.6,29.90000000000001,34.099999999999994,39.3,40.2,36.1,28.700000000000003,34.0,42.3,11.0,40.0,41.1,24.599999999999994,37.5,34.099999999999994,35.900000000000006,39.7,11.599999999999994,26.200000000000003,38.400000000000006,21.3,37.2,27.599999999999994,29.90000000000001,38.5,39.0,39.400000000000006,19.40000000000001,36.5,36.5,28.0,37.8,38.400000000000006,40.5,41.8,44.900000000000006,31.5,39.2,26.099999999999994,37.5,36.0,35.099999999999994,41.0,36.0,23.0,34.0,38.0,36.8,42.0,39.6,20.599999999999994,26.3,37.900000000000006,29.40000000000001,27.0,13.200000000000005,40.1,39.1,40.0,35.900000000000006,22.3,28.0,34.099999999999994,38.5,38.0,32.900000000000006,44.400000000000006,36.2,39.3,40.8,29.40000000000001,37.3,38.8,17.599999999999994,28.8,29.3,35.599999999999994,41.8,41.0,33.7,35.2,33.5,22.5,25.599999999999994,42.400000000000006,39.6,38.0,45.2,37.0,38.2,34.099999999999994,26.5,26.700000000000003,39.8,37.900000000000006,15.0,17.299999999999997,39.7,9.200000000000005,15.099999999999994,24.3,34.0,35.3,37.400000000000006,43.0,32.099999999999994,20.599999999999994,36.8,17.700000000000003,33.0,40.8,36.5,24.3,36.0,28.0,36.400000000000006,40.5,32.900000000000006,36.900000000000006,20.0,37.2,39.7,19.700000000000003,39.1,35.7,43.3,20.8,29.099999999999994,37.5,39.6,45.3,38.6,35.8,21.3,38.7,26.200000000000003,34.3,24.40000000000001,32.099999999999994,34.5,24.40000000000001,40.1,39.0,39.5,39.7,39.1,32.0,44.7,34.2,34.3,38.7,20.8,41.5,35.5,33.400000000000006,36.2,29.200000000000003,37.3,36.8,45.400000000000006,18.0,35.900000000000006,34.5,30.599999999999994,25.700000000000003,24.90000000000001,35.0,34.0,34.400000000000006,33.3,43.3,28.099999999999994,17.900000000000006,39.5,34.099999999999994,37.1,25.3,36.8,39.5,33.5,44.7,21.3,39.5,27.200000000000003,17.200000000000003,35.3,25.8,43.8,38.3,38.7,37.900000000000006,23.3,31.8,22.099999999999994,32.599999999999994,38.0,34.8,38.400000000000006,37.2,19.8,42.1,43.8,38.6,36.6,39.7,36.2,21.8,37.2,25.099999999999994,22.8,43.400000000000006,40.8,33.0,34.400000000000006,22.40000000000001,27.40000000000001,43.1,40.900000000000006,36.900000000000006,40.0,34.400000000000006,40.400000000000006,38.0,15.799999999999995,34.7,40.8,34.599999999999994,28.3,41.2,27.200000000000003,31.200000000000003,34.900000000000006,37.900000000000006,38.7,21.3,35.900000000000006,40.1,39.6,19.200000000000003,36.0,35.7,26.099999999999994,34.099999999999994,24.200000000000003,40.8,37.7,40.1,39.5,34.3,21.3,39.5,27.099999999999994,42.400000000000006,25.099999999999994,22.3,32.3,31.40000000000001,35.0,8.599999999999994,39.400000000000006,26.8,33.7,43.0,39.7,24.200000000000003,37.0,25.0,37.8,39.2,33.099999999999994,37.7,35.099999999999994,22.5,36.0,13.599999999999994,12.599999999999994,35.7,42.400000000000006,39.4,35.900000000000006,37.3,38.5,40.3,33.0,35.3,39.6,27.40000000000001,25.0,40.400000000000006,37.5,40.400000000000006,37.8,23.5,31.90000000000001,22.0,41.7,19.599999999999994,28.90000000000001,20.0,35.2,41.3,40.400000000000006,39.7,35.3,22.5,20.90000000000001,34.0,36.8,26.599999999999994,33.3,38.2,41.3,41.5,25.3,32.0,35.3,41.1,37.6,34.7,38.400000000000006,31.40000000000001,36.0,37.400000000000006,40.8,33.599999999999994,23.0,25.0,37.3,42.7,34.8,34.8,34.400000000000006,21.8,21.5,24.8,35.0,41.0,31.099999999999994,32.7,32.8,37.3,25.099999999999994,37.6,37.6,34.599999999999994,24.200000000000003,25.0,19.099999999999994,15.700000000000005,35.5,17.799999999999997,20.700000000000003,41.0,25.40000000000001,36.0,19.3,25.0,33.900000000000006,12.400000000000006,29.200000000000003,16.299999999999997,39.3,39.8,25.90000000000001,40.6,25.8,36.1,38.7,29.0,46.900000000000006,34.5,38.0,38.7,34.900000000000006,21.0,39.1,30.700000000000003,39.3,36.400000000000006,21.8,36.5,45.5,34.599999999999994,36.7,27.3,35.5,35.900000000000006,41.900000000000006,37.900000000000006,38.5,21.700000000000003,39.400000000000006,22.0,25.5,35.8,16.200000000000003,24.599999999999994,39.7,37.3,38.3,26.599999999999994,16.200000000000003,35.099999999999994,10.5,40.1,35.599999999999994,41.8,33.7,37.8,31.0,46.0,37.0,37.0,13.799999999999995,30.200000000000003,38.7,38.6,46.400000000000006,21.40000000000001,39.7,34.5,31.099999999999994,41.8,41.3,40.2,38.2,41.1,39.7,35.400000000000006,42.0,39.7,40.3,22.3,38.400000000000006,38.1,39.0,39.8,25.5,36.0,35.400000000000006,41.6,37.3,43.0,21.90000000000001,42.2,37.5,33.3,33.0,23.099999999999994,41.6,33.400000000000006,37.5,37.400000000000006,45.6,18.3,25.5,38.7,32.3,27.3,39.0,38.1,31.099999999999994,41.5,23.90000000000001,39.1,17.400000000000006,35.8,38.7,39.6,45.7,41.400000000000006,22.40000000000001,43.900000000000006,38.8,21.40000000000001,33.5,17.900000000000006,40.900000000000006,35.400000000000006,31.099999999999994,36.6,42.5,36.2,33.5,40.900000000000006,42.2,40.400000000000006,39.0,32.7,33.7,39.1,21.599999999999994,31.3,27.200000000000003,37.1,41.2,43.8,17.0,9.900000000000006,35.099999999999994,35.099999999999994,37.7,42.1,33.3,24.90000000000001,42.6,31.700000000000003,17.099999999999994,39.3,33.3,29.40000000000001,31.0,15.799999999999995,23.90000000000001,39.1,38.1,36.6,45.6,17.700000000000003,35.900000000000006,13.200000000000005,22.3,37.8,27.3,36.9,36.4,28.700000000000003,42.3,26.3,40.0,37.6,40.900000000000006,38.900000000000006,32.599999999999994,36.7,35.599999999999994,35.5,37.900000000000006,35.5,42.8,36.2,25.700000000000003,24.099999999999994,39.3,40.1,39.3,24.8,27.40000000000001,35.7,39.900000000000006,30.90000000000001,40.8,30.099999999999994,14.799999999999995,19.5,43.7,33.7,19.3,32.400000000000006,34.0,30.599999999999994,33.5,36.1,36.900000000000006,19.90000000000001,40.400000000000006,38.2,35.3,34.3,33.099999999999994,36.3,31.40000000000001,40.400000000000006,37.3,32.5,25.099999999999994,26.700000000000003,33.599999999999994,41.0,39.3,15.400000000000006,37.400000000000006,39.6,17.099999999999994,37.2,36.1,28.90000000000001,25.099999999999994,38.6,27.5,41.5,17.799999999999997,20.40000000000001,36.0,18.8,32.400000000000006,42.1,37.7,39.1,7.200000000000003,37.2,28.599999999999994,20.3,37.400000000000006,15.299999999999995,34.8,33.599999999999994,36.400000000000006,30.0,27.5,37.0,25.5,30.200000000000003,23.700000000000003,20.099999999999994,20.8,41.5,34.900000000000006,30.40000000000001,37.0,41.3,22.200000000000003,35.5,23.0,25.8,37.400000000000006,42.1,36.3,36.6,44.1,37.5,33.0,39.900000000000006,23.0,39.6,32.8,35.400000000000006,37.8,41.8,19.90000000000001,18.700000000000003,36.3,39.2,20.40000000000001,38.900000000000006,39.900000000000006,35.5,33.7,28.3,36.1,37.3,45.3,37.900000000000006,35.8,43.0,34.099999999999994,41.7,34.7,39.2,39.7,43.2,40.6,40.7,40.5,29.90000000000001,38.7,36.5,40.6,24.40000000000001,28.8,40.3,36.400000000000006,37.3,31.5,37.7,44.0,30.3,36.0,33.7,30.599999999999994,21.099999999999994,41.6,36.3,37.6,40.7,37.3,23.700000000000003,38.5,41.8,35.099999999999994,47.8,10.200000000000005,34.2,41.1,41.1,37.7,38.0,34.599999999999994,39.900000000000006,38.1,41.900000000000006,38.400000000000006,23.700000000000003,20.200000000000003,21.5,31.099999999999994,38.6,33.5,33.3,40.900000000000006,38.7,34.099999999999994,22.200000000000003,27.200000000000003,19.8,33.099999999999994,35.900000000000006,40.400000000000006,45.900000000000006,39.1,34.7,23.8,30.3,35.3,36.6,40.1,38.8,36.0,25.0,36.400000000000006,31.5,24.8,32.900000000000006,20.0,43.1,26.700000000000003,29.3,39.2,26.8,38.0,24.3,39.2,41.900000000000006,29.099999999999994,38.0,21.8,35.8,38.5,35.2,36.2,33.400000000000006,18.099999999999994,35.900000000000006,24.3,18.90000000000001,14.900000000000006,29.0,20.40000000000001,18.5,39.400000000000006,37.2,40.3,32.0,24.099999999999994,40.3,26.8,29.40000000000001,40.400000000000006,37.3,13.299999999999995,38.5,34.5,42.5,20.8,45.3,35.099999999999994,29.0,35.0,24.200000000000003,35.8,30.0,35.2,22.40000000000001,37.1,25.0,29.3,19.0,35.599999999999994,40.900000000000006,35.7,38.900000000000006,39.0,29.5,16.0,27.5,20.099999999999994,28.5,28.3,24.0,37.3,40.1,27.099999999999994,37.1,22.8,39.2,40.8,31.700000000000003,37.6,27.3,43.2,40.5,41.1,17.400000000000006,30.8,37.6,40.7,37.7,29.90000000000001,37.1,25.3,28.5,42.400000000000006,41.2,29.5,38.6,38.8,12.799999999999995,40.2,33.5,15.5,44.5,18.0,34.5,38.1,39.1,36.7,16.799999999999997,43.3,22.90000000000001,39.0,36.400000000000006,29.90000000000001,16.0,36.7,22.8,13.299999999999995,24.200000000000003,22.90000000000001,30.90000000000001,34.7,32.400000000000006,17.599999999999994,38.2,45.400000000000006,42.0,41.5,39.8,17.5,33.2,20.700000000000003,40.400000000000006,36.400000000000006,33.599999999999994,27.5,37.8,24.5,23.90000000000001,44.400000000000006,38.1,43.0,35.099999999999994,38.5,36.400000000000006,40.400000000000006,38.5,38.3,37.8,16.700000000000003,26.40000000000001,44.900000000000006,41.0,35.3,23.0,24.700000000000003,26.5,20.200000000000003,36.900000000000006,30.5,26.3,26.099999999999994,34.900000000000006,34.599999999999994,43.2,42.0,37.1,34.7,41.5,22.90000000000001,17.900000000000006,43.2,38.400000000000006,41.0,36.8,13.200000000000005,37.900000000000006,36.7,40.0,36.3,39.8,18.8,39.0,39.400000000000006,26.5,39.900000000000006,36.5,41.1,41.3,21.8,36.6,43.900000000000006,38.900000000000006,37.0,39.0,39.1,37.6,32.0,43.2,41.1,28.700000000000003,33.099999999999994,39.5,27.599999999999994,17.099999999999994,36.0,34.0,39.1,33.099999999999994,26.099999999999994,20.700000000000003,42.1,40.400000000000006,23.8,38.5,39.2,38.6,39.2,33.099999999999994,38.400000000000006,39.8,42.900000000000006,40.0,37.0,24.8,21.200000000000003,36.0,39.900000000000006,40.3,37.400000000000006,11.900000000000006,39.1,41.400000000000006,38.3,44.3,38.0,26.599999999999994,43.900000000000006,37.7,41.8,35.099999999999994,41.400000000000006,37.6,37.0,21.90000000000001,38.0,26.700000000000003,37.900000000000006,36.2,22.0,19.700000000000003,45.7,39.8,30.0,27.099999999999994,24.40000000000001,28.5,36.6,24.90000000000001,43.900000000000006,32.5,27.8,37.6,22.0,43.5,23.599999999999994,41.2,21.099999999999994,24.099999999999994,32.5,18.599999999999994,35.3,13.700000000000005,37.2,37.6,37.6,35.8,39.1,25.90000000000001,41.2,37.6,38.5,41.6,33.599999999999994,34.7,29.599999999999994,38.0,22.90000000000001,16.0,23.200000000000003,39.8,35.099999999999994,21.099999999999994,39.3,38.6,33.5,37.6,22.90000000000001,35.7,37.900000000000006,36.8,36.6,32.900000000000006,44.2,38.2,26.5,40.400000000000006,44.8,26.40000000000001,32.0,24.700000000000003,32.400000000000006,40.5,39.4,38.0,28.0,40.5,31.599999999999994,35.599999999999994,38.7,32.8,40.5,24.0,36.3,34.8,41.1,26.5,39.400000000000006,36.0,37.1,40.2,34.3,41.1,35.5,23.200000000000003,20.8,27.90000000000001,34.8,9.799999999999995,36.3,43.3,23.40000000000001,35.900000000000006,36.2,17.400000000000006,25.3,42.8,36.8,41.2,18.40000000000001,37.400000000000006,40.1,8.099999999999994,38.3,35.0,35.599999999999994,41.900000000000006,16.900000000000006,31.3,35.5,21.5,28.700000000000003,38.5,41.3,32.5,33.8,40.6,40.400000000000006,36.3,38.0,38.2,34.2,36.0,29.099999999999994,30.90000000000001,38.1,33.099999999999994,39.3,38.6,38.400000000000006,22.3,20.3,13.299999999999995,35.5,45.900000000000006,33.2,39.900000000000006,42.1,22.8,37.7,41.6,37.6,39.5,22.8,34.8,40.0,39.900000000000006,40.0,28.700000000000003,19.599999999999994,17.599999999999994,21.700000000000003,34.7,30.90000000000001,43.5,40.6,19.5,40.7,35.400000000000006,35.0,40.7,41.3,35.2,13.299999999999995,38.2,39.0,36.1,37.7,23.099999999999994,26.099999999999994,42.1,20.90000000000001,25.0,32.599999999999994,34.5,42.5,34.0,36.2,39.3,24.8,35.8,41.5,30.8,42.5,37.3,29.599999999999994,22.90000000000001,39.3,35.2,36.1,38.1,30.200000000000003,30.200000000000003,14.900000000000006,42.2,26.8,37.2,36.5,40.0,34.3,38.400000000000006,27.40000000000001,33.8,32.099999999999994,22.700000000000003,38.400000000000006,42.7,19.0,38.3,43.1,22.099999999999994,41.6,38.900000000000006,38.2,38.3,17.799999999999997,35.7,39.6,23.40000000000001,37.400000000000006,23.700000000000003,37.6,35.3,36.3,36.4,24.90000000000001,24.0,29.8,20.90000000000001,10.799999999999995,41.2,34.900000000000006,35.7,27.200000000000003,30.0,30.3,42.8,39.6,42.1,38.8,39.0,37.9,36.0,38.5,21.5,39.8,41.6,42.2,26.3,40.0,42.8,33.0,19.90000000000001,45.6,37.7,30.599999999999994,38.2,27.700000000000003,24.8,20.700000000000003,17.400000000000006,30.0,25.90000000000001,16.299999999999997,17.200000000000003,34.400000000000006,36.400000000000006,36.2,18.40000000000001,42.3,32.7,19.3,30.099999999999994,35.3,37.900000000000006,26.599999999999994,28.700000000000003,42.400000000000006,13.900000000000006,34.7,22.40000000000001,38.8,18.5,32.400000000000006,27.599999999999994,35.7,32.599999999999994,18.5,38.1,16.0,37.6,37.400000000000006,39.1,23.5,38.1,39.7,26.0,38.1,28.40000000000001,36.5,41.5,37.3,22.5,39.7,15.900000000000006,35.5,17.700000000000003,31.200000000000003,34.5,32.7,44.6,39.0,38.6,26.8,39.8,44.1,21.200000000000003,13.099999999999994,40.6,41.7,34.8,16.0,40.3,42.5,40.5,20.0,34.7,36.3,43.5,39.400000000000006,38.1,27.099999999999994,42.2,39.1,39.8,18.700000000000003,39.8,34.7,37.5,23.40000000000001,36.3,42.2,39.1,39.5,23.8,29.40000000000001,24.90000000000001,45.0,28.5,28.099999999999994,36.900000000000006,40.400000000000006,26.099999999999994,40.400000000000006,43.3,41.5,29.90000000000001,40.6,40.0,35.599999999999994,22.40000000000001,36.7,33.3,34.0,24.599999999999994,37.1,27.599999999999994,23.8,17.0,31.099999999999994,32.900000000000006,41.5,46.3,27.099999999999994,16.200000000000003,30.599999999999994,32.900000000000006,40.0,38.8,20.099999999999994,12.0,37.0,32.7,34.900000000000006,24.700000000000003,32.599999999999994,36.8,27.0,42.1,40.7,35.900000000000006,37.3,20.40000000000001,29.700000000000003,36.8,19.40000000000001,42.400000000000006,27.200000000000003,41.5,23.5,19.599999999999994,38.1,20.5,20.5,41.5,32.7,23.5,40.8,24.0,37.1,48.8,43.3,39.3,39.3,36.2,24.0,28.90000000000001,39.3,31.200000000000003,34.599999999999994,32.3,43.6,37.5,37.3,18.8,33.7,36.2,39.2,24.90000000000001,25.200000000000003,17.299999999999997,20.3,26.8,40.0,15.700000000000005,43.1,42.1,32.5,21.8,36.400000000000006,38.3,37.0,41.1,44.0,43.900000000000006,36.0,40.0,34.5,40.8,42.6,28.8,35.5,32.0,35.099999999999994,23.5,37.7,34.900000000000006,46.400000000000006,23.200000000000003,31.599999999999994,42.3,34.099999999999994,34.7,21.0,37.400000000000006,38.900000000000006,39.7,37.3,33.2,38.3,36.900000000000006,23.5,38.7,39.0,35.8,39.5,36.7,34.400000000000006,37.900000000000006,30.8,39.3,39.8,38.6,40.900000000000006,17.299999999999997,36.0,37.6,31.099999999999994,31.099999999999994,34.900000000000006,16.0,41.0,31.200000000000003,40.7,8.700000000000003,38.7,41.5,16.700000000000003,41.2,35.900000000000006,38.3,36.900000000000006,37.0,32.2,37.0,27.0,37.0,5.599999999999994,26.700000000000003,33.7,30.599999999999994,22.8,41.0,44.3,41.0,23.700000000000003,23.099999999999994,36.1,26.40000000000001,34.900000000000006,35.8,33.400000000000006,25.8,36.900000000000006,39.7,27.90000000000001,41.2,27.40000000000001,13.0,26.5,23.8,38.6,37.7,31.099999999999994,35.0,32.7,26.3,39.6,38.8,37.6,38.3,27.200000000000003,37.8,37.8,19.599999999999994,39.0,38.1,29.099999999999994,36.7,37.8,42.7,17.200000000000003,41.6,43.6,30.90000000000001,31.099999999999994,39.400000000000006,39.1,13.599999999999994,12.700000000000005,24.200000000000003,28.0,39.400000000000006,35.900000000000006,13.400000000000006,35.3,30.599999999999994,41.5,41.2,32.900000000000006,43.5,17.799999999999997,17.5,44.3,41.7,39.8,42.7,33.3,40.400000000000006,34.8,43.0,40.7,36.1,33.0,35.0,34.3,39.1,36.7,42.2,26.099999999999994,41.900000000000006,20.40000000000001,40.8,14.400000000000006,26.200000000000003,35.099999999999994,11.900000000000006,38.8,15.200000000000005,38.8,37.5,37.400000000000006,36.7,18.3,35.900000000000006,31.200000000000003,31.0,30.0,27.599999999999994,36.3,34.7,25.200000000000003,24.90000000000001,39.3,19.599999999999994,33.0,42.6,22.200000000000003,24.700000000000003,27.0,45.5,37.8,38.1,37.8,38.0,13.599999999999994,43.5,21.40000000000001,19.0,32.099999999999994,34.400000000000006,34.900000000000006,40.7,26.90000000000001,35.900000000000006,31.099999999999994,34.2,33.599999999999994,38.1,39.0,13.400000000000006,38.900000000000006,39.400000000000006,42.3,14.099999999999994,31.3,33.400000000000006,40.7,41.900000000000006,40.7,39.7,37.7,35.900000000000006,14.400000000000006,31.0,39.8,14.900000000000006,38.6,34.8,36.900000000000006,40.8,15.099999999999994,34.0,25.3,34.7,38.900000000000006,18.700000000000003,40.2,19.200000000000003,40.0,34.8,37.7,37.6,19.90000000000001,38.3,24.40000000000001,36.0,40.400000000000006,29.200000000000003,15.200000000000005,40.7,40.8,32.2,35.099999999999994,28.599999999999994,10.5,26.90000000000001,31.90000000000001,24.40000000000001,37.8,20.5,43.7,31.3,39.0,33.900000000000006,42.3,37.3,37.400000000000006,28.200000000000003,23.700000000000003,34.599999999999994,31.0,22.200000000000003,11.900000000000006,38.2,25.8,41.900000000000006,37.8,37.7,15.299999999999995,40.900000000000006,36.6,23.200000000000003,40.1,39.0,38.5,37.900000000000006,39.400000000000006,10.099999999999994,17.0,27.90000000000001,33.5,37.1,35.3,37.8,39.0,43.400000000000006,39.2,34.900000000000006,35.2,22.0,33.0,40.3,39.900000000000006,38.2,37.900000000000006,41.5,34.900000000000006,25.099999999999994,33.5,18.200000000000003,28.8,34.599999999999994,39.7,33.099999999999994,34.3,41.900000000000006,39.400000000000006,44.2,24.0,40.1,39.1,38.400000000000006,28.700000000000003,34.3,38.900000000000006,24.40000000000001,45.3,38.400000000000006,37.7,36.900000000000006,39.1,41.2,43.0,38.1,22.099999999999994,41.400000000000006,33.900000000000006,39.3,41.2,38.5,20.200000000000003,38.6,33.099999999999994,40.5,36.5,43.1,34.099999999999994,21.40000000000001,40.3,25.099999999999994,24.0,36.7,28.90000000000001,33.900000000000006,40.900000000000006,19.700000000000003,37.2,28.099999999999994,33.2,42.0,33.2,33.400000000000006,41.0,19.3,39.6,29.90000000000001,39.3,44.0,35.900000000000006,42.0,34.0,31.8,36.6,36.1,41.900000000000006,36.1,36.900000000000006,36.5,44.8,39.0,39.400000000000006,32.5,43.0,34.7,17.700000000000003,40.0,41.5,38.0,24.200000000000003,35.8,37.0,18.0,39.6,37.7,36.400000000000006,43.6,36.400000000000006,36.8,31.200000000000003,12.599999999999994,35.8,36.8,23.40000000000001,29.3,29.40000000000001,43.0,38.5,34.7,37.9,23.700000000000003,13.900000000000006,37.0,39.8,38.5,29.700000000000003,19.599999999999994,37.3,23.40000000000001,39.1,38.7,37.2,18.40000000000001,28.40000000000001,42.8,19.700000000000003,27.0,37.1,25.200000000000003,37.400000000000006,37.7,36.5,41.3,39.6,27.5,23.3,42.5,37.6,29.8,31.90000000000001,25.90000000000001,34.7,25.599999999999994,38.1,43.0,43.3,38.400000000000006,40.8,31.0,41.3,36.3,13.799999999999995,23.200000000000003,39.7,35.8,34.2,32.0,31.3,18.90000000000001,19.200000000000003,35.7,25.599999999999994,36.6,24.3,40.8,24.0,35.900000000000006,20.3,40.6,34.099999999999994,33.2,45.2,29.90000000000001,39.900000000000006,22.5,46.1,18.700000000000003,31.90000000000001,43.5,36.900000000000006,41.0,33.2,36.2,23.3,24.8,37.400000000000006,36.6,25.700000000000003,37.7,17.700000000000003,36.1,32.900000000000006,31.5,45.900000000000006,29.0,38.7,32.7,19.200000000000003,23.8,32.599999999999994,38.0,34.900000000000006,27.40000000000001,30.90000000000001,22.3,40.0,33.099999999999994,18.90000000000001,38.1,38.1,36.5,37.8,32.8,36.0,21.5,36.3,48.5,47.5,38.900000000000006,36.3,29.5,26.099999999999994,34.599999999999994,39.0,23.5,19.200000000000003,28.099999999999994,27.8,32.900000000000006,36.5,40.900000000000006,39.2,36.5,25.0,39.8,43.0,29.599999999999994,38.8,20.700000000000003,41.8,28.0,23.200000000000003,21.200000000000003,37.6,38.900000000000006,33.2,25.5,23.0,24.8,35.8,23.200000000000003,26.099999999999994,38.2,39.7,37.900000000000006,24.099999999999994,38.7,27.8,25.099999999999994,39.3,36.9,40.400000000000006,39.0,39.7,37.8,21.700000000000003,20.5,42.2,41.0,37.8,36.400000000000006,19.0,29.599999999999994,36.400000000000006,20.90000000000001,42.7,25.099999999999994,39.7,30.90000000000001,15.099999999999994,35.400000000000006,12.099999999999994,34.900000000000006,26.0,34.8,32.0,40.900000000000006,35.099999999999994,29.0,34.7,41.900000000000006,39.0,37.5,42.7,37.8,34.599999999999994,48.2,16.599999999999994,38.400000000000006,42.3,22.200000000000003,35.599999999999994,36.7,12.5,20.5,36.3,14.900000000000006,29.5,26.40000000000001,39.0,26.700000000000003,41.400000000000006,39.1,22.5,35.8,37.7,39.7,30.099999999999994,36.5,39.2,16.200000000000003,29.8,31.099999999999994,22.099999999999994,37.2,26.200000000000003,31.599999999999994,12.700000000000005,42.0,18.200000000000003,39.1,38.900000000000006,40.400000000000006,42.6,23.3,37.8,38.6,44.900000000000006,35.400000000000006,35.400000000000006,25.8,28.599999999999994,34.7,27.200000000000003,39.8,34.900000000000006,23.3,30.700000000000003,35.900000000000006,40.5,24.90000000000001,33.099999999999994,18.700000000000003,27.200000000000003,25.40000000000001,21.700000000000003,38.8,30.40000000000001,36.900000000000006,39.6,31.700000000000003,13.700000000000005,36.2,33.400000000000006,40.7,39.6,37.6,38.5,41.3,31.599999999999994,25.700000000000003,34.099999999999994,43.6,16.799999999999997,31.099999999999994,32.599999999999994,40.0,38.8,21.40000000000001,30.8,42.3,31.8,36.8,33.5,38.400000000000006,33.400000000000006,38.1,29.8,30.200000000000003,37.2,22.8,36.5,37.0,36.3,16.299999999999997,31.40000000000001,12.599999999999994,35.3,19.599999999999994,38.900000000000006,41.2,39.2,40.7,39.1,32.5,39.2,36.2,39.900000000000006,36.8,34.0,21.3,34.5,36.1,23.5,41.2,24.599999999999994,37.8,40.3,39.0,22.099999999999994,24.8,19.3,33.599999999999994,40.6,35.099999999999994,24.5,35.2,38.0,33.8,41.0,27.700000000000003,39.1,33.7,36.1,26.599999999999994,28.200000000000003,22.5,38.3,32.5,38.7,36.8,40.9,39.8,25.3,19.0,26.200000000000003,42.8,14.799999999999995,20.3,31.200000000000003,32.5,35.2,42.7,33.2,35.2,37.8,40.3,26.8,33.900000000000006,43.400000000000006,34.400000000000006,26.700000000000003,35.3,39.2,34.5,37.400000000000006,36.8,38.0,37.400000000000006,38.2,38.1,39.3,34.5,42.900000000000006,35.099999999999994,17.400000000000006,25.599999999999994,32.099999999999994,42.5,25.0,40.3,23.90000000000001,41.0,32.099999999999994,18.700000000000003,27.90000000000001,36.0,37.2,39.8,38.7,28.099999999999994,31.599999999999994,30.8,16.900000000000006,35.7,36.400000000000006,34.400000000000006,23.700000000000003,23.099999999999994,38.6,37.8,38.3,43.6,37.0,35.099999999999994,37.400000000000006,43.2,38.8,26.40000000000001,39.2,36.6,35.5,25.099999999999994,36.2,36.900000000000006,41.400000000000006,43.2,41.8,35.599999999999994,25.3,38.5,37.7,38.0,37.8,38.1,34.599999999999994,13.799999999999995,40.400000000000006,16.700000000000003,44.2,40.8,25.599999999999994,35.0,35.0,39.8,13.400000000000006,40.5,35.099999999999994,33.2,28.8,33.0,40.3,36.8,36.7,40.3,38.3,41.1,22.3,14.200000000000005,20.700000000000003,36.7,39.0,36.0,12.299999999999995,33.900000000000006,41.3,33.900000000000006,34.2,39.6,35.599999999999994,11.099999999999994,38.7,40.400000000000006,41.400000000000006,40.7,26.5,35.5,36.2,21.90000000000001,38.8,41.3,36.1,43.8,31.40000000000001,30.8,12.200000000000005,38.0,12.200000000000005,27.40000000000001,37.400000000000006,26.90000000000001,34.8,37.3,42.7,33.8,19.0,35.400000000000006,33.8,39.900000000000006,19.40000000000001,42.0,34.099999999999994,41.7,23.0,36.900000000000006,27.8,39.7,34.7,33.0,23.0,42.5,36.3,23.8,43.1,38.1,35.2,39.900000000000006,38.900000000000006,40.5,39.3,35.3,38.2,37.7,23.0,36.1,37.0,42.0,16.400000000000006,34.099999999999994,37.8,43.7,24.40000000000001,42.0,38.1,38.3,26.3,23.0,39.900000000000006,39.3,35.900000000000006,27.599999999999994,38.7,31.0,42.0,44.400000000000006,35.599999999999994,19.40000000000001,35.5,28.40000000000001,38.6,25.700000000000003,40.0,38.6,24.599999999999994,24.200000000000003,33.2,20.099999999999994,31.40000000000001,21.3,28.40000000000001,37.1,37.1,25.3,27.5,17.400000000000006,25.90000000000001,32.7,36.7,23.200000000000003,29.200000000000003,39.0,33.099999999999994,38.0,39.6,41.1,28.700000000000003,20.3,40.1,19.599999999999994,45.3,30.0,39.1,20.0,40.3,38.400000000000006,30.8,33.7,23.90000000000001,43.6,24.90000000000001,38.400000000000006,40.900000000000006,40.1,26.099999999999994,34.8,15.099999999999994,30.599999999999994,30.3,35.7,39.2,35.400000000000006,28.5,19.3,22.200000000000003,37.2,20.099999999999994,40.3,35.599999999999994,38.1,40.1,32.5,11.700000000000005,37.7,39.7,37.2,14.0,27.5,40.3,28.099999999999994,34.0,31.200000000000003,41.1,36.900000000000006,22.3,37.3,39.3,37.5,32.400000000000006,40.7,33.900000000000006,36.5,25.700000000000003,19.099999999999994,40.8,39.7,33.099999999999994,16.5,39.400000000000006,38.6,35.8,17.400000000000006,33.099999999999994,21.90000000000001,41.1,23.0,28.90000000000001,40.1,30.8,34.400000000000006,27.90000000000001,36.900000000000006,38.0,40.400000000000006,24.3,41.900000000000006,31.8,23.599999999999994,37.8,37.6,34.5,39.8,36.6,35.400000000000006,27.200000000000003,16.700000000000003,36.1,21.0,36.8,47.1,39.7,36.5,41.2,40.1,24.8,43.400000000000006,37.6,20.3,30.90000000000001,22.8,33.2,28.0,19.599999999999994,26.90000000000001,41.5,35.900000000000006,25.8,38.5,29.599999999999994,37.5,32.5,29.099999999999994,36.1,38.400000000000006,35.2,22.40000000000001,34.400000000000006,43.6,36.1,35.400000000000006,17.5,18.599999999999994,29.099999999999994,23.8,35.7,40.3,15.200000000000005,41.5,38.6,38.3,37.5,39.1,42.3,36.900000000000006,15.299999999999995,31.8,37.400000000000006,44.8,35.2,29.40000000000001,16.400000000000006,20.099999999999994,13.099999999999994,34.099999999999994,33.8,37.6,34.7,22.599999999999994,24.8,18.8,25.5,40.0,38.7,42.8,24.700000000000003,40.2,34.2,30.700000000000003,41.5,41.900000000000006,37.0,34.400000000000006,31.3,38.6,31.3,29.099999999999994,33.8,22.700000000000003,39.400000000000006,40.1,14.400000000000006,23.90000000000001,33.2,41.5,36.900000000000006,35.400000000000006,33.3,7.099999999999994,17.799999999999997,30.599999999999994,28.0,23.0,38.0,41.1,20.5,31.0,32.2,28.599999999999994,30.700000000000003,32.5,27.5,30.099999999999994,40.400000000000006,34.2,41.3,39.5,38.1,39.1,38.5,36.7,36.0,38.1,38.0,20.3,26.5,30.90000000000001,40.8,22.90000000000001,23.0,22.0,45.1,38.6,38.900000000000006,19.599999999999994,34.599999999999994,30.5,33.2,37.5,21.200000000000003,34.3,19.40000000000001,44.2,40.5,17.099999999999994,38.0,35.8,43.2,39.6,37.1,43.6,12.900000000000006,24.3,19.700000000000003,24.8,42.2,38.3,27.40000000000001,25.5,40.3,33.400000000000006,40.8,26.90000000000001,38.0,28.8,32.7,41.1,32.3,33.599999999999994,28.8,40.7,33.099999999999994,38.0,34.599999999999994,19.099999999999994,43.7,38.400000000000006,34.400000000000006,24.40000000000001,39.400000000000006,38.5,30.40000000000001,30.700000000000003,28.200000000000003,37.3,32.2,38.8,37.0,37.900000000000006,34.900000000000006,34.7,19.40000000000001,14.900000000000006,38.8,24.099999999999994,37.1,31.700000000000003,38.6,8.900000000000006,32.099999999999994,39.7,30.90000000000001,24.40000000000001,29.200000000000003,27.099999999999994,40.400000000000006,43.2,29.5,43.0,24.700000000000003,33.7,41.6,35.5,14.5,34.900000000000006,23.599999999999994,36.8,39.1,36.0,21.5,37.0,26.0,20.200000000000003,35.900000000000006,38.6,13.0,20.90000000000001,23.3,33.2,37.8,42.2,17.799999999999997,32.7,38.8,35.099999999999994,24.40000000000001,12.099999999999994,40.7,31.3,39.900000000000006,26.3,33.8,34.2,34.8,37.400000000000006,41.400000000000006,15.0,16.099999999999994,29.8,21.90000000000001,22.3,31.200000000000003,41.5,31.0,24.40000000000001,42.3,19.200000000000003,30.5,23.3,16.400000000000006,32.900000000000006,41.900000000000006,24.099999999999994,31.0,18.40000000000001,20.0,26.700000000000003,39.400000000000006,18.8,36.5,39.8,20.90000000000001,41.6,16.0,30.40000000000001,36.1,40.2,23.3,21.3,37.8,33.400000000000006,20.5,31.3,35.2,41.6,25.200000000000003,18.700000000000003,40.6,42.3,17.5,35.599999999999994,35.099999999999994,33.599999999999994,38.6,20.8,14.400000000000006,36.1,39.400000000000006,41.2,43.7,19.40000000000001,36.5,41.1,39.7,36.2,26.599999999999994,40.7,24.3,33.099999999999994,36.0,27.599999999999994,27.8,38.400000000000006,32.599999999999994,41.6,33.8,36.1,14.599999999999994,38.5,37.5,37.0,36.5,34.0,44.5,45.3,23.099999999999994,39.5,21.8,30.700000000000003,21.0,21.8,40.5,17.400000000000006,19.40000000000001,38.2,39.1,35.900000000000006,37.8,33.599999999999994,40.3,35.599999999999994,40.5,19.5,36.1,37.5,30.0,35.900000000000006,32.0,19.099999999999994,42.7,15.299999999999995,38.6,40.400000000000006,32.599999999999994,24.40000000000001,32.900000000000006,32.7,35.3,33.7,31.5,39.1,28.3,31.40000000000001,27.5,39.6,14.400000000000006,41.2,30.599999999999994,25.599999999999994,34.3,37.900000000000006,18.90000000000001,24.5,41.900000000000006,32.8,31.099999999999994,31.8,38.2,15.799999999999995,30.90000000000001,28.3,24.90000000000001,21.200000000000003,29.3,9.099999999999994,25.90000000000001,23.200000000000003,35.5,25.8,14.200000000000005,28.8,19.700000000000003,19.8,28.40000000000001,36.900000000000006,26.90000000000001,20.599999999999994,28.5,41.3,44.7,35.8,41.6,37.6,10.700000000000005,33.400000000000006,26.0,41.5,38.0,39.2,33.900000000000006,28.700000000000003,35.2,34.3,19.40000000000001,32.400000000000006,42.8,42.3,40.900000000000006,40.2,22.200000000000003,20.200000000000003,43.5,37.8,42.2,35.0,34.8,39.7,37.2,33.5,38.400000000000006,35.400000000000006,36.6,38.900000000000006,23.8,22.099999999999994,38.2,33.3,38.900000000000006,24.599999999999994,38.2,28.8,36.5,34.3,37.5,39.5,21.40000000000001,37.3,38.7,38.3,27.5,37.400000000000006,38.4,39.2,27.700000000000003,38.900000000000006,27.90000000000001,34.5,27.8,12.599999999999994,27.40000000000001,37.3,34.900000000000006,37.900000000000006,17.299999999999997,24.3,36.7,28.5,37.1,37.7,38.8,33.8,38.8,40.2,37.7,37.900000000000006,41.3,39.400000000000006,42.7,28.5,22.200000000000003,39.7,34.3,25.200000000000003,37.400000000000006,24.0,24.599999999999994,36.900000000000006,32.3,38.3,23.40000000000001,28.200000000000003,36.1,31.599999999999994,34.900000000000006,38.3,41.6,18.0,38.6,41.1,20.90000000000001,29.200000000000003,24.599999999999994,18.599999999999994,44.1,27.8,29.5,33.5,26.200000000000003,38.400000000000006,36.400000000000006,34.8,37.7,38.1,36.900000000000006,26.599999999999994,43.7,25.099999999999994,22.3,18.8,30.5,22.599999999999994,20.3,43.2,36.2,2.299999999999997,42.1,41.400000000000006,24.90000000000001,21.200000000000003,21.599999999999994,38.900000000000006,23.599999999999994,39.7,28.5,24.200000000000003,17.0,41.2,35.900000000000006,15.200000000000005,38.7,36.0,40.3,26.8,35.2,35.099999999999994,39.3,23.099999999999994,23.700000000000003,35.900000000000006,34.3,34.3,38.5,27.8,37.1,32.099999999999994,38.7,36.400000000000006,22.700000000000003,18.700000000000003,27.8,32.099999999999994,37.3,23.40000000000001,19.90000000000001,37.400000000000006,38.900000000000006,27.200000000000003,18.0,40.5,31.3,30.200000000000003,37.400000000000006,37.5,37.900000000000006,17.700000000000003,35.400000000000006,34.599999999999994,14.299999999999995,37.4,36.7,15.0,16.299999999999997,36.0,37.0,49.1,26.700000000000003,26.0,43.400000000000006,38.0,35.2,45.6,38.7,25.5,42.0,34.8,39.0,31.700000000000003,32.599999999999994,38.8,14.200000000000005,35.900000000000006,39.7,39.0,38.6,41.1,22.700000000000003,15.200000000000005,40.7,39.6,32.0,21.90000000000001,37.6,38.2,38.1,39.7,30.3,41.3,14.400000000000006,31.700000000000003,24.5,35.2,38.7,41.0,32.900000000000006,38.8,19.200000000000003,21.700000000000003,39.2,37.400000000000006,24.40000000000001,30.0,37.900000000000006,21.5,43.1,42.1,39.6,30.599999999999994,24.40000000000001,43.400000000000006,33.2,34.7,42.400000000000006,36.1,15.099999999999994,21.0,38.0,35.599999999999994,24.40000000000001,36.8,38.900000000000006,37.2,36.2,43.0,20.599999999999994,21.200000000000003,39.3,30.40000000000001,42.3,34.3,23.700000000000003,22.5,33.099999999999994,42.0,19.3,43.0,38.0,38.6,40.400000000000006,34.599999999999994,36.3,35.0,35.900000000000006,24.700000000000003,38.900000000000006,16.0,27.0,37.0,23.8,16.0,25.700000000000003,35.3,26.0,29.099999999999994,37.2,21.599999999999994,29.200000000000003,41.400000000000006,40.5,23.599999999999994,36.6,25.8,33.0,39.900000000000006,3.9000000000000057,33.900000000000006,34.5,46.400000000000006,38.5],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"age\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"physical_score\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3b0bcfbe-06bb-4706-8dae-afba33796a4f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.bar(df, x='age',y='physical_score')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5ab2638-1445-4e80-b144-30199d716dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "age=%{x}<br>physical_score=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa"
         },
         "name": "",
         "notched": false,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "box",
         "x": [
          33,
          50,
          52,
          56,
          35,
          58,
          66,
          38,
          53,
          43,
          39,
          58,
          45,
          52,
          36,
          83,
          57,
          39,
          58,
          54,
          65,
          69,
          41,
          43,
          64,
          55,
          46,
          40,
          70,
          36,
          62,
          71,
          38,
          67,
          50,
          68,
          58,
          63,
          60,
          24,
          44,
          55,
          42,
          61,
          49,
          66,
          51,
          65,
          53,
          52,
          60,
          46,
          69,
          62,
          64,
          72,
          66,
          32,
          54,
          59,
          74,
          37,
          32,
          68,
          62,
          58,
          54,
          75,
          48,
          54,
          57,
          31,
          74,
          40,
          54,
          82,
          48,
          53,
          61,
          27,
          62,
          66,
          39,
          51,
          41,
          52,
          46,
          57,
          47,
          82,
          43,
          55,
          57,
          46,
          56,
          49,
          52,
          46,
          56,
          60,
          49,
          67,
          39,
          59,
          67,
          55,
          68,
          44,
          47,
          45,
          70,
          62,
          68,
          46,
          74,
          60,
          52,
          58,
          42,
          50,
          43,
          57,
          51,
          49,
          46,
          47,
          40,
          66,
          48,
          45,
          39,
          47,
          54,
          55,
          66,
          47,
          62,
          51,
          70,
          51,
          48,
          32,
          60,
          50,
          48,
          42,
          51,
          44,
          71,
          57,
          34,
          58,
          31,
          71,
          46,
          69,
          82,
          54,
          59,
          47,
          56,
          54,
          42,
          53,
          77,
          37,
          68,
          66,
          62,
          43,
          48,
          44,
          54,
          39,
          65,
          51,
          30,
          53,
          48,
          51,
          64,
          34,
          43,
          67,
          46,
          46,
          44,
          79,
          59,
          69,
          35,
          49,
          32,
          60,
          41,
          38,
          40,
          35,
          56,
          48,
          36,
          51,
          43,
          52,
          41,
          67,
          61,
          34,
          63,
          62,
          64,
          45,
          53,
          46,
          51,
          51,
          33,
          48,
          50,
          63,
          48,
          51,
          34,
          46,
          56,
          54,
          46,
          66,
          57,
          38,
          34,
          55,
          41,
          49,
          60,
          56,
          66,
          65,
          56,
          52,
          48,
          71,
          54,
          52,
          57,
          38,
          58,
          56,
          46,
          56,
          53,
          61,
          45,
          53,
          46,
          64,
          47,
          46,
          68,
          70,
          41,
          50,
          62,
          43,
          53,
          46,
          52,
          53,
          34,
          40,
          43,
          40,
          50,
          58,
          48,
          39,
          49,
          51,
          47,
          59,
          42,
          44,
          65,
          40,
          43,
          65,
          50,
          49,
          70,
          49,
          52,
          39,
          31,
          64,
          44,
          46,
          32,
          36,
          30,
          68,
          49,
          50,
          35,
          37,
          65,
          61,
          37,
          76,
          48,
          36,
          55,
          65,
          39,
          34,
          25,
          59,
          42,
          54,
          51,
          49,
          59,
          72,
          61,
          41,
          50,
          52,
          34,
          66,
          40,
          37,
          58,
          58,
          50,
          52,
          55,
          36,
          45,
          31,
          57,
          49,
          52,
          75,
          57,
          57,
          38,
          56,
          56,
          60,
          47,
          57,
          59,
          61,
          48,
          78,
          46,
          72,
          48,
          44,
          52,
          76,
          72,
          53,
          47,
          44,
          34,
          45,
          64,
          59,
          68,
          62,
          49,
          40,
          59,
          48,
          40,
          48,
          39,
          51,
          40,
          55,
          41,
          38,
          42,
          66,
          66,
          58,
          43,
          46,
          55,
          54,
          43,
          57,
          40,
          42,
          64,
          72,
          39,
          52,
          43,
          62,
          43,
          77,
          58,
          49,
          44,
          49,
          58,
          40,
          74,
          73,
          44,
          43,
          45,
          40,
          65,
          55,
          55,
          52,
          68,
          56,
          53,
          43,
          64,
          55,
          76,
          46,
          56,
          44,
          38,
          43,
          53,
          81,
          50,
          63,
          30,
          47,
          25,
          55,
          48,
          48,
          50,
          37,
          72,
          47,
          65,
          53,
          82,
          35,
          38,
          37,
          47,
          54,
          39,
          59,
          22,
          56,
          56,
          42,
          58,
          64,
          62,
          64,
          50,
          58,
          52,
          60,
          31,
          42,
          38,
          57,
          41,
          39,
          40,
          56,
          68,
          48,
          66,
          41,
          63,
          49,
          41,
          40,
          55,
          55,
          48,
          41,
          50,
          41,
          32,
          59,
          42,
          54,
          48,
          49,
          60,
          43,
          39,
          48,
          46,
          45,
          53,
          39,
          52,
          33,
          53,
          42,
          67,
          50,
          78,
          58,
          43,
          43,
          46,
          56,
          62,
          35,
          60,
          77,
          58,
          39,
          39,
          48,
          44,
          48,
          74,
          67,
          33,
          41,
          45,
          62,
          65,
          39,
          77,
          63,
          71,
          44,
          58,
          69,
          48,
          64,
          62,
          40,
          69,
          40,
          44,
          48,
          60,
          61,
          40,
          57,
          54,
          63,
          42,
          59,
          41,
          66,
          53,
          36,
          46,
          51,
          45,
          33,
          46,
          75,
          47,
          48,
          47,
          51,
          48,
          38,
          40,
          67,
          72,
          52,
          51,
          63,
          35,
          33,
          62,
          43,
          47,
          70,
          51,
          40,
          39,
          32,
          60,
          33,
          57,
          68,
          69,
          54,
          60,
          57,
          18,
          55,
          46,
          54,
          46,
          54,
          47,
          35,
          48,
          45,
          47,
          41,
          42,
          41,
          41,
          52,
          31,
          41,
          55,
          73,
          64,
          29,
          63,
          54,
          63,
          45,
          65,
          47,
          49,
          57,
          44,
          53,
          29,
          56,
          52,
          44,
          25,
          54,
          40,
          46,
          67,
          45,
          45,
          47,
          65,
          54,
          41,
          43,
          54,
          52,
          68,
          82,
          42,
          75,
          74,
          43,
          65,
          35,
          42,
          55,
          42,
          51,
          71,
          41,
          47,
          28,
          42,
          55,
          70,
          67,
          49,
          55,
          37,
          48,
          37,
          46,
          34,
          63,
          53,
          54,
          76,
          50,
          69,
          48,
          45,
          42,
          39,
          55,
          43,
          38,
          51,
          60,
          70,
          71,
          62,
          69,
          34,
          52,
          56,
          37,
          43,
          67,
          53,
          49,
          44,
          51,
          60,
          37,
          50,
          31,
          45,
          53,
          45,
          66,
          68,
          44,
          50,
          51,
          66,
          48,
          45,
          61,
          43,
          47,
          58,
          33,
          55,
          56,
          54,
          52,
          52,
          64,
          39,
          56,
          73,
          56,
          64,
          43,
          39,
          59,
          52,
          43,
          48,
          48,
          46,
          53,
          59,
          49,
          31,
          72,
          76,
          54,
          39,
          60,
          59,
          42,
          49,
          32,
          41,
          68,
          60,
          76,
          43,
          42,
          74,
          68,
          43,
          53,
          71,
          48,
          37,
          78,
          42,
          47,
          60,
          50,
          41,
          77,
          67,
          64,
          49,
          62,
          46,
          48,
          34,
          66,
          50,
          47,
          71,
          51,
          44,
          64,
          55,
          65,
          62,
          54,
          51,
          57,
          39,
          50,
          52,
          40,
          42,
          46,
          47,
          53,
          51,
          52,
          44,
          43,
          52,
          49,
          53,
          48,
          50,
          71,
          43,
          53,
          53,
          61,
          56,
          47,
          68,
          32,
          40,
          46,
          73,
          56,
          74,
          55,
          74,
          50,
          66,
          42,
          41,
          51,
          42,
          46,
          38,
          46,
          41,
          59,
          62,
          64,
          54,
          54,
          61,
          62,
          38,
          48,
          56,
          73,
          26,
          34,
          50,
          44,
          62,
          32,
          44,
          68,
          45,
          74,
          47,
          36,
          48,
          66,
          56,
          64,
          61,
          49,
          57,
          54,
          66,
          47,
          65,
          63,
          44,
          53,
          35,
          62,
          49,
          64,
          39,
          55,
          67,
          54,
          41,
          57,
          67,
          59,
          38,
          36,
          28,
          31,
          72,
          52,
          49,
          50,
          43,
          49,
          58,
          68,
          49,
          39,
          54,
          63,
          51,
          61,
          62,
          77,
          31,
          70,
          42,
          55,
          42,
          38,
          52,
          55,
          46,
          56,
          71,
          48,
          38,
          50,
          76,
          60,
          68,
          73,
          36,
          66,
          43,
          42,
          61,
          53,
          28,
          34,
          55,
          41,
          44,
          34,
          55,
          63,
          51,
          44,
          45,
          48,
          45,
          46,
          40,
          39,
          51,
          43,
          41,
          67,
          63,
          46,
          78,
          58,
          51,
          62,
          42,
          36,
          70,
          41,
          65,
          44,
          39,
          50,
          47,
          41,
          48,
          74,
          48,
          49,
          58,
          49,
          61,
          61,
          51,
          37,
          49,
          63,
          54,
          50,
          46,
          60,
          50,
          67,
          67,
          47,
          57,
          30,
          62,
          47,
          48,
          42,
          42,
          35,
          54,
          49,
          46,
          61,
          69,
          40,
          30,
          46,
          47,
          77,
          54,
          50,
          51,
          26,
          39,
          52,
          49,
          52,
          27,
          45,
          55,
          67,
          41,
          56,
          66,
          67,
          52,
          57,
          73,
          60,
          44,
          45,
          66,
          60,
          69,
          50,
          78,
          46,
          48,
          41,
          60,
          39,
          64,
          46,
          43,
          37,
          42,
          44,
          40,
          58,
          46,
          57,
          54,
          36,
          66,
          30,
          37,
          58,
          56,
          47,
          61,
          51,
          24,
          35,
          60,
          64,
          40,
          57,
          53,
          50,
          53,
          38,
          56,
          59,
          57,
          39,
          45,
          69,
          49,
          42,
          58,
          50,
          68,
          71,
          44,
          34,
          41,
          48,
          68,
          48,
          55,
          49,
          63,
          37,
          44,
          63,
          42,
          44,
          65,
          44,
          63,
          55,
          47,
          55,
          51,
          54,
          52,
          60,
          71,
          44,
          38,
          41,
          44,
          55,
          42,
          41,
          38,
          58,
          39,
          46,
          39,
          60,
          41,
          44,
          60,
          62,
          64,
          60,
          59,
          65,
          50,
          61,
          44,
          40,
          58,
          46,
          54,
          63,
          37,
          45,
          41,
          58,
          65,
          56,
          44,
          63,
          55,
          47,
          47,
          39,
          52,
          32,
          41,
          48,
          41,
          46,
          55,
          48,
          47,
          38,
          69,
          70,
          60,
          45,
          50,
          44,
          44,
          50,
          49,
          72,
          37,
          68,
          46,
          57,
          54,
          36,
          78,
          52,
          40,
          49,
          81,
          64,
          44,
          43,
          50,
          69,
          54,
          62,
          64,
          46,
          57,
          40,
          52,
          34,
          50,
          21,
          43,
          46,
          41,
          74,
          50,
          38,
          39,
          76,
          60,
          37,
          56,
          66,
          68,
          49,
          39,
          56,
          47,
          65,
          42,
          36,
          57,
          57,
          37,
          54,
          32,
          54,
          54,
          62,
          68,
          37,
          42,
          48,
          66,
          43,
          59,
          59,
          54,
          50,
          52,
          33,
          44,
          53,
          42,
          74,
          54,
          46,
          52,
          52,
          43,
          33,
          60,
          61,
          54,
          57,
          62,
          60,
          64,
          69,
          73,
          47,
          44,
          47,
          44,
          58,
          65,
          32,
          46,
          52,
          58,
          62,
          66,
          77,
          35,
          52,
          40,
          72,
          46,
          51,
          48,
          43,
          65,
          49,
          48,
          38,
          45,
          58,
          62,
          48,
          34,
          38,
          40,
          50,
          59,
          56,
          51,
          80,
          39,
          55,
          46,
          45,
          48,
          68,
          53,
          42,
          34,
          44,
          59,
          45,
          66,
          57,
          44,
          53,
          83,
          72,
          69,
          62,
          50,
          48,
          60,
          63,
          66,
          53,
          80,
          68,
          36,
          32,
          59,
          69,
          51,
          50,
          51,
          44,
          50,
          57,
          44,
          52,
          43,
          33,
          41,
          30,
          61,
          59,
          61,
          49,
          57,
          64,
          47,
          54,
          48,
          47,
          45,
          65,
          49,
          76,
          67,
          56,
          42,
          48,
          58,
          51,
          68,
          54,
          65,
          67,
          46,
          62,
          55,
          57,
          47,
          36,
          57,
          52,
          68,
          65,
          63,
          54,
          43,
          35,
          36,
          74,
          41,
          42,
          39,
          64,
          28,
          52,
          52,
          46,
          58,
          70,
          48,
          57,
          54,
          54,
          68,
          54,
          38,
          74,
          35,
          49,
          59,
          40,
          41,
          62,
          66,
          65,
          71,
          47,
          47,
          65,
          49,
          61,
          81,
          60,
          47,
          69,
          34,
          78,
          34,
          59,
          42,
          46,
          46,
          55,
          31,
          47,
          45,
          50,
          55,
          54,
          62,
          50,
          34,
          62,
          42,
          49,
          42,
          47,
          56,
          49,
          73,
          47,
          53,
          58,
          61,
          49,
          38,
          33,
          57,
          71,
          55,
          43,
          63,
          42,
          60,
          62,
          55,
          55,
          56,
          65,
          50,
          47,
          63,
          46,
          39,
          29,
          45,
          50,
          62,
          38,
          47,
          54,
          49,
          63,
          51,
          43,
          42,
          45,
          54,
          55,
          35,
          30,
          50,
          40,
          43,
          43,
          38,
          57,
          50,
          49,
          58,
          44,
          58,
          53,
          46,
          47,
          44,
          38,
          42,
          56,
          40,
          60,
          31,
          53,
          62,
          37,
          77,
          56,
          55,
          24,
          50,
          55,
          68,
          55,
          58,
          37,
          51,
          40,
          47,
          64,
          51,
          61,
          53,
          64,
          32,
          46,
          68,
          36,
          54,
          46,
          51,
          64,
          30,
          51,
          56,
          43,
          54,
          46,
          44,
          34,
          63,
          61,
          42,
          63,
          57,
          66,
          37,
          59,
          42,
          48,
          60,
          39,
          59,
          36,
          43,
          54,
          57,
          47,
          41,
          83,
          43,
          53,
          70,
          60,
          42,
          48,
          34,
          68,
          44,
          61,
          55,
          71,
          54,
          38,
          49,
          52,
          60,
          70,
          55,
          40,
          36,
          70,
          47,
          57,
          42,
          51,
          44,
          66,
          82,
          48,
          53,
          61,
          54,
          48,
          37,
          84,
          47,
          33,
          63,
          60,
          44,
          37,
          36,
          42,
          61,
          46,
          60,
          37,
          41,
          68,
          54,
          66,
          69,
          68,
          72,
          48,
          62,
          42,
          56,
          51,
          36,
          56,
          43,
          49,
          46,
          69,
          40,
          39,
          52,
          46,
          55,
          41,
          48,
          58,
          71,
          46,
          58,
          71,
          79,
          33,
          46,
          46,
          65,
          57,
          38,
          70,
          46,
          62,
          31,
          42,
          57,
          54,
          56,
          67,
          51,
          49,
          37,
          49,
          42,
          58,
          62,
          60,
          54,
          40,
          51,
          58,
          43,
          33,
          62,
          59,
          49,
          50,
          42,
          56,
          35,
          45,
          44,
          67,
          52,
          52,
          62,
          71,
          54,
          47,
          49,
          54,
          52,
          39,
          51,
          49,
          65,
          55,
          44,
          51,
          59,
          70,
          53,
          49,
          45,
          41,
          55,
          43,
          51,
          59,
          60,
          68,
          60,
          45,
          51,
          37,
          60,
          52,
          50,
          46,
          50,
          64,
          45,
          41,
          54,
          40,
          55,
          38,
          40,
          70,
          60,
          43,
          59,
          40,
          55,
          81,
          39,
          53,
          80,
          61,
          53,
          54,
          63,
          58,
          46,
          38,
          55,
          63,
          43,
          68,
          50,
          50,
          59,
          57,
          55,
          50,
          61,
          55,
          63,
          49,
          56,
          71,
          40,
          84,
          43,
          61,
          46,
          55,
          33,
          65,
          68,
          57,
          76,
          58,
          56,
          39,
          29,
          54,
          47,
          62,
          52,
          47,
          64,
          34,
          59,
          71,
          47,
          67,
          59,
          57,
          58,
          39,
          41,
          41,
          52,
          55,
          46,
          73,
          59,
          39,
          49,
          43,
          47,
          64,
          46,
          46,
          62,
          47,
          32,
          61,
          68,
          66,
          46,
          35,
          45,
          32,
          41,
          29,
          65,
          43,
          43,
          59,
          70,
          41,
          39,
          41,
          45,
          53,
          44,
          52,
          47,
          62,
          50,
          63,
          56,
          45,
          42,
          59,
          39,
          47,
          84,
          52,
          49,
          63,
          38,
          53,
          65,
          45,
          42,
          43,
          44,
          40,
          49,
          37,
          54,
          44,
          63,
          34,
          50,
          55,
          67,
          40,
          48,
          50,
          49,
          64,
          50,
          42,
          40,
          51,
          60,
          70,
          31,
          57,
          38,
          44,
          64,
          38,
          48,
          43,
          43,
          69,
          66,
          47,
          67,
          42,
          64,
          66,
          43,
          41,
          42,
          76,
          46,
          53,
          64,
          49,
          48,
          37,
          39,
          37,
          57,
          40,
          62,
          50,
          54,
          46,
          39,
          45,
          67,
          62,
          44,
          56,
          31,
          48,
          63,
          50,
          37,
          56,
          62,
          53,
          37,
          36,
          47,
          51,
          57,
          59,
          46,
          38,
          39,
          42,
          38,
          47,
          40,
          42,
          57,
          45,
          48,
          66,
          53,
          58,
          49,
          42,
          47,
          51,
          44,
          55,
          48,
          57,
          37,
          42,
          52,
          41,
          48,
          52,
          52,
          48,
          71,
          43,
          41,
          60,
          75,
          40,
          67,
          66,
          68,
          54,
          52,
          45,
          29,
          54,
          59,
          53,
          64,
          53,
          41,
          52,
          57,
          51,
          54,
          51,
          47,
          57,
          51,
          68,
          46,
          41,
          68,
          33,
          45,
          29,
          64,
          58,
          42,
          48,
          36,
          37,
          51,
          67,
          46,
          56,
          66,
          55,
          55,
          53,
          52,
          39,
          49,
          39,
          34,
          40,
          60,
          28,
          58,
          59,
          41,
          63,
          42,
          45,
          53,
          57,
          74,
          41,
          42,
          24,
          65,
          56,
          49,
          60,
          71,
          55,
          47,
          58,
          58,
          55,
          39,
          70,
          69,
          43,
          49,
          48,
          56,
          47,
          41,
          56,
          33,
          60,
          48,
          66,
          70,
          52,
          56,
          37,
          38,
          58,
          49,
          79,
          54,
          67,
          61,
          42,
          44,
          48,
          47,
          65,
          37,
          36,
          48,
          42,
          38,
          46,
          74,
          53,
          64,
          70,
          33,
          39,
          53,
          58,
          58,
          57,
          34,
          40,
          53,
          39,
          46,
          46,
          43,
          68,
          41,
          38,
          46,
          58,
          35,
          60,
          63,
          41,
          49,
          47,
          59,
          45,
          50,
          39,
          66,
          47,
          59,
          80,
          59,
          77,
          33,
          42,
          43,
          37,
          56,
          69,
          46,
          69,
          38,
          64,
          56,
          48,
          56,
          57,
          83,
          36,
          71,
          56,
          48,
          29,
          73,
          38,
          67,
          35,
          47,
          53,
          32,
          47,
          56,
          50,
          50,
          69,
          42,
          39,
          61,
          56,
          44,
          45,
          43,
          54,
          42,
          41,
          53,
          55,
          43,
          47,
          35,
          38,
          46,
          56,
          55,
          40,
          60,
          49,
          63,
          65,
          40,
          36,
          45,
          46,
          61,
          68,
          47,
          47,
          48,
          37,
          45,
          38,
          39,
          56,
          77,
          53,
          34,
          44,
          52,
          45,
          49,
          68,
          39,
          46,
          49,
          64,
          51,
          43,
          28,
          52,
          61,
          37,
          56,
          74,
          70,
          51,
          37,
          53,
          63,
          61,
          44,
          63,
          42,
          48,
          51,
          55,
          57,
          59,
          73,
          49,
          69,
          66,
          42,
          58,
          49,
          63,
          82,
          45,
          51,
          60,
          78,
          37,
          45,
          66,
          37,
          67,
          38,
          47,
          47,
          22,
          44,
          50,
          35,
          67,
          56,
          44,
          61,
          41,
          45,
          64,
          50,
          57,
          53,
          45,
          62,
          41,
          51,
          31,
          42,
          47,
          71,
          47,
          63,
          65,
          43,
          79,
          66,
          45,
          48,
          39,
          66,
          60,
          39,
          73,
          42,
          48,
          46,
          54,
          52,
          52,
          38,
          55,
          50,
          59,
          71,
          54,
          47,
          32,
          54,
          37,
          50,
          56,
          22,
          36,
          41,
          53,
          41,
          44,
          40,
          54,
          40,
          47,
          83,
          36,
          47,
          43,
          41,
          54,
          55,
          49,
          35,
          47,
          37,
          58,
          36,
          47,
          59,
          64,
          55,
          30,
          50,
          40,
          55,
          57,
          80,
          62,
          34,
          56,
          67,
          35,
          55,
          58,
          37,
          68,
          57,
          66,
          47,
          51,
          41,
          37,
          35,
          55,
          44,
          47,
          51,
          54,
          61,
          33,
          60,
          55,
          46,
          34,
          41,
          60,
          39,
          38,
          36,
          45,
          53,
          39,
          48,
          58,
          62,
          55,
          56,
          29,
          35,
          77,
          71,
          57,
          57,
          53,
          43,
          59,
          60,
          34,
          51,
          48,
          50,
          49,
          57,
          66,
          60,
          66,
          44,
          39,
          53,
          32,
          51,
          52,
          71,
          47,
          39,
          57,
          49,
          46,
          57,
          43,
          53,
          38,
          47,
          44,
          45,
          60,
          47,
          45,
          50,
          39,
          52,
          35,
          52,
          54,
          66,
          30,
          38,
          39,
          52,
          52,
          43,
          49,
          58,
          39,
          59,
          60,
          63,
          38,
          61,
          70,
          45,
          44,
          52,
          58,
          45,
          40,
          75,
          44,
          37,
          53,
          54,
          58,
          52,
          58,
          34,
          56,
          60,
          68,
          68,
          60,
          43,
          44,
          75,
          50,
          45,
          60,
          51,
          64,
          45,
          62,
          55,
          71,
          38,
          72,
          67,
          55,
          56,
          52,
          38,
          43,
          48,
          69,
          37,
          63,
          71,
          44,
          67,
          48,
          61,
          44,
          62,
          68,
          36,
          62,
          44,
          60,
          62,
          75,
          33,
          56,
          40,
          46,
          43,
          64,
          51,
          63,
          59,
          41,
          40,
          47,
          45,
          41,
          53,
          58,
          40,
          69,
          46,
          65,
          48,
          41,
          42,
          71,
          65,
          56,
          33,
          68,
          47,
          43,
          53,
          56,
          60,
          54,
          49,
          38,
          38,
          44,
          28,
          54,
          39,
          48,
          50,
          41,
          33,
          50,
          41,
          45,
          52,
          45,
          47,
          38,
          51,
          56,
          44,
          48,
          46,
          60,
          41,
          40,
          59,
          61,
          52,
          53,
          65,
          35,
          62,
          46,
          42,
          44,
          63,
          40,
          36,
          52,
          32,
          79,
          48,
          49,
          37,
          52,
          43,
          50,
          41,
          49,
          42,
          45,
          55,
          71,
          61,
          54,
          43,
          65,
          45,
          40,
          38,
          53,
          62,
          58,
          64,
          62,
          52,
          32,
          35,
          39,
          50,
          51,
          50,
          49,
          51,
          50,
          53,
          44,
          54,
          54,
          54,
          53,
          53,
          63,
          39,
          50,
          56,
          42,
          58,
          44,
          59,
          54,
          41,
          63,
          52,
          63,
          50,
          36,
          42,
          57,
          47,
          71,
          56,
          62,
          77,
          72,
          64,
          58,
          71,
          42,
          46,
          40,
          63,
          76,
          41,
          49,
          51,
          44,
          44,
          62,
          40,
          60,
          44,
          53,
          22,
          55,
          67,
          60,
          51,
          46,
          55,
          52,
          81,
          55,
          74,
          54,
          76,
          41,
          33,
          67,
          40,
          46,
          53,
          59,
          63,
          60,
          55,
          48,
          65,
          52,
          43,
          67,
          53,
          44,
          48,
          31,
          54,
          42,
          52,
          45,
          37,
          36,
          70,
          49,
          45,
          46,
          46,
          53,
          55,
          46,
          63,
          35,
          36,
          61,
          50,
          48,
          80,
          34,
          47,
          65,
          31,
          61,
          58,
          40,
          49,
          46,
          67,
          47,
          77,
          40,
          43,
          58,
          56,
          53,
          56,
          59,
          71,
          73,
          54,
          54,
          46,
          69,
          45,
          31,
          39,
          51,
          37,
          61,
          50,
          60,
          34,
          41,
          57,
          63,
          35,
          74,
          64,
          35,
          54,
          36,
          49,
          39,
          47,
          47,
          46,
          43,
          48,
          72,
          57,
          28,
          47,
          53,
          66,
          67,
          64,
          60,
          59,
          66,
          65,
          68,
          51,
          52,
          44,
          43,
          53,
          53,
          45,
          62,
          72,
          47,
          48,
          49,
          51,
          67,
          37,
          50,
          46,
          41,
          45,
          68,
          42,
          31,
          55,
          37,
          42,
          46,
          32,
          50,
          43,
          25,
          42,
          41,
          44,
          39,
          49,
          58,
          35,
          45,
          64,
          61,
          42,
          52,
          69,
          44,
          58,
          51,
          55,
          70,
          59,
          39,
          46,
          68,
          49,
          42,
          46,
          47,
          57,
          46,
          67,
          39,
          35,
          46,
          64,
          60,
          48,
          41,
          41,
          57,
          61,
          45,
          30,
          52,
          28,
          50,
          61,
          31,
          34,
          41,
          68,
          43,
          42,
          45,
          57,
          40,
          65,
          53,
          41,
          66,
          57,
          25,
          43,
          51,
          58,
          52,
          44,
          58,
          65,
          34,
          48,
          62,
          41,
          75,
          39,
          51,
          45,
          64,
          73,
          56,
          77,
          68,
          62,
          48,
          48,
          45,
          32,
          48,
          56,
          51,
          48,
          48,
          41,
          53,
          48,
          64,
          49,
          58,
          70,
          62,
          44,
          52,
          53,
          40,
          46,
          58,
          50,
          53,
          57,
          49,
          55,
          42,
          59,
          27,
          40,
          69,
          38,
          38,
          70,
          57,
          54,
          66,
          49,
          53,
          38,
          45,
          48,
          63,
          55,
          45,
          56,
          52,
          66,
          45,
          48,
          41,
          51,
          45,
          48,
          52,
          48,
          54,
          35,
          41,
          59,
          53,
          59,
          43,
          66,
          52,
          42,
          56,
          57,
          47,
          76,
          58,
          35,
          40,
          32,
          63,
          48,
          32,
          69,
          41,
          59,
          54,
          43,
          69,
          60,
          54,
          57,
          53,
          39,
          43,
          56,
          50,
          31,
          28,
          53,
          43,
          48,
          44,
          58,
          52,
          62,
          44,
          53,
          38,
          39,
          37,
          68,
          66,
          70,
          49,
          35,
          49,
          44,
          41,
          57,
          41,
          35,
          43,
          65,
          61,
          48,
          38,
          42,
          50,
          57,
          63,
          64,
          70,
          57,
          55,
          34,
          37,
          54,
          39,
          55,
          53,
          38,
          37,
          50,
          70,
          34,
          40,
          46,
          45,
          61,
          69,
          44,
          54,
          58,
          60,
          50,
          42,
          63,
          47,
          49,
          43,
          48,
          45,
          66,
          34,
          48,
          55,
          50,
          36,
          44,
          54,
          45,
          58,
          55,
          63,
          39,
          52,
          44,
          58,
          42,
          59,
          32,
          53,
          58,
          49,
          62,
          48,
          31,
          67,
          44,
          29,
          70,
          36,
          49,
          43,
          62,
          64,
          56,
          29,
          72,
          47,
          60,
          42,
          56,
          42,
          52,
          59,
          45,
          55,
          65,
          69,
          43,
          56,
          44,
          59,
          69,
          57,
          30,
          41,
          41,
          50,
          45,
          62,
          60,
          48,
          66,
          48,
          58,
          37,
          62,
          34,
          32,
          48,
          74,
          35,
          61,
          56,
          41,
          65,
          70,
          64,
          62,
          53,
          63,
          57,
          59,
          59,
          52,
          49,
          72,
          40,
          61,
          52,
          62,
          46,
          46,
          55,
          68,
          43,
          71,
          51,
          52,
          41,
          64,
          58,
          63,
          47,
          50,
          69,
          43,
          65,
          52,
          54,
          47,
          53,
          47,
          38,
          75,
          47,
          46,
          54,
          42,
          50,
          61,
          40,
          64,
          50,
          62,
          62,
          49,
          68,
          37,
          45,
          33,
          51,
          47,
          42,
          76,
          65,
          40,
          32,
          47,
          63,
          46,
          38,
          43,
          63,
          55,
          56,
          36,
          45,
          42,
          60,
          36,
          36,
          46,
          63,
          48,
          50,
          44,
          61,
          51,
          42,
          44,
          35,
          47,
          62,
          55,
          32,
          60,
          48,
          43,
          41,
          60,
          46,
          36,
          46,
          52,
          44,
          51,
          49,
          68,
          47,
          48,
          60,
          70,
          50,
          54,
          54,
          56,
          55,
          44,
          49,
          21,
          66,
          62,
          62,
          60,
          46,
          45,
          48,
          55,
          49,
          61,
          41,
          48,
          61,
          53,
          49,
          41,
          33,
          52,
          49,
          56,
          39,
          48,
          69,
          36,
          69,
          48,
          69,
          67,
          42,
          45,
          60,
          38,
          52,
          67,
          38,
          50,
          52,
          24,
          36,
          41,
          45,
          47,
          73,
          60,
          44,
          66,
          54,
          44,
          25,
          50,
          37,
          69,
          58,
          37,
          42,
          71,
          61,
          65,
          52,
          65,
          54,
          61,
          55,
          32,
          57,
          56,
          44,
          47,
          56,
          37,
          31,
          29,
          45,
          44,
          53,
          34,
          40,
          63,
          52,
          59,
          51,
          69,
          46,
          57,
          27,
          66,
          51,
          38,
          54,
          45,
          68,
          52,
          41,
          67,
          52,
          42,
          44,
          58,
          63,
          35,
          47,
          54,
          44,
          44,
          49,
          47,
          50,
          45,
          39,
          42,
          43,
          54,
          40,
          47,
          59,
          60,
          52,
          61,
          46,
          53,
          45,
          80,
          32,
          53,
          75,
          44,
          62,
          50,
          44,
          46,
          66,
          49,
          57,
          57,
          56,
          64,
          53,
          58,
          54,
          46,
          37,
          33,
          67,
          55,
          44,
          66,
          54,
          55,
          59,
          68,
          49,
          49,
          64,
          40,
          61,
          70,
          57,
          73,
          46,
          48,
          63,
          49,
          57,
          59,
          50,
          39,
          50,
          50,
          50,
          44,
          48,
          45,
          36,
          39,
          56,
          51,
          47,
          40,
          72,
          54,
          30,
          45,
          60,
          44,
          39,
          67,
          68,
          55,
          55,
          42,
          47,
          74,
          57,
          59,
          39,
          41,
          61,
          28,
          79,
          68,
          34,
          37,
          37,
          36,
          60,
          44,
          49,
          28,
          38,
          43,
          68,
          50,
          48,
          44,
          37,
          40,
          61,
          41,
          70,
          53,
          59,
          53,
          46,
          80,
          45,
          59,
          41,
          38,
          50,
          48,
          60,
          45,
          65,
          66,
          62,
          68,
          54,
          45,
          70,
          66,
          57,
          50,
          51,
          36,
          68,
          51,
          64,
          44,
          50,
          43,
          51,
          50,
          75,
          31,
          58,
          57,
          57,
          47,
          68,
          38,
          65,
          42,
          54,
          55,
          45,
          42,
          33,
          61,
          48,
          45,
          36,
          57,
          63,
          64,
          38,
          37,
          46,
          28,
          51,
          68,
          79,
          51,
          43,
          63,
          44,
          55,
          38,
          36,
          58,
          39,
          59,
          47,
          49,
          70,
          51,
          57,
          44,
          55,
          52,
          53,
          70,
          53,
          60,
          56,
          45,
          64,
          66,
          38,
          38,
          57,
          55,
          51,
          72,
          70,
          54,
          55,
          38,
          66,
          38,
          66,
          43,
          46,
          40,
          50,
          38,
          52,
          60,
          54,
          62,
          72,
          84,
          44,
          66,
          41,
          47,
          44,
          67,
          36,
          48,
          62,
          30,
          42,
          51,
          44,
          45,
          72,
          62,
          57,
          47,
          60,
          54,
          43,
          36,
          37,
          38,
          49,
          55,
          64,
          66,
          46,
          49,
          36,
          45,
          30,
          52,
          53,
          64,
          67,
          61,
          54,
          45,
          61,
          56,
          35,
          38,
          30,
          49,
          38,
          42,
          42,
          55,
          53,
          36,
          58,
          29,
          42,
          47,
          41,
          39,
          49,
          35,
          45,
          73,
          39,
          53,
          38,
          38,
          44,
          61,
          41,
          58,
          39,
          50,
          44,
          56,
          64,
          37,
          66,
          53,
          54,
          53,
          73,
          33,
          57,
          49,
          47,
          56,
          32,
          61,
          52,
          43,
          65,
          39,
          68,
          48,
          44,
          50,
          43,
          61,
          56,
          49,
          39,
          36,
          45,
          45,
          53,
          40,
          45,
          32,
          61,
          30,
          47,
          67,
          46,
          30,
          47,
          55,
          39,
          44,
          71,
          45,
          51,
          56,
          40,
          51,
          46,
          55,
          76,
          56,
          58,
          74,
          56,
          56,
          27,
          44,
          54,
          62,
          55,
          65,
          49,
          39,
          56,
          62,
          66,
          53,
          51,
          42,
          42,
          51,
          70,
          46,
          42,
          58,
          55,
          39,
          59,
          58,
          53,
          47,
          34,
          43,
          72,
          79,
          34,
          46,
          58,
          71,
          65,
          49,
          70,
          59,
          39,
          38,
          43,
          37,
          61,
          39,
          38,
          73,
          63,
          46,
          41,
          51,
          59,
          50,
          59,
          80,
          48,
          67,
          42,
          64,
          35,
          46,
          51,
          60,
          45,
          58,
          52,
          29,
          63,
          43,
          72,
          29,
          57,
          57,
          29,
          46,
          29,
          48,
          52,
          61,
          58,
          42,
          55,
          59,
          49,
          77,
          39,
          70,
          56,
          24,
          64,
          37,
          49,
          65,
          57,
          51,
          49,
          57,
          51,
          60,
          66,
          41,
          55,
          75,
          38,
          44,
          51,
          25,
          58,
          44,
          63,
          44,
          29,
          35,
          38,
          54,
          70,
          54,
          48,
          43,
          52,
          58,
          61,
          45,
          65,
          49,
          36,
          55,
          54,
          68,
          36,
          34,
          62,
          48,
          60,
          44,
          49,
          63,
          61,
          52,
          47,
          57,
          72,
          68,
          42,
          52,
          61,
          47,
          44,
          41,
          49,
          57,
          46,
          76,
          55,
          43,
          46,
          44,
          45,
          45,
          46,
          60,
          67,
          34,
          38,
          44,
          57,
          65,
          50,
          40,
          66,
          27,
          64,
          45,
          58,
          78,
          57,
          77,
          60,
          68,
          46,
          53,
          40,
          48,
          62,
          54,
          36,
          40,
          69,
          36,
          49,
          48,
          28,
          68,
          41,
          35,
          70,
          46,
          50,
          77,
          60,
          47,
          69,
          67,
          60,
          46,
          39,
          41,
          42,
          53,
          46,
          47,
          37,
          49,
          52,
          43,
          73,
          63,
          42,
          54,
          58,
          66,
          60,
          90,
          42,
          65,
          45,
          48,
          40,
          43,
          61,
          43,
          48,
          36,
          54,
          45,
          54,
          68,
          56,
          51,
          35,
          46,
          71,
          64,
          49,
          43,
          60,
          66,
          64,
          56,
          56,
          70,
          40,
          41,
          54,
          51,
          43,
          66,
          58,
          48,
          36,
          49,
          50,
          51,
          30,
          46,
          52,
          68,
          34,
          77,
          58,
          50,
          49,
          49,
          64,
          52,
          41,
          56,
          48,
          58,
          51,
          63,
          50,
          54,
          61,
          39,
          63,
          37,
          46,
          49,
          53,
          57,
          69,
          45,
          71,
          48,
          43,
          43,
          41,
          35,
          53,
          49,
          52,
          38,
          53,
          55,
          55,
          48,
          47,
          71,
          37,
          59,
          51,
          40,
          36,
          54,
          58,
          59,
          45,
          38,
          45,
          69,
          57,
          42,
          55,
          38,
          60,
          37,
          53,
          46,
          51,
          57,
          49,
          40,
          64,
          45,
          43,
          49,
          42,
          61,
          74,
          60,
          29,
          67,
          69,
          41,
          59,
          51,
          46,
          49,
          55,
          55,
          33,
          65,
          58,
          39,
          64,
          67,
          53,
          45,
          49,
          49,
          51,
          51,
          54,
          49,
          53,
          45,
          50,
          37,
          51,
          67,
          56,
          52,
          36,
          65,
          30,
          69,
          33,
          55,
          50,
          63,
          54,
          50,
          48,
          38,
          74,
          57,
          58,
          61,
          55,
          55,
          56,
          73,
          55,
          40,
          54,
          61,
          33,
          50,
          48,
          48,
          41,
          35,
          68,
          42,
          49,
          50,
          63,
          56,
          55,
          41,
          37,
          47,
          50,
          64,
          44,
          41,
          47,
          39,
          41,
          41,
          75,
          37,
          58,
          30,
          36,
          60,
          49,
          52,
          35,
          54,
          38,
          49,
          51,
          60,
          54,
          39,
          41,
          36,
          39,
          47,
          33,
          62,
          73,
          49,
          48,
          36,
          50,
          62,
          46,
          44,
          48,
          42,
          61,
          55,
          71,
          34,
          40,
          41,
          39,
          54,
          50,
          43,
          56,
          43,
          38,
          50,
          28,
          57,
          58,
          72,
          47,
          87,
          62,
          52,
          67,
          50,
          54,
          51,
          53,
          56,
          54,
          55,
          41,
          65,
          37,
          46,
          37,
          60,
          60,
          42,
          47,
          49,
          49,
          66,
          41,
          59,
          58,
          44,
          46,
          53,
          43,
          32,
          33,
          40,
          50,
          48,
          53,
          54,
          53,
          57,
          36,
          71,
          52,
          43,
          29,
          61,
          35,
          49,
          48,
          55,
          70,
          43,
          42,
          47,
          59,
          44,
          57,
          36,
          34,
          53,
          73,
          45,
          59,
          43,
          68,
          45,
          64,
          59,
          57,
          57,
          67,
          60,
          65,
          59,
          52,
          47,
          71,
          60,
          68,
          67,
          55,
          38,
          55,
          63,
          40,
          46,
          49,
          45,
          41,
          71,
          72,
          41,
          64,
          32,
          51,
          48,
          57,
          39,
          49,
          81,
          57,
          64,
          46,
          62,
          42,
          40,
          45,
          65,
          59,
          55,
          53,
          67,
          48,
          41,
          59,
          57,
          69,
          64,
          49,
          64,
          37,
          49,
          40,
          41,
          58,
          56,
          54,
          37,
          42,
          63,
          54,
          55,
          50,
          55,
          52,
          31,
          44,
          71,
          40,
          42,
          52,
          62,
          31,
          58,
          43,
          58,
          68,
          38,
          43,
          57,
          71,
          36,
          46,
          42,
          63,
          50,
          38,
          48,
          63,
          63,
          55,
          60,
          63,
          52,
          55,
          48,
          42,
          61,
          36,
          60,
          69,
          46,
          51,
          56,
          42,
          54,
          60,
          62,
          59,
          42,
          67,
          55,
          31,
          44,
          52,
          29,
          38,
          57,
          47,
          39,
          63,
          64,
          63,
          49,
          64,
          81,
          55,
          46,
          41,
          60,
          50,
          58,
          47,
          58,
          58,
          42,
          39,
          53,
          61,
          52,
          31,
          40,
          45,
          64,
          58,
          61,
          62,
          42,
          35,
          70,
          38,
          42,
          44,
          53,
          36,
          42,
          57,
          65,
          47,
          49,
          41,
          52,
          57,
          62,
          67,
          60,
          53,
          59,
          52,
          50,
          67,
          62,
          66,
          48,
          39,
          40,
          41,
          63,
          36,
          59,
          58,
          48,
          38,
          48,
          60,
          50,
          37,
          62,
          63,
          50,
          56,
          44,
          43,
          66,
          65,
          49,
          34,
          42,
          54,
          62,
          59,
          69,
          57,
          70,
          56,
          46,
          31,
          70,
          49,
          56,
          60,
          55,
          52,
          61,
          69,
          44,
          49,
          47,
          36,
          51,
          42,
          42,
          34,
          48,
          48,
          51,
          72,
          71,
          69,
          50,
          65,
          48,
          66,
          36,
          45,
          43,
          75,
          53,
          50,
          55,
          50,
          51,
          49,
          64,
          23,
          48,
          75,
          47,
          62,
          33,
          56,
          53,
          38,
          63,
          64,
          63,
          64,
          45,
          47,
          76,
          69,
          50,
          44,
          45,
          53,
          43,
          62,
          61,
          41,
          43,
          62,
          58,
          42,
          48,
          50,
          64,
          78,
          52,
          44,
          61,
          63,
          42,
          45,
          62,
          62,
          55,
          47,
          58,
          61,
          50,
          46,
          63,
          40,
          62,
          74,
          35,
          67,
          48,
          61,
          36,
          65,
          56,
          44,
          60,
          73,
          68,
          62,
          38,
          28,
          64,
          34,
          48,
          42,
          50,
          53,
          60,
          56,
          57,
          48,
          38,
          59,
          67,
          59,
          62,
          64,
          50,
          40,
          71,
          69,
          63,
          53,
          44,
          45,
          59,
          54,
          51,
          51,
          59,
          74,
          38,
          48,
          35,
          64,
          58,
          54,
          44,
          46,
          29,
          58,
          69,
          64,
          63,
          76,
          53,
          45,
          50,
          64,
          39,
          65,
          50,
          52,
          54,
          58,
          40,
          63,
          60,
          70,
          59,
          61,
          48,
          60,
          50,
          46,
          60,
          48,
          61,
          61,
          55,
          33,
          58,
          63,
          44,
          44,
          58,
          70,
          46,
          37,
          57,
          56,
          39,
          53,
          63,
          41,
          48,
          50,
          61,
          48,
          64,
          46,
          35,
          36,
          35,
          69,
          43,
          44,
          48,
          48,
          54,
          43,
          46,
          51,
          40,
          61,
          47,
          44,
          66,
          45,
          56,
          52,
          58,
          50,
          47,
          55,
          45,
          54,
          29,
          39,
          58,
          45,
          74,
          53,
          53,
          66,
          46,
          65,
          76,
          48,
          49,
          60,
          47,
          53,
          41,
          53,
          35,
          57,
          43,
          49,
          66,
          45,
          47,
          58,
          37,
          83,
          47,
          45,
          58,
          57,
          63,
          52,
          61,
          55,
          52,
          44,
          63,
          55,
          59,
          39,
          75,
          42,
          65,
          66,
          48,
          49,
          70,
          66,
          34,
          58,
          56,
          49,
          50,
          65,
          62,
          47,
          85,
          61,
          62,
          72,
          55,
          61,
          46,
          46,
          75,
          63,
          59,
          69,
          61,
          57,
          49,
          61,
          53,
          49,
          32,
          52,
          42,
          46,
          78,
          60,
          61,
          41,
          52,
          40,
          63,
          66,
          51,
          57,
          63,
          51,
          27,
          31,
          37,
          35,
          66,
          71,
          31,
          52,
          41,
          54,
          39,
          43,
          43,
          57,
          36,
          51,
          44,
          41,
          74,
          42,
          48,
          50,
          44,
          56,
          52,
          61,
          47,
          61,
          41,
          39,
          75,
          37,
          54,
          47,
          76,
          43,
          49,
          45,
          62,
          41,
          60,
          77,
          56,
          63,
          68,
          36,
          49,
          47,
          71,
          68,
          43,
          51,
          47,
          46,
          46,
          45,
          42,
          41,
          51,
          48,
          42,
          35,
          39,
          49,
          65,
          46,
          50,
          52,
          51,
          66,
          58,
          45,
          55,
          44,
          72,
          57,
          45,
          60,
          42,
          57,
          44,
          50,
          50,
          39,
          57,
          61,
          58,
          77,
          37,
          68,
          67,
          62,
          62,
          47,
          52,
          47,
          40,
          41,
          41,
          59,
          31,
          60,
          52,
          66,
          52,
          55,
          60,
          31,
          60,
          68,
          27,
          39,
          60,
          61,
          70,
          42,
          56,
          46,
          57,
          57,
          65,
          29,
          53,
          59,
          53,
          51,
          46,
          64,
          55,
          54,
          43,
          49,
          68,
          57,
          44,
          49,
          51,
          53,
          53,
          55,
          41,
          32,
          49,
          58,
          61,
          57,
          65,
          66,
          59,
          49,
          47,
          57,
          64,
          38,
          64,
          70,
          37,
          49,
          59,
          63,
          55,
          50,
          79,
          65,
          50,
          62,
          64,
          53,
          46,
          40,
          53,
          55,
          37,
          39,
          57,
          30,
          44,
          55,
          42,
          51,
          35,
          53,
          66,
          47,
          74,
          54,
          47,
          48,
          45,
          44,
          75,
          58,
          43,
          34,
          69,
          62,
          49,
          41,
          52,
          36,
          65,
          46,
          77,
          68,
          60,
          47,
          44,
          58,
          46,
          49,
          61,
          86,
          41,
          53,
          59,
          61,
          47,
          78,
          31,
          45,
          56,
          54,
          66,
          33,
          51,
          54,
          44,
          51,
          50,
          61,
          50,
          45,
          47,
          42,
          36,
          48,
          46,
          38,
          70,
          62,
          50,
          59,
          30,
          43,
          76,
          53,
          76,
          50,
          63,
          40,
          45,
          39,
          42,
          54,
          49,
          55,
          51,
          70,
          47,
          83,
          62,
          36,
          59,
          59,
          59,
          46,
          55,
          56,
          40,
          59,
          53,
          36,
          50,
          57,
          50,
          53,
          62,
          41,
          73,
          57,
          49,
          38,
          48
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          40.7,
          37.2,
          24.700000000000003,
          31,
          42.900000000000006,
          23,
          28.90000000000001,
          41.1,
          32,
          41.5,
          42.1,
          31.3,
          39.8,
          34.599999999999994,
          43,
          10.700000000000005,
          32.900000000000006,
          40.7,
          26.8,
          36.2,
          20.8,
          25.8,
          41.5,
          39.1,
          22.90000000000001,
          20.5,
          35.900000000000006,
          41,
          25.40000000000001,
          39.900000000000006,
          19,
          18.700000000000003,
          44.6,
          32.900000000000006,
          28.700000000000003,
          23.3,
          28.599999999999994,
          30.3,
          31.90000000000001,
          46.900000000000006,
          35.900000000000006,
          36.5,
          39.3,
          27.40000000000001,
          24.700000000000003,
          20.700000000000003,
          35.099999999999994,
          25.200000000000003,
          34.5,
          35.400000000000006,
          16.799999999999997,
          37.2,
          17.599999999999994,
          34.900000000000006,
          25.40000000000001,
          20.40000000000001,
          34.099999999999994,
          44.6,
          30.8,
          29.8,
          25.8,
          39.1,
          44.400000000000006,
          24.3,
          20,
          22.5,
          32.3,
          6.400000000000006,
          30.599999999999994,
          37.3,
          23.700000000000003,
          40.1,
          19.099999999999994,
          42.5,
          36.8,
          19.40000000000001,
          36.5,
          23,
          26.200000000000003,
          45.8,
          22.8,
          31.5,
          39.1,
          35.5,
          42.1,
          34.8,
          40,
          27.700000000000003,
          35.7,
          14.099999999999994,
          40.2,
          36.5,
          34.5,
          36.5,
          22.099999999999994,
          21.200000000000003,
          24.90000000000001,
          41.5,
          35.7,
          32.900000000000006,
          22.90000000000001,
          24.200000000000003,
          41.3,
          34.3,
          33.400000000000006,
          34.5,
          32.2,
          39.8,
          37.6,
          41.6,
          20.099999999999994,
          30,
          23,
          37.400000000000006,
          13.099999999999994,
          29.599999999999994,
          36.3,
          32.400000000000006,
          37.8,
          40,
          42.8,
          33.099999999999994,
          33.5,
          50,
          35.099999999999994,
          34.2,
          39,
          30.5,
          34.900000000000006,
          40.6,
          38.8,
          34.400000000000006,
          27.90000000000001,
          31.90000000000001,
          14.700000000000005,
          37.900000000000006,
          30.40000000000001,
          16.599999999999994,
          16.799999999999997,
          36.1,
          40.1,
          43,
          21.700000000000003,
          37.400000000000006,
          34.400000000000006,
          40.5,
          34.900000000000006,
          39.1,
          24.8,
          37.1,
          44.2,
          22.099999999999994,
          44.3,
          16.700000000000003,
          33.3,
          31.700000000000003,
          19.599999999999994,
          24.40000000000001,
          31.3,
          37.8,
          24.90000000000001,
          34.400000000000006,
          39.6,
          34.400000000000006,
          17.799999999999997,
          43.400000000000006,
          8.799999999999997,
          24,
          32.599999999999994,
          43.400000000000006,
          37.9,
          28.3,
          32.5,
          36.900000000000006,
          23.3,
          15.799999999999995,
          42.2,
          32.900000000000006,
          36.400000000000006,
          33.2,
          15.900000000000006,
          45.5,
          38.400000000000006,
          18.90000000000001,
          36.900000000000006,
          41.2,
          40,
          26.8,
          36.5,
          28.90000000000001,
          41.8,
          12.099999999999994,
          42.6,
          40.5,
          38.1,
          41.1,
          38.8,
          38.1,
          27.90000000000001,
          24.200000000000003,
          40.900000000000006,
          35.099999999999994,
          40.400000000000006,
          33.900000000000006,
          44.6,
          13.799999999999995,
          24,
          41.400000000000006,
          27.40000000000001,
          28.099999999999994,
          36.6,
          32.400000000000006,
          33.8,
          41,
          39.2,
          37.3,
          44.3,
          34.7,
          37.6,
          30,
          35.599999999999994,
          34,
          40.5,
          40.5,
          27.200000000000003,
          22.599999999999994,
          35.2,
          16.700000000000003,
          24.599999999999994,
          41,
          48.3,
          31.599999999999994,
          31.90000000000001,
          40.1,
          20.700000000000003,
          26.099999999999994,
          21.3,
          22.700000000000003,
          24.40000000000001,
          40.1,
          35.8,
          22.5,
          38.1,
          34.7,
          33.099999999999994,
          40.2,
          17.599999999999994,
          33,
          37,
          33.099999999999994,
          21.700000000000003,
          33.599999999999994,
          36.5,
          32.2,
          39.1,
          32.5,
          32.099999999999994,
          38.3,
          22.8,
          23.5,
          38.5,
          35.7,
          15.799999999999995,
          38.7,
          33.400000000000006,
          22.700000000000003,
          38,
          26.5,
          38.7,
          40.1,
          40.5,
          36.5,
          35.2,
          36.8,
          35.7,
          40.900000000000006,
          34.7,
          33.400000000000006,
          39.3,
          23.599999999999994,
          41.5,
          38.8,
          37.1,
          45,
          38.8,
          23.5,
          35.400000000000006,
          39.5,
          20.599999999999994,
          35.2,
          35.5,
          38.900000000000006,
          42.5,
          21.5,
          36.7,
          39.3,
          41.1,
          38.6,
          42.8,
          23.599999999999994,
          35.2,
          29.90000000000001,
          41.1,
          41.7,
          22.90000000000001,
          34.099999999999994,
          38.7,
          11.5,
          36.8,
          36.1,
          33.400000000000006,
          21.700000000000003,
          43.8,
          43.2,
          44.8,
          32.400000000000006,
          38.400000000000006,
          36.6,
          38.8,
          35.599999999999994,
          34,
          16.099999999999994,
          26,
          38.7,
          45,
          25.099999999999994,
          42.2,
          29.3,
          40.6,
          42.1,
          22.599999999999994,
          29.3,
          33.8,
          9.5,
          28.599999999999994,
          40.1,
          36.900000000000006,
          43.400000000000006,
          22.599999999999994,
          38.900000000000006,
          35.099999999999994,
          14.799999999999995,
          32.8,
          24.40000000000001,
          42.900000000000006,
          21.8,
          19.599999999999994,
          27.200000000000003,
          34,
          22.5,
          29.5,
          19.599999999999994,
          36.400000000000006,
          14.799999999999995,
          39.3,
          12.799999999999995,
          38,
          37.1,
          37.2,
          24.200000000000003,
          24.90000000000001,
          31.700000000000003,
          36.400000000000006,
          34.400000000000006,
          40.6,
          39,
          24.200000000000003,
          22.599999999999994,
          16.5,
          30.700000000000003,
          38.1,
          36.400000000000006,
          24.599999999999994,
          42,
          39.3,
          36.6,
          37.6,
          28.099999999999994,
          39.3,
          37.8,
          41.1,
          42.400000000000006,
          38.5,
          29.599999999999994,
          26.5,
          38.900000000000006,
          38.1,
          36.3,
          19.90000000000001,
          33.099999999999994,
          37.5,
          21.5,
          37.8,
          38.2,
          18.40000000000001,
          18.40000000000001,
          37.900000000000006,
          26.200000000000003,
          36,
          22.200000000000003,
          39.400000000000006,
          27.90000000000001,
          28.40000000000001,
          34.900000000000006,
          35.3,
          37.900000000000006,
          18.3,
          40.400000000000006,
          24.599999999999994,
          20.599999999999994,
          36.6,
          47.3,
          39.1,
          36.400000000000006,
          35.099999999999994,
          25.3,
          25.40000000000001,
          32.099999999999994,
          20.5,
          38.3,
          38.6,
          28.8,
          12.900000000000006,
          36.3,
          21.200000000000003,
          37.7,
          24.700000000000003,
          39.6,
          42.1,
          41.400000000000006,
          35.900000000000006,
          23.90000000000001,
          40.7,
          28.200000000000003,
          41.8,
          40.7,
          45.1,
          35.5,
          39.900000000000006,
          36.8,
          34.900000000000006,
          35.400000000000006,
          25,
          38.900000000000006,
          22.8,
          36.6,
          19.40000000000001,
          42.8,
          43,
          39.8,
          37.1,
          30.200000000000003,
          42.1,
          39.400000000000006,
          49.5,
          36.1,
          37.900000000000006,
          43.6,
          32.8,
          28.8,
          31,
          22.099999999999994,
          34.2,
          27.700000000000003,
          28.90000000000001,
          34.400000000000006,
          43.2,
          39.400000000000006,
          41.8,
          38.2,
          35.900000000000006,
          42,
          44.1,
          34.599999999999994,
          26.099999999999994,
          39,
          24.90000000000001,
          38.1,
          24.5,
          36.7,
          28.599999999999994,
          39.6,
          22.5,
          37.1,
          35.5,
          39.6,
          30.099999999999994,
          35.099999999999994,
          39.2,
          32,
          37.5,
          21.599999999999994,
          23.5,
          26.200000000000003,
          33.3,
          40.6,
          38.900000000000006,
          35.099999999999994,
          40.1,
          35.599999999999994,
          33.2,
          45.7,
          27.90000000000001,
          39.400000000000006,
          36.8,
          41.2,
          30.5,
          37.1,
          21.8,
          30.599999999999994,
          37.900000000000006,
          37.6,
          23.099999999999994,
          28.599999999999994,
          20.40000000000001,
          39.3,
          17.400000000000006,
          29.3,
          33.400000000000006,
          42.2,
          32.2,
          39.3,
          39.7,
          39.8,
          19.099999999999994,
          23.8,
          41.1,
          37.7,
          38.8,
          23.700000000000003,
          26.8,
          40.1,
          27.700000000000003,
          25.5,
          20.099999999999994,
          39.8,
          23.40000000000001,
          20.599999999999994,
          38.1,
          20,
          28.5,
          37,
          17.200000000000003,
          40.400000000000006,
          37.400000000000006,
          35.400000000000006,
          20.8,
          37.900000000000006,
          40.900000000000006,
          7.799999999999997,
          32,
          26.200000000000003,
          37.900000000000006,
          30.8,
          42.2,
          27.40000000000001,
          35.8,
          41.900000000000006,
          39,
          23.599999999999994,
          37.400000000000006,
          40.1,
          39.6,
          21.3,
          38.6,
          38,
          36,
          33.2,
          37.8,
          40.400000000000006,
          43.2,
          16.200000000000003,
          20.200000000000003,
          35.2,
          19.3,
          30.5,
          40.900000000000006,
          43.5,
          27.5,
          39.400000000000006,
          37.2,
          28.099999999999994,
          43.2,
          40.5,
          38.2,
          39.7,
          33.099999999999994,
          45.6,
          12.900000000000006,
          20.200000000000003,
          20.099999999999994,
          36,
          22.8,
          29.5,
          48.2,
          22.40000000000001,
          37.1,
          34.8,
          36.1,
          35.7,
          36.6,
          34.599999999999994,
          40.1,
          36.1,
          33.900000000000006,
          39.2,
          37.2,
          38.6,
          37.8,
          38,
          36.3,
          38.8,
          33.7,
          18.90000000000001,
          29.200000000000003,
          42.400000000000006,
          25.3,
          23.90000000000001,
          33.400000000000006,
          41.400000000000006,
          30.40000000000001,
          37.400000000000006,
          38.8,
          33.400000000000006,
          41.5,
          34.2,
          44.5,
          34.2,
          39.5,
          39.7,
          47.2,
          33.3,
          37.3,
          36.7,
          25,
          36.3,
          35.3,
          33.7,
          27.700000000000003,
          39.3,
          38,
          28.3,
          34.7,
          37.6,
          23.700000000000003,
          12,
          38.900000000000006,
          14.299999999999995,
          16.299999999999997,
          40.2,
          17.700000000000003,
          40.400000000000006,
          41.6,
          16,
          40.1,
          33.2,
          15.599999999999994,
          41.7,
          35.2,
          47.8,
          36.3,
          31.3,
          33.5,
          26.200000000000003,
          36.7,
          33,
          41.2,
          34.099999999999994,
          44.8,
          37.6,
          38.7,
          22.700000000000003,
          31.8,
          12.400000000000006,
          25,
          28.90000000000001,
          27.099999999999994,
          39.7,
          36.5,
          42,
          43,
          35.8,
          36.2,
          43.900000000000006,
          24,
          27.3,
          28.099999999999994,
          28.700000000000003,
          24.700000000000003,
          31.90000000000001,
          43.1,
          39.7,
          33.7,
          42,
          44.5,
          20.099999999999994,
          36.900000000000006,
          34.400000000000006,
          41.1,
          35.7,
          24.200000000000003,
          42.3,
          39.400000000000006,
          47.5,
          38.2,
          26.3,
          37.2,
          30.599999999999994,
          22.8,
          26.3,
          28.8,
          33.099999999999994,
          30,
          36.8,
          36.3,
          18,
          38.2,
          36.400000000000006,
          35.599999999999994,
          43.5,
          23.200000000000003,
          34.7,
          40,
          39.400000000000006,
          32.5,
          20.5,
          40.8,
          20.90000000000001,
          28.5,
          25.5,
          19.700000000000003,
          40.6,
          40.2,
          23.200000000000003,
          35.900000000000006,
          41.5,
          41.5,
          37,
          39,
          34.8,
          38.9,
          35.099999999999994,
          43.8,
          14.599999999999994,
          4.5,
          35.900000000000006,
          37.7,
          25.40000000000001,
          33,
          38.5,
          34.099999999999994,
          41.7,
          22.700000000000003,
          20.5,
          26.8,
          28.5,
          36.5,
          35.3,
          25.3,
          23.90000000000001,
          42.2,
          37.1,
          27.90000000000001,
          36.7,
          37.8,
          15.700000000000005,
          35.2,
          37.2,
          27.099999999999994,
          40.1,
          41.8,
          16.700000000000003,
          26,
          25.700000000000003,
          34.3,
          19.40000000000001,
          35.599999999999994,
          38.6,
          44.3,
          22.5,
          38.900000000000006,
          37.8,
          23,
          34.900000000000006,
          37.1,
          26.3,
          28.700000000000003,
          23.099999999999994,
          27.40000000000001,
          33.900000000000006,
          36.8,
          16.099999999999994,
          41,
          36.3,
          37.8,
          39.400000000000006,
          38.1,
          39.6,
          38.400000000000006,
          30.40000000000001,
          27.8,
          31.599999999999994,
          34.599999999999994,
          41.3,
          22.099999999999994,
          38.8,
          36.2,
          37.7,
          35.599999999999994,
          21.40000000000001,
          29.8,
          25,
          35.400000000000006,
          14.299999999999995,
          36.7,
          37.900000000000006,
          31.3,
          43.6,
          39.5,
          36.900000000000006,
          25.599999999999994,
          35,
          11.099999999999994,
          18.599999999999994,
          12.200000000000005,
          33.7,
          18.200000000000003,
          38.6,
          41.400000000000006,
          31,
          39.5,
          41.400000000000006,
          39.3,
          35.900000000000006,
          35.7,
          32.7,
          32.599999999999994,
          22.90000000000001,
          33.2,
          35.8,
          22.099999999999994,
          19.200000000000003,
          41.1,
          39,
          32.599999999999994,
          20.5,
          41.7,
          43.900000000000006,
          21.599999999999994,
          41.3,
          13.700000000000005,
          38,
          36,
          28.700000000000003,
          40.7,
          15.700000000000005,
          38.2,
          42.2,
          36.8,
          27,
          35.8,
          36.6,
          17.799999999999997,
          26,
          24.40000000000001,
          30.599999999999994,
          23.90000000000001,
          40.6,
          16.200000000000003,
          30,
          39.3,
          36.2,
          42,
          23.5,
          37.400000000000006,
          23.3,
          40.6,
          37,
          24.099999999999994,
          30.90000000000001,
          40.8,
          22.90000000000001,
          23.90000000000001,
          24.200000000000003,
          44.1,
          38.900000000000006,
          46.7,
          42.7,
          12.099999999999994,
          32.2,
          37.2,
          36.900000000000006,
          38.8,
          31.3,
          25.3,
          34.099999999999994,
          35.599999999999994,
          37.8,
          30.5,
          13.900000000000006,
          31.5,
          25,
          25,
          21,
          46.3,
          20.5,
          37.900000000000006,
          31.599999999999994,
          10.400000000000006,
          40.8,
          35.3,
          24.40000000000001,
          40.7,
          26.3,
          24.3,
          39.3,
          41.6,
          34.5,
          21,
          31.700000000000003,
          17.799999999999997,
          17.400000000000006,
          39,
          20,
          37.5,
          38.3,
          32.400000000000006,
          36.3,
          41,
          42,
          36.5,
          37,
          36.6,
          36.1,
          32.2,
          18.90000000000001,
          33.599999999999994,
          43.6,
          40.900000000000006,
          35.599999999999994,
          39,
          38.3,
          36.400000000000006,
          37.6,
          38,
          38,
          39.1,
          26.3,
          38.6,
          38.7,
          10.299999999999995,
          22.40000000000001,
          35.099999999999994,
          18,
          35,
          42.7,
          27.700000000000003,
          42.8,
          15,
          36.8,
          42.400000000000006,
          34.7,
          36.2,
          38.900000000000006,
          38.8,
          14.599999999999994,
          36.3,
          37.1,
          17.200000000000003,
          32.2,
          31.200000000000003,
          18.40000000000001,
          37,
          41.7,
          37.8,
          23.200000000000003,
          22.099999999999994,
          39.3,
          37.400000000000006,
          32.5,
          34.3,
          15.599999999999994,
          26.8,
          40.900000000000006,
          18.5,
          44.1,
          29.5,
          22.90000000000001,
          35.599999999999994,
          41.2,
          39.1,
          41,
          25.700000000000003,
          38.900000000000006,
          37.1,
          22.90000000000001,
          16.700000000000003,
          39.7,
          44.7,
          33.900000000000006,
          35.2,
          18.3,
          33.400000000000006,
          37.2,
          24.099999999999994,
          43.2,
          38,
          29.3,
          29.40000000000001,
          34.900000000000006,
          43.400000000000006,
          23.40000000000001,
          34.599999999999994,
          26.40000000000001,
          44.900000000000006,
          38.5,
          31.8,
          22.599999999999994,
          37.2,
          33,
          22.3,
          16.200000000000003,
          37.6,
          36.7,
          31.200000000000003,
          35.7,
          13.299999999999995,
          35,
          21.200000000000003,
          37.2,
          38,
          37.5,
          28.90000000000001,
          38.2,
          30.40000000000001,
          30.8,
          38.6,
          40.1,
          41.900000000000006,
          43.2,
          38.6,
          32.900000000000006,
          37.6,
          30.8,
          36,
          42.6,
          23.8,
          40.5,
          40.2,
          31.599999999999994,
          30.099999999999994,
          36.5,
          24.8,
          37.6,
          47.7,
          41.3,
          32.5,
          22.5,
          40.8,
          31.700000000000003,
          37,
          33.099999999999994,
          33.7,
          42,
          36.1,
          22.5,
          31.200000000000003,
          41.3,
          40.8,
          14,
          33.8,
          38.1,
          29,
          36.5,
          16,
          28.40000000000001,
          40.5,
          41.1,
          38.8,
          34.7,
          29.40000000000001,
          33.900000000000006,
          27.5,
          38.2,
          32.400000000000006,
          42.5,
          37.900000000000006,
          30.3,
          35.3,
          37.2,
          32.8,
          37.900000000000006,
          15.299999999999995,
          20.599999999999994,
          33.8,
          36.400000000000006,
          20.5,
          21.200000000000003,
          31.200000000000003,
          18.599999999999994,
          28.90000000000001,
          37.2,
          38.5,
          36.400000000000006,
          37.8,
          25.40000000000001,
          35.7,
          41.6,
          39.8,
          22.8,
          39.2,
          37.3,
          42.7,
          36.4,
          43.400000000000006,
          38.6,
          14.700000000000005,
          25.200000000000003,
          29.200000000000003,
          19.90000000000001,
          25.40000000000001,
          20.099999999999994,
          35.7,
          11.599999999999994,
          36.6,
          39.8,
          36.3,
          19.40000000000001,
          36.5,
          18.200000000000003,
          44.900000000000006,
          42.3,
          38.1,
          31.700000000000003,
          19.3,
          35,
          40.1,
          29.200000000000003,
          31.200000000000003,
          38.2,
          39.6,
          35.099999999999994,
          32.3,
          43.7,
          43.5,
          34.7,
          39.400000000000006,
          35.5,
          37.400000000000006,
          35.900000000000006,
          34.599999999999994,
          41.8,
          23.200000000000003,
          12.700000000000005,
          20.200000000000003,
          33.2,
          39.6,
          37.2,
          38.6,
          40,
          36.8,
          22.90000000000001,
          41.1,
          24.200000000000003,
          40.1,
          34.599999999999994,
          37.400000000000006,
          41.3,
          17.5,
          36.400000000000006,
          39.2,
          37.3,
          15.900000000000006,
          24.90000000000001,
          38.900000000000006,
          36.900000000000006,
          38.2,
          13.200000000000005,
          30.90000000000001,
          23.40000000000001,
          34.2,
          38.1,
          32.8,
          38.2,
          34.400000000000006,
          40.400000000000006,
          36.900000000000006,
          46.5,
          38.5,
          31.40000000000001,
          34.900000000000006,
          26.200000000000003,
          31,
          39.2,
          39.400000000000006,
          27.3,
          23.5,
          38.400000000000006,
          24.5,
          21,
          28.3,
          31.8,
          38.900000000000006,
          10.900000000000006,
          37.400000000000006,
          19.200000000000003,
          41.6,
          40.8,
          29.40000000000001,
          30.5,
          39.1,
          19.700000000000003,
          42.7,
          35.400000000000006,
          34.900000000000006,
          24.40000000000001,
          22.700000000000003,
          42.7,
          41.3,
          36.2,
          0,
          33.3,
          21.5,
          34.3,
          33.2,
          35,
          38.2,
          38.8,
          35.8,
          37,
          39.3,
          28,
          37.7,
          37.8,
          21.099999999999994,
          37.1,
          42.6,
          41.3,
          35.5,
          28.599999999999994,
          38.2,
          28.8,
          25,
          11.400000000000006,
          19.3,
          19,
          21.5,
          35.099999999999994,
          38.7,
          39.8,
          42.3,
          14.900000000000006,
          14.099999999999994,
          42.1,
          38.2,
          36.2,
          25.599999999999994,
          33.900000000000006,
          17.900000000000006,
          11.400000000000006,
          43.8,
          35.2,
          37.900000000000006,
          18.099999999999994,
          34.099999999999994,
          33.400000000000006,
          42,
          38.7,
          28.8,
          31.8,
          39.1,
          42.2,
          38.1,
          34.599999999999994,
          23.599999999999994,
          33.099999999999994,
          35.2,
          42.900000000000006,
          39.6,
          32.8,
          17.700000000000003,
          35.7,
          33.3,
          23,
          36.400000000000006,
          28.40000000000001,
          36.8,
          37.8,
          37,
          25.200000000000003,
          24.5,
          38.5,
          38.900000000000006,
          39.400000000000006,
          33.400000000000006,
          34.3,
          13.700000000000005,
          32.3,
          37.3,
          38.8,
          17.200000000000003,
          22,
          24.599999999999994,
          16.700000000000003,
          34.2,
          33.2,
          22.5,
          18.5,
          22.5,
          35.5,
          13.799999999999995,
          19.099999999999994,
          41.400000000000006,
          38.400000000000006,
          21,
          27.5,
          39,
          38.400000000000006,
          34.7,
          34.8,
          35.8,
          30.700000000000003,
          39.3,
          32.900000000000006,
          36.400000000000006,
          40.1,
          33.2,
          45.6,
          37.3,
          33.900000000000006,
          29.5,
          37.7,
          23,
          11.099999999999994,
          35.5,
          29.40000000000001,
          39.2,
          37.900000000000006,
          39.2,
          26.8,
          36,
          19.700000000000003,
          29.90000000000001,
          20.200000000000003,
          36.900000000000006,
          39.1,
          36.900000000000006,
          35.599999999999994,
          17.200000000000003,
          37.8,
          19.200000000000003,
          17.900000000000006,
          25.099999999999994,
          27.099999999999994,
          34.3,
          30.5,
          37.8,
          39.900000000000006,
          32.3,
          37,
          33.400000000000006,
          21.200000000000003,
          30.700000000000003,
          36.6,
          41.2,
          41.6,
          41.3,
          26.40000000000001,
          38.7,
          35.8,
          38.6,
          24.3,
          41.2,
          37.1,
          20.200000000000003,
          36.7,
          32.8,
          32,
          36.2,
          32.599999999999994,
          23.90000000000001,
          23.3,
          24.5,
          33.900000000000006,
          43.2,
          17.599999999999994,
          40.400000000000006,
          35.400000000000006,
          28.200000000000003,
          38.5,
          36.7,
          25.200000000000003,
          26.3,
          16.299999999999997,
          22.200000000000003,
          38.400000000000006,
          36.6,
          24.099999999999994,
          36.2,
          26.90000000000001,
          17.799999999999997,
          28.599999999999994,
          40.5,
          23.200000000000003,
          45,
          15.799999999999995,
          43.900000000000006,
          15.200000000000005,
          43.1,
          37.7,
          36,
          27.200000000000003,
          41.6,
          35.099999999999994,
          30.90000000000001,
          35.599999999999994,
          17.700000000000003,
          32.3,
          35.900000000000006,
          37,
          41.6,
          23.099999999999994,
          38.2,
          38.1,
          38.5,
          30,
          28.099999999999994,
          37.1,
          30.200000000000003,
          34.5,
          35.599999999999994,
          22,
          29.700000000000003,
          38.2,
          39.3,
          40.7,
          34.8,
          18.90000000000001,
          19.5,
          39,
          27,
          40.1,
          17.599999999999994,
          26.40000000000001,
          36.900000000000006,
          30.5,
          32.2,
          28.40000000000001,
          26.3,
          35,
          32.400000000000006,
          40.2,
          37.400000000000006,
          46.7,
          42.900000000000006,
          38,
          22.90000000000001,
          39.2,
          37,
          35.099999999999994,
          36.7,
          29.90000000000001,
          34,
          37.8,
          37.400000000000006,
          35.5,
          23,
          29.3,
          36.6,
          43.1,
          40.3,
          41.1,
          42.5,
          37.5,
          40.1,
          36.3,
          37.8,
          34.900000000000006,
          19.599999999999994,
          33.5,
          20.700000000000003,
          18.599999999999994,
          39.8,
          38.3,
          32.2,
          41.1,
          41.1,
          30.5,
          40.8,
          31,
          42.400000000000006,
          26.099999999999994,
          28.90000000000001,
          39.8,
          15.400000000000006,
          35.5,
          35.599999999999994,
          45.6,
          25.5,
          13.400000000000006,
          34.3,
          39.7,
          31.099999999999994,
          36.8,
          40,
          40.8,
          31.5,
          15.5,
          38.3,
          25,
          16.799999999999997,
          19.90000000000001,
          40.900000000000006,
          32.8,
          23.099999999999994,
          39,
          33.900000000000006,
          23.599999999999994,
          27.40000000000001,
          28.8,
          40.5,
          30,
          14.400000000000006,
          41.5,
          24.700000000000003,
          30.700000000000003,
          35.400000000000006,
          38.8,
          43.2,
          26.8,
          43.400000000000006,
          20.40000000000001,
          34.599999999999994,
          14.5,
          38.8,
          35.3,
          41.3,
          37.5,
          26.8,
          41.8,
          24.700000000000003,
          42.1,
          34.5,
          30.200000000000003,
          18.3,
          41.6,
          41,
          24.099999999999994,
          41.8,
          38.400000000000006,
          17.900000000000006,
          33.3,
          23.40000000000001,
          34.7,
          41.900000000000006,
          13.5,
          36.900000000000006,
          31.599999999999994,
          31.8,
          22.099999999999994,
          38.3,
          38.3,
          35.3,
          40.1,
          23.599999999999994,
          15.599999999999994,
          26.5,
          42.7,
          40,
          19.8,
          40.5,
          35.400000000000006,
          37.6,
          33.400000000000006,
          38,
          13.700000000000005,
          7.799999999999997,
          42.400000000000006,
          39.400000000000006,
          34.099999999999994,
          36.2,
          40.1,
          40.900000000000006,
          19.3,
          37.400000000000006,
          42.3,
          23.90000000000001,
          27.40000000000001,
          41.5,
          44.8,
          40.5,
          40.8,
          17.400000000000006,
          39.8,
          35,
          42,
          38.5,
          25.700000000000003,
          25.700000000000003,
          19.90000000000001,
          21.8,
          17.700000000000003,
          17.400000000000006,
          36.900000000000006,
          30.700000000000003,
          36.400000000000006,
          34.099999999999994,
          27.200000000000003,
          36.900000000000006,
          30.099999999999994,
          31.200000000000003,
          36.6,
          42.1,
          32.599999999999994,
          36.3,
          38.7,
          37.4,
          35.8,
          33.5,
          39.3,
          34.099999999999994,
          27.700000000000003,
          9.599999999999994,
          33,
          30.599999999999994,
          21.5,
          25,
          40.3,
          41,
          37.900000000000006,
          20.3,
          29.90000000000001,
          39.6,
          24.5,
          37.8,
          33.400000000000006,
          44.1,
          37.1,
          29.200000000000003,
          35.099999999999994,
          38.6,
          21.099999999999994,
          36.1,
          37.400000000000006,
          42.3,
          36.5,
          37.6,
          26.700000000000003,
          17.299999999999997,
          21.40000000000001,
          34,
          44,
          36.3,
          30.599999999999994,
          44.7,
          43.5,
          20.099999999999994,
          22,
          29.8,
          24.3,
          35.7,
          34.3,
          42.8,
          39.6,
          27.3,
          19.8,
          35.8,
          37.7,
          31.099999999999994,
          23.5,
          20.599999999999994,
          24,
          39.6,
          22.099999999999994,
          29.700000000000003,
          37.6,
          37.3,
          39.900000000000006,
          31.200000000000003,
          24.40000000000001,
          41.6,
          36.6,
          34.5,
          21.40000000000001,
          36,
          35.5,
          42.6,
          39.6,
          39.400000000000006,
          39.2,
          38.8,
          24.40000000000001,
          13.900000000000006,
          23.099999999999994,
          22.200000000000003,
          37.6,
          35.900000000000006,
          41.7,
          26.8,
          35.599999999999994,
          35.900000000000006,
          38.8,
          39.6,
          40.3,
          36.900000000000006,
          36.7,
          23.8,
          31.8,
          34.8,
          37.3,
          42.1,
          24.40000000000001,
          34.900000000000006,
          40.5,
          26.90000000000001,
          43.3,
          33.599999999999994,
          22,
          37.8,
          25.90000000000001,
          21.099999999999994,
          22.200000000000003,
          38.400000000000006,
          33.900000000000006,
          30.099999999999994,
          24.200000000000003,
          36.7,
          40,
          23.599999999999994,
          33.8,
          38.900000000000006,
          17.700000000000003,
          37.7,
          36.400000000000006,
          33.099999999999994,
          21.599999999999994,
          30,
          37.8,
          25.5,
          34.400000000000006,
          25.8,
          42,
          36.6,
          20.5,
          37.2,
          25.8,
          39.1,
          33,
          40.2,
          31.40000000000001,
          43.2,
          23.5,
          19.3,
          16.299999999999997,
          21.90000000000001,
          25,
          29.5,
          36.6,
          43,
          37.2,
          39,
          16.200000000000003,
          38.2,
          34.3,
          17,
          44.5,
          33.599999999999994,
          25.5,
          34.8,
          25.40000000000001,
          19.8,
          29,
          35.5,
          37.7,
          42.3,
          42.3,
          25.90000000000001,
          30.3,
          30.8,
          9.900000000000006,
          34,
          44,
          35.099999999999994,
          37.8,
          31.3,
          21.700000000000003,
          38.6,
          34.3,
          30,
          21.099999999999994,
          38.8,
          20.8,
          21.40000000000001,
          21.3,
          37.6,
          41.400000000000006,
          34.2,
          46.400000000000006,
          39.900000000000006,
          43.900000000000006,
          33.2,
          38.5,
          37.6,
          20.8,
          20.3,
          37.400000000000006,
          41.2,
          41.6,
          35.599999999999994,
          37.400000000000006,
          36.7,
          38.900000000000006,
          38.5,
          31.099999999999994,
          38.5,
          20.200000000000003,
          33.3,
          41.1,
          33.7,
          33.3,
          41.3,
          38.900000000000006,
          6.5,
          31.599999999999994,
          40.400000000000006,
          23.3,
          43.6,
          27.3,
          26,
          34.3,
          39.5,
          38.3,
          42.6,
          40.5,
          30.700000000000003,
          38,
          37.6,
          40.2,
          29.099999999999994,
          41,
          25.90000000000001,
          34.400000000000006,
          17.5,
          38.2,
          39.8,
          31.90000000000001,
          39.6,
          29.90000000000001,
          34.099999999999994,
          39.3,
          40.2,
          36.1,
          28.700000000000003,
          34,
          42.3,
          11,
          40,
          41.1,
          24.599999999999994,
          37.5,
          34.099999999999994,
          35.900000000000006,
          39.7,
          11.599999999999994,
          26.200000000000003,
          38.400000000000006,
          21.3,
          37.2,
          27.599999999999994,
          29.90000000000001,
          38.5,
          39,
          39.400000000000006,
          19.40000000000001,
          36.5,
          36.5,
          28,
          37.8,
          38.400000000000006,
          40.5,
          41.8,
          44.900000000000006,
          31.5,
          39.2,
          26.099999999999994,
          37.5,
          36,
          35.099999999999994,
          41,
          36,
          23,
          34,
          38,
          36.8,
          42,
          39.6,
          20.599999999999994,
          26.3,
          37.900000000000006,
          29.40000000000001,
          27,
          13.200000000000005,
          40.1,
          39.1,
          40,
          35.900000000000006,
          22.3,
          28,
          34.099999999999994,
          38.5,
          38,
          32.900000000000006,
          44.400000000000006,
          36.2,
          39.3,
          40.8,
          29.40000000000001,
          37.3,
          38.8,
          17.599999999999994,
          28.8,
          29.3,
          35.599999999999994,
          41.8,
          41,
          33.7,
          35.2,
          33.5,
          22.5,
          25.599999999999994,
          42.400000000000006,
          39.6,
          38,
          45.2,
          37,
          38.2,
          34.099999999999994,
          26.5,
          26.700000000000003,
          39.8,
          37.900000000000006,
          15,
          17.299999999999997,
          39.7,
          9.200000000000005,
          15.099999999999994,
          24.3,
          34,
          35.3,
          37.400000000000006,
          43,
          32.099999999999994,
          20.599999999999994,
          36.8,
          17.700000000000003,
          33,
          40.8,
          36.5,
          24.3,
          36,
          28,
          36.400000000000006,
          40.5,
          32.900000000000006,
          36.900000000000006,
          20,
          37.2,
          39.7,
          19.700000000000003,
          39.1,
          35.7,
          43.3,
          20.8,
          29.099999999999994,
          37.5,
          39.6,
          45.3,
          38.6,
          35.8,
          21.3,
          38.7,
          26.200000000000003,
          34.3,
          24.40000000000001,
          32.099999999999994,
          34.5,
          24.40000000000001,
          40.1,
          39,
          39.5,
          39.7,
          39.1,
          32,
          44.7,
          34.2,
          34.3,
          38.7,
          20.8,
          41.5,
          35.5,
          33.400000000000006,
          36.2,
          29.200000000000003,
          37.3,
          36.8,
          45.400000000000006,
          18,
          35.900000000000006,
          34.5,
          30.599999999999994,
          25.700000000000003,
          24.90000000000001,
          35,
          34,
          34.400000000000006,
          33.3,
          43.3,
          28.099999999999994,
          17.900000000000006,
          39.5,
          34.099999999999994,
          37.1,
          25.3,
          36.8,
          39.5,
          33.5,
          44.7,
          21.3,
          39.5,
          27.200000000000003,
          17.200000000000003,
          35.3,
          25.8,
          43.8,
          38.3,
          38.7,
          37.900000000000006,
          23.3,
          31.8,
          22.099999999999994,
          32.599999999999994,
          38,
          34.8,
          38.400000000000006,
          37.2,
          19.8,
          42.1,
          43.8,
          38.6,
          36.6,
          39.7,
          36.2,
          21.8,
          37.2,
          25.099999999999994,
          22.8,
          43.400000000000006,
          40.8,
          33,
          34.400000000000006,
          22.40000000000001,
          27.40000000000001,
          43.1,
          40.900000000000006,
          36.900000000000006,
          40,
          34.400000000000006,
          40.400000000000006,
          38,
          15.799999999999995,
          34.7,
          40.8,
          34.599999999999994,
          28.3,
          41.2,
          27.200000000000003,
          31.200000000000003,
          34.900000000000006,
          37.900000000000006,
          38.7,
          21.3,
          35.900000000000006,
          40.1,
          39.6,
          19.200000000000003,
          36,
          35.7,
          26.099999999999994,
          34.099999999999994,
          24.200000000000003,
          40.8,
          37.7,
          40.1,
          39.5,
          34.3,
          21.3,
          39.5,
          27.099999999999994,
          42.400000000000006,
          25.099999999999994,
          22.3,
          32.3,
          31.40000000000001,
          35,
          8.599999999999994,
          39.400000000000006,
          26.8,
          33.7,
          43,
          39.7,
          24.200000000000003,
          37,
          25,
          37.8,
          39.2,
          33.099999999999994,
          37.7,
          35.099999999999994,
          22.5,
          36,
          13.599999999999994,
          12.599999999999994,
          35.7,
          42.400000000000006,
          39.4,
          35.900000000000006,
          37.3,
          38.5,
          40.3,
          33,
          35.3,
          39.6,
          27.40000000000001,
          25,
          40.400000000000006,
          37.5,
          40.400000000000006,
          37.8,
          23.5,
          31.90000000000001,
          22,
          41.7,
          19.599999999999994,
          28.90000000000001,
          20,
          35.2,
          41.3,
          40.400000000000006,
          39.7,
          35.3,
          22.5,
          20.90000000000001,
          34,
          36.8,
          26.599999999999994,
          33.3,
          38.2,
          41.3,
          41.5,
          25.3,
          32,
          35.3,
          41.1,
          37.6,
          34.7,
          38.400000000000006,
          31.40000000000001,
          36,
          37.400000000000006,
          40.8,
          33.599999999999994,
          23,
          25,
          37.3,
          42.7,
          34.8,
          34.8,
          34.400000000000006,
          21.8,
          21.5,
          24.8,
          35,
          41,
          31.099999999999994,
          32.7,
          32.8,
          37.3,
          25.099999999999994,
          37.6,
          37.6,
          34.599999999999994,
          24.200000000000003,
          25,
          19.099999999999994,
          15.700000000000005,
          35.5,
          17.799999999999997,
          20.700000000000003,
          41,
          25.40000000000001,
          36,
          19.3,
          25,
          33.900000000000006,
          12.400000000000006,
          29.200000000000003,
          16.299999999999997,
          39.3,
          39.8,
          25.90000000000001,
          40.6,
          25.8,
          36.1,
          38.7,
          29,
          46.900000000000006,
          34.5,
          38,
          38.7,
          34.900000000000006,
          21,
          39.1,
          30.700000000000003,
          39.3,
          36.400000000000006,
          21.8,
          36.5,
          45.5,
          34.599999999999994,
          36.7,
          27.3,
          35.5,
          35.900000000000006,
          41.900000000000006,
          37.900000000000006,
          38.5,
          21.700000000000003,
          39.400000000000006,
          22,
          25.5,
          35.8,
          16.200000000000003,
          24.599999999999994,
          39.7,
          37.3,
          38.3,
          26.599999999999994,
          16.200000000000003,
          35.099999999999994,
          10.5,
          40.1,
          35.599999999999994,
          41.8,
          33.7,
          37.8,
          31,
          46,
          37,
          37,
          13.799999999999995,
          30.200000000000003,
          38.7,
          38.6,
          46.400000000000006,
          21.40000000000001,
          39.7,
          34.5,
          31.099999999999994,
          41.8,
          41.3,
          40.2,
          38.2,
          41.1,
          39.7,
          35.400000000000006,
          42,
          39.7,
          40.3,
          22.3,
          38.400000000000006,
          38.1,
          39,
          39.8,
          25.5,
          36,
          35.400000000000006,
          41.6,
          37.3,
          43,
          21.90000000000001,
          42.2,
          37.5,
          33.3,
          33,
          23.099999999999994,
          41.6,
          33.400000000000006,
          37.5,
          37.400000000000006,
          45.6,
          18.3,
          25.5,
          38.7,
          32.3,
          27.3,
          39,
          38.1,
          31.099999999999994,
          41.5,
          23.90000000000001,
          39.1,
          17.400000000000006,
          35.8,
          38.7,
          39.6,
          45.7,
          41.400000000000006,
          22.40000000000001,
          43.900000000000006,
          38.8,
          21.40000000000001,
          33.5,
          17.900000000000006,
          40.900000000000006,
          35.400000000000006,
          31.099999999999994,
          36.6,
          42.5,
          36.2,
          33.5,
          40.900000000000006,
          42.2,
          40.400000000000006,
          39,
          32.7,
          33.7,
          39.1,
          21.599999999999994,
          31.3,
          27.200000000000003,
          37.1,
          41.2,
          43.8,
          17,
          9.900000000000006,
          35.099999999999994,
          35.099999999999994,
          37.7,
          42.1,
          33.3,
          24.90000000000001,
          42.6,
          31.700000000000003,
          17.099999999999994,
          39.3,
          33.3,
          29.40000000000001,
          31,
          15.799999999999995,
          23.90000000000001,
          39.1,
          38.1,
          36.6,
          45.6,
          17.700000000000003,
          35.900000000000006,
          13.200000000000005,
          22.3,
          37.8,
          27.3,
          36.9,
          36.4,
          28.700000000000003,
          42.3,
          26.3,
          40,
          37.6,
          40.900000000000006,
          38.900000000000006,
          32.599999999999994,
          36.7,
          35.599999999999994,
          35.5,
          37.900000000000006,
          35.5,
          42.8,
          36.2,
          25.700000000000003,
          24.099999999999994,
          39.3,
          40.1,
          39.3,
          24.8,
          27.40000000000001,
          35.7,
          39.900000000000006,
          30.90000000000001,
          40.8,
          30.099999999999994,
          14.799999999999995,
          19.5,
          43.7,
          33.7,
          19.3,
          32.400000000000006,
          34,
          30.599999999999994,
          33.5,
          36.1,
          36.900000000000006,
          19.90000000000001,
          40.400000000000006,
          38.2,
          35.3,
          34.3,
          33.099999999999994,
          36.3,
          31.40000000000001,
          40.400000000000006,
          37.3,
          32.5,
          25.099999999999994,
          26.700000000000003,
          33.599999999999994,
          41,
          39.3,
          15.400000000000006,
          37.400000000000006,
          39.6,
          17.099999999999994,
          37.2,
          36.1,
          28.90000000000001,
          25.099999999999994,
          38.6,
          27.5,
          41.5,
          17.799999999999997,
          20.40000000000001,
          36,
          18.8,
          32.400000000000006,
          42.1,
          37.7,
          39.1,
          7.200000000000003,
          37.2,
          28.599999999999994,
          20.3,
          37.400000000000006,
          15.299999999999995,
          34.8,
          33.599999999999994,
          36.400000000000006,
          30,
          27.5,
          37,
          25.5,
          30.200000000000003,
          23.700000000000003,
          20.099999999999994,
          20.8,
          41.5,
          34.900000000000006,
          30.40000000000001,
          37,
          41.3,
          22.200000000000003,
          35.5,
          23,
          25.8,
          37.400000000000006,
          42.1,
          36.3,
          36.6,
          44.1,
          37.5,
          33,
          39.900000000000006,
          23,
          39.6,
          32.8,
          35.400000000000006,
          37.8,
          41.8,
          19.90000000000001,
          18.700000000000003,
          36.3,
          39.2,
          20.40000000000001,
          38.900000000000006,
          39.900000000000006,
          35.5,
          33.7,
          28.3,
          36.1,
          37.3,
          45.3,
          37.900000000000006,
          35.8,
          43,
          34.099999999999994,
          41.7,
          34.7,
          39.2,
          39.7,
          43.2,
          40.6,
          40.7,
          40.5,
          29.90000000000001,
          38.7,
          36.5,
          40.6,
          24.40000000000001,
          28.8,
          40.3,
          36.400000000000006,
          37.3,
          31.5,
          37.7,
          44,
          30.3,
          36,
          33.7,
          30.599999999999994,
          21.099999999999994,
          41.6,
          36.3,
          37.6,
          40.7,
          37.3,
          23.700000000000003,
          38.5,
          41.8,
          35.099999999999994,
          47.8,
          10.200000000000005,
          34.2,
          41.1,
          41.1,
          37.7,
          38,
          34.599999999999994,
          39.900000000000006,
          38.1,
          41.900000000000006,
          38.400000000000006,
          23.700000000000003,
          20.200000000000003,
          21.5,
          31.099999999999994,
          38.6,
          33.5,
          33.3,
          40.900000000000006,
          38.7,
          34.099999999999994,
          22.200000000000003,
          27.200000000000003,
          19.8,
          33.099999999999994,
          35.900000000000006,
          40.400000000000006,
          45.900000000000006,
          39.1,
          34.7,
          23.8,
          30.3,
          35.3,
          36.6,
          40.1,
          38.8,
          36,
          25,
          36.400000000000006,
          31.5,
          24.8,
          32.900000000000006,
          20,
          43.1,
          26.700000000000003,
          29.3,
          39.2,
          26.8,
          38,
          24.3,
          39.2,
          41.900000000000006,
          29.099999999999994,
          38,
          21.8,
          35.8,
          38.5,
          35.2,
          36.2,
          33.400000000000006,
          18.099999999999994,
          35.900000000000006,
          24.3,
          18.90000000000001,
          14.900000000000006,
          29,
          20.40000000000001,
          18.5,
          39.400000000000006,
          37.2,
          40.3,
          32,
          24.099999999999994,
          40.3,
          26.8,
          29.40000000000001,
          40.400000000000006,
          37.3,
          13.299999999999995,
          38.5,
          34.5,
          42.5,
          20.8,
          45.3,
          35.099999999999994,
          29,
          35,
          24.200000000000003,
          35.8,
          30,
          35.2,
          22.40000000000001,
          37.1,
          25,
          29.3,
          19,
          35.599999999999994,
          40.900000000000006,
          35.7,
          38.900000000000006,
          39,
          29.5,
          16,
          27.5,
          20.099999999999994,
          28.5,
          28.3,
          24,
          37.3,
          40.1,
          27.099999999999994,
          37.1,
          22.8,
          39.2,
          40.8,
          31.700000000000003,
          37.6,
          27.3,
          43.2,
          40.5,
          41.1,
          17.400000000000006,
          30.8,
          37.6,
          40.7,
          37.7,
          29.90000000000001,
          37.1,
          25.3,
          28.5,
          42.400000000000006,
          41.2,
          29.5,
          38.6,
          38.8,
          12.799999999999995,
          40.2,
          33.5,
          15.5,
          44.5,
          18,
          34.5,
          38.1,
          39.1,
          36.7,
          16.799999999999997,
          43.3,
          22.90000000000001,
          39,
          36.400000000000006,
          29.90000000000001,
          16,
          36.7,
          22.8,
          13.299999999999995,
          24.200000000000003,
          22.90000000000001,
          30.90000000000001,
          34.7,
          32.400000000000006,
          17.599999999999994,
          38.2,
          45.400000000000006,
          42,
          41.5,
          39.8,
          17.5,
          33.2,
          20.700000000000003,
          40.400000000000006,
          36.400000000000006,
          33.599999999999994,
          27.5,
          37.8,
          24.5,
          23.90000000000001,
          44.400000000000006,
          38.1,
          43,
          35.099999999999994,
          38.5,
          36.400000000000006,
          40.400000000000006,
          38.5,
          38.3,
          37.8,
          16.700000000000003,
          26.40000000000001,
          44.900000000000006,
          41,
          35.3,
          23,
          24.700000000000003,
          26.5,
          20.200000000000003,
          36.900000000000006,
          30.5,
          26.3,
          26.099999999999994,
          34.900000000000006,
          34.599999999999994,
          43.2,
          42,
          37.1,
          34.7,
          41.5,
          22.90000000000001,
          17.900000000000006,
          43.2,
          38.400000000000006,
          41,
          36.8,
          13.200000000000005,
          37.900000000000006,
          36.7,
          40,
          36.3,
          39.8,
          18.8,
          39,
          39.400000000000006,
          26.5,
          39.900000000000006,
          36.5,
          41.1,
          41.3,
          21.8,
          36.6,
          43.900000000000006,
          38.900000000000006,
          37,
          39,
          39.1,
          37.6,
          32,
          43.2,
          41.1,
          28.700000000000003,
          33.099999999999994,
          39.5,
          27.599999999999994,
          17.099999999999994,
          36,
          34,
          39.1,
          33.099999999999994,
          26.099999999999994,
          20.700000000000003,
          42.1,
          40.400000000000006,
          23.8,
          38.5,
          39.2,
          38.6,
          39.2,
          33.099999999999994,
          38.400000000000006,
          39.8,
          42.900000000000006,
          40,
          37,
          24.8,
          21.200000000000003,
          36,
          39.900000000000006,
          40.3,
          37.400000000000006,
          11.900000000000006,
          39.1,
          41.400000000000006,
          38.3,
          44.3,
          38,
          26.599999999999994,
          43.900000000000006,
          37.7,
          41.8,
          35.099999999999994,
          41.400000000000006,
          37.6,
          37,
          21.90000000000001,
          38,
          26.700000000000003,
          37.900000000000006,
          36.2,
          22,
          19.700000000000003,
          45.7,
          39.8,
          30,
          27.099999999999994,
          24.40000000000001,
          28.5,
          36.6,
          24.90000000000001,
          43.900000000000006,
          32.5,
          27.8,
          37.6,
          22,
          43.5,
          23.599999999999994,
          41.2,
          21.099999999999994,
          24.099999999999994,
          32.5,
          18.599999999999994,
          35.3,
          13.700000000000005,
          37.2,
          37.6,
          37.6,
          35.8,
          39.1,
          25.90000000000001,
          41.2,
          37.6,
          38.5,
          41.6,
          33.599999999999994,
          34.7,
          29.599999999999994,
          38,
          22.90000000000001,
          16,
          23.200000000000003,
          39.8,
          35.099999999999994,
          21.099999999999994,
          39.3,
          38.6,
          33.5,
          37.6,
          22.90000000000001,
          35.7,
          37.900000000000006,
          36.8,
          36.6,
          32.900000000000006,
          44.2,
          38.2,
          26.5,
          40.400000000000006,
          44.8,
          26.40000000000001,
          32,
          24.700000000000003,
          32.400000000000006,
          40.5,
          39.4,
          38,
          28,
          40.5,
          31.599999999999994,
          35.599999999999994,
          38.7,
          32.8,
          40.5,
          24,
          36.3,
          34.8,
          41.1,
          26.5,
          39.400000000000006,
          36,
          37.1,
          40.2,
          34.3,
          41.1,
          35.5,
          23.200000000000003,
          20.8,
          27.90000000000001,
          34.8,
          9.799999999999995,
          36.3,
          43.3,
          23.40000000000001,
          35.900000000000006,
          36.2,
          17.400000000000006,
          25.3,
          42.8,
          36.8,
          41.2,
          18.40000000000001,
          37.400000000000006,
          40.1,
          8.099999999999994,
          38.3,
          35,
          35.599999999999994,
          41.900000000000006,
          16.900000000000006,
          31.3,
          35.5,
          21.5,
          28.700000000000003,
          38.5,
          41.3,
          32.5,
          33.8,
          40.6,
          40.400000000000006,
          36.3,
          38,
          38.2,
          34.2,
          36,
          29.099999999999994,
          30.90000000000001,
          38.1,
          33.099999999999994,
          39.3,
          38.6,
          38.400000000000006,
          22.3,
          20.3,
          13.299999999999995,
          35.5,
          45.900000000000006,
          33.2,
          39.900000000000006,
          42.1,
          22.8,
          37.7,
          41.6,
          37.6,
          39.5,
          22.8,
          34.8,
          40,
          39.900000000000006,
          40,
          28.700000000000003,
          19.599999999999994,
          17.599999999999994,
          21.700000000000003,
          34.7,
          30.90000000000001,
          43.5,
          40.6,
          19.5,
          40.7,
          35.400000000000006,
          35,
          40.7,
          41.3,
          35.2,
          13.299999999999995,
          38.2,
          39,
          36.1,
          37.7,
          23.099999999999994,
          26.099999999999994,
          42.1,
          20.90000000000001,
          25,
          32.599999999999994,
          34.5,
          42.5,
          34,
          36.2,
          39.3,
          24.8,
          35.8,
          41.5,
          30.8,
          42.5,
          37.3,
          29.599999999999994,
          22.90000000000001,
          39.3,
          35.2,
          36.1,
          38.1,
          30.200000000000003,
          30.200000000000003,
          14.900000000000006,
          42.2,
          26.8,
          37.2,
          36.5,
          40,
          34.3,
          38.400000000000006,
          27.40000000000001,
          33.8,
          32.099999999999994,
          22.700000000000003,
          38.400000000000006,
          42.7,
          19,
          38.3,
          43.1,
          22.099999999999994,
          41.6,
          38.900000000000006,
          38.2,
          38.3,
          17.799999999999997,
          35.7,
          39.6,
          23.40000000000001,
          37.400000000000006,
          23.700000000000003,
          37.6,
          35.3,
          36.3,
          36.4,
          24.90000000000001,
          24,
          29.8,
          20.90000000000001,
          10.799999999999995,
          41.2,
          34.900000000000006,
          35.7,
          27.200000000000003,
          30,
          30.3,
          42.8,
          39.6,
          42.1,
          38.8,
          39,
          37.9,
          36,
          38.5,
          21.5,
          39.8,
          41.6,
          42.2,
          26.3,
          40,
          42.8,
          33,
          19.90000000000001,
          45.6,
          37.7,
          30.599999999999994,
          38.2,
          27.700000000000003,
          24.8,
          20.700000000000003,
          17.400000000000006,
          30,
          25.90000000000001,
          16.299999999999997,
          17.200000000000003,
          34.400000000000006,
          36.400000000000006,
          36.2,
          18.40000000000001,
          42.3,
          32.7,
          19.3,
          30.099999999999994,
          35.3,
          37.900000000000006,
          26.599999999999994,
          28.700000000000003,
          42.400000000000006,
          13.900000000000006,
          34.7,
          22.40000000000001,
          38.8,
          18.5,
          32.400000000000006,
          27.599999999999994,
          35.7,
          32.599999999999994,
          18.5,
          38.1,
          16,
          37.6,
          37.400000000000006,
          39.1,
          23.5,
          38.1,
          39.7,
          26,
          38.1,
          28.40000000000001,
          36.5,
          41.5,
          37.3,
          22.5,
          39.7,
          15.900000000000006,
          35.5,
          17.700000000000003,
          31.200000000000003,
          34.5,
          32.7,
          44.6,
          39,
          38.6,
          26.8,
          39.8,
          44.1,
          21.200000000000003,
          13.099999999999994,
          40.6,
          41.7,
          34.8,
          16,
          40.3,
          42.5,
          40.5,
          20,
          34.7,
          36.3,
          43.5,
          39.400000000000006,
          38.1,
          27.099999999999994,
          42.2,
          39.1,
          39.8,
          18.700000000000003,
          39.8,
          34.7,
          37.5,
          23.40000000000001,
          36.3,
          42.2,
          39.1,
          39.5,
          23.8,
          29.40000000000001,
          24.90000000000001,
          45,
          28.5,
          28.099999999999994,
          36.900000000000006,
          40.400000000000006,
          26.099999999999994,
          40.400000000000006,
          43.3,
          41.5,
          29.90000000000001,
          40.6,
          40,
          35.599999999999994,
          22.40000000000001,
          36.7,
          33.3,
          34,
          24.599999999999994,
          37.1,
          27.599999999999994,
          23.8,
          17,
          31.099999999999994,
          32.900000000000006,
          41.5,
          46.3,
          27.099999999999994,
          16.200000000000003,
          30.599999999999994,
          32.900000000000006,
          40,
          38.8,
          20.099999999999994,
          12,
          37,
          32.7,
          34.900000000000006,
          24.700000000000003,
          32.599999999999994,
          36.8,
          27,
          42.1,
          40.7,
          35.900000000000006,
          37.3,
          20.40000000000001,
          29.700000000000003,
          36.8,
          19.40000000000001,
          42.400000000000006,
          27.200000000000003,
          41.5,
          23.5,
          19.599999999999994,
          38.1,
          20.5,
          20.5,
          41.5,
          32.7,
          23.5,
          40.8,
          24,
          37.1,
          48.8,
          43.3,
          39.3,
          39.3,
          36.2,
          24,
          28.90000000000001,
          39.3,
          31.200000000000003,
          34.599999999999994,
          32.3,
          43.6,
          37.5,
          37.3,
          18.8,
          33.7,
          36.2,
          39.2,
          24.90000000000001,
          25.200000000000003,
          17.299999999999997,
          20.3,
          26.8,
          40,
          15.700000000000005,
          43.1,
          42.1,
          32.5,
          21.8,
          36.400000000000006,
          38.3,
          37,
          41.1,
          44,
          43.900000000000006,
          36,
          40,
          34.5,
          40.8,
          42.6,
          28.8,
          35.5,
          32,
          35.099999999999994,
          23.5,
          37.7,
          34.900000000000006,
          46.400000000000006,
          23.200000000000003,
          31.599999999999994,
          42.3,
          34.099999999999994,
          34.7,
          21,
          37.400000000000006,
          38.900000000000006,
          39.7,
          37.3,
          33.2,
          38.3,
          36.900000000000006,
          23.5,
          38.7,
          39,
          35.8,
          39.5,
          36.7,
          34.400000000000006,
          37.900000000000006,
          30.8,
          39.3,
          39.8,
          38.6,
          40.900000000000006,
          17.299999999999997,
          36,
          37.6,
          31.099999999999994,
          31.099999999999994,
          34.900000000000006,
          16,
          41,
          31.200000000000003,
          40.7,
          8.700000000000003,
          38.7,
          41.5,
          16.700000000000003,
          41.2,
          35.900000000000006,
          38.3,
          36.900000000000006,
          37,
          32.2,
          37,
          27,
          37,
          5.599999999999994,
          26.700000000000003,
          33.7,
          30.599999999999994,
          22.8,
          41,
          44.3,
          41,
          23.700000000000003,
          23.099999999999994,
          36.1,
          26.40000000000001,
          34.900000000000006,
          35.8,
          33.400000000000006,
          25.8,
          36.900000000000006,
          39.7,
          27.90000000000001,
          41.2,
          27.40000000000001,
          13,
          26.5,
          23.8,
          38.6,
          37.7,
          31.099999999999994,
          35,
          32.7,
          26.3,
          39.6,
          38.8,
          37.6,
          38.3,
          27.200000000000003,
          37.8,
          37.8,
          19.599999999999994,
          39,
          38.1,
          29.099999999999994,
          36.7,
          37.8,
          42.7,
          17.200000000000003,
          41.6,
          43.6,
          30.90000000000001,
          31.099999999999994,
          39.400000000000006,
          39.1,
          13.599999999999994,
          12.700000000000005,
          24.200000000000003,
          28,
          39.400000000000006,
          35.900000000000006,
          13.400000000000006,
          35.3,
          30.599999999999994,
          41.5,
          41.2,
          32.900000000000006,
          43.5,
          17.799999999999997,
          17.5,
          44.3,
          41.7,
          39.8,
          42.7,
          33.3,
          40.400000000000006,
          34.8,
          43,
          40.7,
          36.1,
          33,
          35,
          34.3,
          39.1,
          36.7,
          42.2,
          26.099999999999994,
          41.900000000000006,
          20.40000000000001,
          40.8,
          14.400000000000006,
          26.200000000000003,
          35.099999999999994,
          11.900000000000006,
          38.8,
          15.200000000000005,
          38.8,
          37.5,
          37.400000000000006,
          36.7,
          18.3,
          35.900000000000006,
          31.200000000000003,
          31,
          30,
          27.599999999999994,
          36.3,
          34.7,
          25.200000000000003,
          24.90000000000001,
          39.3,
          19.599999999999994,
          33,
          42.6,
          22.200000000000003,
          24.700000000000003,
          27,
          45.5,
          37.8,
          38.1,
          37.8,
          38,
          13.599999999999994,
          43.5,
          21.40000000000001,
          19,
          32.099999999999994,
          34.400000000000006,
          34.900000000000006,
          40.7,
          26.90000000000001,
          35.900000000000006,
          31.099999999999994,
          34.2,
          33.599999999999994,
          38.1,
          39,
          13.400000000000006,
          38.900000000000006,
          39.400000000000006,
          42.3,
          14.099999999999994,
          31.3,
          33.400000000000006,
          40.7,
          41.900000000000006,
          40.7,
          39.7,
          37.7,
          35.900000000000006,
          14.400000000000006,
          31,
          39.8,
          14.900000000000006,
          38.6,
          34.8,
          36.900000000000006,
          40.8,
          15.099999999999994,
          34,
          25.3,
          34.7,
          38.900000000000006,
          18.700000000000003,
          40.2,
          19.200000000000003,
          40,
          34.8,
          37.7,
          37.6,
          19.90000000000001,
          38.3,
          24.40000000000001,
          36,
          40.400000000000006,
          29.200000000000003,
          15.200000000000005,
          40.7,
          40.8,
          32.2,
          35.099999999999994,
          28.599999999999994,
          10.5,
          26.90000000000001,
          31.90000000000001,
          24.40000000000001,
          37.8,
          20.5,
          43.7,
          31.3,
          39,
          33.900000000000006,
          42.3,
          37.3,
          37.400000000000006,
          28.200000000000003,
          23.700000000000003,
          34.599999999999994,
          31,
          22.200000000000003,
          11.900000000000006,
          38.2,
          25.8,
          41.900000000000006,
          37.8,
          37.7,
          15.299999999999995,
          40.900000000000006,
          36.6,
          23.200000000000003,
          40.1,
          39,
          38.5,
          37.900000000000006,
          39.400000000000006,
          10.099999999999994,
          17,
          27.90000000000001,
          33.5,
          37.1,
          35.3,
          37.8,
          39,
          43.400000000000006,
          39.2,
          34.900000000000006,
          35.2,
          22,
          33,
          40.3,
          39.900000000000006,
          38.2,
          37.900000000000006,
          41.5,
          34.900000000000006,
          25.099999999999994,
          33.5,
          18.200000000000003,
          28.8,
          34.599999999999994,
          39.7,
          33.099999999999994,
          34.3,
          41.900000000000006,
          39.400000000000006,
          44.2,
          24,
          40.1,
          39.1,
          38.400000000000006,
          28.700000000000003,
          34.3,
          38.900000000000006,
          24.40000000000001,
          45.3,
          38.400000000000006,
          37.7,
          36.900000000000006,
          39.1,
          41.2,
          43,
          38.1,
          22.099999999999994,
          41.400000000000006,
          33.900000000000006,
          39.3,
          41.2,
          38.5,
          20.200000000000003,
          38.6,
          33.099999999999994,
          40.5,
          36.5,
          43.1,
          34.099999999999994,
          21.40000000000001,
          40.3,
          25.099999999999994,
          24,
          36.7,
          28.90000000000001,
          33.900000000000006,
          40.900000000000006,
          19.700000000000003,
          37.2,
          28.099999999999994,
          33.2,
          42,
          33.2,
          33.400000000000006,
          41,
          19.3,
          39.6,
          29.90000000000001,
          39.3,
          44,
          35.900000000000006,
          42,
          34,
          31.8,
          36.6,
          36.1,
          41.900000000000006,
          36.1,
          36.900000000000006,
          36.5,
          44.8,
          39,
          39.400000000000006,
          32.5,
          43,
          34.7,
          17.700000000000003,
          40,
          41.5,
          38,
          24.200000000000003,
          35.8,
          37,
          18,
          39.6,
          37.7,
          36.400000000000006,
          43.6,
          36.400000000000006,
          36.8,
          31.200000000000003,
          12.599999999999994,
          35.8,
          36.8,
          23.40000000000001,
          29.3,
          29.40000000000001,
          43,
          38.5,
          34.7,
          37.9,
          23.700000000000003,
          13.900000000000006,
          37,
          39.8,
          38.5,
          29.700000000000003,
          19.599999999999994,
          37.3,
          23.40000000000001,
          39.1,
          38.7,
          37.2,
          18.40000000000001,
          28.40000000000001,
          42.8,
          19.700000000000003,
          27,
          37.1,
          25.200000000000003,
          37.400000000000006,
          37.7,
          36.5,
          41.3,
          39.6,
          27.5,
          23.3,
          42.5,
          37.6,
          29.8,
          31.90000000000001,
          25.90000000000001,
          34.7,
          25.599999999999994,
          38.1,
          43,
          43.3,
          38.400000000000006,
          40.8,
          31,
          41.3,
          36.3,
          13.799999999999995,
          23.200000000000003,
          39.7,
          35.8,
          34.2,
          32,
          31.3,
          18.90000000000001,
          19.200000000000003,
          35.7,
          25.599999999999994,
          36.6,
          24.3,
          40.8,
          24,
          35.900000000000006,
          20.3,
          40.6,
          34.099999999999994,
          33.2,
          45.2,
          29.90000000000001,
          39.900000000000006,
          22.5,
          46.1,
          18.700000000000003,
          31.90000000000001,
          43.5,
          36.900000000000006,
          41,
          33.2,
          36.2,
          23.3,
          24.8,
          37.400000000000006,
          36.6,
          25.700000000000003,
          37.7,
          17.700000000000003,
          36.1,
          32.900000000000006,
          31.5,
          45.900000000000006,
          29,
          38.7,
          32.7,
          19.200000000000003,
          23.8,
          32.599999999999994,
          38,
          34.900000000000006,
          27.40000000000001,
          30.90000000000001,
          22.3,
          40,
          33.099999999999994,
          18.90000000000001,
          38.1,
          38.1,
          36.5,
          37.8,
          32.8,
          36,
          21.5,
          36.3,
          48.5,
          47.5,
          38.900000000000006,
          36.3,
          29.5,
          26.099999999999994,
          34.599999999999994,
          39,
          23.5,
          19.200000000000003,
          28.099999999999994,
          27.8,
          32.900000000000006,
          36.5,
          40.900000000000006,
          39.2,
          36.5,
          25,
          39.8,
          43,
          29.599999999999994,
          38.8,
          20.700000000000003,
          41.8,
          28,
          23.200000000000003,
          21.200000000000003,
          37.6,
          38.900000000000006,
          33.2,
          25.5,
          23,
          24.8,
          35.8,
          23.200000000000003,
          26.099999999999994,
          38.2,
          39.7,
          37.900000000000006,
          24.099999999999994,
          38.7,
          27.8,
          25.099999999999994,
          39.3,
          36.9,
          40.400000000000006,
          39,
          39.7,
          37.8,
          21.700000000000003,
          20.5,
          42.2,
          41,
          37.8,
          36.400000000000006,
          19,
          29.599999999999994,
          36.400000000000006,
          20.90000000000001,
          42.7,
          25.099999999999994,
          39.7,
          30.90000000000001,
          15.099999999999994,
          35.400000000000006,
          12.099999999999994,
          34.900000000000006,
          26,
          34.8,
          32,
          40.900000000000006,
          35.099999999999994,
          29,
          34.7,
          41.900000000000006,
          39,
          37.5,
          42.7,
          37.8,
          34.599999999999994,
          48.2,
          16.599999999999994,
          38.400000000000006,
          42.3,
          22.200000000000003,
          35.599999999999994,
          36.7,
          12.5,
          20.5,
          36.3,
          14.900000000000006,
          29.5,
          26.40000000000001,
          39,
          26.700000000000003,
          41.400000000000006,
          39.1,
          22.5,
          35.8,
          37.7,
          39.7,
          30.099999999999994,
          36.5,
          39.2,
          16.200000000000003,
          29.8,
          31.099999999999994,
          22.099999999999994,
          37.2,
          26.200000000000003,
          31.599999999999994,
          12.700000000000005,
          42,
          18.200000000000003,
          39.1,
          38.900000000000006,
          40.400000000000006,
          42.6,
          23.3,
          37.8,
          38.6,
          44.900000000000006,
          35.400000000000006,
          35.400000000000006,
          25.8,
          28.599999999999994,
          34.7,
          27.200000000000003,
          39.8,
          34.900000000000006,
          23.3,
          30.700000000000003,
          35.900000000000006,
          40.5,
          24.90000000000001,
          33.099999999999994,
          18.700000000000003,
          27.200000000000003,
          25.40000000000001,
          21.700000000000003,
          38.8,
          30.40000000000001,
          36.900000000000006,
          39.6,
          31.700000000000003,
          13.700000000000005,
          36.2,
          33.400000000000006,
          40.7,
          39.6,
          37.6,
          38.5,
          41.3,
          31.599999999999994,
          25.700000000000003,
          34.099999999999994,
          43.6,
          16.799999999999997,
          31.099999999999994,
          32.599999999999994,
          40,
          38.8,
          21.40000000000001,
          30.8,
          42.3,
          31.8,
          36.8,
          33.5,
          38.400000000000006,
          33.400000000000006,
          38.1,
          29.8,
          30.200000000000003,
          37.2,
          22.8,
          36.5,
          37,
          36.3,
          16.299999999999997,
          31.40000000000001,
          12.599999999999994,
          35.3,
          19.599999999999994,
          38.900000000000006,
          41.2,
          39.2,
          40.7,
          39.1,
          32.5,
          39.2,
          36.2,
          39.900000000000006,
          36.8,
          34,
          21.3,
          34.5,
          36.1,
          23.5,
          41.2,
          24.599999999999994,
          37.8,
          40.3,
          39,
          22.099999999999994,
          24.8,
          19.3,
          33.599999999999994,
          40.6,
          35.099999999999994,
          24.5,
          35.2,
          38,
          33.8,
          41,
          27.700000000000003,
          39.1,
          33.7,
          36.1,
          26.599999999999994,
          28.200000000000003,
          22.5,
          38.3,
          32.5,
          38.7,
          36.8,
          40.9,
          39.8,
          25.3,
          19,
          26.200000000000003,
          42.8,
          14.799999999999995,
          20.3,
          31.200000000000003,
          32.5,
          35.2,
          42.7,
          33.2,
          35.2,
          37.8,
          40.3,
          26.8,
          33.900000000000006,
          43.400000000000006,
          34.400000000000006,
          26.700000000000003,
          35.3,
          39.2,
          34.5,
          37.400000000000006,
          36.8,
          38,
          37.400000000000006,
          38.2,
          38.1,
          39.3,
          34.5,
          42.900000000000006,
          35.099999999999994,
          17.400000000000006,
          25.599999999999994,
          32.099999999999994,
          42.5,
          25,
          40.3,
          23.90000000000001,
          41,
          32.099999999999994,
          18.700000000000003,
          27.90000000000001,
          36,
          37.2,
          39.8,
          38.7,
          28.099999999999994,
          31.599999999999994,
          30.8,
          16.900000000000006,
          35.7,
          36.400000000000006,
          34.400000000000006,
          23.700000000000003,
          23.099999999999994,
          38.6,
          37.8,
          38.3,
          43.6,
          37,
          35.099999999999994,
          37.400000000000006,
          43.2,
          38.8,
          26.40000000000001,
          39.2,
          36.6,
          35.5,
          25.099999999999994,
          36.2,
          36.900000000000006,
          41.400000000000006,
          43.2,
          41.8,
          35.599999999999994,
          25.3,
          38.5,
          37.7,
          38,
          37.8,
          38.1,
          34.599999999999994,
          13.799999999999995,
          40.400000000000006,
          16.700000000000003,
          44.2,
          40.8,
          25.599999999999994,
          35,
          35,
          39.8,
          13.400000000000006,
          40.5,
          35.099999999999994,
          33.2,
          28.8,
          33,
          40.3,
          36.8,
          36.7,
          40.3,
          38.3,
          41.1,
          22.3,
          14.200000000000005,
          20.700000000000003,
          36.7,
          39,
          36,
          12.299999999999995,
          33.900000000000006,
          41.3,
          33.900000000000006,
          34.2,
          39.6,
          35.599999999999994,
          11.099999999999994,
          38.7,
          40.400000000000006,
          41.400000000000006,
          40.7,
          26.5,
          35.5,
          36.2,
          21.90000000000001,
          38.8,
          41.3,
          36.1,
          43.8,
          31.40000000000001,
          30.8,
          12.200000000000005,
          38,
          12.200000000000005,
          27.40000000000001,
          37.400000000000006,
          26.90000000000001,
          34.8,
          37.3,
          42.7,
          33.8,
          19,
          35.400000000000006,
          33.8,
          39.900000000000006,
          19.40000000000001,
          42,
          34.099999999999994,
          41.7,
          23,
          36.900000000000006,
          27.8,
          39.7,
          34.7,
          33,
          23,
          42.5,
          36.3,
          23.8,
          43.1,
          38.1,
          35.2,
          39.900000000000006,
          38.900000000000006,
          40.5,
          39.3,
          35.3,
          38.2,
          37.7,
          23,
          36.1,
          37,
          42,
          16.400000000000006,
          34.099999999999994,
          37.8,
          43.7,
          24.40000000000001,
          42,
          38.1,
          38.3,
          26.3,
          23,
          39.900000000000006,
          39.3,
          35.900000000000006,
          27.599999999999994,
          38.7,
          31,
          42,
          44.400000000000006,
          35.599999999999994,
          19.40000000000001,
          35.5,
          28.40000000000001,
          38.6,
          25.700000000000003,
          40,
          38.6,
          24.599999999999994,
          24.200000000000003,
          33.2,
          20.099999999999994,
          31.40000000000001,
          21.3,
          28.40000000000001,
          37.1,
          37.1,
          25.3,
          27.5,
          17.400000000000006,
          25.90000000000001,
          32.7,
          36.7,
          23.200000000000003,
          29.200000000000003,
          39,
          33.099999999999994,
          38,
          39.6,
          41.1,
          28.700000000000003,
          20.3,
          40.1,
          19.599999999999994,
          45.3,
          30,
          39.1,
          20,
          40.3,
          38.400000000000006,
          30.8,
          33.7,
          23.90000000000001,
          43.6,
          24.90000000000001,
          38.400000000000006,
          40.900000000000006,
          40.1,
          26.099999999999994,
          34.8,
          15.099999999999994,
          30.599999999999994,
          30.3,
          35.7,
          39.2,
          35.400000000000006,
          28.5,
          19.3,
          22.200000000000003,
          37.2,
          20.099999999999994,
          40.3,
          35.599999999999994,
          38.1,
          40.1,
          32.5,
          11.700000000000005,
          37.7,
          39.7,
          37.2,
          14,
          27.5,
          40.3,
          28.099999999999994,
          34,
          31.200000000000003,
          41.1,
          36.900000000000006,
          22.3,
          37.3,
          39.3,
          37.5,
          32.400000000000006,
          40.7,
          33.900000000000006,
          36.5,
          25.700000000000003,
          19.099999999999994,
          40.8,
          39.7,
          33.099999999999994,
          16.5,
          39.400000000000006,
          38.6,
          35.8,
          17.400000000000006,
          33.099999999999994,
          21.90000000000001,
          41.1,
          23,
          28.90000000000001,
          40.1,
          30.8,
          34.400000000000006,
          27.90000000000001,
          36.900000000000006,
          38,
          40.400000000000006,
          24.3,
          41.900000000000006,
          31.8,
          23.599999999999994,
          37.8,
          37.6,
          34.5,
          39.8,
          36.6,
          35.400000000000006,
          27.200000000000003,
          16.700000000000003,
          36.1,
          21,
          36.8,
          47.1,
          39.7,
          36.5,
          41.2,
          40.1,
          24.8,
          43.400000000000006,
          37.6,
          20.3,
          30.90000000000001,
          22.8,
          33.2,
          28,
          19.599999999999994,
          26.90000000000001,
          41.5,
          35.900000000000006,
          25.8,
          38.5,
          29.599999999999994,
          37.5,
          32.5,
          29.099999999999994,
          36.1,
          38.400000000000006,
          35.2,
          22.40000000000001,
          34.400000000000006,
          43.6,
          36.1,
          35.400000000000006,
          17.5,
          18.599999999999994,
          29.099999999999994,
          23.8,
          35.7,
          40.3,
          15.200000000000005,
          41.5,
          38.6,
          38.3,
          37.5,
          39.1,
          42.3,
          36.900000000000006,
          15.299999999999995,
          31.8,
          37.400000000000006,
          44.8,
          35.2,
          29.40000000000001,
          16.400000000000006,
          20.099999999999994,
          13.099999999999994,
          34.099999999999994,
          33.8,
          37.6,
          34.7,
          22.599999999999994,
          24.8,
          18.8,
          25.5,
          40,
          38.7,
          42.8,
          24.700000000000003,
          40.2,
          34.2,
          30.700000000000003,
          41.5,
          41.900000000000006,
          37,
          34.400000000000006,
          31.3,
          38.6,
          31.3,
          29.099999999999994,
          33.8,
          22.700000000000003,
          39.400000000000006,
          40.1,
          14.400000000000006,
          23.90000000000001,
          33.2,
          41.5,
          36.900000000000006,
          35.400000000000006,
          33.3,
          7.099999999999994,
          17.799999999999997,
          30.599999999999994,
          28,
          23,
          38,
          41.1,
          20.5,
          31,
          32.2,
          28.599999999999994,
          30.700000000000003,
          32.5,
          27.5,
          30.099999999999994,
          40.400000000000006,
          34.2,
          41.3,
          39.5,
          38.1,
          39.1,
          38.5,
          36.7,
          36,
          38.1,
          38,
          20.3,
          26.5,
          30.90000000000001,
          40.8,
          22.90000000000001,
          23,
          22,
          45.1,
          38.6,
          38.900000000000006,
          19.599999999999994,
          34.599999999999994,
          30.5,
          33.2,
          37.5,
          21.200000000000003,
          34.3,
          19.40000000000001,
          44.2,
          40.5,
          17.099999999999994,
          38,
          35.8,
          43.2,
          39.6,
          37.1,
          43.6,
          12.900000000000006,
          24.3,
          19.700000000000003,
          24.8,
          42.2,
          38.3,
          27.40000000000001,
          25.5,
          40.3,
          33.400000000000006,
          40.8,
          26.90000000000001,
          38,
          28.8,
          32.7,
          41.1,
          32.3,
          33.599999999999994,
          28.8,
          40.7,
          33.099999999999994,
          38,
          34.599999999999994,
          19.099999999999994,
          43.7,
          38.400000000000006,
          34.400000000000006,
          24.40000000000001,
          39.400000000000006,
          38.5,
          30.40000000000001,
          30.700000000000003,
          28.200000000000003,
          37.3,
          32.2,
          38.8,
          37,
          37.900000000000006,
          34.900000000000006,
          34.7,
          19.40000000000001,
          14.900000000000006,
          38.8,
          24.099999999999994,
          37.1,
          31.700000000000003,
          38.6,
          8.900000000000006,
          32.099999999999994,
          39.7,
          30.90000000000001,
          24.40000000000001,
          29.200000000000003,
          27.099999999999994,
          40.400000000000006,
          43.2,
          29.5,
          43,
          24.700000000000003,
          33.7,
          41.6,
          35.5,
          14.5,
          34.900000000000006,
          23.599999999999994,
          36.8,
          39.1,
          36,
          21.5,
          37,
          26,
          20.200000000000003,
          35.900000000000006,
          38.6,
          13,
          20.90000000000001,
          23.3,
          33.2,
          37.8,
          42.2,
          17.799999999999997,
          32.7,
          38.8,
          35.099999999999994,
          24.40000000000001,
          12.099999999999994,
          40.7,
          31.3,
          39.900000000000006,
          26.3,
          33.8,
          34.2,
          34.8,
          37.400000000000006,
          41.400000000000006,
          15,
          16.099999999999994,
          29.8,
          21.90000000000001,
          22.3,
          31.200000000000003,
          41.5,
          31,
          24.40000000000001,
          42.3,
          19.200000000000003,
          30.5,
          23.3,
          16.400000000000006,
          32.900000000000006,
          41.900000000000006,
          24.099999999999994,
          31,
          18.40000000000001,
          20,
          26.700000000000003,
          39.400000000000006,
          18.8,
          36.5,
          39.8,
          20.90000000000001,
          41.6,
          16,
          30.40000000000001,
          36.1,
          40.2,
          23.3,
          21.3,
          37.8,
          33.400000000000006,
          20.5,
          31.3,
          35.2,
          41.6,
          25.200000000000003,
          18.700000000000003,
          40.6,
          42.3,
          17.5,
          35.599999999999994,
          35.099999999999994,
          33.599999999999994,
          38.6,
          20.8,
          14.400000000000006,
          36.1,
          39.400000000000006,
          41.2,
          43.7,
          19.40000000000001,
          36.5,
          41.1,
          39.7,
          36.2,
          26.599999999999994,
          40.7,
          24.3,
          33.099999999999994,
          36,
          27.599999999999994,
          27.8,
          38.400000000000006,
          32.599999999999994,
          41.6,
          33.8,
          36.1,
          14.599999999999994,
          38.5,
          37.5,
          37,
          36.5,
          34,
          44.5,
          45.3,
          23.099999999999994,
          39.5,
          21.8,
          30.700000000000003,
          21,
          21.8,
          40.5,
          17.400000000000006,
          19.40000000000001,
          38.2,
          39.1,
          35.900000000000006,
          37.8,
          33.599999999999994,
          40.3,
          35.599999999999994,
          40.5,
          19.5,
          36.1,
          37.5,
          30,
          35.900000000000006,
          32,
          19.099999999999994,
          42.7,
          15.299999999999995,
          38.6,
          40.400000000000006,
          32.599999999999994,
          24.40000000000001,
          32.900000000000006,
          32.7,
          35.3,
          33.7,
          31.5,
          39.1,
          28.3,
          31.40000000000001,
          27.5,
          39.6,
          14.400000000000006,
          41.2,
          30.599999999999994,
          25.599999999999994,
          34.3,
          37.900000000000006,
          18.90000000000001,
          24.5,
          41.900000000000006,
          32.8,
          31.099999999999994,
          31.8,
          38.2,
          15.799999999999995,
          30.90000000000001,
          28.3,
          24.90000000000001,
          21.200000000000003,
          29.3,
          9.099999999999994,
          25.90000000000001,
          23.200000000000003,
          35.5,
          25.8,
          14.200000000000005,
          28.8,
          19.700000000000003,
          19.8,
          28.40000000000001,
          36.900000000000006,
          26.90000000000001,
          20.599999999999994,
          28.5,
          41.3,
          44.7,
          35.8,
          41.6,
          37.6,
          10.700000000000005,
          33.400000000000006,
          26,
          41.5,
          38,
          39.2,
          33.900000000000006,
          28.700000000000003,
          35.2,
          34.3,
          19.40000000000001,
          32.400000000000006,
          42.8,
          42.3,
          40.900000000000006,
          40.2,
          22.200000000000003,
          20.200000000000003,
          43.5,
          37.8,
          42.2,
          35,
          34.8,
          39.7,
          37.2,
          33.5,
          38.400000000000006,
          35.400000000000006,
          36.6,
          38.900000000000006,
          23.8,
          22.099999999999994,
          38.2,
          33.3,
          38.900000000000006,
          24.599999999999994,
          38.2,
          28.8,
          36.5,
          34.3,
          37.5,
          39.5,
          21.40000000000001,
          37.3,
          38.7,
          38.3,
          27.5,
          37.400000000000006,
          38.4,
          39.2,
          27.700000000000003,
          38.900000000000006,
          27.90000000000001,
          34.5,
          27.8,
          12.599999999999994,
          27.40000000000001,
          37.3,
          34.900000000000006,
          37.900000000000006,
          17.299999999999997,
          24.3,
          36.7,
          28.5,
          37.1,
          37.7,
          38.8,
          33.8,
          38.8,
          40.2,
          37.7,
          37.900000000000006,
          41.3,
          39.400000000000006,
          42.7,
          28.5,
          22.200000000000003,
          39.7,
          34.3,
          25.200000000000003,
          37.400000000000006,
          24,
          24.599999999999994,
          36.900000000000006,
          32.3,
          38.3,
          23.40000000000001,
          28.200000000000003,
          36.1,
          31.599999999999994,
          34.900000000000006,
          38.3,
          41.6,
          18,
          38.6,
          41.1,
          20.90000000000001,
          29.200000000000003,
          24.599999999999994,
          18.599999999999994,
          44.1,
          27.8,
          29.5,
          33.5,
          26.200000000000003,
          38.400000000000006,
          36.400000000000006,
          34.8,
          37.7,
          38.1,
          36.900000000000006,
          26.599999999999994,
          43.7,
          25.099999999999994,
          22.3,
          18.8,
          30.5,
          22.599999999999994,
          20.3,
          43.2,
          36.2,
          2.299999999999997,
          42.1,
          41.400000000000006,
          24.90000000000001,
          21.200000000000003,
          21.599999999999994,
          38.900000000000006,
          23.599999999999994,
          39.7,
          28.5,
          24.200000000000003,
          17,
          41.2,
          35.900000000000006,
          15.200000000000005,
          38.7,
          36,
          40.3,
          26.8,
          35.2,
          35.099999999999994,
          39.3,
          23.099999999999994,
          23.700000000000003,
          35.900000000000006,
          34.3,
          34.3,
          38.5,
          27.8,
          37.1,
          32.099999999999994,
          38.7,
          36.400000000000006,
          22.700000000000003,
          18.700000000000003,
          27.8,
          32.099999999999994,
          37.3,
          23.40000000000001,
          19.90000000000001,
          37.400000000000006,
          38.900000000000006,
          27.200000000000003,
          18,
          40.5,
          31.3,
          30.200000000000003,
          37.400000000000006,
          37.5,
          37.900000000000006,
          17.700000000000003,
          35.400000000000006,
          34.599999999999994,
          14.299999999999995,
          37.4,
          36.7,
          15,
          16.299999999999997,
          36,
          37,
          49.1,
          26.700000000000003,
          26,
          43.400000000000006,
          38,
          35.2,
          45.6,
          38.7,
          25.5,
          42,
          34.8,
          39,
          31.700000000000003,
          32.599999999999994,
          38.8,
          14.200000000000005,
          35.900000000000006,
          39.7,
          39,
          38.6,
          41.1,
          22.700000000000003,
          15.200000000000005,
          40.7,
          39.6,
          32,
          21.90000000000001,
          37.6,
          38.2,
          38.1,
          39.7,
          30.3,
          41.3,
          14.400000000000006,
          31.700000000000003,
          24.5,
          35.2,
          38.7,
          41,
          32.900000000000006,
          38.8,
          19.200000000000003,
          21.700000000000003,
          39.2,
          37.400000000000006,
          24.40000000000001,
          30,
          37.900000000000006,
          21.5,
          43.1,
          42.1,
          39.6,
          30.599999999999994,
          24.40000000000001,
          43.400000000000006,
          33.2,
          34.7,
          42.400000000000006,
          36.1,
          15.099999999999994,
          21,
          38,
          35.599999999999994,
          24.40000000000001,
          36.8,
          38.900000000000006,
          37.2,
          36.2,
          43,
          20.599999999999994,
          21.200000000000003,
          39.3,
          30.40000000000001,
          42.3,
          34.3,
          23.700000000000003,
          22.5,
          33.099999999999994,
          42,
          19.3,
          43,
          38,
          38.6,
          40.400000000000006,
          34.599999999999994,
          36.3,
          35,
          35.900000000000006,
          24.700000000000003,
          38.900000000000006,
          16,
          27,
          37,
          23.8,
          16,
          25.700000000000003,
          35.3,
          26,
          29.099999999999994,
          37.2,
          21.599999999999994,
          29.200000000000003,
          41.400000000000006,
          40.5,
          23.599999999999994,
          36.6,
          25.8,
          33,
          39.900000000000006,
          3.9000000000000057,
          33.900000000000006,
          34.5,
          46.400000000000006,
          38.5
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "boxmode": "group",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "age"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "physical_score"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"c370513f-c547-45a8-835e-0aef0d872454\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c370513f-c547-45a8-835e-0aef0d872454\")) {                    Plotly.newPlot(                        \"c370513f-c547-45a8-835e-0aef0d872454\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"age=%{x}<br>physical_score=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"\",\"notched\":false,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[33.0,50.0,52.0,56.0,35.0,58.0,66.0,38.0,53.0,43.0,39.0,58.0,45.0,52.0,36.0,83.0,57.0,39.0,58.0,54.0,65.0,69.0,41.0,43.0,64.0,55.0,46.0,40.0,70.0,36.0,62.0,71.0,38.0,67.0,50.0,68.0,58.0,63.0,60.0,24.0,44.0,55.0,42.0,61.0,49.0,66.0,51.0,65.0,53.0,52.0,60.0,46.0,69.0,62.0,64.0,72.0,66.0,32.0,54.0,59.0,74.0,37.0,32.0,68.0,62.0,58.0,54.0,75.0,48.0,54.0,57.0,31.0,74.0,40.0,54.0,82.0,48.0,53.0,61.0,27.0,62.0,66.0,39.0,51.0,41.0,52.0,46.0,57.0,47.0,82.0,43.0,55.0,57.0,46.0,56.0,49.0,52.0,46.0,56.0,60.0,49.0,67.0,39.0,59.0,67.0,55.0,68.0,44.0,47.0,45.0,70.0,62.0,68.0,46.0,74.0,60.0,52.0,58.0,42.0,50.0,43.0,57.0,51.0,49.0,46.0,47.0,40.0,66.0,48.0,45.0,39.0,47.0,54.0,55.0,66.0,47.0,62.0,51.0,70.0,51.0,48.0,32.0,60.0,50.0,48.0,42.0,51.0,44.0,71.0,57.0,34.0,58.0,31.0,71.0,46.0,69.0,82.0,54.0,59.0,47.0,56.0,54.0,42.0,53.0,77.0,37.0,68.0,66.0,62.0,43.0,48.0,44.0,54.0,39.0,65.0,51.0,30.0,53.0,48.0,51.0,64.0,34.0,43.0,67.0,46.0,46.0,44.0,79.0,59.0,69.0,35.0,49.0,32.0,60.0,41.0,38.0,40.0,35.0,56.0,48.0,36.0,51.0,43.0,52.0,41.0,67.0,61.0,34.0,63.0,62.0,64.0,45.0,53.0,46.0,51.0,51.0,33.0,48.0,50.0,63.0,48.0,51.0,34.0,46.0,56.0,54.0,46.0,66.0,57.0,38.0,34.0,55.0,41.0,49.0,60.0,56.0,66.0,65.0,56.0,52.0,48.0,71.0,54.0,52.0,57.0,38.0,58.0,56.0,46.0,56.0,53.0,61.0,45.0,53.0,46.0,64.0,47.0,46.0,68.0,70.0,41.0,50.0,62.0,43.0,53.0,46.0,52.0,53.0,34.0,40.0,43.0,40.0,50.0,58.0,48.0,39.0,49.0,51.0,47.0,59.0,42.0,44.0,65.0,40.0,43.0,65.0,50.0,49.0,70.0,49.0,52.0,39.0,31.0,64.0,44.0,46.0,32.0,36.0,30.0,68.0,49.0,50.0,35.0,37.0,65.0,61.0,37.0,76.0,48.0,36.0,55.0,65.0,39.0,34.0,25.0,59.0,42.0,54.0,51.0,49.0,59.0,72.0,61.0,41.0,50.0,52.0,34.0,66.0,40.0,37.0,58.0,58.0,50.0,52.0,55.0,36.0,45.0,31.0,57.0,49.0,52.0,75.0,57.0,57.0,38.0,56.0,56.0,60.0,47.0,57.0,59.0,61.0,48.0,78.0,46.0,72.0,48.0,44.0,52.0,76.0,72.0,53.0,47.0,44.0,34.0,45.0,64.0,59.0,68.0,62.0,49.0,40.0,59.0,48.0,40.0,48.0,39.0,51.0,40.0,55.0,41.0,38.0,42.0,66.0,66.0,58.0,43.0,46.0,55.0,54.0,43.0,57.0,40.0,42.0,64.0,72.0,39.0,52.0,43.0,62.0,43.0,77.0,58.0,49.0,44.0,49.0,58.0,40.0,74.0,73.0,44.0,43.0,45.0,40.0,65.0,55.0,55.0,52.0,68.0,56.0,53.0,43.0,64.0,55.0,76.0,46.0,56.0,44.0,38.0,43.0,53.0,81.0,50.0,63.0,30.0,47.0,25.0,55.0,48.0,48.0,50.0,37.0,72.0,47.0,65.0,53.0,82.0,35.0,38.0,37.0,47.0,54.0,39.0,59.0,22.0,56.0,56.0,42.0,58.0,64.0,62.0,64.0,50.0,58.0,52.0,60.0,31.0,42.0,38.0,57.0,41.0,39.0,40.0,56.0,68.0,48.0,66.0,41.0,63.0,49.0,41.0,40.0,55.0,55.0,48.0,41.0,50.0,41.0,32.0,59.0,42.0,54.0,48.0,49.0,60.0,43.0,39.0,48.0,46.0,45.0,53.0,39.0,52.0,33.0,53.0,42.0,67.0,50.0,78.0,58.0,43.0,43.0,46.0,56.0,62.0,35.0,60.0,77.0,58.0,39.0,39.0,48.0,44.0,48.0,74.0,67.0,33.0,41.0,45.0,62.0,65.0,39.0,77.0,63.0,71.0,44.0,58.0,69.0,48.0,64.0,62.0,40.0,69.0,40.0,44.0,48.0,60.0,61.0,40.0,57.0,54.0,63.0,42.0,59.0,41.0,66.0,53.0,36.0,46.0,51.0,45.0,33.0,46.0,75.0,47.0,48.0,47.0,51.0,48.0,38.0,40.0,67.0,72.0,52.0,51.0,63.0,35.0,33.0,62.0,43.0,47.0,70.0,51.0,40.0,39.0,32.0,60.0,33.0,57.0,68.0,69.0,54.0,60.0,57.0,18.0,55.0,46.0,54.0,46.0,54.0,47.0,35.0,48.0,45.0,47.0,41.0,42.0,41.0,41.0,52.0,31.0,41.0,55.0,73.0,64.0,29.0,63.0,54.0,63.0,45.0,65.0,47.0,49.0,57.0,44.0,53.0,29.0,56.0,52.0,44.0,25.0,54.0,40.0,46.0,67.0,45.0,45.0,47.0,65.0,54.0,41.0,43.0,54.0,52.0,68.0,82.0,42.0,75.0,74.0,43.0,65.0,35.0,42.0,55.0,42.0,51.0,71.0,41.0,47.0,28.0,42.0,55.0,70.0,67.0,49.0,55.0,37.0,48.0,37.0,46.0,34.0,63.0,53.0,54.0,76.0,50.0,69.0,48.0,45.0,42.0,39.0,55.0,43.0,38.0,51.0,60.0,70.0,71.0,62.0,69.0,34.0,52.0,56.0,37.0,43.0,67.0,53.0,49.0,44.0,51.0,60.0,37.0,50.0,31.0,45.0,53.0,45.0,66.0,68.0,44.0,50.0,51.0,66.0,48.0,45.0,61.0,43.0,47.0,58.0,33.0,55.0,56.0,54.0,52.0,52.0,64.0,39.0,56.0,73.0,56.0,64.0,43.0,39.0,59.0,52.0,43.0,48.0,48.0,46.0,53.0,59.0,49.0,31.0,72.0,76.0,54.0,39.0,60.0,59.0,42.0,49.0,32.0,41.0,68.0,60.0,76.0,43.0,42.0,74.0,68.0,43.0,53.0,71.0,48.0,37.0,78.0,42.0,47.0,60.0,50.0,41.0,77.0,67.0,64.0,49.0,62.0,46.0,48.0,34.0,66.0,50.0,47.0,71.0,51.0,44.0,64.0,55.0,65.0,62.0,54.0,51.0,57.0,39.0,50.0,52.0,40.0,42.0,46.0,47.0,53.0,51.0,52.0,44.0,43.0,52.0,49.0,53.0,48.0,50.0,71.0,43.0,53.0,53.0,61.0,56.0,47.0,68.0,32.0,40.0,46.0,73.0,56.0,74.0,55.0,74.0,50.0,66.0,42.0,41.0,51.0,42.0,46.0,38.0,46.0,41.0,59.0,62.0,64.0,54.0,54.0,61.0,62.0,38.0,48.0,56.0,73.0,26.0,34.0,50.0,44.0,62.0,32.0,44.0,68.0,45.0,74.0,47.0,36.0,48.0,66.0,56.0,64.0,61.0,49.0,57.0,54.0,66.0,47.0,65.0,63.0,44.0,53.0,35.0,62.0,49.0,64.0,39.0,55.0,67.0,54.0,41.0,57.0,67.0,59.0,38.0,36.0,28.0,31.0,72.0,52.0,49.0,50.0,43.0,49.0,58.0,68.0,49.0,39.0,54.0,63.0,51.0,61.0,62.0,77.0,31.0,70.0,42.0,55.0,42.0,38.0,52.0,55.0,46.0,56.0,71.0,48.0,38.0,50.0,76.0,60.0,68.0,73.0,36.0,66.0,43.0,42.0,61.0,53.0,28.0,34.0,55.0,41.0,44.0,34.0,55.0,63.0,51.0,44.0,45.0,48.0,45.0,46.0,40.0,39.0,51.0,43.0,41.0,67.0,63.0,46.0,78.0,58.0,51.0,62.0,42.0,36.0,70.0,41.0,65.0,44.0,39.0,50.0,47.0,41.0,48.0,74.0,48.0,49.0,58.0,49.0,61.0,61.0,51.0,37.0,49.0,63.0,54.0,50.0,46.0,60.0,50.0,67.0,67.0,47.0,57.0,30.0,62.0,47.0,48.0,42.0,42.0,35.0,54.0,49.0,46.0,61.0,69.0,40.0,30.0,46.0,47.0,77.0,54.0,50.0,51.0,26.0,39.0,52.0,49.0,52.0,27.0,45.0,55.0,67.0,41.0,56.0,66.0,67.0,52.0,57.0,73.0,60.0,44.0,45.0,66.0,60.0,69.0,50.0,78.0,46.0,48.0,41.0,60.0,39.0,64.0,46.0,43.0,37.0,42.0,44.0,40.0,58.0,46.0,57.0,54.0,36.0,66.0,30.0,37.0,58.0,56.0,47.0,61.0,51.0,24.0,35.0,60.0,64.0,40.0,57.0,53.0,50.0,53.0,38.0,56.0,59.0,57.0,39.0,45.0,69.0,49.0,42.0,58.0,50.0,68.0,71.0,44.0,34.0,41.0,48.0,68.0,48.0,55.0,49.0,63.0,37.0,44.0,63.0,42.0,44.0,65.0,44.0,63.0,55.0,47.0,55.0,51.0,54.0,52.0,60.0,71.0,44.0,38.0,41.0,44.0,55.0,42.0,41.0,38.0,58.0,39.0,46.0,39.0,60.0,41.0,44.0,60.0,62.0,64.0,60.0,59.0,65.0,50.0,61.0,44.0,40.0,58.0,46.0,54.0,63.0,37.0,45.0,41.0,58.0,65.0,56.0,44.0,63.0,55.0,47.0,47.0,39.0,52.0,32.0,41.0,48.0,41.0,46.0,55.0,48.0,47.0,38.0,69.0,70.0,60.0,45.0,50.0,44.0,44.0,50.0,49.0,72.0,37.0,68.0,46.0,57.0,54.0,36.0,78.0,52.0,40.0,49.0,81.0,64.0,44.0,43.0,50.0,69.0,54.0,62.0,64.0,46.0,57.0,40.0,52.0,34.0,50.0,21.0,43.0,46.0,41.0,74.0,50.0,38.0,39.0,76.0,60.0,37.0,56.0,66.0,68.0,49.0,39.0,56.0,47.0,65.0,42.0,36.0,57.0,57.0,37.0,54.0,32.0,54.0,54.0,62.0,68.0,37.0,42.0,48.0,66.0,43.0,59.0,59.0,54.0,50.0,52.0,33.0,44.0,53.0,42.0,74.0,54.0,46.0,52.0,52.0,43.0,33.0,60.0,61.0,54.0,57.0,62.0,60.0,64.0,69.0,73.0,47.0,44.0,47.0,44.0,58.0,65.0,32.0,46.0,52.0,58.0,62.0,66.0,77.0,35.0,52.0,40.0,72.0,46.0,51.0,48.0,43.0,65.0,49.0,48.0,38.0,45.0,58.0,62.0,48.0,34.0,38.0,40.0,50.0,59.0,56.0,51.0,80.0,39.0,55.0,46.0,45.0,48.0,68.0,53.0,42.0,34.0,44.0,59.0,45.0,66.0,57.0,44.0,53.0,83.0,72.0,69.0,62.0,50.0,48.0,60.0,63.0,66.0,53.0,80.0,68.0,36.0,32.0,59.0,69.0,51.0,50.0,51.0,44.0,50.0,57.0,44.0,52.0,43.0,33.0,41.0,30.0,61.0,59.0,61.0,49.0,57.0,64.0,47.0,54.0,48.0,47.0,45.0,65.0,49.0,76.0,67.0,56.0,42.0,48.0,58.0,51.0,68.0,54.0,65.0,67.0,46.0,62.0,55.0,57.0,47.0,36.0,57.0,52.0,68.0,65.0,63.0,54.0,43.0,35.0,36.0,74.0,41.0,42.0,39.0,64.0,28.0,52.0,52.0,46.0,58.0,70.0,48.0,57.0,54.0,54.0,68.0,54.0,38.0,74.0,35.0,49.0,59.0,40.0,41.0,62.0,66.0,65.0,71.0,47.0,47.0,65.0,49.0,61.0,81.0,60.0,47.0,69.0,34.0,78.0,34.0,59.0,42.0,46.0,46.0,55.0,31.0,47.0,45.0,50.0,55.0,54.0,62.0,50.0,34.0,62.0,42.0,49.0,42.0,47.0,56.0,49.0,73.0,47.0,53.0,58.0,61.0,49.0,38.0,33.0,57.0,71.0,55.0,43.0,63.0,42.0,60.0,62.0,55.0,55.0,56.0,65.0,50.0,47.0,63.0,46.0,39.0,29.0,45.0,50.0,62.0,38.0,47.0,54.0,49.0,63.0,51.0,43.0,42.0,45.0,54.0,55.0,35.0,30.0,50.0,40.0,43.0,43.0,38.0,57.0,50.0,49.0,58.0,44.0,58.0,53.0,46.0,47.0,44.0,38.0,42.0,56.0,40.0,60.0,31.0,53.0,62.0,37.0,77.0,56.0,55.0,24.0,50.0,55.0,68.0,55.0,58.0,37.0,51.0,40.0,47.0,64.0,51.0,61.0,53.0,64.0,32.0,46.0,68.0,36.0,54.0,46.0,51.0,64.0,30.0,51.0,56.0,43.0,54.0,46.0,44.0,34.0,63.0,61.0,42.0,63.0,57.0,66.0,37.0,59.0,42.0,48.0,60.0,39.0,59.0,36.0,43.0,54.0,57.0,47.0,41.0,83.0,43.0,53.0,70.0,60.0,42.0,48.0,34.0,68.0,44.0,61.0,55.0,71.0,54.0,38.0,49.0,52.0,60.0,70.0,55.0,40.0,36.0,70.0,47.0,57.0,42.0,51.0,44.0,66.0,82.0,48.0,53.0,61.0,54.0,48.0,37.0,84.0,47.0,33.0,63.0,60.0,44.0,37.0,36.0,42.0,61.0,46.0,60.0,37.0,41.0,68.0,54.0,66.0,69.0,68.0,72.0,48.0,62.0,42.0,56.0,51.0,36.0,56.0,43.0,49.0,46.0,69.0,40.0,39.0,52.0,46.0,55.0,41.0,48.0,58.0,71.0,46.0,58.0,71.0,79.0,33.0,46.0,46.0,65.0,57.0,38.0,70.0,46.0,62.0,31.0,42.0,57.0,54.0,56.0,67.0,51.0,49.0,37.0,49.0,42.0,58.0,62.0,60.0,54.0,40.0,51.0,58.0,43.0,33.0,62.0,59.0,49.0,50.0,42.0,56.0,35.0,45.0,44.0,67.0,52.0,52.0,62.0,71.0,54.0,47.0,49.0,54.0,52.0,39.0,51.0,49.0,65.0,55.0,44.0,51.0,59.0,70.0,53.0,49.0,45.0,41.0,55.0,43.0,51.0,59.0,60.0,68.0,60.0,45.0,51.0,37.0,60.0,52.0,50.0,46.0,50.0,64.0,45.0,41.0,54.0,40.0,55.0,38.0,40.0,70.0,60.0,43.0,59.0,40.0,55.0,81.0,39.0,53.0,80.0,61.0,53.0,54.0,63.0,58.0,46.0,38.0,55.0,63.0,43.0,68.0,50.0,50.0,59.0,57.0,55.0,50.0,61.0,55.0,63.0,49.0,56.0,71.0,40.0,84.0,43.0,61.0,46.0,55.0,33.0,65.0,68.0,57.0,76.0,58.0,56.0,39.0,29.0,54.0,47.0,62.0,52.0,47.0,64.0,34.0,59.0,71.0,47.0,67.0,59.0,57.0,58.0,39.0,41.0,41.0,52.0,55.0,46.0,73.0,59.0,39.0,49.0,43.0,47.0,64.0,46.0,46.0,62.0,47.0,32.0,61.0,68.0,66.0,46.0,35.0,45.0,32.0,41.0,29.0,65.0,43.0,43.0,59.0,70.0,41.0,39.0,41.0,45.0,53.0,44.0,52.0,47.0,62.0,50.0,63.0,56.0,45.0,42.0,59.0,39.0,47.0,84.0,52.0,49.0,63.0,38.0,53.0,65.0,45.0,42.0,43.0,44.0,40.0,49.0,37.0,54.0,44.0,63.0,34.0,50.0,55.0,67.0,40.0,48.0,50.0,49.0,64.0,50.0,42.0,40.0,51.0,60.0,70.0,31.0,57.0,38.0,44.0,64.0,38.0,48.0,43.0,43.0,69.0,66.0,47.0,67.0,42.0,64.0,66.0,43.0,41.0,42.0,76.0,46.0,53.0,64.0,49.0,48.0,37.0,39.0,37.0,57.0,40.0,62.0,50.0,54.0,46.0,39.0,45.0,67.0,62.0,44.0,56.0,31.0,48.0,63.0,50.0,37.0,56.0,62.0,53.0,37.0,36.0,47.0,51.0,57.0,59.0,46.0,38.0,39.0,42.0,38.0,47.0,40.0,42.0,57.0,45.0,48.0,66.0,53.0,58.0,49.0,42.0,47.0,51.0,44.0,55.0,48.0,57.0,37.0,42.0,52.0,41.0,48.0,52.0,52.0,48.0,71.0,43.0,41.0,60.0,75.0,40.0,67.0,66.0,68.0,54.0,52.0,45.0,29.0,54.0,59.0,53.0,64.0,53.0,41.0,52.0,57.0,51.0,54.0,51.0,47.0,57.0,51.0,68.0,46.0,41.0,68.0,33.0,45.0,29.0,64.0,58.0,42.0,48.0,36.0,37.0,51.0,67.0,46.0,56.0,66.0,55.0,55.0,53.0,52.0,39.0,49.0,39.0,34.0,40.0,60.0,28.0,58.0,59.0,41.0,63.0,42.0,45.0,53.0,57.0,74.0,41.0,42.0,24.0,65.0,56.0,49.0,60.0,71.0,55.0,47.0,58.0,58.0,55.0,39.0,70.0,69.0,43.0,49.0,48.0,56.0,47.0,41.0,56.0,33.0,60.0,48.0,66.0,70.0,52.0,56.0,37.0,38.0,58.0,49.0,79.0,54.0,67.0,61.0,42.0,44.0,48.0,47.0,65.0,37.0,36.0,48.0,42.0,38.0,46.0,74.0,53.0,64.0,70.0,33.0,39.0,53.0,58.0,58.0,57.0,34.0,40.0,53.0,39.0,46.0,46.0,43.0,68.0,41.0,38.0,46.0,58.0,35.0,60.0,63.0,41.0,49.0,47.0,59.0,45.0,50.0,39.0,66.0,47.0,59.0,80.0,59.0,77.0,33.0,42.0,43.0,37.0,56.0,69.0,46.0,69.0,38.0,64.0,56.0,48.0,56.0,57.0,83.0,36.0,71.0,56.0,48.0,29.0,73.0,38.0,67.0,35.0,47.0,53.0,32.0,47.0,56.0,50.0,50.0,69.0,42.0,39.0,61.0,56.0,44.0,45.0,43.0,54.0,42.0,41.0,53.0,55.0,43.0,47.0,35.0,38.0,46.0,56.0,55.0,40.0,60.0,49.0,63.0,65.0,40.0,36.0,45.0,46.0,61.0,68.0,47.0,47.0,48.0,37.0,45.0,38.0,39.0,56.0,77.0,53.0,34.0,44.0,52.0,45.0,49.0,68.0,39.0,46.0,49.0,64.0,51.0,43.0,28.0,52.0,61.0,37.0,56.0,74.0,70.0,51.0,37.0,53.0,63.0,61.0,44.0,63.0,42.0,48.0,51.0,55.0,57.0,59.0,73.0,49.0,69.0,66.0,42.0,58.0,49.0,63.0,82.0,45.0,51.0,60.0,78.0,37.0,45.0,66.0,37.0,67.0,38.0,47.0,47.0,22.0,44.0,50.0,35.0,67.0,56.0,44.0,61.0,41.0,45.0,64.0,50.0,57.0,53.0,45.0,62.0,41.0,51.0,31.0,42.0,47.0,71.0,47.0,63.0,65.0,43.0,79.0,66.0,45.0,48.0,39.0,66.0,60.0,39.0,73.0,42.0,48.0,46.0,54.0,52.0,52.0,38.0,55.0,50.0,59.0,71.0,54.0,47.0,32.0,54.0,37.0,50.0,56.0,22.0,36.0,41.0,53.0,41.0,44.0,40.0,54.0,40.0,47.0,83.0,36.0,47.0,43.0,41.0,54.0,55.0,49.0,35.0,47.0,37.0,58.0,36.0,47.0,59.0,64.0,55.0,30.0,50.0,40.0,55.0,57.0,80.0,62.0,34.0,56.0,67.0,35.0,55.0,58.0,37.0,68.0,57.0,66.0,47.0,51.0,41.0,37.0,35.0,55.0,44.0,47.0,51.0,54.0,61.0,33.0,60.0,55.0,46.0,34.0,41.0,60.0,39.0,38.0,36.0,45.0,53.0,39.0,48.0,58.0,62.0,55.0,56.0,29.0,35.0,77.0,71.0,57.0,57.0,53.0,43.0,59.0,60.0,34.0,51.0,48.0,50.0,49.0,57.0,66.0,60.0,66.0,44.0,39.0,53.0,32.0,51.0,52.0,71.0,47.0,39.0,57.0,49.0,46.0,57.0,43.0,53.0,38.0,47.0,44.0,45.0,60.0,47.0,45.0,50.0,39.0,52.0,35.0,52.0,54.0,66.0,30.0,38.0,39.0,52.0,52.0,43.0,49.0,58.0,39.0,59.0,60.0,63.0,38.0,61.0,70.0,45.0,44.0,52.0,58.0,45.0,40.0,75.0,44.0,37.0,53.0,54.0,58.0,52.0,58.0,34.0,56.0,60.0,68.0,68.0,60.0,43.0,44.0,75.0,50.0,45.0,60.0,51.0,64.0,45.0,62.0,55.0,71.0,38.0,72.0,67.0,55.0,56.0,52.0,38.0,43.0,48.0,69.0,37.0,63.0,71.0,44.0,67.0,48.0,61.0,44.0,62.0,68.0,36.0,62.0,44.0,60.0,62.0,75.0,33.0,56.0,40.0,46.0,43.0,64.0,51.0,63.0,59.0,41.0,40.0,47.0,45.0,41.0,53.0,58.0,40.0,69.0,46.0,65.0,48.0,41.0,42.0,71.0,65.0,56.0,33.0,68.0,47.0,43.0,53.0,56.0,60.0,54.0,49.0,38.0,38.0,44.0,28.0,54.0,39.0,48.0,50.0,41.0,33.0,50.0,41.0,45.0,52.0,45.0,47.0,38.0,51.0,56.0,44.0,48.0,46.0,60.0,41.0,40.0,59.0,61.0,52.0,53.0,65.0,35.0,62.0,46.0,42.0,44.0,63.0,40.0,36.0,52.0,32.0,79.0,48.0,49.0,37.0,52.0,43.0,50.0,41.0,49.0,42.0,45.0,55.0,71.0,61.0,54.0,43.0,65.0,45.0,40.0,38.0,53.0,62.0,58.0,64.0,62.0,52.0,32.0,35.0,39.0,50.0,51.0,50.0,49.0,51.0,50.0,53.0,44.0,54.0,54.0,54.0,53.0,53.0,63.0,39.0,50.0,56.0,42.0,58.0,44.0,59.0,54.0,41.0,63.0,52.0,63.0,50.0,36.0,42.0,57.0,47.0,71.0,56.0,62.0,77.0,72.0,64.0,58.0,71.0,42.0,46.0,40.0,63.0,76.0,41.0,49.0,51.0,44.0,44.0,62.0,40.0,60.0,44.0,53.0,22.0,55.0,67.0,60.0,51.0,46.0,55.0,52.0,81.0,55.0,74.0,54.0,76.0,41.0,33.0,67.0,40.0,46.0,53.0,59.0,63.0,60.0,55.0,48.0,65.0,52.0,43.0,67.0,53.0,44.0,48.0,31.0,54.0,42.0,52.0,45.0,37.0,36.0,70.0,49.0,45.0,46.0,46.0,53.0,55.0,46.0,63.0,35.0,36.0,61.0,50.0,48.0,80.0,34.0,47.0,65.0,31.0,61.0,58.0,40.0,49.0,46.0,67.0,47.0,77.0,40.0,43.0,58.0,56.0,53.0,56.0,59.0,71.0,73.0,54.0,54.0,46.0,69.0,45.0,31.0,39.0,51.0,37.0,61.0,50.0,60.0,34.0,41.0,57.0,63.0,35.0,74.0,64.0,35.0,54.0,36.0,49.0,39.0,47.0,47.0,46.0,43.0,48.0,72.0,57.0,28.0,47.0,53.0,66.0,67.0,64.0,60.0,59.0,66.0,65.0,68.0,51.0,52.0,44.0,43.0,53.0,53.0,45.0,62.0,72.0,47.0,48.0,49.0,51.0,67.0,37.0,50.0,46.0,41.0,45.0,68.0,42.0,31.0,55.0,37.0,42.0,46.0,32.0,50.0,43.0,25.0,42.0,41.0,44.0,39.0,49.0,58.0,35.0,45.0,64.0,61.0,42.0,52.0,69.0,44.0,58.0,51.0,55.0,70.0,59.0,39.0,46.0,68.0,49.0,42.0,46.0,47.0,57.0,46.0,67.0,39.0,35.0,46.0,64.0,60.0,48.0,41.0,41.0,57.0,61.0,45.0,30.0,52.0,28.0,50.0,61.0,31.0,34.0,41.0,68.0,43.0,42.0,45.0,57.0,40.0,65.0,53.0,41.0,66.0,57.0,25.0,43.0,51.0,58.0,52.0,44.0,58.0,65.0,34.0,48.0,62.0,41.0,75.0,39.0,51.0,45.0,64.0,73.0,56.0,77.0,68.0,62.0,48.0,48.0,45.0,32.0,48.0,56.0,51.0,48.0,48.0,41.0,53.0,48.0,64.0,49.0,58.0,70.0,62.0,44.0,52.0,53.0,40.0,46.0,58.0,50.0,53.0,57.0,49.0,55.0,42.0,59.0,27.0,40.0,69.0,38.0,38.0,70.0,57.0,54.0,66.0,49.0,53.0,38.0,45.0,48.0,63.0,55.0,45.0,56.0,52.0,66.0,45.0,48.0,41.0,51.0,45.0,48.0,52.0,48.0,54.0,35.0,41.0,59.0,53.0,59.0,43.0,66.0,52.0,42.0,56.0,57.0,47.0,76.0,58.0,35.0,40.0,32.0,63.0,48.0,32.0,69.0,41.0,59.0,54.0,43.0,69.0,60.0,54.0,57.0,53.0,39.0,43.0,56.0,50.0,31.0,28.0,53.0,43.0,48.0,44.0,58.0,52.0,62.0,44.0,53.0,38.0,39.0,37.0,68.0,66.0,70.0,49.0,35.0,49.0,44.0,41.0,57.0,41.0,35.0,43.0,65.0,61.0,48.0,38.0,42.0,50.0,57.0,63.0,64.0,70.0,57.0,55.0,34.0,37.0,54.0,39.0,55.0,53.0,38.0,37.0,50.0,70.0,34.0,40.0,46.0,45.0,61.0,69.0,44.0,54.0,58.0,60.0,50.0,42.0,63.0,47.0,49.0,43.0,48.0,45.0,66.0,34.0,48.0,55.0,50.0,36.0,44.0,54.0,45.0,58.0,55.0,63.0,39.0,52.0,44.0,58.0,42.0,59.0,32.0,53.0,58.0,49.0,62.0,48.0,31.0,67.0,44.0,29.0,70.0,36.0,49.0,43.0,62.0,64.0,56.0,29.0,72.0,47.0,60.0,42.0,56.0,42.0,52.0,59.0,45.0,55.0,65.0,69.0,43.0,56.0,44.0,59.0,69.0,57.0,30.0,41.0,41.0,50.0,45.0,62.0,60.0,48.0,66.0,48.0,58.0,37.0,62.0,34.0,32.0,48.0,74.0,35.0,61.0,56.0,41.0,65.0,70.0,64.0,62.0,53.0,63.0,57.0,59.0,59.0,52.0,49.0,72.0,40.0,61.0,52.0,62.0,46.0,46.0,55.0,68.0,43.0,71.0,51.0,52.0,41.0,64.0,58.0,63.0,47.0,50.0,69.0,43.0,65.0,52.0,54.0,47.0,53.0,47.0,38.0,75.0,47.0,46.0,54.0,42.0,50.0,61.0,40.0,64.0,50.0,62.0,62.0,49.0,68.0,37.0,45.0,33.0,51.0,47.0,42.0,76.0,65.0,40.0,32.0,47.0,63.0,46.0,38.0,43.0,63.0,55.0,56.0,36.0,45.0,42.0,60.0,36.0,36.0,46.0,63.0,48.0,50.0,44.0,61.0,51.0,42.0,44.0,35.0,47.0,62.0,55.0,32.0,60.0,48.0,43.0,41.0,60.0,46.0,36.0,46.0,52.0,44.0,51.0,49.0,68.0,47.0,48.0,60.0,70.0,50.0,54.0,54.0,56.0,55.0,44.0,49.0,21.0,66.0,62.0,62.0,60.0,46.0,45.0,48.0,55.0,49.0,61.0,41.0,48.0,61.0,53.0,49.0,41.0,33.0,52.0,49.0,56.0,39.0,48.0,69.0,36.0,69.0,48.0,69.0,67.0,42.0,45.0,60.0,38.0,52.0,67.0,38.0,50.0,52.0,24.0,36.0,41.0,45.0,47.0,73.0,60.0,44.0,66.0,54.0,44.0,25.0,50.0,37.0,69.0,58.0,37.0,42.0,71.0,61.0,65.0,52.0,65.0,54.0,61.0,55.0,32.0,57.0,56.0,44.0,47.0,56.0,37.0,31.0,29.0,45.0,44.0,53.0,34.0,40.0,63.0,52.0,59.0,51.0,69.0,46.0,57.0,27.0,66.0,51.0,38.0,54.0,45.0,68.0,52.0,41.0,67.0,52.0,42.0,44.0,58.0,63.0,35.0,47.0,54.0,44.0,44.0,49.0,47.0,50.0,45.0,39.0,42.0,43.0,54.0,40.0,47.0,59.0,60.0,52.0,61.0,46.0,53.0,45.0,80.0,32.0,53.0,75.0,44.0,62.0,50.0,44.0,46.0,66.0,49.0,57.0,57.0,56.0,64.0,53.0,58.0,54.0,46.0,37.0,33.0,67.0,55.0,44.0,66.0,54.0,55.0,59.0,68.0,49.0,49.0,64.0,40.0,61.0,70.0,57.0,73.0,46.0,48.0,63.0,49.0,57.0,59.0,50.0,39.0,50.0,50.0,50.0,44.0,48.0,45.0,36.0,39.0,56.0,51.0,47.0,40.0,72.0,54.0,30.0,45.0,60.0,44.0,39.0,67.0,68.0,55.0,55.0,42.0,47.0,74.0,57.0,59.0,39.0,41.0,61.0,28.0,79.0,68.0,34.0,37.0,37.0,36.0,60.0,44.0,49.0,28.0,38.0,43.0,68.0,50.0,48.0,44.0,37.0,40.0,61.0,41.0,70.0,53.0,59.0,53.0,46.0,80.0,45.0,59.0,41.0,38.0,50.0,48.0,60.0,45.0,65.0,66.0,62.0,68.0,54.0,45.0,70.0,66.0,57.0,50.0,51.0,36.0,68.0,51.0,64.0,44.0,50.0,43.0,51.0,50.0,75.0,31.0,58.0,57.0,57.0,47.0,68.0,38.0,65.0,42.0,54.0,55.0,45.0,42.0,33.0,61.0,48.0,45.0,36.0,57.0,63.0,64.0,38.0,37.0,46.0,28.0,51.0,68.0,79.0,51.0,43.0,63.0,44.0,55.0,38.0,36.0,58.0,39.0,59.0,47.0,49.0,70.0,51.0,57.0,44.0,55.0,52.0,53.0,70.0,53.0,60.0,56.0,45.0,64.0,66.0,38.0,38.0,57.0,55.0,51.0,72.0,70.0,54.0,55.0,38.0,66.0,38.0,66.0,43.0,46.0,40.0,50.0,38.0,52.0,60.0,54.0,62.0,72.0,84.0,44.0,66.0,41.0,47.0,44.0,67.0,36.0,48.0,62.0,30.0,42.0,51.0,44.0,45.0,72.0,62.0,57.0,47.0,60.0,54.0,43.0,36.0,37.0,38.0,49.0,55.0,64.0,66.0,46.0,49.0,36.0,45.0,30.0,52.0,53.0,64.0,67.0,61.0,54.0,45.0,61.0,56.0,35.0,38.0,30.0,49.0,38.0,42.0,42.0,55.0,53.0,36.0,58.0,29.0,42.0,47.0,41.0,39.0,49.0,35.0,45.0,73.0,39.0,53.0,38.0,38.0,44.0,61.0,41.0,58.0,39.0,50.0,44.0,56.0,64.0,37.0,66.0,53.0,54.0,53.0,73.0,33.0,57.0,49.0,47.0,56.0,32.0,61.0,52.0,43.0,65.0,39.0,68.0,48.0,44.0,50.0,43.0,61.0,56.0,49.0,39.0,36.0,45.0,45.0,53.0,40.0,45.0,32.0,61.0,30.0,47.0,67.0,46.0,30.0,47.0,55.0,39.0,44.0,71.0,45.0,51.0,56.0,40.0,51.0,46.0,55.0,76.0,56.0,58.0,74.0,56.0,56.0,27.0,44.0,54.0,62.0,55.0,65.0,49.0,39.0,56.0,62.0,66.0,53.0,51.0,42.0,42.0,51.0,70.0,46.0,42.0,58.0,55.0,39.0,59.0,58.0,53.0,47.0,34.0,43.0,72.0,79.0,34.0,46.0,58.0,71.0,65.0,49.0,70.0,59.0,39.0,38.0,43.0,37.0,61.0,39.0,38.0,73.0,63.0,46.0,41.0,51.0,59.0,50.0,59.0,80.0,48.0,67.0,42.0,64.0,35.0,46.0,51.0,60.0,45.0,58.0,52.0,29.0,63.0,43.0,72.0,29.0,57.0,57.0,29.0,46.0,29.0,48.0,52.0,61.0,58.0,42.0,55.0,59.0,49.0,77.0,39.0,70.0,56.0,24.0,64.0,37.0,49.0,65.0,57.0,51.0,49.0,57.0,51.0,60.0,66.0,41.0,55.0,75.0,38.0,44.0,51.0,25.0,58.0,44.0,63.0,44.0,29.0,35.0,38.0,54.0,70.0,54.0,48.0,43.0,52.0,58.0,61.0,45.0,65.0,49.0,36.0,55.0,54.0,68.0,36.0,34.0,62.0,48.0,60.0,44.0,49.0,63.0,61.0,52.0,47.0,57.0,72.0,68.0,42.0,52.0,61.0,47.0,44.0,41.0,49.0,57.0,46.0,76.0,55.0,43.0,46.0,44.0,45.0,45.0,46.0,60.0,67.0,34.0,38.0,44.0,57.0,65.0,50.0,40.0,66.0,27.0,64.0,45.0,58.0,78.0,57.0,77.0,60.0,68.0,46.0,53.0,40.0,48.0,62.0,54.0,36.0,40.0,69.0,36.0,49.0,48.0,28.0,68.0,41.0,35.0,70.0,46.0,50.0,77.0,60.0,47.0,69.0,67.0,60.0,46.0,39.0,41.0,42.0,53.0,46.0,47.0,37.0,49.0,52.0,43.0,73.0,63.0,42.0,54.0,58.0,66.0,60.0,90.0,42.0,65.0,45.0,48.0,40.0,43.0,61.0,43.0,48.0,36.0,54.0,45.0,54.0,68.0,56.0,51.0,35.0,46.0,71.0,64.0,49.0,43.0,60.0,66.0,64.0,56.0,56.0,70.0,40.0,41.0,54.0,51.0,43.0,66.0,58.0,48.0,36.0,49.0,50.0,51.0,30.0,46.0,52.0,68.0,34.0,77.0,58.0,50.0,49.0,49.0,64.0,52.0,41.0,56.0,48.0,58.0,51.0,63.0,50.0,54.0,61.0,39.0,63.0,37.0,46.0,49.0,53.0,57.0,69.0,45.0,71.0,48.0,43.0,43.0,41.0,35.0,53.0,49.0,52.0,38.0,53.0,55.0,55.0,48.0,47.0,71.0,37.0,59.0,51.0,40.0,36.0,54.0,58.0,59.0,45.0,38.0,45.0,69.0,57.0,42.0,55.0,38.0,60.0,37.0,53.0,46.0,51.0,57.0,49.0,40.0,64.0,45.0,43.0,49.0,42.0,61.0,74.0,60.0,29.0,67.0,69.0,41.0,59.0,51.0,46.0,49.0,55.0,55.0,33.0,65.0,58.0,39.0,64.0,67.0,53.0,45.0,49.0,49.0,51.0,51.0,54.0,49.0,53.0,45.0,50.0,37.0,51.0,67.0,56.0,52.0,36.0,65.0,30.0,69.0,33.0,55.0,50.0,63.0,54.0,50.0,48.0,38.0,74.0,57.0,58.0,61.0,55.0,55.0,56.0,73.0,55.0,40.0,54.0,61.0,33.0,50.0,48.0,48.0,41.0,35.0,68.0,42.0,49.0,50.0,63.0,56.0,55.0,41.0,37.0,47.0,50.0,64.0,44.0,41.0,47.0,39.0,41.0,41.0,75.0,37.0,58.0,30.0,36.0,60.0,49.0,52.0,35.0,54.0,38.0,49.0,51.0,60.0,54.0,39.0,41.0,36.0,39.0,47.0,33.0,62.0,73.0,49.0,48.0,36.0,50.0,62.0,46.0,44.0,48.0,42.0,61.0,55.0,71.0,34.0,40.0,41.0,39.0,54.0,50.0,43.0,56.0,43.0,38.0,50.0,28.0,57.0,58.0,72.0,47.0,87.0,62.0,52.0,67.0,50.0,54.0,51.0,53.0,56.0,54.0,55.0,41.0,65.0,37.0,46.0,37.0,60.0,60.0,42.0,47.0,49.0,49.0,66.0,41.0,59.0,58.0,44.0,46.0,53.0,43.0,32.0,33.0,40.0,50.0,48.0,53.0,54.0,53.0,57.0,36.0,71.0,52.0,43.0,29.0,61.0,35.0,49.0,48.0,55.0,70.0,43.0,42.0,47.0,59.0,44.0,57.0,36.0,34.0,53.0,73.0,45.0,59.0,43.0,68.0,45.0,64.0,59.0,57.0,57.0,67.0,60.0,65.0,59.0,52.0,47.0,71.0,60.0,68.0,67.0,55.0,38.0,55.0,63.0,40.0,46.0,49.0,45.0,41.0,71.0,72.0,41.0,64.0,32.0,51.0,48.0,57.0,39.0,49.0,81.0,57.0,64.0,46.0,62.0,42.0,40.0,45.0,65.0,59.0,55.0,53.0,67.0,48.0,41.0,59.0,57.0,69.0,64.0,49.0,64.0,37.0,49.0,40.0,41.0,58.0,56.0,54.0,37.0,42.0,63.0,54.0,55.0,50.0,55.0,52.0,31.0,44.0,71.0,40.0,42.0,52.0,62.0,31.0,58.0,43.0,58.0,68.0,38.0,43.0,57.0,71.0,36.0,46.0,42.0,63.0,50.0,38.0,48.0,63.0,63.0,55.0,60.0,63.0,52.0,55.0,48.0,42.0,61.0,36.0,60.0,69.0,46.0,51.0,56.0,42.0,54.0,60.0,62.0,59.0,42.0,67.0,55.0,31.0,44.0,52.0,29.0,38.0,57.0,47.0,39.0,63.0,64.0,63.0,49.0,64.0,81.0,55.0,46.0,41.0,60.0,50.0,58.0,47.0,58.0,58.0,42.0,39.0,53.0,61.0,52.0,31.0,40.0,45.0,64.0,58.0,61.0,62.0,42.0,35.0,70.0,38.0,42.0,44.0,53.0,36.0,42.0,57.0,65.0,47.0,49.0,41.0,52.0,57.0,62.0,67.0,60.0,53.0,59.0,52.0,50.0,67.0,62.0,66.0,48.0,39.0,40.0,41.0,63.0,36.0,59.0,58.0,48.0,38.0,48.0,60.0,50.0,37.0,62.0,63.0,50.0,56.0,44.0,43.0,66.0,65.0,49.0,34.0,42.0,54.0,62.0,59.0,69.0,57.0,70.0,56.0,46.0,31.0,70.0,49.0,56.0,60.0,55.0,52.0,61.0,69.0,44.0,49.0,47.0,36.0,51.0,42.0,42.0,34.0,48.0,48.0,51.0,72.0,71.0,69.0,50.0,65.0,48.0,66.0,36.0,45.0,43.0,75.0,53.0,50.0,55.0,50.0,51.0,49.0,64.0,23.0,48.0,75.0,47.0,62.0,33.0,56.0,53.0,38.0,63.0,64.0,63.0,64.0,45.0,47.0,76.0,69.0,50.0,44.0,45.0,53.0,43.0,62.0,61.0,41.0,43.0,62.0,58.0,42.0,48.0,50.0,64.0,78.0,52.0,44.0,61.0,63.0,42.0,45.0,62.0,62.0,55.0,47.0,58.0,61.0,50.0,46.0,63.0,40.0,62.0,74.0,35.0,67.0,48.0,61.0,36.0,65.0,56.0,44.0,60.0,73.0,68.0,62.0,38.0,28.0,64.0,34.0,48.0,42.0,50.0,53.0,60.0,56.0,57.0,48.0,38.0,59.0,67.0,59.0,62.0,64.0,50.0,40.0,71.0,69.0,63.0,53.0,44.0,45.0,59.0,54.0,51.0,51.0,59.0,74.0,38.0,48.0,35.0,64.0,58.0,54.0,44.0,46.0,29.0,58.0,69.0,64.0,63.0,76.0,53.0,45.0,50.0,64.0,39.0,65.0,50.0,52.0,54.0,58.0,40.0,63.0,60.0,70.0,59.0,61.0,48.0,60.0,50.0,46.0,60.0,48.0,61.0,61.0,55.0,33.0,58.0,63.0,44.0,44.0,58.0,70.0,46.0,37.0,57.0,56.0,39.0,53.0,63.0,41.0,48.0,50.0,61.0,48.0,64.0,46.0,35.0,36.0,35.0,69.0,43.0,44.0,48.0,48.0,54.0,43.0,46.0,51.0,40.0,61.0,47.0,44.0,66.0,45.0,56.0,52.0,58.0,50.0,47.0,55.0,45.0,54.0,29.0,39.0,58.0,45.0,74.0,53.0,53.0,66.0,46.0,65.0,76.0,48.0,49.0,60.0,47.0,53.0,41.0,53.0,35.0,57.0,43.0,49.0,66.0,45.0,47.0,58.0,37.0,83.0,47.0,45.0,58.0,57.0,63.0,52.0,61.0,55.0,52.0,44.0,63.0,55.0,59.0,39.0,75.0,42.0,65.0,66.0,48.0,49.0,70.0,66.0,34.0,58.0,56.0,49.0,50.0,65.0,62.0,47.0,85.0,61.0,62.0,72.0,55.0,61.0,46.0,46.0,75.0,63.0,59.0,69.0,61.0,57.0,49.0,61.0,53.0,49.0,32.0,52.0,42.0,46.0,78.0,60.0,61.0,41.0,52.0,40.0,63.0,66.0,51.0,57.0,63.0,51.0,27.0,31.0,37.0,35.0,66.0,71.0,31.0,52.0,41.0,54.0,39.0,43.0,43.0,57.0,36.0,51.0,44.0,41.0,74.0,42.0,48.0,50.0,44.0,56.0,52.0,61.0,47.0,61.0,41.0,39.0,75.0,37.0,54.0,47.0,76.0,43.0,49.0,45.0,62.0,41.0,60.0,77.0,56.0,63.0,68.0,36.0,49.0,47.0,71.0,68.0,43.0,51.0,47.0,46.0,46.0,45.0,42.0,41.0,51.0,48.0,42.0,35.0,39.0,49.0,65.0,46.0,50.0,52.0,51.0,66.0,58.0,45.0,55.0,44.0,72.0,57.0,45.0,60.0,42.0,57.0,44.0,50.0,50.0,39.0,57.0,61.0,58.0,77.0,37.0,68.0,67.0,62.0,62.0,47.0,52.0,47.0,40.0,41.0,41.0,59.0,31.0,60.0,52.0,66.0,52.0,55.0,60.0,31.0,60.0,68.0,27.0,39.0,60.0,61.0,70.0,42.0,56.0,46.0,57.0,57.0,65.0,29.0,53.0,59.0,53.0,51.0,46.0,64.0,55.0,54.0,43.0,49.0,68.0,57.0,44.0,49.0,51.0,53.0,53.0,55.0,41.0,32.0,49.0,58.0,61.0,57.0,65.0,66.0,59.0,49.0,47.0,57.0,64.0,38.0,64.0,70.0,37.0,49.0,59.0,63.0,55.0,50.0,79.0,65.0,50.0,62.0,64.0,53.0,46.0,40.0,53.0,55.0,37.0,39.0,57.0,30.0,44.0,55.0,42.0,51.0,35.0,53.0,66.0,47.0,74.0,54.0,47.0,48.0,45.0,44.0,75.0,58.0,43.0,34.0,69.0,62.0,49.0,41.0,52.0,36.0,65.0,46.0,77.0,68.0,60.0,47.0,44.0,58.0,46.0,49.0,61.0,86.0,41.0,53.0,59.0,61.0,47.0,78.0,31.0,45.0,56.0,54.0,66.0,33.0,51.0,54.0,44.0,51.0,50.0,61.0,50.0,45.0,47.0,42.0,36.0,48.0,46.0,38.0,70.0,62.0,50.0,59.0,30.0,43.0,76.0,53.0,76.0,50.0,63.0,40.0,45.0,39.0,42.0,54.0,49.0,55.0,51.0,70.0,47.0,83.0,62.0,36.0,59.0,59.0,59.0,46.0,55.0,56.0,40.0,59.0,53.0,36.0,50.0,57.0,50.0,53.0,62.0,41.0,73.0,57.0,49.0,38.0,48.0],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[40.7,37.2,24.700000000000003,31.0,42.900000000000006,23.0,28.90000000000001,41.1,32.0,41.5,42.1,31.3,39.8,34.599999999999994,43.0,10.700000000000005,32.900000000000006,40.7,26.8,36.2,20.8,25.8,41.5,39.1,22.90000000000001,20.5,35.900000000000006,41.0,25.40000000000001,39.900000000000006,19.0,18.700000000000003,44.6,32.900000000000006,28.700000000000003,23.3,28.599999999999994,30.3,31.90000000000001,46.900000000000006,35.900000000000006,36.5,39.3,27.40000000000001,24.700000000000003,20.700000000000003,35.099999999999994,25.200000000000003,34.5,35.400000000000006,16.799999999999997,37.2,17.599999999999994,34.900000000000006,25.40000000000001,20.40000000000001,34.099999999999994,44.6,30.8,29.8,25.8,39.1,44.400000000000006,24.3,20.0,22.5,32.3,6.400000000000006,30.599999999999994,37.3,23.700000000000003,40.1,19.099999999999994,42.5,36.8,19.40000000000001,36.5,23.0,26.200000000000003,45.8,22.8,31.5,39.1,35.5,42.1,34.8,40.0,27.700000000000003,35.7,14.099999999999994,40.2,36.5,34.5,36.5,22.099999999999994,21.200000000000003,24.90000000000001,41.5,35.7,32.900000000000006,22.90000000000001,24.200000000000003,41.3,34.3,33.400000000000006,34.5,32.2,39.8,37.6,41.6,20.099999999999994,30.0,23.0,37.400000000000006,13.099999999999994,29.599999999999994,36.3,32.400000000000006,37.8,40.0,42.8,33.099999999999994,33.5,50.0,35.099999999999994,34.2,39.0,30.5,34.900000000000006,40.6,38.8,34.400000000000006,27.90000000000001,31.90000000000001,14.700000000000005,37.900000000000006,30.40000000000001,16.599999999999994,16.799999999999997,36.1,40.1,43.0,21.700000000000003,37.400000000000006,34.400000000000006,40.5,34.900000000000006,39.1,24.8,37.1,44.2,22.099999999999994,44.3,16.700000000000003,33.3,31.700000000000003,19.599999999999994,24.40000000000001,31.3,37.8,24.90000000000001,34.400000000000006,39.6,34.400000000000006,17.799999999999997,43.400000000000006,8.799999999999997,24.0,32.599999999999994,43.400000000000006,37.9,28.3,32.5,36.900000000000006,23.3,15.799999999999995,42.2,32.900000000000006,36.400000000000006,33.2,15.900000000000006,45.5,38.400000000000006,18.90000000000001,36.900000000000006,41.2,40.0,26.8,36.5,28.90000000000001,41.8,12.099999999999994,42.6,40.5,38.1,41.1,38.8,38.1,27.90000000000001,24.200000000000003,40.900000000000006,35.099999999999994,40.400000000000006,33.900000000000006,44.6,13.799999999999995,24.0,41.400000000000006,27.40000000000001,28.099999999999994,36.6,32.400000000000006,33.8,41.0,39.2,37.3,44.3,34.7,37.6,30.0,35.599999999999994,34.0,40.5,40.5,27.200000000000003,22.599999999999994,35.2,16.700000000000003,24.599999999999994,41.0,48.3,31.599999999999994,31.90000000000001,40.1,20.700000000000003,26.099999999999994,21.3,22.700000000000003,24.40000000000001,40.1,35.8,22.5,38.1,34.7,33.099999999999994,40.2,17.599999999999994,33.0,37.0,33.099999999999994,21.700000000000003,33.599999999999994,36.5,32.2,39.1,32.5,32.099999999999994,38.3,22.8,23.5,38.5,35.7,15.799999999999995,38.7,33.400000000000006,22.700000000000003,38.0,26.5,38.7,40.1,40.5,36.5,35.2,36.8,35.7,40.900000000000006,34.7,33.400000000000006,39.3,23.599999999999994,41.5,38.8,37.1,45.0,38.8,23.5,35.400000000000006,39.5,20.599999999999994,35.2,35.5,38.900000000000006,42.5,21.5,36.7,39.3,41.1,38.6,42.8,23.599999999999994,35.2,29.90000000000001,41.1,41.7,22.90000000000001,34.099999999999994,38.7,11.5,36.8,36.1,33.400000000000006,21.700000000000003,43.8,43.2,44.8,32.400000000000006,38.400000000000006,36.6,38.8,35.599999999999994,34.0,16.099999999999994,26.0,38.7,45.0,25.099999999999994,42.2,29.3,40.6,42.1,22.599999999999994,29.3,33.8,9.5,28.599999999999994,40.1,36.900000000000006,43.400000000000006,22.599999999999994,38.900000000000006,35.099999999999994,14.799999999999995,32.8,24.40000000000001,42.900000000000006,21.8,19.599999999999994,27.200000000000003,34.0,22.5,29.5,19.599999999999994,36.400000000000006,14.799999999999995,39.3,12.799999999999995,38.0,37.1,37.2,24.200000000000003,24.90000000000001,31.700000000000003,36.400000000000006,34.400000000000006,40.6,39.0,24.200000000000003,22.599999999999994,16.5,30.700000000000003,38.1,36.400000000000006,24.599999999999994,42.0,39.3,36.6,37.6,28.099999999999994,39.3,37.8,41.1,42.400000000000006,38.5,29.599999999999994,26.5,38.900000000000006,38.1,36.3,19.90000000000001,33.099999999999994,37.5,21.5,37.8,38.2,18.40000000000001,18.40000000000001,37.900000000000006,26.200000000000003,36.0,22.200000000000003,39.400000000000006,27.90000000000001,28.40000000000001,34.900000000000006,35.3,37.900000000000006,18.3,40.400000000000006,24.599999999999994,20.599999999999994,36.6,47.3,39.1,36.400000000000006,35.099999999999994,25.3,25.40000000000001,32.099999999999994,20.5,38.3,38.6,28.8,12.900000000000006,36.3,21.200000000000003,37.7,24.700000000000003,39.6,42.1,41.400000000000006,35.900000000000006,23.90000000000001,40.7,28.200000000000003,41.8,40.7,45.1,35.5,39.900000000000006,36.8,34.900000000000006,35.400000000000006,25.0,38.900000000000006,22.8,36.6,19.40000000000001,42.8,43.0,39.8,37.1,30.200000000000003,42.1,39.400000000000006,49.5,36.1,37.900000000000006,43.6,32.8,28.8,31.0,22.099999999999994,34.2,27.700000000000003,28.90000000000001,34.400000000000006,43.2,39.400000000000006,41.8,38.2,35.900000000000006,42.0,44.1,34.599999999999994,26.099999999999994,39.0,24.90000000000001,38.1,24.5,36.7,28.599999999999994,39.6,22.5,37.1,35.5,39.6,30.099999999999994,35.099999999999994,39.2,32.0,37.5,21.599999999999994,23.5,26.200000000000003,33.3,40.6,38.900000000000006,35.099999999999994,40.1,35.599999999999994,33.2,45.7,27.90000000000001,39.400000000000006,36.8,41.2,30.5,37.1,21.8,30.599999999999994,37.900000000000006,37.6,23.099999999999994,28.599999999999994,20.40000000000001,39.3,17.400000000000006,29.3,33.400000000000006,42.2,32.2,39.3,39.7,39.8,19.099999999999994,23.8,41.1,37.7,38.8,23.700000000000003,26.8,40.1,27.700000000000003,25.5,20.099999999999994,39.8,23.40000000000001,20.599999999999994,38.1,20.0,28.5,37.0,17.200000000000003,40.400000000000006,37.400000000000006,35.400000000000006,20.8,37.900000000000006,40.900000000000006,7.799999999999997,32.0,26.200000000000003,37.900000000000006,30.8,42.2,27.40000000000001,35.8,41.900000000000006,39.0,23.599999999999994,37.400000000000006,40.1,39.6,21.3,38.6,38.0,36.0,33.2,37.8,40.400000000000006,43.2,16.200000000000003,20.200000000000003,35.2,19.3,30.5,40.900000000000006,43.5,27.5,39.400000000000006,37.2,28.099999999999994,43.2,40.5,38.2,39.7,33.099999999999994,45.6,12.900000000000006,20.200000000000003,20.099999999999994,36.0,22.8,29.5,48.2,22.40000000000001,37.1,34.8,36.1,35.7,36.6,34.599999999999994,40.1,36.1,33.900000000000006,39.2,37.2,38.6,37.8,38.0,36.3,38.8,33.7,18.90000000000001,29.200000000000003,42.400000000000006,25.3,23.90000000000001,33.400000000000006,41.400000000000006,30.40000000000001,37.400000000000006,38.8,33.400000000000006,41.5,34.2,44.5,34.2,39.5,39.7,47.2,33.3,37.3,36.7,25.0,36.3,35.3,33.7,27.700000000000003,39.3,38.0,28.3,34.7,37.6,23.700000000000003,12.0,38.900000000000006,14.299999999999995,16.299999999999997,40.2,17.700000000000003,40.400000000000006,41.6,16.0,40.1,33.2,15.599999999999994,41.7,35.2,47.8,36.3,31.3,33.5,26.200000000000003,36.7,33.0,41.2,34.099999999999994,44.8,37.6,38.7,22.700000000000003,31.8,12.400000000000006,25.0,28.90000000000001,27.099999999999994,39.7,36.5,42.0,43.0,35.8,36.2,43.900000000000006,24.0,27.3,28.099999999999994,28.700000000000003,24.700000000000003,31.90000000000001,43.1,39.7,33.7,42.0,44.5,20.099999999999994,36.900000000000006,34.400000000000006,41.1,35.7,24.200000000000003,42.3,39.400000000000006,47.5,38.2,26.3,37.2,30.599999999999994,22.8,26.3,28.8,33.099999999999994,30.0,36.8,36.3,18.0,38.2,36.400000000000006,35.599999999999994,43.5,23.200000000000003,34.7,40.0,39.400000000000006,32.5,20.5,40.8,20.90000000000001,28.5,25.5,19.700000000000003,40.6,40.2,23.200000000000003,35.900000000000006,41.5,41.5,37.0,39.0,34.8,38.9,35.099999999999994,43.8,14.599999999999994,4.5,35.900000000000006,37.7,25.40000000000001,33.0,38.5,34.099999999999994,41.7,22.700000000000003,20.5,26.8,28.5,36.5,35.3,25.3,23.90000000000001,42.2,37.1,27.90000000000001,36.7,37.8,15.700000000000005,35.2,37.2,27.099999999999994,40.1,41.8,16.700000000000003,26.0,25.700000000000003,34.3,19.40000000000001,35.599999999999994,38.6,44.3,22.5,38.900000000000006,37.8,23.0,34.900000000000006,37.1,26.3,28.700000000000003,23.099999999999994,27.40000000000001,33.900000000000006,36.8,16.099999999999994,41.0,36.3,37.8,39.400000000000006,38.1,39.6,38.400000000000006,30.40000000000001,27.8,31.599999999999994,34.599999999999994,41.3,22.099999999999994,38.8,36.2,37.7,35.599999999999994,21.40000000000001,29.8,25.0,35.400000000000006,14.299999999999995,36.7,37.900000000000006,31.3,43.6,39.5,36.900000000000006,25.599999999999994,35.0,11.099999999999994,18.599999999999994,12.200000000000005,33.7,18.200000000000003,38.6,41.400000000000006,31.0,39.5,41.400000000000006,39.3,35.900000000000006,35.7,32.7,32.599999999999994,22.90000000000001,33.2,35.8,22.099999999999994,19.200000000000003,41.1,39.0,32.599999999999994,20.5,41.7,43.900000000000006,21.599999999999994,41.3,13.700000000000005,38.0,36.0,28.700000000000003,40.7,15.700000000000005,38.2,42.2,36.8,27.0,35.8,36.6,17.799999999999997,26.0,24.40000000000001,30.599999999999994,23.90000000000001,40.6,16.200000000000003,30.0,39.3,36.2,42.0,23.5,37.400000000000006,23.3,40.6,37.0,24.099999999999994,30.90000000000001,40.8,22.90000000000001,23.90000000000001,24.200000000000003,44.1,38.900000000000006,46.7,42.7,12.099999999999994,32.2,37.2,36.900000000000006,38.8,31.3,25.3,34.099999999999994,35.599999999999994,37.8,30.5,13.900000000000006,31.5,25.0,25.0,21.0,46.3,20.5,37.900000000000006,31.599999999999994,10.400000000000006,40.8,35.3,24.40000000000001,40.7,26.3,24.3,39.3,41.6,34.5,21.0,31.700000000000003,17.799999999999997,17.400000000000006,39.0,20.0,37.5,38.3,32.400000000000006,36.3,41.0,42.0,36.5,37.0,36.6,36.1,32.2,18.90000000000001,33.599999999999994,43.6,40.900000000000006,35.599999999999994,39.0,38.3,36.400000000000006,37.6,38.0,38.0,39.1,26.3,38.6,38.7,10.299999999999995,22.40000000000001,35.099999999999994,18.0,35.0,42.7,27.700000000000003,42.8,15.0,36.8,42.400000000000006,34.7,36.2,38.900000000000006,38.8,14.599999999999994,36.3,37.1,17.200000000000003,32.2,31.200000000000003,18.40000000000001,37.0,41.7,37.8,23.200000000000003,22.099999999999994,39.3,37.400000000000006,32.5,34.3,15.599999999999994,26.8,40.900000000000006,18.5,44.1,29.5,22.90000000000001,35.599999999999994,41.2,39.1,41.0,25.700000000000003,38.900000000000006,37.1,22.90000000000001,16.700000000000003,39.7,44.7,33.900000000000006,35.2,18.3,33.400000000000006,37.2,24.099999999999994,43.2,38.0,29.3,29.40000000000001,34.900000000000006,43.400000000000006,23.40000000000001,34.599999999999994,26.40000000000001,44.900000000000006,38.5,31.8,22.599999999999994,37.2,33.0,22.3,16.200000000000003,37.6,36.7,31.200000000000003,35.7,13.299999999999995,35.0,21.200000000000003,37.2,38.0,37.5,28.90000000000001,38.2,30.40000000000001,30.8,38.6,40.1,41.900000000000006,43.2,38.6,32.900000000000006,37.6,30.8,36.0,42.6,23.8,40.5,40.2,31.599999999999994,30.099999999999994,36.5,24.8,37.6,47.7,41.3,32.5,22.5,40.8,31.700000000000003,37.0,33.099999999999994,33.7,42.0,36.1,22.5,31.200000000000003,41.3,40.8,14.0,33.8,38.1,29.0,36.5,16.0,28.40000000000001,40.5,41.1,38.8,34.7,29.40000000000001,33.900000000000006,27.5,38.2,32.400000000000006,42.5,37.900000000000006,30.3,35.3,37.2,32.8,37.900000000000006,15.299999999999995,20.599999999999994,33.8,36.400000000000006,20.5,21.200000000000003,31.200000000000003,18.599999999999994,28.90000000000001,37.2,38.5,36.400000000000006,37.8,25.40000000000001,35.7,41.6,39.8,22.8,39.2,37.3,42.7,36.4,43.400000000000006,38.6,14.700000000000005,25.200000000000003,29.200000000000003,19.90000000000001,25.40000000000001,20.099999999999994,35.7,11.599999999999994,36.6,39.8,36.3,19.40000000000001,36.5,18.200000000000003,44.900000000000006,42.3,38.1,31.700000000000003,19.3,35.0,40.1,29.200000000000003,31.200000000000003,38.2,39.6,35.099999999999994,32.3,43.7,43.5,34.7,39.400000000000006,35.5,37.400000000000006,35.900000000000006,34.599999999999994,41.8,23.200000000000003,12.700000000000005,20.200000000000003,33.2,39.6,37.2,38.6,40.0,36.8,22.90000000000001,41.1,24.200000000000003,40.1,34.599999999999994,37.400000000000006,41.3,17.5,36.400000000000006,39.2,37.3,15.900000000000006,24.90000000000001,38.900000000000006,36.900000000000006,38.2,13.200000000000005,30.90000000000001,23.40000000000001,34.2,38.1,32.8,38.2,34.400000000000006,40.400000000000006,36.900000000000006,46.5,38.5,31.40000000000001,34.900000000000006,26.200000000000003,31.0,39.2,39.400000000000006,27.3,23.5,38.400000000000006,24.5,21.0,28.3,31.8,38.900000000000006,10.900000000000006,37.400000000000006,19.200000000000003,41.6,40.8,29.40000000000001,30.5,39.1,19.700000000000003,42.7,35.400000000000006,34.900000000000006,24.40000000000001,22.700000000000003,42.7,41.3,36.2,-0.0,33.3,21.5,34.3,33.2,35.0,38.2,38.8,35.8,37.0,39.3,28.0,37.7,37.8,21.099999999999994,37.1,42.6,41.3,35.5,28.599999999999994,38.2,28.8,25.0,11.400000000000006,19.3,19.0,21.5,35.099999999999994,38.7,39.8,42.3,14.900000000000006,14.099999999999994,42.1,38.2,36.2,25.599999999999994,33.900000000000006,17.900000000000006,11.400000000000006,43.8,35.2,37.900000000000006,18.099999999999994,34.099999999999994,33.400000000000006,42.0,38.7,28.8,31.8,39.1,42.2,38.1,34.599999999999994,23.599999999999994,33.099999999999994,35.2,42.900000000000006,39.6,32.8,17.700000000000003,35.7,33.3,23.0,36.400000000000006,28.40000000000001,36.8,37.8,37.0,25.200000000000003,24.5,38.5,38.900000000000006,39.400000000000006,33.400000000000006,34.3,13.700000000000005,32.3,37.3,38.8,17.200000000000003,22.0,24.599999999999994,16.700000000000003,34.2,33.2,22.5,18.5,22.5,35.5,13.799999999999995,19.099999999999994,41.400000000000006,38.400000000000006,21.0,27.5,39.0,38.400000000000006,34.7,34.8,35.8,30.700000000000003,39.3,32.900000000000006,36.400000000000006,40.1,33.2,45.6,37.3,33.900000000000006,29.5,37.7,23.0,11.099999999999994,35.5,29.40000000000001,39.2,37.900000000000006,39.2,26.8,36.0,19.700000000000003,29.90000000000001,20.200000000000003,36.900000000000006,39.1,36.900000000000006,35.599999999999994,17.200000000000003,37.8,19.200000000000003,17.900000000000006,25.099999999999994,27.099999999999994,34.3,30.5,37.8,39.900000000000006,32.3,37.0,33.400000000000006,21.200000000000003,30.700000000000003,36.6,41.2,41.6,41.3,26.40000000000001,38.7,35.8,38.6,24.3,41.2,37.1,20.200000000000003,36.7,32.8,32.0,36.2,32.599999999999994,23.90000000000001,23.3,24.5,33.900000000000006,43.2,17.599999999999994,40.400000000000006,35.400000000000006,28.200000000000003,38.5,36.7,25.200000000000003,26.3,16.299999999999997,22.200000000000003,38.400000000000006,36.6,24.099999999999994,36.2,26.90000000000001,17.799999999999997,28.599999999999994,40.5,23.200000000000003,45.0,15.799999999999995,43.900000000000006,15.200000000000005,43.1,37.7,36.0,27.200000000000003,41.6,35.099999999999994,30.90000000000001,35.599999999999994,17.700000000000003,32.3,35.900000000000006,37.0,41.6,23.099999999999994,38.2,38.1,38.5,30.0,28.099999999999994,37.1,30.200000000000003,34.5,35.599999999999994,22.0,29.700000000000003,38.2,39.3,40.7,34.8,18.90000000000001,19.5,39.0,27.0,40.1,17.599999999999994,26.40000000000001,36.900000000000006,30.5,32.2,28.40000000000001,26.3,35.0,32.400000000000006,40.2,37.400000000000006,46.7,42.900000000000006,38.0,22.90000000000001,39.2,37.0,35.099999999999994,36.7,29.90000000000001,34.0,37.8,37.400000000000006,35.5,23.0,29.3,36.6,43.1,40.3,41.1,42.5,37.5,40.1,36.3,37.8,34.900000000000006,19.599999999999994,33.5,20.700000000000003,18.599999999999994,39.8,38.3,32.2,41.1,41.1,30.5,40.8,31.0,42.400000000000006,26.099999999999994,28.90000000000001,39.8,15.400000000000006,35.5,35.599999999999994,45.6,25.5,13.400000000000006,34.3,39.7,31.099999999999994,36.8,40.0,40.8,31.5,15.5,38.3,25.0,16.799999999999997,19.90000000000001,40.900000000000006,32.8,23.099999999999994,39.0,33.900000000000006,23.599999999999994,27.40000000000001,28.8,40.5,30.0,14.400000000000006,41.5,24.700000000000003,30.700000000000003,35.400000000000006,38.8,43.2,26.8,43.400000000000006,20.40000000000001,34.599999999999994,14.5,38.8,35.3,41.3,37.5,26.8,41.8,24.700000000000003,42.1,34.5,30.200000000000003,18.3,41.6,41.0,24.099999999999994,41.8,38.400000000000006,17.900000000000006,33.3,23.40000000000001,34.7,41.900000000000006,13.5,36.900000000000006,31.599999999999994,31.8,22.099999999999994,38.3,38.3,35.3,40.1,23.599999999999994,15.599999999999994,26.5,42.7,40.0,19.8,40.5,35.400000000000006,37.6,33.400000000000006,38.0,13.700000000000005,7.799999999999997,42.400000000000006,39.400000000000006,34.099999999999994,36.2,40.1,40.900000000000006,19.3,37.400000000000006,42.3,23.90000000000001,27.40000000000001,41.5,44.8,40.5,40.8,17.400000000000006,39.8,35.0,42.0,38.5,25.700000000000003,25.700000000000003,19.90000000000001,21.8,17.700000000000003,17.400000000000006,36.900000000000006,30.700000000000003,36.400000000000006,34.099999999999994,27.200000000000003,36.900000000000006,30.099999999999994,31.200000000000003,36.6,42.1,32.599999999999994,36.3,38.7,37.4,35.8,33.5,39.3,34.099999999999994,27.700000000000003,9.599999999999994,33.0,30.599999999999994,21.5,25.0,40.3,41.0,37.900000000000006,20.3,29.90000000000001,39.6,24.5,37.8,33.400000000000006,44.1,37.1,29.200000000000003,35.099999999999994,38.6,21.099999999999994,36.1,37.400000000000006,42.3,36.5,37.6,26.700000000000003,17.299999999999997,21.40000000000001,34.0,44.0,36.3,30.599999999999994,44.7,43.5,20.099999999999994,22.0,29.8,24.3,35.7,34.3,42.8,39.6,27.3,19.8,35.8,37.7,31.099999999999994,23.5,20.599999999999994,24.0,39.6,22.099999999999994,29.700000000000003,37.6,37.3,39.900000000000006,31.200000000000003,24.40000000000001,41.6,36.6,34.5,21.40000000000001,36.0,35.5,42.6,39.6,39.400000000000006,39.2,38.8,24.40000000000001,13.900000000000006,23.099999999999994,22.200000000000003,37.6,35.900000000000006,41.7,26.8,35.599999999999994,35.900000000000006,38.8,39.6,40.3,36.900000000000006,36.7,23.8,31.8,34.8,37.3,42.1,24.40000000000001,34.900000000000006,40.5,26.90000000000001,43.3,33.599999999999994,22.0,37.8,25.90000000000001,21.099999999999994,22.200000000000003,38.400000000000006,33.900000000000006,30.099999999999994,24.200000000000003,36.7,40.0,23.599999999999994,33.8,38.900000000000006,17.700000000000003,37.7,36.400000000000006,33.099999999999994,21.599999999999994,30.0,37.8,25.5,34.400000000000006,25.8,42.0,36.6,20.5,37.2,25.8,39.1,33.0,40.2,31.40000000000001,43.2,23.5,19.3,16.299999999999997,21.90000000000001,25.0,29.5,36.6,43.0,37.2,39.0,16.200000000000003,38.2,34.3,17.0,44.5,33.599999999999994,25.5,34.8,25.40000000000001,19.8,29.0,35.5,37.7,42.3,42.3,25.90000000000001,30.3,30.8,9.900000000000006,34.0,44.0,35.099999999999994,37.8,31.3,21.700000000000003,38.6,34.3,30.0,21.099999999999994,38.8,20.8,21.40000000000001,21.3,37.6,41.400000000000006,34.2,46.400000000000006,39.900000000000006,43.900000000000006,33.2,38.5,37.6,20.8,20.3,37.400000000000006,41.2,41.6,35.599999999999994,37.400000000000006,36.7,38.900000000000006,38.5,31.099999999999994,38.5,20.200000000000003,33.3,41.1,33.7,33.3,41.3,38.900000000000006,6.5,31.599999999999994,40.400000000000006,23.3,43.6,27.3,26.0,34.3,39.5,38.3,42.6,40.5,30.700000000000003,38.0,37.6,40.2,29.099999999999994,41.0,25.90000000000001,34.400000000000006,17.5,38.2,39.8,31.90000000000001,39.6,29.90000000000001,34.099999999999994,39.3,40.2,36.1,28.700000000000003,34.0,42.3,11.0,40.0,41.1,24.599999999999994,37.5,34.099999999999994,35.900000000000006,39.7,11.599999999999994,26.200000000000003,38.400000000000006,21.3,37.2,27.599999999999994,29.90000000000001,38.5,39.0,39.400000000000006,19.40000000000001,36.5,36.5,28.0,37.8,38.400000000000006,40.5,41.8,44.900000000000006,31.5,39.2,26.099999999999994,37.5,36.0,35.099999999999994,41.0,36.0,23.0,34.0,38.0,36.8,42.0,39.6,20.599999999999994,26.3,37.900000000000006,29.40000000000001,27.0,13.200000000000005,40.1,39.1,40.0,35.900000000000006,22.3,28.0,34.099999999999994,38.5,38.0,32.900000000000006,44.400000000000006,36.2,39.3,40.8,29.40000000000001,37.3,38.8,17.599999999999994,28.8,29.3,35.599999999999994,41.8,41.0,33.7,35.2,33.5,22.5,25.599999999999994,42.400000000000006,39.6,38.0,45.2,37.0,38.2,34.099999999999994,26.5,26.700000000000003,39.8,37.900000000000006,15.0,17.299999999999997,39.7,9.200000000000005,15.099999999999994,24.3,34.0,35.3,37.400000000000006,43.0,32.099999999999994,20.599999999999994,36.8,17.700000000000003,33.0,40.8,36.5,24.3,36.0,28.0,36.400000000000006,40.5,32.900000000000006,36.900000000000006,20.0,37.2,39.7,19.700000000000003,39.1,35.7,43.3,20.8,29.099999999999994,37.5,39.6,45.3,38.6,35.8,21.3,38.7,26.200000000000003,34.3,24.40000000000001,32.099999999999994,34.5,24.40000000000001,40.1,39.0,39.5,39.7,39.1,32.0,44.7,34.2,34.3,38.7,20.8,41.5,35.5,33.400000000000006,36.2,29.200000000000003,37.3,36.8,45.400000000000006,18.0,35.900000000000006,34.5,30.599999999999994,25.700000000000003,24.90000000000001,35.0,34.0,34.400000000000006,33.3,43.3,28.099999999999994,17.900000000000006,39.5,34.099999999999994,37.1,25.3,36.8,39.5,33.5,44.7,21.3,39.5,27.200000000000003,17.200000000000003,35.3,25.8,43.8,38.3,38.7,37.900000000000006,23.3,31.8,22.099999999999994,32.599999999999994,38.0,34.8,38.400000000000006,37.2,19.8,42.1,43.8,38.6,36.6,39.7,36.2,21.8,37.2,25.099999999999994,22.8,43.400000000000006,40.8,33.0,34.400000000000006,22.40000000000001,27.40000000000001,43.1,40.900000000000006,36.900000000000006,40.0,34.400000000000006,40.400000000000006,38.0,15.799999999999995,34.7,40.8,34.599999999999994,28.3,41.2,27.200000000000003,31.200000000000003,34.900000000000006,37.900000000000006,38.7,21.3,35.900000000000006,40.1,39.6,19.200000000000003,36.0,35.7,26.099999999999994,34.099999999999994,24.200000000000003,40.8,37.7,40.1,39.5,34.3,21.3,39.5,27.099999999999994,42.400000000000006,25.099999999999994,22.3,32.3,31.40000000000001,35.0,8.599999999999994,39.400000000000006,26.8,33.7,43.0,39.7,24.200000000000003,37.0,25.0,37.8,39.2,33.099999999999994,37.7,35.099999999999994,22.5,36.0,13.599999999999994,12.599999999999994,35.7,42.400000000000006,39.4,35.900000000000006,37.3,38.5,40.3,33.0,35.3,39.6,27.40000000000001,25.0,40.400000000000006,37.5,40.400000000000006,37.8,23.5,31.90000000000001,22.0,41.7,19.599999999999994,28.90000000000001,20.0,35.2,41.3,40.400000000000006,39.7,35.3,22.5,20.90000000000001,34.0,36.8,26.599999999999994,33.3,38.2,41.3,41.5,25.3,32.0,35.3,41.1,37.6,34.7,38.400000000000006,31.40000000000001,36.0,37.400000000000006,40.8,33.599999999999994,23.0,25.0,37.3,42.7,34.8,34.8,34.400000000000006,21.8,21.5,24.8,35.0,41.0,31.099999999999994,32.7,32.8,37.3,25.099999999999994,37.6,37.6,34.599999999999994,24.200000000000003,25.0,19.099999999999994,15.700000000000005,35.5,17.799999999999997,20.700000000000003,41.0,25.40000000000001,36.0,19.3,25.0,33.900000000000006,12.400000000000006,29.200000000000003,16.299999999999997,39.3,39.8,25.90000000000001,40.6,25.8,36.1,38.7,29.0,46.900000000000006,34.5,38.0,38.7,34.900000000000006,21.0,39.1,30.700000000000003,39.3,36.400000000000006,21.8,36.5,45.5,34.599999999999994,36.7,27.3,35.5,35.900000000000006,41.900000000000006,37.900000000000006,38.5,21.700000000000003,39.400000000000006,22.0,25.5,35.8,16.200000000000003,24.599999999999994,39.7,37.3,38.3,26.599999999999994,16.200000000000003,35.099999999999994,10.5,40.1,35.599999999999994,41.8,33.7,37.8,31.0,46.0,37.0,37.0,13.799999999999995,30.200000000000003,38.7,38.6,46.400000000000006,21.40000000000001,39.7,34.5,31.099999999999994,41.8,41.3,40.2,38.2,41.1,39.7,35.400000000000006,42.0,39.7,40.3,22.3,38.400000000000006,38.1,39.0,39.8,25.5,36.0,35.400000000000006,41.6,37.3,43.0,21.90000000000001,42.2,37.5,33.3,33.0,23.099999999999994,41.6,33.400000000000006,37.5,37.400000000000006,45.6,18.3,25.5,38.7,32.3,27.3,39.0,38.1,31.099999999999994,41.5,23.90000000000001,39.1,17.400000000000006,35.8,38.7,39.6,45.7,41.400000000000006,22.40000000000001,43.900000000000006,38.8,21.40000000000001,33.5,17.900000000000006,40.900000000000006,35.400000000000006,31.099999999999994,36.6,42.5,36.2,33.5,40.900000000000006,42.2,40.400000000000006,39.0,32.7,33.7,39.1,21.599999999999994,31.3,27.200000000000003,37.1,41.2,43.8,17.0,9.900000000000006,35.099999999999994,35.099999999999994,37.7,42.1,33.3,24.90000000000001,42.6,31.700000000000003,17.099999999999994,39.3,33.3,29.40000000000001,31.0,15.799999999999995,23.90000000000001,39.1,38.1,36.6,45.6,17.700000000000003,35.900000000000006,13.200000000000005,22.3,37.8,27.3,36.9,36.4,28.700000000000003,42.3,26.3,40.0,37.6,40.900000000000006,38.900000000000006,32.599999999999994,36.7,35.599999999999994,35.5,37.900000000000006,35.5,42.8,36.2,25.700000000000003,24.099999999999994,39.3,40.1,39.3,24.8,27.40000000000001,35.7,39.900000000000006,30.90000000000001,40.8,30.099999999999994,14.799999999999995,19.5,43.7,33.7,19.3,32.400000000000006,34.0,30.599999999999994,33.5,36.1,36.900000000000006,19.90000000000001,40.400000000000006,38.2,35.3,34.3,33.099999999999994,36.3,31.40000000000001,40.400000000000006,37.3,32.5,25.099999999999994,26.700000000000003,33.599999999999994,41.0,39.3,15.400000000000006,37.400000000000006,39.6,17.099999999999994,37.2,36.1,28.90000000000001,25.099999999999994,38.6,27.5,41.5,17.799999999999997,20.40000000000001,36.0,18.8,32.400000000000006,42.1,37.7,39.1,7.200000000000003,37.2,28.599999999999994,20.3,37.400000000000006,15.299999999999995,34.8,33.599999999999994,36.400000000000006,30.0,27.5,37.0,25.5,30.200000000000003,23.700000000000003,20.099999999999994,20.8,41.5,34.900000000000006,30.40000000000001,37.0,41.3,22.200000000000003,35.5,23.0,25.8,37.400000000000006,42.1,36.3,36.6,44.1,37.5,33.0,39.900000000000006,23.0,39.6,32.8,35.400000000000006,37.8,41.8,19.90000000000001,18.700000000000003,36.3,39.2,20.40000000000001,38.900000000000006,39.900000000000006,35.5,33.7,28.3,36.1,37.3,45.3,37.900000000000006,35.8,43.0,34.099999999999994,41.7,34.7,39.2,39.7,43.2,40.6,40.7,40.5,29.90000000000001,38.7,36.5,40.6,24.40000000000001,28.8,40.3,36.400000000000006,37.3,31.5,37.7,44.0,30.3,36.0,33.7,30.599999999999994,21.099999999999994,41.6,36.3,37.6,40.7,37.3,23.700000000000003,38.5,41.8,35.099999999999994,47.8,10.200000000000005,34.2,41.1,41.1,37.7,38.0,34.599999999999994,39.900000000000006,38.1,41.900000000000006,38.400000000000006,23.700000000000003,20.200000000000003,21.5,31.099999999999994,38.6,33.5,33.3,40.900000000000006,38.7,34.099999999999994,22.200000000000003,27.200000000000003,19.8,33.099999999999994,35.900000000000006,40.400000000000006,45.900000000000006,39.1,34.7,23.8,30.3,35.3,36.6,40.1,38.8,36.0,25.0,36.400000000000006,31.5,24.8,32.900000000000006,20.0,43.1,26.700000000000003,29.3,39.2,26.8,38.0,24.3,39.2,41.900000000000006,29.099999999999994,38.0,21.8,35.8,38.5,35.2,36.2,33.400000000000006,18.099999999999994,35.900000000000006,24.3,18.90000000000001,14.900000000000006,29.0,20.40000000000001,18.5,39.400000000000006,37.2,40.3,32.0,24.099999999999994,40.3,26.8,29.40000000000001,40.400000000000006,37.3,13.299999999999995,38.5,34.5,42.5,20.8,45.3,35.099999999999994,29.0,35.0,24.200000000000003,35.8,30.0,35.2,22.40000000000001,37.1,25.0,29.3,19.0,35.599999999999994,40.900000000000006,35.7,38.900000000000006,39.0,29.5,16.0,27.5,20.099999999999994,28.5,28.3,24.0,37.3,40.1,27.099999999999994,37.1,22.8,39.2,40.8,31.700000000000003,37.6,27.3,43.2,40.5,41.1,17.400000000000006,30.8,37.6,40.7,37.7,29.90000000000001,37.1,25.3,28.5,42.400000000000006,41.2,29.5,38.6,38.8,12.799999999999995,40.2,33.5,15.5,44.5,18.0,34.5,38.1,39.1,36.7,16.799999999999997,43.3,22.90000000000001,39.0,36.400000000000006,29.90000000000001,16.0,36.7,22.8,13.299999999999995,24.200000000000003,22.90000000000001,30.90000000000001,34.7,32.400000000000006,17.599999999999994,38.2,45.400000000000006,42.0,41.5,39.8,17.5,33.2,20.700000000000003,40.400000000000006,36.400000000000006,33.599999999999994,27.5,37.8,24.5,23.90000000000001,44.400000000000006,38.1,43.0,35.099999999999994,38.5,36.400000000000006,40.400000000000006,38.5,38.3,37.8,16.700000000000003,26.40000000000001,44.900000000000006,41.0,35.3,23.0,24.700000000000003,26.5,20.200000000000003,36.900000000000006,30.5,26.3,26.099999999999994,34.900000000000006,34.599999999999994,43.2,42.0,37.1,34.7,41.5,22.90000000000001,17.900000000000006,43.2,38.400000000000006,41.0,36.8,13.200000000000005,37.900000000000006,36.7,40.0,36.3,39.8,18.8,39.0,39.400000000000006,26.5,39.900000000000006,36.5,41.1,41.3,21.8,36.6,43.900000000000006,38.900000000000006,37.0,39.0,39.1,37.6,32.0,43.2,41.1,28.700000000000003,33.099999999999994,39.5,27.599999999999994,17.099999999999994,36.0,34.0,39.1,33.099999999999994,26.099999999999994,20.700000000000003,42.1,40.400000000000006,23.8,38.5,39.2,38.6,39.2,33.099999999999994,38.400000000000006,39.8,42.900000000000006,40.0,37.0,24.8,21.200000000000003,36.0,39.900000000000006,40.3,37.400000000000006,11.900000000000006,39.1,41.400000000000006,38.3,44.3,38.0,26.599999999999994,43.900000000000006,37.7,41.8,35.099999999999994,41.400000000000006,37.6,37.0,21.90000000000001,38.0,26.700000000000003,37.900000000000006,36.2,22.0,19.700000000000003,45.7,39.8,30.0,27.099999999999994,24.40000000000001,28.5,36.6,24.90000000000001,43.900000000000006,32.5,27.8,37.6,22.0,43.5,23.599999999999994,41.2,21.099999999999994,24.099999999999994,32.5,18.599999999999994,35.3,13.700000000000005,37.2,37.6,37.6,35.8,39.1,25.90000000000001,41.2,37.6,38.5,41.6,33.599999999999994,34.7,29.599999999999994,38.0,22.90000000000001,16.0,23.200000000000003,39.8,35.099999999999994,21.099999999999994,39.3,38.6,33.5,37.6,22.90000000000001,35.7,37.900000000000006,36.8,36.6,32.900000000000006,44.2,38.2,26.5,40.400000000000006,44.8,26.40000000000001,32.0,24.700000000000003,32.400000000000006,40.5,39.4,38.0,28.0,40.5,31.599999999999994,35.599999999999994,38.7,32.8,40.5,24.0,36.3,34.8,41.1,26.5,39.400000000000006,36.0,37.1,40.2,34.3,41.1,35.5,23.200000000000003,20.8,27.90000000000001,34.8,9.799999999999995,36.3,43.3,23.40000000000001,35.900000000000006,36.2,17.400000000000006,25.3,42.8,36.8,41.2,18.40000000000001,37.400000000000006,40.1,8.099999999999994,38.3,35.0,35.599999999999994,41.900000000000006,16.900000000000006,31.3,35.5,21.5,28.700000000000003,38.5,41.3,32.5,33.8,40.6,40.400000000000006,36.3,38.0,38.2,34.2,36.0,29.099999999999994,30.90000000000001,38.1,33.099999999999994,39.3,38.6,38.400000000000006,22.3,20.3,13.299999999999995,35.5,45.900000000000006,33.2,39.900000000000006,42.1,22.8,37.7,41.6,37.6,39.5,22.8,34.8,40.0,39.900000000000006,40.0,28.700000000000003,19.599999999999994,17.599999999999994,21.700000000000003,34.7,30.90000000000001,43.5,40.6,19.5,40.7,35.400000000000006,35.0,40.7,41.3,35.2,13.299999999999995,38.2,39.0,36.1,37.7,23.099999999999994,26.099999999999994,42.1,20.90000000000001,25.0,32.599999999999994,34.5,42.5,34.0,36.2,39.3,24.8,35.8,41.5,30.8,42.5,37.3,29.599999999999994,22.90000000000001,39.3,35.2,36.1,38.1,30.200000000000003,30.200000000000003,14.900000000000006,42.2,26.8,37.2,36.5,40.0,34.3,38.400000000000006,27.40000000000001,33.8,32.099999999999994,22.700000000000003,38.400000000000006,42.7,19.0,38.3,43.1,22.099999999999994,41.6,38.900000000000006,38.2,38.3,17.799999999999997,35.7,39.6,23.40000000000001,37.400000000000006,23.700000000000003,37.6,35.3,36.3,36.4,24.90000000000001,24.0,29.8,20.90000000000001,10.799999999999995,41.2,34.900000000000006,35.7,27.200000000000003,30.0,30.3,42.8,39.6,42.1,38.8,39.0,37.9,36.0,38.5,21.5,39.8,41.6,42.2,26.3,40.0,42.8,33.0,19.90000000000001,45.6,37.7,30.599999999999994,38.2,27.700000000000003,24.8,20.700000000000003,17.400000000000006,30.0,25.90000000000001,16.299999999999997,17.200000000000003,34.400000000000006,36.400000000000006,36.2,18.40000000000001,42.3,32.7,19.3,30.099999999999994,35.3,37.900000000000006,26.599999999999994,28.700000000000003,42.400000000000006,13.900000000000006,34.7,22.40000000000001,38.8,18.5,32.400000000000006,27.599999999999994,35.7,32.599999999999994,18.5,38.1,16.0,37.6,37.400000000000006,39.1,23.5,38.1,39.7,26.0,38.1,28.40000000000001,36.5,41.5,37.3,22.5,39.7,15.900000000000006,35.5,17.700000000000003,31.200000000000003,34.5,32.7,44.6,39.0,38.6,26.8,39.8,44.1,21.200000000000003,13.099999999999994,40.6,41.7,34.8,16.0,40.3,42.5,40.5,20.0,34.7,36.3,43.5,39.400000000000006,38.1,27.099999999999994,42.2,39.1,39.8,18.700000000000003,39.8,34.7,37.5,23.40000000000001,36.3,42.2,39.1,39.5,23.8,29.40000000000001,24.90000000000001,45.0,28.5,28.099999999999994,36.900000000000006,40.400000000000006,26.099999999999994,40.400000000000006,43.3,41.5,29.90000000000001,40.6,40.0,35.599999999999994,22.40000000000001,36.7,33.3,34.0,24.599999999999994,37.1,27.599999999999994,23.8,17.0,31.099999999999994,32.900000000000006,41.5,46.3,27.099999999999994,16.200000000000003,30.599999999999994,32.900000000000006,40.0,38.8,20.099999999999994,12.0,37.0,32.7,34.900000000000006,24.700000000000003,32.599999999999994,36.8,27.0,42.1,40.7,35.900000000000006,37.3,20.40000000000001,29.700000000000003,36.8,19.40000000000001,42.400000000000006,27.200000000000003,41.5,23.5,19.599999999999994,38.1,20.5,20.5,41.5,32.7,23.5,40.8,24.0,37.1,48.8,43.3,39.3,39.3,36.2,24.0,28.90000000000001,39.3,31.200000000000003,34.599999999999994,32.3,43.6,37.5,37.3,18.8,33.7,36.2,39.2,24.90000000000001,25.200000000000003,17.299999999999997,20.3,26.8,40.0,15.700000000000005,43.1,42.1,32.5,21.8,36.400000000000006,38.3,37.0,41.1,44.0,43.900000000000006,36.0,40.0,34.5,40.8,42.6,28.8,35.5,32.0,35.099999999999994,23.5,37.7,34.900000000000006,46.400000000000006,23.200000000000003,31.599999999999994,42.3,34.099999999999994,34.7,21.0,37.400000000000006,38.900000000000006,39.7,37.3,33.2,38.3,36.900000000000006,23.5,38.7,39.0,35.8,39.5,36.7,34.400000000000006,37.900000000000006,30.8,39.3,39.8,38.6,40.900000000000006,17.299999999999997,36.0,37.6,31.099999999999994,31.099999999999994,34.900000000000006,16.0,41.0,31.200000000000003,40.7,8.700000000000003,38.7,41.5,16.700000000000003,41.2,35.900000000000006,38.3,36.900000000000006,37.0,32.2,37.0,27.0,37.0,5.599999999999994,26.700000000000003,33.7,30.599999999999994,22.8,41.0,44.3,41.0,23.700000000000003,23.099999999999994,36.1,26.40000000000001,34.900000000000006,35.8,33.400000000000006,25.8,36.900000000000006,39.7,27.90000000000001,41.2,27.40000000000001,13.0,26.5,23.8,38.6,37.7,31.099999999999994,35.0,32.7,26.3,39.6,38.8,37.6,38.3,27.200000000000003,37.8,37.8,19.599999999999994,39.0,38.1,29.099999999999994,36.7,37.8,42.7,17.200000000000003,41.6,43.6,30.90000000000001,31.099999999999994,39.400000000000006,39.1,13.599999999999994,12.700000000000005,24.200000000000003,28.0,39.400000000000006,35.900000000000006,13.400000000000006,35.3,30.599999999999994,41.5,41.2,32.900000000000006,43.5,17.799999999999997,17.5,44.3,41.7,39.8,42.7,33.3,40.400000000000006,34.8,43.0,40.7,36.1,33.0,35.0,34.3,39.1,36.7,42.2,26.099999999999994,41.900000000000006,20.40000000000001,40.8,14.400000000000006,26.200000000000003,35.099999999999994,11.900000000000006,38.8,15.200000000000005,38.8,37.5,37.400000000000006,36.7,18.3,35.900000000000006,31.200000000000003,31.0,30.0,27.599999999999994,36.3,34.7,25.200000000000003,24.90000000000001,39.3,19.599999999999994,33.0,42.6,22.200000000000003,24.700000000000003,27.0,45.5,37.8,38.1,37.8,38.0,13.599999999999994,43.5,21.40000000000001,19.0,32.099999999999994,34.400000000000006,34.900000000000006,40.7,26.90000000000001,35.900000000000006,31.099999999999994,34.2,33.599999999999994,38.1,39.0,13.400000000000006,38.900000000000006,39.400000000000006,42.3,14.099999999999994,31.3,33.400000000000006,40.7,41.900000000000006,40.7,39.7,37.7,35.900000000000006,14.400000000000006,31.0,39.8,14.900000000000006,38.6,34.8,36.900000000000006,40.8,15.099999999999994,34.0,25.3,34.7,38.900000000000006,18.700000000000003,40.2,19.200000000000003,40.0,34.8,37.7,37.6,19.90000000000001,38.3,24.40000000000001,36.0,40.400000000000006,29.200000000000003,15.200000000000005,40.7,40.8,32.2,35.099999999999994,28.599999999999994,10.5,26.90000000000001,31.90000000000001,24.40000000000001,37.8,20.5,43.7,31.3,39.0,33.900000000000006,42.3,37.3,37.400000000000006,28.200000000000003,23.700000000000003,34.599999999999994,31.0,22.200000000000003,11.900000000000006,38.2,25.8,41.900000000000006,37.8,37.7,15.299999999999995,40.900000000000006,36.6,23.200000000000003,40.1,39.0,38.5,37.900000000000006,39.400000000000006,10.099999999999994,17.0,27.90000000000001,33.5,37.1,35.3,37.8,39.0,43.400000000000006,39.2,34.900000000000006,35.2,22.0,33.0,40.3,39.900000000000006,38.2,37.900000000000006,41.5,34.900000000000006,25.099999999999994,33.5,18.200000000000003,28.8,34.599999999999994,39.7,33.099999999999994,34.3,41.900000000000006,39.400000000000006,44.2,24.0,40.1,39.1,38.400000000000006,28.700000000000003,34.3,38.900000000000006,24.40000000000001,45.3,38.400000000000006,37.7,36.900000000000006,39.1,41.2,43.0,38.1,22.099999999999994,41.400000000000006,33.900000000000006,39.3,41.2,38.5,20.200000000000003,38.6,33.099999999999994,40.5,36.5,43.1,34.099999999999994,21.40000000000001,40.3,25.099999999999994,24.0,36.7,28.90000000000001,33.900000000000006,40.900000000000006,19.700000000000003,37.2,28.099999999999994,33.2,42.0,33.2,33.400000000000006,41.0,19.3,39.6,29.90000000000001,39.3,44.0,35.900000000000006,42.0,34.0,31.8,36.6,36.1,41.900000000000006,36.1,36.900000000000006,36.5,44.8,39.0,39.400000000000006,32.5,43.0,34.7,17.700000000000003,40.0,41.5,38.0,24.200000000000003,35.8,37.0,18.0,39.6,37.7,36.400000000000006,43.6,36.400000000000006,36.8,31.200000000000003,12.599999999999994,35.8,36.8,23.40000000000001,29.3,29.40000000000001,43.0,38.5,34.7,37.9,23.700000000000003,13.900000000000006,37.0,39.8,38.5,29.700000000000003,19.599999999999994,37.3,23.40000000000001,39.1,38.7,37.2,18.40000000000001,28.40000000000001,42.8,19.700000000000003,27.0,37.1,25.200000000000003,37.400000000000006,37.7,36.5,41.3,39.6,27.5,23.3,42.5,37.6,29.8,31.90000000000001,25.90000000000001,34.7,25.599999999999994,38.1,43.0,43.3,38.400000000000006,40.8,31.0,41.3,36.3,13.799999999999995,23.200000000000003,39.7,35.8,34.2,32.0,31.3,18.90000000000001,19.200000000000003,35.7,25.599999999999994,36.6,24.3,40.8,24.0,35.900000000000006,20.3,40.6,34.099999999999994,33.2,45.2,29.90000000000001,39.900000000000006,22.5,46.1,18.700000000000003,31.90000000000001,43.5,36.900000000000006,41.0,33.2,36.2,23.3,24.8,37.400000000000006,36.6,25.700000000000003,37.7,17.700000000000003,36.1,32.900000000000006,31.5,45.900000000000006,29.0,38.7,32.7,19.200000000000003,23.8,32.599999999999994,38.0,34.900000000000006,27.40000000000001,30.90000000000001,22.3,40.0,33.099999999999994,18.90000000000001,38.1,38.1,36.5,37.8,32.8,36.0,21.5,36.3,48.5,47.5,38.900000000000006,36.3,29.5,26.099999999999994,34.599999999999994,39.0,23.5,19.200000000000003,28.099999999999994,27.8,32.900000000000006,36.5,40.900000000000006,39.2,36.5,25.0,39.8,43.0,29.599999999999994,38.8,20.700000000000003,41.8,28.0,23.200000000000003,21.200000000000003,37.6,38.900000000000006,33.2,25.5,23.0,24.8,35.8,23.200000000000003,26.099999999999994,38.2,39.7,37.900000000000006,24.099999999999994,38.7,27.8,25.099999999999994,39.3,36.9,40.400000000000006,39.0,39.7,37.8,21.700000000000003,20.5,42.2,41.0,37.8,36.400000000000006,19.0,29.599999999999994,36.400000000000006,20.90000000000001,42.7,25.099999999999994,39.7,30.90000000000001,15.099999999999994,35.400000000000006,12.099999999999994,34.900000000000006,26.0,34.8,32.0,40.900000000000006,35.099999999999994,29.0,34.7,41.900000000000006,39.0,37.5,42.7,37.8,34.599999999999994,48.2,16.599999999999994,38.400000000000006,42.3,22.200000000000003,35.599999999999994,36.7,12.5,20.5,36.3,14.900000000000006,29.5,26.40000000000001,39.0,26.700000000000003,41.400000000000006,39.1,22.5,35.8,37.7,39.7,30.099999999999994,36.5,39.2,16.200000000000003,29.8,31.099999999999994,22.099999999999994,37.2,26.200000000000003,31.599999999999994,12.700000000000005,42.0,18.200000000000003,39.1,38.900000000000006,40.400000000000006,42.6,23.3,37.8,38.6,44.900000000000006,35.400000000000006,35.400000000000006,25.8,28.599999999999994,34.7,27.200000000000003,39.8,34.900000000000006,23.3,30.700000000000003,35.900000000000006,40.5,24.90000000000001,33.099999999999994,18.700000000000003,27.200000000000003,25.40000000000001,21.700000000000003,38.8,30.40000000000001,36.900000000000006,39.6,31.700000000000003,13.700000000000005,36.2,33.400000000000006,40.7,39.6,37.6,38.5,41.3,31.599999999999994,25.700000000000003,34.099999999999994,43.6,16.799999999999997,31.099999999999994,32.599999999999994,40.0,38.8,21.40000000000001,30.8,42.3,31.8,36.8,33.5,38.400000000000006,33.400000000000006,38.1,29.8,30.200000000000003,37.2,22.8,36.5,37.0,36.3,16.299999999999997,31.40000000000001,12.599999999999994,35.3,19.599999999999994,38.900000000000006,41.2,39.2,40.7,39.1,32.5,39.2,36.2,39.900000000000006,36.8,34.0,21.3,34.5,36.1,23.5,41.2,24.599999999999994,37.8,40.3,39.0,22.099999999999994,24.8,19.3,33.599999999999994,40.6,35.099999999999994,24.5,35.2,38.0,33.8,41.0,27.700000000000003,39.1,33.7,36.1,26.599999999999994,28.200000000000003,22.5,38.3,32.5,38.7,36.8,40.9,39.8,25.3,19.0,26.200000000000003,42.8,14.799999999999995,20.3,31.200000000000003,32.5,35.2,42.7,33.2,35.2,37.8,40.3,26.8,33.900000000000006,43.400000000000006,34.400000000000006,26.700000000000003,35.3,39.2,34.5,37.400000000000006,36.8,38.0,37.400000000000006,38.2,38.1,39.3,34.5,42.900000000000006,35.099999999999994,17.400000000000006,25.599999999999994,32.099999999999994,42.5,25.0,40.3,23.90000000000001,41.0,32.099999999999994,18.700000000000003,27.90000000000001,36.0,37.2,39.8,38.7,28.099999999999994,31.599999999999994,30.8,16.900000000000006,35.7,36.400000000000006,34.400000000000006,23.700000000000003,23.099999999999994,38.6,37.8,38.3,43.6,37.0,35.099999999999994,37.400000000000006,43.2,38.8,26.40000000000001,39.2,36.6,35.5,25.099999999999994,36.2,36.900000000000006,41.400000000000006,43.2,41.8,35.599999999999994,25.3,38.5,37.7,38.0,37.8,38.1,34.599999999999994,13.799999999999995,40.400000000000006,16.700000000000003,44.2,40.8,25.599999999999994,35.0,35.0,39.8,13.400000000000006,40.5,35.099999999999994,33.2,28.8,33.0,40.3,36.8,36.7,40.3,38.3,41.1,22.3,14.200000000000005,20.700000000000003,36.7,39.0,36.0,12.299999999999995,33.900000000000006,41.3,33.900000000000006,34.2,39.6,35.599999999999994,11.099999999999994,38.7,40.400000000000006,41.400000000000006,40.7,26.5,35.5,36.2,21.90000000000001,38.8,41.3,36.1,43.8,31.40000000000001,30.8,12.200000000000005,38.0,12.200000000000005,27.40000000000001,37.400000000000006,26.90000000000001,34.8,37.3,42.7,33.8,19.0,35.400000000000006,33.8,39.900000000000006,19.40000000000001,42.0,34.099999999999994,41.7,23.0,36.900000000000006,27.8,39.7,34.7,33.0,23.0,42.5,36.3,23.8,43.1,38.1,35.2,39.900000000000006,38.900000000000006,40.5,39.3,35.3,38.2,37.7,23.0,36.1,37.0,42.0,16.400000000000006,34.099999999999994,37.8,43.7,24.40000000000001,42.0,38.1,38.3,26.3,23.0,39.900000000000006,39.3,35.900000000000006,27.599999999999994,38.7,31.0,42.0,44.400000000000006,35.599999999999994,19.40000000000001,35.5,28.40000000000001,38.6,25.700000000000003,40.0,38.6,24.599999999999994,24.200000000000003,33.2,20.099999999999994,31.40000000000001,21.3,28.40000000000001,37.1,37.1,25.3,27.5,17.400000000000006,25.90000000000001,32.7,36.7,23.200000000000003,29.200000000000003,39.0,33.099999999999994,38.0,39.6,41.1,28.700000000000003,20.3,40.1,19.599999999999994,45.3,30.0,39.1,20.0,40.3,38.400000000000006,30.8,33.7,23.90000000000001,43.6,24.90000000000001,38.400000000000006,40.900000000000006,40.1,26.099999999999994,34.8,15.099999999999994,30.599999999999994,30.3,35.7,39.2,35.400000000000006,28.5,19.3,22.200000000000003,37.2,20.099999999999994,40.3,35.599999999999994,38.1,40.1,32.5,11.700000000000005,37.7,39.7,37.2,14.0,27.5,40.3,28.099999999999994,34.0,31.200000000000003,41.1,36.900000000000006,22.3,37.3,39.3,37.5,32.400000000000006,40.7,33.900000000000006,36.5,25.700000000000003,19.099999999999994,40.8,39.7,33.099999999999994,16.5,39.400000000000006,38.6,35.8,17.400000000000006,33.099999999999994,21.90000000000001,41.1,23.0,28.90000000000001,40.1,30.8,34.400000000000006,27.90000000000001,36.900000000000006,38.0,40.400000000000006,24.3,41.900000000000006,31.8,23.599999999999994,37.8,37.6,34.5,39.8,36.6,35.400000000000006,27.200000000000003,16.700000000000003,36.1,21.0,36.8,47.1,39.7,36.5,41.2,40.1,24.8,43.400000000000006,37.6,20.3,30.90000000000001,22.8,33.2,28.0,19.599999999999994,26.90000000000001,41.5,35.900000000000006,25.8,38.5,29.599999999999994,37.5,32.5,29.099999999999994,36.1,38.400000000000006,35.2,22.40000000000001,34.400000000000006,43.6,36.1,35.400000000000006,17.5,18.599999999999994,29.099999999999994,23.8,35.7,40.3,15.200000000000005,41.5,38.6,38.3,37.5,39.1,42.3,36.900000000000006,15.299999999999995,31.8,37.400000000000006,44.8,35.2,29.40000000000001,16.400000000000006,20.099999999999994,13.099999999999994,34.099999999999994,33.8,37.6,34.7,22.599999999999994,24.8,18.8,25.5,40.0,38.7,42.8,24.700000000000003,40.2,34.2,30.700000000000003,41.5,41.900000000000006,37.0,34.400000000000006,31.3,38.6,31.3,29.099999999999994,33.8,22.700000000000003,39.400000000000006,40.1,14.400000000000006,23.90000000000001,33.2,41.5,36.900000000000006,35.400000000000006,33.3,7.099999999999994,17.799999999999997,30.599999999999994,28.0,23.0,38.0,41.1,20.5,31.0,32.2,28.599999999999994,30.700000000000003,32.5,27.5,30.099999999999994,40.400000000000006,34.2,41.3,39.5,38.1,39.1,38.5,36.7,36.0,38.1,38.0,20.3,26.5,30.90000000000001,40.8,22.90000000000001,23.0,22.0,45.1,38.6,38.900000000000006,19.599999999999994,34.599999999999994,30.5,33.2,37.5,21.200000000000003,34.3,19.40000000000001,44.2,40.5,17.099999999999994,38.0,35.8,43.2,39.6,37.1,43.6,12.900000000000006,24.3,19.700000000000003,24.8,42.2,38.3,27.40000000000001,25.5,40.3,33.400000000000006,40.8,26.90000000000001,38.0,28.8,32.7,41.1,32.3,33.599999999999994,28.8,40.7,33.099999999999994,38.0,34.599999999999994,19.099999999999994,43.7,38.400000000000006,34.400000000000006,24.40000000000001,39.400000000000006,38.5,30.40000000000001,30.700000000000003,28.200000000000003,37.3,32.2,38.8,37.0,37.900000000000006,34.900000000000006,34.7,19.40000000000001,14.900000000000006,38.8,24.099999999999994,37.1,31.700000000000003,38.6,8.900000000000006,32.099999999999994,39.7,30.90000000000001,24.40000000000001,29.200000000000003,27.099999999999994,40.400000000000006,43.2,29.5,43.0,24.700000000000003,33.7,41.6,35.5,14.5,34.900000000000006,23.599999999999994,36.8,39.1,36.0,21.5,37.0,26.0,20.200000000000003,35.900000000000006,38.6,13.0,20.90000000000001,23.3,33.2,37.8,42.2,17.799999999999997,32.7,38.8,35.099999999999994,24.40000000000001,12.099999999999994,40.7,31.3,39.900000000000006,26.3,33.8,34.2,34.8,37.400000000000006,41.400000000000006,15.0,16.099999999999994,29.8,21.90000000000001,22.3,31.200000000000003,41.5,31.0,24.40000000000001,42.3,19.200000000000003,30.5,23.3,16.400000000000006,32.900000000000006,41.900000000000006,24.099999999999994,31.0,18.40000000000001,20.0,26.700000000000003,39.400000000000006,18.8,36.5,39.8,20.90000000000001,41.6,16.0,30.40000000000001,36.1,40.2,23.3,21.3,37.8,33.400000000000006,20.5,31.3,35.2,41.6,25.200000000000003,18.700000000000003,40.6,42.3,17.5,35.599999999999994,35.099999999999994,33.599999999999994,38.6,20.8,14.400000000000006,36.1,39.400000000000006,41.2,43.7,19.40000000000001,36.5,41.1,39.7,36.2,26.599999999999994,40.7,24.3,33.099999999999994,36.0,27.599999999999994,27.8,38.400000000000006,32.599999999999994,41.6,33.8,36.1,14.599999999999994,38.5,37.5,37.0,36.5,34.0,44.5,45.3,23.099999999999994,39.5,21.8,30.700000000000003,21.0,21.8,40.5,17.400000000000006,19.40000000000001,38.2,39.1,35.900000000000006,37.8,33.599999999999994,40.3,35.599999999999994,40.5,19.5,36.1,37.5,30.0,35.900000000000006,32.0,19.099999999999994,42.7,15.299999999999995,38.6,40.400000000000006,32.599999999999994,24.40000000000001,32.900000000000006,32.7,35.3,33.7,31.5,39.1,28.3,31.40000000000001,27.5,39.6,14.400000000000006,41.2,30.599999999999994,25.599999999999994,34.3,37.900000000000006,18.90000000000001,24.5,41.900000000000006,32.8,31.099999999999994,31.8,38.2,15.799999999999995,30.90000000000001,28.3,24.90000000000001,21.200000000000003,29.3,9.099999999999994,25.90000000000001,23.200000000000003,35.5,25.8,14.200000000000005,28.8,19.700000000000003,19.8,28.40000000000001,36.900000000000006,26.90000000000001,20.599999999999994,28.5,41.3,44.7,35.8,41.6,37.6,10.700000000000005,33.400000000000006,26.0,41.5,38.0,39.2,33.900000000000006,28.700000000000003,35.2,34.3,19.40000000000001,32.400000000000006,42.8,42.3,40.900000000000006,40.2,22.200000000000003,20.200000000000003,43.5,37.8,42.2,35.0,34.8,39.7,37.2,33.5,38.400000000000006,35.400000000000006,36.6,38.900000000000006,23.8,22.099999999999994,38.2,33.3,38.900000000000006,24.599999999999994,38.2,28.8,36.5,34.3,37.5,39.5,21.40000000000001,37.3,38.7,38.3,27.5,37.400000000000006,38.4,39.2,27.700000000000003,38.900000000000006,27.90000000000001,34.5,27.8,12.599999999999994,27.40000000000001,37.3,34.900000000000006,37.900000000000006,17.299999999999997,24.3,36.7,28.5,37.1,37.7,38.8,33.8,38.8,40.2,37.7,37.900000000000006,41.3,39.400000000000006,42.7,28.5,22.200000000000003,39.7,34.3,25.200000000000003,37.400000000000006,24.0,24.599999999999994,36.900000000000006,32.3,38.3,23.40000000000001,28.200000000000003,36.1,31.599999999999994,34.900000000000006,38.3,41.6,18.0,38.6,41.1,20.90000000000001,29.200000000000003,24.599999999999994,18.599999999999994,44.1,27.8,29.5,33.5,26.200000000000003,38.400000000000006,36.400000000000006,34.8,37.7,38.1,36.900000000000006,26.599999999999994,43.7,25.099999999999994,22.3,18.8,30.5,22.599999999999994,20.3,43.2,36.2,2.299999999999997,42.1,41.400000000000006,24.90000000000001,21.200000000000003,21.599999999999994,38.900000000000006,23.599999999999994,39.7,28.5,24.200000000000003,17.0,41.2,35.900000000000006,15.200000000000005,38.7,36.0,40.3,26.8,35.2,35.099999999999994,39.3,23.099999999999994,23.700000000000003,35.900000000000006,34.3,34.3,38.5,27.8,37.1,32.099999999999994,38.7,36.400000000000006,22.700000000000003,18.700000000000003,27.8,32.099999999999994,37.3,23.40000000000001,19.90000000000001,37.400000000000006,38.900000000000006,27.200000000000003,18.0,40.5,31.3,30.200000000000003,37.400000000000006,37.5,37.900000000000006,17.700000000000003,35.400000000000006,34.599999999999994,14.299999999999995,37.4,36.7,15.0,16.299999999999997,36.0,37.0,49.1,26.700000000000003,26.0,43.400000000000006,38.0,35.2,45.6,38.7,25.5,42.0,34.8,39.0,31.700000000000003,32.599999999999994,38.8,14.200000000000005,35.900000000000006,39.7,39.0,38.6,41.1,22.700000000000003,15.200000000000005,40.7,39.6,32.0,21.90000000000001,37.6,38.2,38.1,39.7,30.3,41.3,14.400000000000006,31.700000000000003,24.5,35.2,38.7,41.0,32.900000000000006,38.8,19.200000000000003,21.700000000000003,39.2,37.400000000000006,24.40000000000001,30.0,37.900000000000006,21.5,43.1,42.1,39.6,30.599999999999994,24.40000000000001,43.400000000000006,33.2,34.7,42.400000000000006,36.1,15.099999999999994,21.0,38.0,35.599999999999994,24.40000000000001,36.8,38.900000000000006,37.2,36.2,43.0,20.599999999999994,21.200000000000003,39.3,30.40000000000001,42.3,34.3,23.700000000000003,22.5,33.099999999999994,42.0,19.3,43.0,38.0,38.6,40.400000000000006,34.599999999999994,36.3,35.0,35.900000000000006,24.700000000000003,38.900000000000006,16.0,27.0,37.0,23.8,16.0,25.700000000000003,35.3,26.0,29.099999999999994,37.2,21.599999999999994,29.200000000000003,41.400000000000006,40.5,23.599999999999994,36.6,25.8,33.0,39.900000000000006,3.9000000000000057,33.900000000000006,34.5,46.400000000000006,38.5],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"age\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"physical_score\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"boxmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('c370513f-c547-45a8-835e-0aef0d872454');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.box(df, x='age',y='physical_score')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "792ffcd7-8482-4858-8b6c-2e2996fec085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "test_result=%{x}<br>age=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa"
         },
         "name": "",
         "notched": false,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "box",
         "x": [
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          33,
          50,
          52,
          56,
          35,
          58,
          66,
          38,
          53,
          43,
          39,
          58,
          45,
          52,
          36,
          83,
          57,
          39,
          58,
          54,
          65,
          69,
          41,
          43,
          64,
          55,
          46,
          40,
          70,
          36,
          62,
          71,
          38,
          67,
          50,
          68,
          58,
          63,
          60,
          24,
          44,
          55,
          42,
          61,
          49,
          66,
          51,
          65,
          53,
          52,
          60,
          46,
          69,
          62,
          64,
          72,
          66,
          32,
          54,
          59,
          74,
          37,
          32,
          68,
          62,
          58,
          54,
          75,
          48,
          54,
          57,
          31,
          74,
          40,
          54,
          82,
          48,
          53,
          61,
          27,
          62,
          66,
          39,
          51,
          41,
          52,
          46,
          57,
          47,
          82,
          43,
          55,
          57,
          46,
          56,
          49,
          52,
          46,
          56,
          60,
          49,
          67,
          39,
          59,
          67,
          55,
          68,
          44,
          47,
          45,
          70,
          62,
          68,
          46,
          74,
          60,
          52,
          58,
          42,
          50,
          43,
          57,
          51,
          49,
          46,
          47,
          40,
          66,
          48,
          45,
          39,
          47,
          54,
          55,
          66,
          47,
          62,
          51,
          70,
          51,
          48,
          32,
          60,
          50,
          48,
          42,
          51,
          44,
          71,
          57,
          34,
          58,
          31,
          71,
          46,
          69,
          82,
          54,
          59,
          47,
          56,
          54,
          42,
          53,
          77,
          37,
          68,
          66,
          62,
          43,
          48,
          44,
          54,
          39,
          65,
          51,
          30,
          53,
          48,
          51,
          64,
          34,
          43,
          67,
          46,
          46,
          44,
          79,
          59,
          69,
          35,
          49,
          32,
          60,
          41,
          38,
          40,
          35,
          56,
          48,
          36,
          51,
          43,
          52,
          41,
          67,
          61,
          34,
          63,
          62,
          64,
          45,
          53,
          46,
          51,
          51,
          33,
          48,
          50,
          63,
          48,
          51,
          34,
          46,
          56,
          54,
          46,
          66,
          57,
          38,
          34,
          55,
          41,
          49,
          60,
          56,
          66,
          65,
          56,
          52,
          48,
          71,
          54,
          52,
          57,
          38,
          58,
          56,
          46,
          56,
          53,
          61,
          45,
          53,
          46,
          64,
          47,
          46,
          68,
          70,
          41,
          50,
          62,
          43,
          53,
          46,
          52,
          53,
          34,
          40,
          43,
          40,
          50,
          58,
          48,
          39,
          49,
          51,
          47,
          59,
          42,
          44,
          65,
          40,
          43,
          65,
          50,
          49,
          70,
          49,
          52,
          39,
          31,
          64,
          44,
          46,
          32,
          36,
          30,
          68,
          49,
          50,
          35,
          37,
          65,
          61,
          37,
          76,
          48,
          36,
          55,
          65,
          39,
          34,
          25,
          59,
          42,
          54,
          51,
          49,
          59,
          72,
          61,
          41,
          50,
          52,
          34,
          66,
          40,
          37,
          58,
          58,
          50,
          52,
          55,
          36,
          45,
          31,
          57,
          49,
          52,
          75,
          57,
          57,
          38,
          56,
          56,
          60,
          47,
          57,
          59,
          61,
          48,
          78,
          46,
          72,
          48,
          44,
          52,
          76,
          72,
          53,
          47,
          44,
          34,
          45,
          64,
          59,
          68,
          62,
          49,
          40,
          59,
          48,
          40,
          48,
          39,
          51,
          40,
          55,
          41,
          38,
          42,
          66,
          66,
          58,
          43,
          46,
          55,
          54,
          43,
          57,
          40,
          42,
          64,
          72,
          39,
          52,
          43,
          62,
          43,
          77,
          58,
          49,
          44,
          49,
          58,
          40,
          74,
          73,
          44,
          43,
          45,
          40,
          65,
          55,
          55,
          52,
          68,
          56,
          53,
          43,
          64,
          55,
          76,
          46,
          56,
          44,
          38,
          43,
          53,
          81,
          50,
          63,
          30,
          47,
          25,
          55,
          48,
          48,
          50,
          37,
          72,
          47,
          65,
          53,
          82,
          35,
          38,
          37,
          47,
          54,
          39,
          59,
          22,
          56,
          56,
          42,
          58,
          64,
          62,
          64,
          50,
          58,
          52,
          60,
          31,
          42,
          38,
          57,
          41,
          39,
          40,
          56,
          68,
          48,
          66,
          41,
          63,
          49,
          41,
          40,
          55,
          55,
          48,
          41,
          50,
          41,
          32,
          59,
          42,
          54,
          48,
          49,
          60,
          43,
          39,
          48,
          46,
          45,
          53,
          39,
          52,
          33,
          53,
          42,
          67,
          50,
          78,
          58,
          43,
          43,
          46,
          56,
          62,
          35,
          60,
          77,
          58,
          39,
          39,
          48,
          44,
          48,
          74,
          67,
          33,
          41,
          45,
          62,
          65,
          39,
          77,
          63,
          71,
          44,
          58,
          69,
          48,
          64,
          62,
          40,
          69,
          40,
          44,
          48,
          60,
          61,
          40,
          57,
          54,
          63,
          42,
          59,
          41,
          66,
          53,
          36,
          46,
          51,
          45,
          33,
          46,
          75,
          47,
          48,
          47,
          51,
          48,
          38,
          40,
          67,
          72,
          52,
          51,
          63,
          35,
          33,
          62,
          43,
          47,
          70,
          51,
          40,
          39,
          32,
          60,
          33,
          57,
          68,
          69,
          54,
          60,
          57,
          18,
          55,
          46,
          54,
          46,
          54,
          47,
          35,
          48,
          45,
          47,
          41,
          42,
          41,
          41,
          52,
          31,
          41,
          55,
          73,
          64,
          29,
          63,
          54,
          63,
          45,
          65,
          47,
          49,
          57,
          44,
          53,
          29,
          56,
          52,
          44,
          25,
          54,
          40,
          46,
          67,
          45,
          45,
          47,
          65,
          54,
          41,
          43,
          54,
          52,
          68,
          82,
          42,
          75,
          74,
          43,
          65,
          35,
          42,
          55,
          42,
          51,
          71,
          41,
          47,
          28,
          42,
          55,
          70,
          67,
          49,
          55,
          37,
          48,
          37,
          46,
          34,
          63,
          53,
          54,
          76,
          50,
          69,
          48,
          45,
          42,
          39,
          55,
          43,
          38,
          51,
          60,
          70,
          71,
          62,
          69,
          34,
          52,
          56,
          37,
          43,
          67,
          53,
          49,
          44,
          51,
          60,
          37,
          50,
          31,
          45,
          53,
          45,
          66,
          68,
          44,
          50,
          51,
          66,
          48,
          45,
          61,
          43,
          47,
          58,
          33,
          55,
          56,
          54,
          52,
          52,
          64,
          39,
          56,
          73,
          56,
          64,
          43,
          39,
          59,
          52,
          43,
          48,
          48,
          46,
          53,
          59,
          49,
          31,
          72,
          76,
          54,
          39,
          60,
          59,
          42,
          49,
          32,
          41,
          68,
          60,
          76,
          43,
          42,
          74,
          68,
          43,
          53,
          71,
          48,
          37,
          78,
          42,
          47,
          60,
          50,
          41,
          77,
          67,
          64,
          49,
          62,
          46,
          48,
          34,
          66,
          50,
          47,
          71,
          51,
          44,
          64,
          55,
          65,
          62,
          54,
          51,
          57,
          39,
          50,
          52,
          40,
          42,
          46,
          47,
          53,
          51,
          52,
          44,
          43,
          52,
          49,
          53,
          48,
          50,
          71,
          43,
          53,
          53,
          61,
          56,
          47,
          68,
          32,
          40,
          46,
          73,
          56,
          74,
          55,
          74,
          50,
          66,
          42,
          41,
          51,
          42,
          46,
          38,
          46,
          41,
          59,
          62,
          64,
          54,
          54,
          61,
          62,
          38,
          48,
          56,
          73,
          26,
          34,
          50,
          44,
          62,
          32,
          44,
          68,
          45,
          74,
          47,
          36,
          48,
          66,
          56,
          64,
          61,
          49,
          57,
          54,
          66,
          47,
          65,
          63,
          44,
          53,
          35,
          62,
          49,
          64,
          39,
          55,
          67,
          54,
          41,
          57,
          67,
          59,
          38,
          36,
          28,
          31,
          72,
          52,
          49,
          50,
          43,
          49,
          58,
          68,
          49,
          39,
          54,
          63,
          51,
          61,
          62,
          77,
          31,
          70,
          42,
          55,
          42,
          38,
          52,
          55,
          46,
          56,
          71,
          48,
          38,
          50,
          76,
          60,
          68,
          73,
          36,
          66,
          43,
          42,
          61,
          53,
          28,
          34,
          55,
          41,
          44,
          34,
          55,
          63,
          51,
          44,
          45,
          48,
          45,
          46,
          40,
          39,
          51,
          43,
          41,
          67,
          63,
          46,
          78,
          58,
          51,
          62,
          42,
          36,
          70,
          41,
          65,
          44,
          39,
          50,
          47,
          41,
          48,
          74,
          48,
          49,
          58,
          49,
          61,
          61,
          51,
          37,
          49,
          63,
          54,
          50,
          46,
          60,
          50,
          67,
          67,
          47,
          57,
          30,
          62,
          47,
          48,
          42,
          42,
          35,
          54,
          49,
          46,
          61,
          69,
          40,
          30,
          46,
          47,
          77,
          54,
          50,
          51,
          26,
          39,
          52,
          49,
          52,
          27,
          45,
          55,
          67,
          41,
          56,
          66,
          67,
          52,
          57,
          73,
          60,
          44,
          45,
          66,
          60,
          69,
          50,
          78,
          46,
          48,
          41,
          60,
          39,
          64,
          46,
          43,
          37,
          42,
          44,
          40,
          58,
          46,
          57,
          54,
          36,
          66,
          30,
          37,
          58,
          56,
          47,
          61,
          51,
          24,
          35,
          60,
          64,
          40,
          57,
          53,
          50,
          53,
          38,
          56,
          59,
          57,
          39,
          45,
          69,
          49,
          42,
          58,
          50,
          68,
          71,
          44,
          34,
          41,
          48,
          68,
          48,
          55,
          49,
          63,
          37,
          44,
          63,
          42,
          44,
          65,
          44,
          63,
          55,
          47,
          55,
          51,
          54,
          52,
          60,
          71,
          44,
          38,
          41,
          44,
          55,
          42,
          41,
          38,
          58,
          39,
          46,
          39,
          60,
          41,
          44,
          60,
          62,
          64,
          60,
          59,
          65,
          50,
          61,
          44,
          40,
          58,
          46,
          54,
          63,
          37,
          45,
          41,
          58,
          65,
          56,
          44,
          63,
          55,
          47,
          47,
          39,
          52,
          32,
          41,
          48,
          41,
          46,
          55,
          48,
          47,
          38,
          69,
          70,
          60,
          45,
          50,
          44,
          44,
          50,
          49,
          72,
          37,
          68,
          46,
          57,
          54,
          36,
          78,
          52,
          40,
          49,
          81,
          64,
          44,
          43,
          50,
          69,
          54,
          62,
          64,
          46,
          57,
          40,
          52,
          34,
          50,
          21,
          43,
          46,
          41,
          74,
          50,
          38,
          39,
          76,
          60,
          37,
          56,
          66,
          68,
          49,
          39,
          56,
          47,
          65,
          42,
          36,
          57,
          57,
          37,
          54,
          32,
          54,
          54,
          62,
          68,
          37,
          42,
          48,
          66,
          43,
          59,
          59,
          54,
          50,
          52,
          33,
          44,
          53,
          42,
          74,
          54,
          46,
          52,
          52,
          43,
          33,
          60,
          61,
          54,
          57,
          62,
          60,
          64,
          69,
          73,
          47,
          44,
          47,
          44,
          58,
          65,
          32,
          46,
          52,
          58,
          62,
          66,
          77,
          35,
          52,
          40,
          72,
          46,
          51,
          48,
          43,
          65,
          49,
          48,
          38,
          45,
          58,
          62,
          48,
          34,
          38,
          40,
          50,
          59,
          56,
          51,
          80,
          39,
          55,
          46,
          45,
          48,
          68,
          53,
          42,
          34,
          44,
          59,
          45,
          66,
          57,
          44,
          53,
          83,
          72,
          69,
          62,
          50,
          48,
          60,
          63,
          66,
          53,
          80,
          68,
          36,
          32,
          59,
          69,
          51,
          50,
          51,
          44,
          50,
          57,
          44,
          52,
          43,
          33,
          41,
          30,
          61,
          59,
          61,
          49,
          57,
          64,
          47,
          54,
          48,
          47,
          45,
          65,
          49,
          76,
          67,
          56,
          42,
          48,
          58,
          51,
          68,
          54,
          65,
          67,
          46,
          62,
          55,
          57,
          47,
          36,
          57,
          52,
          68,
          65,
          63,
          54,
          43,
          35,
          36,
          74,
          41,
          42,
          39,
          64,
          28,
          52,
          52,
          46,
          58,
          70,
          48,
          57,
          54,
          54,
          68,
          54,
          38,
          74,
          35,
          49,
          59,
          40,
          41,
          62,
          66,
          65,
          71,
          47,
          47,
          65,
          49,
          61,
          81,
          60,
          47,
          69,
          34,
          78,
          34,
          59,
          42,
          46,
          46,
          55,
          31,
          47,
          45,
          50,
          55,
          54,
          62,
          50,
          34,
          62,
          42,
          49,
          42,
          47,
          56,
          49,
          73,
          47,
          53,
          58,
          61,
          49,
          38,
          33,
          57,
          71,
          55,
          43,
          63,
          42,
          60,
          62,
          55,
          55,
          56,
          65,
          50,
          47,
          63,
          46,
          39,
          29,
          45,
          50,
          62,
          38,
          47,
          54,
          49,
          63,
          51,
          43,
          42,
          45,
          54,
          55,
          35,
          30,
          50,
          40,
          43,
          43,
          38,
          57,
          50,
          49,
          58,
          44,
          58,
          53,
          46,
          47,
          44,
          38,
          42,
          56,
          40,
          60,
          31,
          53,
          62,
          37,
          77,
          56,
          55,
          24,
          50,
          55,
          68,
          55,
          58,
          37,
          51,
          40,
          47,
          64,
          51,
          61,
          53,
          64,
          32,
          46,
          68,
          36,
          54,
          46,
          51,
          64,
          30,
          51,
          56,
          43,
          54,
          46,
          44,
          34,
          63,
          61,
          42,
          63,
          57,
          66,
          37,
          59,
          42,
          48,
          60,
          39,
          59,
          36,
          43,
          54,
          57,
          47,
          41,
          83,
          43,
          53,
          70,
          60,
          42,
          48,
          34,
          68,
          44,
          61,
          55,
          71,
          54,
          38,
          49,
          52,
          60,
          70,
          55,
          40,
          36,
          70,
          47,
          57,
          42,
          51,
          44,
          66,
          82,
          48,
          53,
          61,
          54,
          48,
          37,
          84,
          47,
          33,
          63,
          60,
          44,
          37,
          36,
          42,
          61,
          46,
          60,
          37,
          41,
          68,
          54,
          66,
          69,
          68,
          72,
          48,
          62,
          42,
          56,
          51,
          36,
          56,
          43,
          49,
          46,
          69,
          40,
          39,
          52,
          46,
          55,
          41,
          48,
          58,
          71,
          46,
          58,
          71,
          79,
          33,
          46,
          46,
          65,
          57,
          38,
          70,
          46,
          62,
          31,
          42,
          57,
          54,
          56,
          67,
          51,
          49,
          37,
          49,
          42,
          58,
          62,
          60,
          54,
          40,
          51,
          58,
          43,
          33,
          62,
          59,
          49,
          50,
          42,
          56,
          35,
          45,
          44,
          67,
          52,
          52,
          62,
          71,
          54,
          47,
          49,
          54,
          52,
          39,
          51,
          49,
          65,
          55,
          44,
          51,
          59,
          70,
          53,
          49,
          45,
          41,
          55,
          43,
          51,
          59,
          60,
          68,
          60,
          45,
          51,
          37,
          60,
          52,
          50,
          46,
          50,
          64,
          45,
          41,
          54,
          40,
          55,
          38,
          40,
          70,
          60,
          43,
          59,
          40,
          55,
          81,
          39,
          53,
          80,
          61,
          53,
          54,
          63,
          58,
          46,
          38,
          55,
          63,
          43,
          68,
          50,
          50,
          59,
          57,
          55,
          50,
          61,
          55,
          63,
          49,
          56,
          71,
          40,
          84,
          43,
          61,
          46,
          55,
          33,
          65,
          68,
          57,
          76,
          58,
          56,
          39,
          29,
          54,
          47,
          62,
          52,
          47,
          64,
          34,
          59,
          71,
          47,
          67,
          59,
          57,
          58,
          39,
          41,
          41,
          52,
          55,
          46,
          73,
          59,
          39,
          49,
          43,
          47,
          64,
          46,
          46,
          62,
          47,
          32,
          61,
          68,
          66,
          46,
          35,
          45,
          32,
          41,
          29,
          65,
          43,
          43,
          59,
          70,
          41,
          39,
          41,
          45,
          53,
          44,
          52,
          47,
          62,
          50,
          63,
          56,
          45,
          42,
          59,
          39,
          47,
          84,
          52,
          49,
          63,
          38,
          53,
          65,
          45,
          42,
          43,
          44,
          40,
          49,
          37,
          54,
          44,
          63,
          34,
          50,
          55,
          67,
          40,
          48,
          50,
          49,
          64,
          50,
          42,
          40,
          51,
          60,
          70,
          31,
          57,
          38,
          44,
          64,
          38,
          48,
          43,
          43,
          69,
          66,
          47,
          67,
          42,
          64,
          66,
          43,
          41,
          42,
          76,
          46,
          53,
          64,
          49,
          48,
          37,
          39,
          37,
          57,
          40,
          62,
          50,
          54,
          46,
          39,
          45,
          67,
          62,
          44,
          56,
          31,
          48,
          63,
          50,
          37,
          56,
          62,
          53,
          37,
          36,
          47,
          51,
          57,
          59,
          46,
          38,
          39,
          42,
          38,
          47,
          40,
          42,
          57,
          45,
          48,
          66,
          53,
          58,
          49,
          42,
          47,
          51,
          44,
          55,
          48,
          57,
          37,
          42,
          52,
          41,
          48,
          52,
          52,
          48,
          71,
          43,
          41,
          60,
          75,
          40,
          67,
          66,
          68,
          54,
          52,
          45,
          29,
          54,
          59,
          53,
          64,
          53,
          41,
          52,
          57,
          51,
          54,
          51,
          47,
          57,
          51,
          68,
          46,
          41,
          68,
          33,
          45,
          29,
          64,
          58,
          42,
          48,
          36,
          37,
          51,
          67,
          46,
          56,
          66,
          55,
          55,
          53,
          52,
          39,
          49,
          39,
          34,
          40,
          60,
          28,
          58,
          59,
          41,
          63,
          42,
          45,
          53,
          57,
          74,
          41,
          42,
          24,
          65,
          56,
          49,
          60,
          71,
          55,
          47,
          58,
          58,
          55,
          39,
          70,
          69,
          43,
          49,
          48,
          56,
          47,
          41,
          56,
          33,
          60,
          48,
          66,
          70,
          52,
          56,
          37,
          38,
          58,
          49,
          79,
          54,
          67,
          61,
          42,
          44,
          48,
          47,
          65,
          37,
          36,
          48,
          42,
          38,
          46,
          74,
          53,
          64,
          70,
          33,
          39,
          53,
          58,
          58,
          57,
          34,
          40,
          53,
          39,
          46,
          46,
          43,
          68,
          41,
          38,
          46,
          58,
          35,
          60,
          63,
          41,
          49,
          47,
          59,
          45,
          50,
          39,
          66,
          47,
          59,
          80,
          59,
          77,
          33,
          42,
          43,
          37,
          56,
          69,
          46,
          69,
          38,
          64,
          56,
          48,
          56,
          57,
          83,
          36,
          71,
          56,
          48,
          29,
          73,
          38,
          67,
          35,
          47,
          53,
          32,
          47,
          56,
          50,
          50,
          69,
          42,
          39,
          61,
          56,
          44,
          45,
          43,
          54,
          42,
          41,
          53,
          55,
          43,
          47,
          35,
          38,
          46,
          56,
          55,
          40,
          60,
          49,
          63,
          65,
          40,
          36,
          45,
          46,
          61,
          68,
          47,
          47,
          48,
          37,
          45,
          38,
          39,
          56,
          77,
          53,
          34,
          44,
          52,
          45,
          49,
          68,
          39,
          46,
          49,
          64,
          51,
          43,
          28,
          52,
          61,
          37,
          56,
          74,
          70,
          51,
          37,
          53,
          63,
          61,
          44,
          63,
          42,
          48,
          51,
          55,
          57,
          59,
          73,
          49,
          69,
          66,
          42,
          58,
          49,
          63,
          82,
          45,
          51,
          60,
          78,
          37,
          45,
          66,
          37,
          67,
          38,
          47,
          47,
          22,
          44,
          50,
          35,
          67,
          56,
          44,
          61,
          41,
          45,
          64,
          50,
          57,
          53,
          45,
          62,
          41,
          51,
          31,
          42,
          47,
          71,
          47,
          63,
          65,
          43,
          79,
          66,
          45,
          48,
          39,
          66,
          60,
          39,
          73,
          42,
          48,
          46,
          54,
          52,
          52,
          38,
          55,
          50,
          59,
          71,
          54,
          47,
          32,
          54,
          37,
          50,
          56,
          22,
          36,
          41,
          53,
          41,
          44,
          40,
          54,
          40,
          47,
          83,
          36,
          47,
          43,
          41,
          54,
          55,
          49,
          35,
          47,
          37,
          58,
          36,
          47,
          59,
          64,
          55,
          30,
          50,
          40,
          55,
          57,
          80,
          62,
          34,
          56,
          67,
          35,
          55,
          58,
          37,
          68,
          57,
          66,
          47,
          51,
          41,
          37,
          35,
          55,
          44,
          47,
          51,
          54,
          61,
          33,
          60,
          55,
          46,
          34,
          41,
          60,
          39,
          38,
          36,
          45,
          53,
          39,
          48,
          58,
          62,
          55,
          56,
          29,
          35,
          77,
          71,
          57,
          57,
          53,
          43,
          59,
          60,
          34,
          51,
          48,
          50,
          49,
          57,
          66,
          60,
          66,
          44,
          39,
          53,
          32,
          51,
          52,
          71,
          47,
          39,
          57,
          49,
          46,
          57,
          43,
          53,
          38,
          47,
          44,
          45,
          60,
          47,
          45,
          50,
          39,
          52,
          35,
          52,
          54,
          66,
          30,
          38,
          39,
          52,
          52,
          43,
          49,
          58,
          39,
          59,
          60,
          63,
          38,
          61,
          70,
          45,
          44,
          52,
          58,
          45,
          40,
          75,
          44,
          37,
          53,
          54,
          58,
          52,
          58,
          34,
          56,
          60,
          68,
          68,
          60,
          43,
          44,
          75,
          50,
          45,
          60,
          51,
          64,
          45,
          62,
          55,
          71,
          38,
          72,
          67,
          55,
          56,
          52,
          38,
          43,
          48,
          69,
          37,
          63,
          71,
          44,
          67,
          48,
          61,
          44,
          62,
          68,
          36,
          62,
          44,
          60,
          62,
          75,
          33,
          56,
          40,
          46,
          43,
          64,
          51,
          63,
          59,
          41,
          40,
          47,
          45,
          41,
          53,
          58,
          40,
          69,
          46,
          65,
          48,
          41,
          42,
          71,
          65,
          56,
          33,
          68,
          47,
          43,
          53,
          56,
          60,
          54,
          49,
          38,
          38,
          44,
          28,
          54,
          39,
          48,
          50,
          41,
          33,
          50,
          41,
          45,
          52,
          45,
          47,
          38,
          51,
          56,
          44,
          48,
          46,
          60,
          41,
          40,
          59,
          61,
          52,
          53,
          65,
          35,
          62,
          46,
          42,
          44,
          63,
          40,
          36,
          52,
          32,
          79,
          48,
          49,
          37,
          52,
          43,
          50,
          41,
          49,
          42,
          45,
          55,
          71,
          61,
          54,
          43,
          65,
          45,
          40,
          38,
          53,
          62,
          58,
          64,
          62,
          52,
          32,
          35,
          39,
          50,
          51,
          50,
          49,
          51,
          50,
          53,
          44,
          54,
          54,
          54,
          53,
          53,
          63,
          39,
          50,
          56,
          42,
          58,
          44,
          59,
          54,
          41,
          63,
          52,
          63,
          50,
          36,
          42,
          57,
          47,
          71,
          56,
          62,
          77,
          72,
          64,
          58,
          71,
          42,
          46,
          40,
          63,
          76,
          41,
          49,
          51,
          44,
          44,
          62,
          40,
          60,
          44,
          53,
          22,
          55,
          67,
          60,
          51,
          46,
          55,
          52,
          81,
          55,
          74,
          54,
          76,
          41,
          33,
          67,
          40,
          46,
          53,
          59,
          63,
          60,
          55,
          48,
          65,
          52,
          43,
          67,
          53,
          44,
          48,
          31,
          54,
          42,
          52,
          45,
          37,
          36,
          70,
          49,
          45,
          46,
          46,
          53,
          55,
          46,
          63,
          35,
          36,
          61,
          50,
          48,
          80,
          34,
          47,
          65,
          31,
          61,
          58,
          40,
          49,
          46,
          67,
          47,
          77,
          40,
          43,
          58,
          56,
          53,
          56,
          59,
          71,
          73,
          54,
          54,
          46,
          69,
          45,
          31,
          39,
          51,
          37,
          61,
          50,
          60,
          34,
          41,
          57,
          63,
          35,
          74,
          64,
          35,
          54,
          36,
          49,
          39,
          47,
          47,
          46,
          43,
          48,
          72,
          57,
          28,
          47,
          53,
          66,
          67,
          64,
          60,
          59,
          66,
          65,
          68,
          51,
          52,
          44,
          43,
          53,
          53,
          45,
          62,
          72,
          47,
          48,
          49,
          51,
          67,
          37,
          50,
          46,
          41,
          45,
          68,
          42,
          31,
          55,
          37,
          42,
          46,
          32,
          50,
          43,
          25,
          42,
          41,
          44,
          39,
          49,
          58,
          35,
          45,
          64,
          61,
          42,
          52,
          69,
          44,
          58,
          51,
          55,
          70,
          59,
          39,
          46,
          68,
          49,
          42,
          46,
          47,
          57,
          46,
          67,
          39,
          35,
          46,
          64,
          60,
          48,
          41,
          41,
          57,
          61,
          45,
          30,
          52,
          28,
          50,
          61,
          31,
          34,
          41,
          68,
          43,
          42,
          45,
          57,
          40,
          65,
          53,
          41,
          66,
          57,
          25,
          43,
          51,
          58,
          52,
          44,
          58,
          65,
          34,
          48,
          62,
          41,
          75,
          39,
          51,
          45,
          64,
          73,
          56,
          77,
          68,
          62,
          48,
          48,
          45,
          32,
          48,
          56,
          51,
          48,
          48,
          41,
          53,
          48,
          64,
          49,
          58,
          70,
          62,
          44,
          52,
          53,
          40,
          46,
          58,
          50,
          53,
          57,
          49,
          55,
          42,
          59,
          27,
          40,
          69,
          38,
          38,
          70,
          57,
          54,
          66,
          49,
          53,
          38,
          45,
          48,
          63,
          55,
          45,
          56,
          52,
          66,
          45,
          48,
          41,
          51,
          45,
          48,
          52,
          48,
          54,
          35,
          41,
          59,
          53,
          59,
          43,
          66,
          52,
          42,
          56,
          57,
          47,
          76,
          58,
          35,
          40,
          32,
          63,
          48,
          32,
          69,
          41,
          59,
          54,
          43,
          69,
          60,
          54,
          57,
          53,
          39,
          43,
          56,
          50,
          31,
          28,
          53,
          43,
          48,
          44,
          58,
          52,
          62,
          44,
          53,
          38,
          39,
          37,
          68,
          66,
          70,
          49,
          35,
          49,
          44,
          41,
          57,
          41,
          35,
          43,
          65,
          61,
          48,
          38,
          42,
          50,
          57,
          63,
          64,
          70,
          57,
          55,
          34,
          37,
          54,
          39,
          55,
          53,
          38,
          37,
          50,
          70,
          34,
          40,
          46,
          45,
          61,
          69,
          44,
          54,
          58,
          60,
          50,
          42,
          63,
          47,
          49,
          43,
          48,
          45,
          66,
          34,
          48,
          55,
          50,
          36,
          44,
          54,
          45,
          58,
          55,
          63,
          39,
          52,
          44,
          58,
          42,
          59,
          32,
          53,
          58,
          49,
          62,
          48,
          31,
          67,
          44,
          29,
          70,
          36,
          49,
          43,
          62,
          64,
          56,
          29,
          72,
          47,
          60,
          42,
          56,
          42,
          52,
          59,
          45,
          55,
          65,
          69,
          43,
          56,
          44,
          59,
          69,
          57,
          30,
          41,
          41,
          50,
          45,
          62,
          60,
          48,
          66,
          48,
          58,
          37,
          62,
          34,
          32,
          48,
          74,
          35,
          61,
          56,
          41,
          65,
          70,
          64,
          62,
          53,
          63,
          57,
          59,
          59,
          52,
          49,
          72,
          40,
          61,
          52,
          62,
          46,
          46,
          55,
          68,
          43,
          71,
          51,
          52,
          41,
          64,
          58,
          63,
          47,
          50,
          69,
          43,
          65,
          52,
          54,
          47,
          53,
          47,
          38,
          75,
          47,
          46,
          54,
          42,
          50,
          61,
          40,
          64,
          50,
          62,
          62,
          49,
          68,
          37,
          45,
          33,
          51,
          47,
          42,
          76,
          65,
          40,
          32,
          47,
          63,
          46,
          38,
          43,
          63,
          55,
          56,
          36,
          45,
          42,
          60,
          36,
          36,
          46,
          63,
          48,
          50,
          44,
          61,
          51,
          42,
          44,
          35,
          47,
          62,
          55,
          32,
          60,
          48,
          43,
          41,
          60,
          46,
          36,
          46,
          52,
          44,
          51,
          49,
          68,
          47,
          48,
          60,
          70,
          50,
          54,
          54,
          56,
          55,
          44,
          49,
          21,
          66,
          62,
          62,
          60,
          46,
          45,
          48,
          55,
          49,
          61,
          41,
          48,
          61,
          53,
          49,
          41,
          33,
          52,
          49,
          56,
          39,
          48,
          69,
          36,
          69,
          48,
          69,
          67,
          42,
          45,
          60,
          38,
          52,
          67,
          38,
          50,
          52,
          24,
          36,
          41,
          45,
          47,
          73,
          60,
          44,
          66,
          54,
          44,
          25,
          50,
          37,
          69,
          58,
          37,
          42,
          71,
          61,
          65,
          52,
          65,
          54,
          61,
          55,
          32,
          57,
          56,
          44,
          47,
          56,
          37,
          31,
          29,
          45,
          44,
          53,
          34,
          40,
          63,
          52,
          59,
          51,
          69,
          46,
          57,
          27,
          66,
          51,
          38,
          54,
          45,
          68,
          52,
          41,
          67,
          52,
          42,
          44,
          58,
          63,
          35,
          47,
          54,
          44,
          44,
          49,
          47,
          50,
          45,
          39,
          42,
          43,
          54,
          40,
          47,
          59,
          60,
          52,
          61,
          46,
          53,
          45,
          80,
          32,
          53,
          75,
          44,
          62,
          50,
          44,
          46,
          66,
          49,
          57,
          57,
          56,
          64,
          53,
          58,
          54,
          46,
          37,
          33,
          67,
          55,
          44,
          66,
          54,
          55,
          59,
          68,
          49,
          49,
          64,
          40,
          61,
          70,
          57,
          73,
          46,
          48,
          63,
          49,
          57,
          59,
          50,
          39,
          50,
          50,
          50,
          44,
          48,
          45,
          36,
          39,
          56,
          51,
          47,
          40,
          72,
          54,
          30,
          45,
          60,
          44,
          39,
          67,
          68,
          55,
          55,
          42,
          47,
          74,
          57,
          59,
          39,
          41,
          61,
          28,
          79,
          68,
          34,
          37,
          37,
          36,
          60,
          44,
          49,
          28,
          38,
          43,
          68,
          50,
          48,
          44,
          37,
          40,
          61,
          41,
          70,
          53,
          59,
          53,
          46,
          80,
          45,
          59,
          41,
          38,
          50,
          48,
          60,
          45,
          65,
          66,
          62,
          68,
          54,
          45,
          70,
          66,
          57,
          50,
          51,
          36,
          68,
          51,
          64,
          44,
          50,
          43,
          51,
          50,
          75,
          31,
          58,
          57,
          57,
          47,
          68,
          38,
          65,
          42,
          54,
          55,
          45,
          42,
          33,
          61,
          48,
          45,
          36,
          57,
          63,
          64,
          38,
          37,
          46,
          28,
          51,
          68,
          79,
          51,
          43,
          63,
          44,
          55,
          38,
          36,
          58,
          39,
          59,
          47,
          49,
          70,
          51,
          57,
          44,
          55,
          52,
          53,
          70,
          53,
          60,
          56,
          45,
          64,
          66,
          38,
          38,
          57,
          55,
          51,
          72,
          70,
          54,
          55,
          38,
          66,
          38,
          66,
          43,
          46,
          40,
          50,
          38,
          52,
          60,
          54,
          62,
          72,
          84,
          44,
          66,
          41,
          47,
          44,
          67,
          36,
          48,
          62,
          30,
          42,
          51,
          44,
          45,
          72,
          62,
          57,
          47,
          60,
          54,
          43,
          36,
          37,
          38,
          49,
          55,
          64,
          66,
          46,
          49,
          36,
          45,
          30,
          52,
          53,
          64,
          67,
          61,
          54,
          45,
          61,
          56,
          35,
          38,
          30,
          49,
          38,
          42,
          42,
          55,
          53,
          36,
          58,
          29,
          42,
          47,
          41,
          39,
          49,
          35,
          45,
          73,
          39,
          53,
          38,
          38,
          44,
          61,
          41,
          58,
          39,
          50,
          44,
          56,
          64,
          37,
          66,
          53,
          54,
          53,
          73,
          33,
          57,
          49,
          47,
          56,
          32,
          61,
          52,
          43,
          65,
          39,
          68,
          48,
          44,
          50,
          43,
          61,
          56,
          49,
          39,
          36,
          45,
          45,
          53,
          40,
          45,
          32,
          61,
          30,
          47,
          67,
          46,
          30,
          47,
          55,
          39,
          44,
          71,
          45,
          51,
          56,
          40,
          51,
          46,
          55,
          76,
          56,
          58,
          74,
          56,
          56,
          27,
          44,
          54,
          62,
          55,
          65,
          49,
          39,
          56,
          62,
          66,
          53,
          51,
          42,
          42,
          51,
          70,
          46,
          42,
          58,
          55,
          39,
          59,
          58,
          53,
          47,
          34,
          43,
          72,
          79,
          34,
          46,
          58,
          71,
          65,
          49,
          70,
          59,
          39,
          38,
          43,
          37,
          61,
          39,
          38,
          73,
          63,
          46,
          41,
          51,
          59,
          50,
          59,
          80,
          48,
          67,
          42,
          64,
          35,
          46,
          51,
          60,
          45,
          58,
          52,
          29,
          63,
          43,
          72,
          29,
          57,
          57,
          29,
          46,
          29,
          48,
          52,
          61,
          58,
          42,
          55,
          59,
          49,
          77,
          39,
          70,
          56,
          24,
          64,
          37,
          49,
          65,
          57,
          51,
          49,
          57,
          51,
          60,
          66,
          41,
          55,
          75,
          38,
          44,
          51,
          25,
          58,
          44,
          63,
          44,
          29,
          35,
          38,
          54,
          70,
          54,
          48,
          43,
          52,
          58,
          61,
          45,
          65,
          49,
          36,
          55,
          54,
          68,
          36,
          34,
          62,
          48,
          60,
          44,
          49,
          63,
          61,
          52,
          47,
          57,
          72,
          68,
          42,
          52,
          61,
          47,
          44,
          41,
          49,
          57,
          46,
          76,
          55,
          43,
          46,
          44,
          45,
          45,
          46,
          60,
          67,
          34,
          38,
          44,
          57,
          65,
          50,
          40,
          66,
          27,
          64,
          45,
          58,
          78,
          57,
          77,
          60,
          68,
          46,
          53,
          40,
          48,
          62,
          54,
          36,
          40,
          69,
          36,
          49,
          48,
          28,
          68,
          41,
          35,
          70,
          46,
          50,
          77,
          60,
          47,
          69,
          67,
          60,
          46,
          39,
          41,
          42,
          53,
          46,
          47,
          37,
          49,
          52,
          43,
          73,
          63,
          42,
          54,
          58,
          66,
          60,
          90,
          42,
          65,
          45,
          48,
          40,
          43,
          61,
          43,
          48,
          36,
          54,
          45,
          54,
          68,
          56,
          51,
          35,
          46,
          71,
          64,
          49,
          43,
          60,
          66,
          64,
          56,
          56,
          70,
          40,
          41,
          54,
          51,
          43,
          66,
          58,
          48,
          36,
          49,
          50,
          51,
          30,
          46,
          52,
          68,
          34,
          77,
          58,
          50,
          49,
          49,
          64,
          52,
          41,
          56,
          48,
          58,
          51,
          63,
          50,
          54,
          61,
          39,
          63,
          37,
          46,
          49,
          53,
          57,
          69,
          45,
          71,
          48,
          43,
          43,
          41,
          35,
          53,
          49,
          52,
          38,
          53,
          55,
          55,
          48,
          47,
          71,
          37,
          59,
          51,
          40,
          36,
          54,
          58,
          59,
          45,
          38,
          45,
          69,
          57,
          42,
          55,
          38,
          60,
          37,
          53,
          46,
          51,
          57,
          49,
          40,
          64,
          45,
          43,
          49,
          42,
          61,
          74,
          60,
          29,
          67,
          69,
          41,
          59,
          51,
          46,
          49,
          55,
          55,
          33,
          65,
          58,
          39,
          64,
          67,
          53,
          45,
          49,
          49,
          51,
          51,
          54,
          49,
          53,
          45,
          50,
          37,
          51,
          67,
          56,
          52,
          36,
          65,
          30,
          69,
          33,
          55,
          50,
          63,
          54,
          50,
          48,
          38,
          74,
          57,
          58,
          61,
          55,
          55,
          56,
          73,
          55,
          40,
          54,
          61,
          33,
          50,
          48,
          48,
          41,
          35,
          68,
          42,
          49,
          50,
          63,
          56,
          55,
          41,
          37,
          47,
          50,
          64,
          44,
          41,
          47,
          39,
          41,
          41,
          75,
          37,
          58,
          30,
          36,
          60,
          49,
          52,
          35,
          54,
          38,
          49,
          51,
          60,
          54,
          39,
          41,
          36,
          39,
          47,
          33,
          62,
          73,
          49,
          48,
          36,
          50,
          62,
          46,
          44,
          48,
          42,
          61,
          55,
          71,
          34,
          40,
          41,
          39,
          54,
          50,
          43,
          56,
          43,
          38,
          50,
          28,
          57,
          58,
          72,
          47,
          87,
          62,
          52,
          67,
          50,
          54,
          51,
          53,
          56,
          54,
          55,
          41,
          65,
          37,
          46,
          37,
          60,
          60,
          42,
          47,
          49,
          49,
          66,
          41,
          59,
          58,
          44,
          46,
          53,
          43,
          32,
          33,
          40,
          50,
          48,
          53,
          54,
          53,
          57,
          36,
          71,
          52,
          43,
          29,
          61,
          35,
          49,
          48,
          55,
          70,
          43,
          42,
          47,
          59,
          44,
          57,
          36,
          34,
          53,
          73,
          45,
          59,
          43,
          68,
          45,
          64,
          59,
          57,
          57,
          67,
          60,
          65,
          59,
          52,
          47,
          71,
          60,
          68,
          67,
          55,
          38,
          55,
          63,
          40,
          46,
          49,
          45,
          41,
          71,
          72,
          41,
          64,
          32,
          51,
          48,
          57,
          39,
          49,
          81,
          57,
          64,
          46,
          62,
          42,
          40,
          45,
          65,
          59,
          55,
          53,
          67,
          48,
          41,
          59,
          57,
          69,
          64,
          49,
          64,
          37,
          49,
          40,
          41,
          58,
          56,
          54,
          37,
          42,
          63,
          54,
          55,
          50,
          55,
          52,
          31,
          44,
          71,
          40,
          42,
          52,
          62,
          31,
          58,
          43,
          58,
          68,
          38,
          43,
          57,
          71,
          36,
          46,
          42,
          63,
          50,
          38,
          48,
          63,
          63,
          55,
          60,
          63,
          52,
          55,
          48,
          42,
          61,
          36,
          60,
          69,
          46,
          51,
          56,
          42,
          54,
          60,
          62,
          59,
          42,
          67,
          55,
          31,
          44,
          52,
          29,
          38,
          57,
          47,
          39,
          63,
          64,
          63,
          49,
          64,
          81,
          55,
          46,
          41,
          60,
          50,
          58,
          47,
          58,
          58,
          42,
          39,
          53,
          61,
          52,
          31,
          40,
          45,
          64,
          58,
          61,
          62,
          42,
          35,
          70,
          38,
          42,
          44,
          53,
          36,
          42,
          57,
          65,
          47,
          49,
          41,
          52,
          57,
          62,
          67,
          60,
          53,
          59,
          52,
          50,
          67,
          62,
          66,
          48,
          39,
          40,
          41,
          63,
          36,
          59,
          58,
          48,
          38,
          48,
          60,
          50,
          37,
          62,
          63,
          50,
          56,
          44,
          43,
          66,
          65,
          49,
          34,
          42,
          54,
          62,
          59,
          69,
          57,
          70,
          56,
          46,
          31,
          70,
          49,
          56,
          60,
          55,
          52,
          61,
          69,
          44,
          49,
          47,
          36,
          51,
          42,
          42,
          34,
          48,
          48,
          51,
          72,
          71,
          69,
          50,
          65,
          48,
          66,
          36,
          45,
          43,
          75,
          53,
          50,
          55,
          50,
          51,
          49,
          64,
          23,
          48,
          75,
          47,
          62,
          33,
          56,
          53,
          38,
          63,
          64,
          63,
          64,
          45,
          47,
          76,
          69,
          50,
          44,
          45,
          53,
          43,
          62,
          61,
          41,
          43,
          62,
          58,
          42,
          48,
          50,
          64,
          78,
          52,
          44,
          61,
          63,
          42,
          45,
          62,
          62,
          55,
          47,
          58,
          61,
          50,
          46,
          63,
          40,
          62,
          74,
          35,
          67,
          48,
          61,
          36,
          65,
          56,
          44,
          60,
          73,
          68,
          62,
          38,
          28,
          64,
          34,
          48,
          42,
          50,
          53,
          60,
          56,
          57,
          48,
          38,
          59,
          67,
          59,
          62,
          64,
          50,
          40,
          71,
          69,
          63,
          53,
          44,
          45,
          59,
          54,
          51,
          51,
          59,
          74,
          38,
          48,
          35,
          64,
          58,
          54,
          44,
          46,
          29,
          58,
          69,
          64,
          63,
          76,
          53,
          45,
          50,
          64,
          39,
          65,
          50,
          52,
          54,
          58,
          40,
          63,
          60,
          70,
          59,
          61,
          48,
          60,
          50,
          46,
          60,
          48,
          61,
          61,
          55,
          33,
          58,
          63,
          44,
          44,
          58,
          70,
          46,
          37,
          57,
          56,
          39,
          53,
          63,
          41,
          48,
          50,
          61,
          48,
          64,
          46,
          35,
          36,
          35,
          69,
          43,
          44,
          48,
          48,
          54,
          43,
          46,
          51,
          40,
          61,
          47,
          44,
          66,
          45,
          56,
          52,
          58,
          50,
          47,
          55,
          45,
          54,
          29,
          39,
          58,
          45,
          74,
          53,
          53,
          66,
          46,
          65,
          76,
          48,
          49,
          60,
          47,
          53,
          41,
          53,
          35,
          57,
          43,
          49,
          66,
          45,
          47,
          58,
          37,
          83,
          47,
          45,
          58,
          57,
          63,
          52,
          61,
          55,
          52,
          44,
          63,
          55,
          59,
          39,
          75,
          42,
          65,
          66,
          48,
          49,
          70,
          66,
          34,
          58,
          56,
          49,
          50,
          65,
          62,
          47,
          85,
          61,
          62,
          72,
          55,
          61,
          46,
          46,
          75,
          63,
          59,
          69,
          61,
          57,
          49,
          61,
          53,
          49,
          32,
          52,
          42,
          46,
          78,
          60,
          61,
          41,
          52,
          40,
          63,
          66,
          51,
          57,
          63,
          51,
          27,
          31,
          37,
          35,
          66,
          71,
          31,
          52,
          41,
          54,
          39,
          43,
          43,
          57,
          36,
          51,
          44,
          41,
          74,
          42,
          48,
          50,
          44,
          56,
          52,
          61,
          47,
          61,
          41,
          39,
          75,
          37,
          54,
          47,
          76,
          43,
          49,
          45,
          62,
          41,
          60,
          77,
          56,
          63,
          68,
          36,
          49,
          47,
          71,
          68,
          43,
          51,
          47,
          46,
          46,
          45,
          42,
          41,
          51,
          48,
          42,
          35,
          39,
          49,
          65,
          46,
          50,
          52,
          51,
          66,
          58,
          45,
          55,
          44,
          72,
          57,
          45,
          60,
          42,
          57,
          44,
          50,
          50,
          39,
          57,
          61,
          58,
          77,
          37,
          68,
          67,
          62,
          62,
          47,
          52,
          47,
          40,
          41,
          41,
          59,
          31,
          60,
          52,
          66,
          52,
          55,
          60,
          31,
          60,
          68,
          27,
          39,
          60,
          61,
          70,
          42,
          56,
          46,
          57,
          57,
          65,
          29,
          53,
          59,
          53,
          51,
          46,
          64,
          55,
          54,
          43,
          49,
          68,
          57,
          44,
          49,
          51,
          53,
          53,
          55,
          41,
          32,
          49,
          58,
          61,
          57,
          65,
          66,
          59,
          49,
          47,
          57,
          64,
          38,
          64,
          70,
          37,
          49,
          59,
          63,
          55,
          50,
          79,
          65,
          50,
          62,
          64,
          53,
          46,
          40,
          53,
          55,
          37,
          39,
          57,
          30,
          44,
          55,
          42,
          51,
          35,
          53,
          66,
          47,
          74,
          54,
          47,
          48,
          45,
          44,
          75,
          58,
          43,
          34,
          69,
          62,
          49,
          41,
          52,
          36,
          65,
          46,
          77,
          68,
          60,
          47,
          44,
          58,
          46,
          49,
          61,
          86,
          41,
          53,
          59,
          61,
          47,
          78,
          31,
          45,
          56,
          54,
          66,
          33,
          51,
          54,
          44,
          51,
          50,
          61,
          50,
          45,
          47,
          42,
          36,
          48,
          46,
          38,
          70,
          62,
          50,
          59,
          30,
          43,
          76,
          53,
          76,
          50,
          63,
          40,
          45,
          39,
          42,
          54,
          49,
          55,
          51,
          70,
          47,
          83,
          62,
          36,
          59,
          59,
          59,
          46,
          55,
          56,
          40,
          59,
          53,
          36,
          50,
          57,
          50,
          53,
          62,
          41,
          73,
          57,
          49,
          38,
          48
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "boxmode": "group",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "test_result"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "age"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"125511f1-26c5-4510-8dec-4c7f289432b8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"125511f1-26c5-4510-8dec-4c7f289432b8\")) {                    Plotly.newPlot(                        \"125511f1-26c5-4510-8dec-4c7f289432b8\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"test_result=%{x}<br>age=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"\",\"notched\":false,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[1,1,0,0,1,0,0,1,0,1,1,1,1,1,1,0,0,1,0,1,0,0,1,1,0,0,1,1,0,1,0,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,1,0,1,0,0,1,0,1,0,0,0,1,1,0,0,1,1,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0,0,1,1,1,1,1,0,1,0,1,1,1,1,0,0,0,1,1,0,0,0,1,0,0,1,1,1,1,1,0,0,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,0,0,1,1,1,0,0,0,1,1,0,0,1,1,1,0,1,1,1,1,1,0,1,1,0,1,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,1,1,0,0,1,1,0,0,1,1,1,1,0,1,1,0,1,1,1,0,1,0,1,0,1,0,1,1,1,1,0,0,1,1,1,1,1,0,0,1,0,0,0,1,1,1,1,1,1,1,1,0,1,0,1,1,0,0,1,0,0,1,1,1,0,1,0,0,0,0,0,0,1,0,0,1,1,1,0,1,1,0,0,1,1,1,1,0,0,1,0,0,1,1,0,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,1,0,0,0,1,1,0,1,1,1,1,1,0,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,1,1,1,1,0,0,1,0,0,1,1,1,0,1,1,0,1,0,1,0,0,0,1,0,1,0,1,0,1,0,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,0,1,1,1,1,0,1,0,1,1,1,0,0,1,1,1,0,1,1,0,1,1,0,0,1,0,1,0,1,0,0,1,1,1,0,1,0,0,1,1,1,1,1,0,0,1,0,1,1,0,0,1,0,1,0,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,0,1,0,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1,1,1,1,1,1,1,0,0,1,0,1,0,1,0,1,0,0,1,1,0,1,1,0,1,0,0,0,0,1,1,1,1,1,1,1,0,1,0,1,0,1,0,1,1,1,0,0,0,1,0,0,1,1,0,1,1,1,0,0,1,1,1,0,0,1,0,0,0,1,0,0,1,0,0,1,0,1,1,1,0,1,1,0,1,0,1,1,1,0,1,1,1,0,1,1,1,0,1,1,0,1,1,1,1,0,0,1,0,0,1,1,0,1,1,0,0,1,1,1,1,1,0,0,0,1,0,0,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,0,1,1,0,0,1,0,0,1,0,1,1,0,1,1,0,1,1,1,1,0,0,0,1,0,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,0,0,1,0,0,0,0,0,0,1,1,0,1,1,1,1,0,0,1,1,1,0,1,0,0,0,0,1,1,0,1,1,1,1,1,1,0,1,1,0,0,1,1,0,1,1,1,1,0,0,0,0,1,1,0,0,1,1,0,1,1,0,1,1,0,1,1,0,0,0,1,0,0,1,1,0,1,1,0,1,1,0,0,0,0,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,0,0,0,1,0,1,1,0,1,1,1,0,1,0,0,0,1,0,1,1,0,1,1,1,1,1,0,1,0,0,1,0,0,1,1,1,0,1,1,0,1,0,1,1,0,1,0,1,1,1,0,1,1,0,0,0,0,0,1,0,1,1,1,1,0,1,0,1,1,0,1,1,0,0,0,1,1,1,1,0,1,1,1,1,1,0,0,1,1,0,0,1,0,0,0,1,0,1,1,0,1,1,0,1,0,0,1,1,1,0,1,0,0,1,0,1,1,0,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,0,1,0,1,1,0,1,0,1,1,1,1,1,1,0,1,1,0,1,1,0,1,1,1,0,0,1,1,1,1,0,0,1,0,1,0,0,1,1,1,1,0,1,1,0,0,1,1,0,1,0,1,1,0,1,1,0,0,0,1,0,1,0,1,1,1,0,1,1,0,0,1,1,1,1,0,1,0,1,1,1,1,1,0,0,1,1,1,1,1,0,1,0,1,1,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,0,1,1,0,1,0,1,1,1,1,1,0,1,0,1,1,1,1,0,1,1,0,1,0,0,1,1,0,0,1,0,0,1,1,1,1,0,1,1,1,0,1,1,1,0,1,1,0,0,1,0,0,0,0,0,1,1,0,0,1,0,1,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,0,1,0,1,0,1,1,0,1,1,1,0,0,1,1,1,0,1,0,0,1,0,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,0,0,0,1,0,1,0,1,1,0,0,1,0,1,1,1,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,0,0,0,0,0,0,1,1,1,1,0,0,1,1,1,0,1,0,0,1,1,1,0,1,1,1,1,0,1,1,1,1,1,0,0,1,1,1,0,0,1,1,0,1,0,1,1,1,0,0,1,1,1,0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,1,0,0,1,1,0,0,1,1,1,1,1,0,1,1,1,1,0,1,0,1,0,1,0,0,1,0,1,1,1,0,1,0,0,0,1,1,1,0,0,1,0,0,0,0,1,0,1,1,0,1,0,0,0,1,1,1,1,0,1,1,1,1,1,1,0,1,0,0,1,0,0,0,0,1,1,0,1,1,0,1,1,0,0,0,0,1,1,0,1,0,0,0,0,0,1,0,1,0,1,1,1,0,1,1,0,1,0,1,1,1,1,0,1,1,1,0,0,1,0,1,1,0,0,1,1,1,1,0,0,1,0,1,0,0,1,0,0,0,0,1,1,1,1,1,1,1,0,1,1,0,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1,1,1,1,0,1,0,1,0,0,1,0,1,1,1,0,0,0,0,1,0,1,1,1,0,1,0,0,0,1,1,0,1,1,0,0,0,1,0,0,1,0,0,1,1,0,0,1,0,1,0,1,1,1,1,0,1,0,1,1,1,0,1,1,0,1,1,0,1,0,1,1,0,1,0,1,0,1,1,1,1,0,0,0,1,1,0,1,0,1,0,1,0,0,1,1,0,1,1,1,0,1,1,0,0,1,1,1,1,0,1,0,1,1,0,0,0,0,0,0,1,0,1,1,0,1,0,0,1,1,0,1,1,0,1,1,1,1,0,0,1,0,0,0,1,1,1,0,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,0,0,0,1,1,0,0,1,1,0,0,0,0,1,1,1,1,0,0,1,1,0,0,0,0,1,0,0,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,0,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,0,1,1,0,1,0,0,0,1,1,0,0,0,1,0,1,1,0,0,1,0,0,0,1,0,1,0,1,1,0,1,0,1,1,1,1,1,0,0,0,0,0,1,1,1,1,1,0,1,1,0,1,0,0,1,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,1,0,1,1,1,0,1,0,0,0,1,1,1,1,1,1,0,0,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,1,1,1,0,0,1,0,1,0,0,1,1,1,0,1,0,1,1,1,1,1,0,1,0,1,1,0,0,1,1,1,1,1,0,0,1,0,1,1,0,1,0,1,1,0,0,1,0,1,0,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,0,0,1,1,1,1,0,0,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,0,1,0,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,0,0,1,1,0,0,1,0,0,0,1,1,1,0,1,0,1,0,1,1,1,0,1,0,1,1,1,1,0,1,1,0,1,1,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,0,1,1,1,0,0,1,1,0,0,1,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,0,1,1,0,1,0,1,0,0,1,1,1,1,0,1,1,1,1,1,1,0,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,0,1,1,1,0,1,0,0,1,1,1,0,1,1,1,0,1,1,0,1,0,1,1,1,1,0,0,1,0,1,0,0,1,0,1,0,1,0,1,0,1,0,1,0,1,1,1,1,1,0,1,0,0,1,1,0,1,1,1,1,0,1,1,0,0,1,1,1,1,0,0,0,1,0,0,0,0,1,1,0,1,0,0,1,1,0,0,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,1,1,1,1,0,0,0,0,0,1,0,1,1,1,0,1,1,1,0,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,1,1,0,1,0,1,1,0,1,1,1,1,0,0,1,1,1,1,0,1,0,1,1,0,0,1,1,1,1,0,1,0,0,1,0,0,1,1,1,0,0,1,0,1,1,1,0,1,1,1,1,1,0,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,0,1,0,1,1,0,0,0,1,1,0,1,1,1,1,0,1,0,1,1,1,1,1,0,1,1,0,0,0,1,0,1,1,1,1,1,1,1,1,1,1,0,1,0,1,0,1,1,1,0,0,0,1,1,1,1,0,1,0,0,1,1,0,1,0,0,1,1,1,1,0,1,0,0,1,0,0,0,0,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,0,0,1,1,0,1,0,0,0,1,0,0,0,1,0,1,1,1,0,1,1,1,1,1,1,0,1,1,1,0,0,1,1,1,0,1,1,0,1,0,0,0,0,0,1,0,0,1,0,0,1,1,1,0,1,0,0,1,0,1,0,1,0,0,1,0,0,0,0,0,1,1,0,1,1,0,0,0,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,0,0,1,0,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,1,0,0,1,1,1,0,1,1,0,1,1,0,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,0,1,1,1,1,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,1,0,1,0,1,1,0,1,0,1,1,1,1,1,0,1,0,0,0,1,0,0,1,1,1,1,0,1,0,0,1,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,1,0,0,0,1,1,0,1,1,0,0,0,0,0,0,0,1,1,0,1,0,1,1,1,1,0,1,1,1,0,0,1,1,1,0,1,0,0,1,1,1,1,1,0,1,1,0,1,0,1,1,1,1,0,1,0,1,1,0,0,1,0,0,0,0,1,1,0,0,1,1,0,1,1,0,1,0,1,1,1,0,1,0,0,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,0,1,0,1,1,0,0,1,1,1,1,0,1,1,0,0,1,1,1,1,0,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,0,0,1,0,1,1,0,0,1,1,0,1,1,1,1,1,1,0,1,1,1,0,0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,1,1,0,1,0,1,1,0,0,1,1,0,0,0,0,1,0,1,0,0,1,0,1,0,1,0,0,1,0,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,0,0,1,1,0,1,1,1,1,0,1,1,0,1,1,1,1,0,1,1,0,1,0,0,1,0,1,0,1,0,1,1,1,1,0,1,1,1,0,1,1,1,1,0,1,1,0,0,0,1,0,1,1,0,1,1,0,0,1,1,1,0,1,1,0,1,1,1,1,0,1,1,0,0,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,0,0,1,1,0,1,1,0,1,1,1,0,0,1,1,1,1,1,0,0,0,0,0,1,1,0,1,1,1,1,1,0,0,1,1,1,1,0,0,1,0,0,0,1,1,0,0,1,0,1,1,0,1,1,0,0,1,1,1,1,1,0,0,1,0,1,1,1,1,1,0,1,0,0,1,1,0,1,1,0,1,1,1,0,0,1,1,0,1,0,1,1,1,0,0,0,0,0,0,1,1,1,0,0,0,1,1,1,1,1,0,0,1,0,1,0,1,0,1,1,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,1,1,0,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1,1,1,0,1,1,0,1,0,1,1,1,0,1,0,1,0,0,1,0,1,1,1,0,1,0,0,0,1,1,1,0,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,0,0,0,1,0,0,1,1,0,1,1,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,0,1,1,0,0,0,1,1,1,0,0,1,1,1,0,1,1,0,1,1,1,1,0,0,1,0,1,0,1,0,0,1,0,0,1,0,0,1,0,1,1,1,1,1,1,0,0,1,0,1,0,1,1,1,0,1,1,1,0,0,0,0,0,1,0,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,0,1,0,1,0,1,1,1,0,1,1,1,1,0,1,1,0,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,0,1,0,1,0,1,1,0,1,1,1,1,1,0,1,0,0,0,0,0,0,0,1,1,1,0,0,1,0,1,1,1,0,1,1,0,1,0,0,0,0,1,1,1,1,0,0,1,1,1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,0,0,1,1,0,0,0,0,1,1,0,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,0,0,1,0,1,0,1,1,1,1,0,1,1,0,0,0,1,1,0,0,1,0,1,1,0,0,0,1,1,1,1,1,0,1,0,0,1,1,0,1,0,1,0,1,1,1,1,0,1,1,1,0,0,0,1,1,1,1,1,0,0,1,1,0,1,1,1,1,0,0,0,1,1,0,1,0,1,1,1,1,0,1,0,1,1,0,0,1,1,1,1,0,0,0,1,0,1,0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,0,1,1,1,0,1,1,0,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,0,0,0,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,0,1,0,0,1,0,0,1,0,1,0,1,1,1,0,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,0,1,1,0,0,0,1,1,1,0,0,0,1,1,1,0,0,1,0,1,1,1,0,0,1,0,0,1,0,1,1,1,1,1,0,0,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,0,1,0,1,0,1,0,1,1,1,1,0,1,0,1,0,1,1,1,1,1,1,0,0,1,1,0,1,0,1,0,0,1,0,1,1,0,0,1,1,1,0,0,0,1,1,0,1,1,0,1,0,1,0,1,1,1,1,1,0,0,1,1,0,0,0,0,1,1,1,1,1,0,1,1,0,1,0,1,0,0,0,0,1,1,0,0,0,1,0,0,1,1,1,0,1,0,0,1,0,1,1,1,1,0,0,1,1,1,1,0,0,1,0,1,0,1,0,0,1,0,1,0,1,1,1,0,0,1,1,1,0,1,1,1,1,0,1,1,0,1,0,0,0,1,0,0,0,1,0,1,1,0,1,1,1,0,1,1,0,0,0,0,0,0,0,0,1,0,1,1,1,1,0,1,1,1,1,1,0,1,1,0,1,1,0,0,1,1,0,1,0,0,0,0,1,0,1,1,1,0,1,0,1,1,1,1,1,0,0,0,1,0,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,1,0,1,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,0,1,1,1,0,0,0,1,1,1,0,1,1,1,1,0,1,0,1,0,0,0,1,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,0,1,1,1,1,1,1,0,0,1,1,1,1,0,1,1,1,1,1,1,1,1,0,0,0,1,0,1,0,1,1,0,0,1,1,1,1,0,1,0,0,0,1,0,0,0,1,1,0,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,0,1,1,0,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,0,0,0,1,1,1,0,1,1,1,1,0,1,0,1,1,1,1,0,1,1,0,1,1,1,1,1,1,0,1,0,0,1,0,1,0,1,1,0,0,1,1,0,1,1,1,0,1,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,0,1,1,1,0,0,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,1,0,0,1,0,1,1,1,0,0,1,0,1,0,1,0,1,1,0,1,0,0,0,1,1,1,0,1,0,0,0,1,1,1,0,0,0,1,0,1,1,1,1,1,0,1,1,1,0,0,1,0,1,0,1,1,0,1,1,1,0,1,0,1,0,0,1,1,1,0,1,1,1,0,1,0,1,0,0,1,0,1,0,1,1,1,0,1,1,0,1,1,1,1,1,1,0,0,1,0,1,1,1,1,1,1,0,1,1,0,1,0,1,1,0,0,1,1,0,1,0,1,1,0,1,1,1,0,1,1,1,1,0,0,0,0,1,1,0,1,1,1,1,1,1,1,0,1,1,1,0,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,0,1,1,0,1,1,1,0,0,1,0,0,1,0,1,1,0,0,1,1,1,0,0,0,0,0,0,0,1,1,0,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,0,0,0,1,1,1,0,1,0,1,1,0,1,0,1,1,0,1,1,1,0,1,1,0,0,0,0,1,1,0,0,1,1,1,0,1,0,1,1,0,1,0,1,1,1,1,0,0,1,1,0,1,1,0,1,0,1,1,0,1,1,0,1,0,0,1,0,1,1,1,0,0,1,1,0,0,0,1,1,0,1,0,0,1,1,0,1,0,1,1,1,0,0,0,0,0,1,0,0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,1,1,1,1,1,0,0,0,0,0,0,1,1,0,1,0,0,0,0,1,1,0,0,0,0,0,1,0,1,1,0,1,0,0,1,1,0,0,1,0,0,0,1,1,0,0,1,1,0,1,1,1,0,0,0,1,1,1,1,0,1,1,1,1,0,1,0,1,1,0,0,1,0,1,0,1,0,0,1,0,1,1,1,1,0,1,0,1,0,0,1,0,0,1,1,1,1,1,1,1,1,0,1,1,0,1,0,0,1,0,1,1,1,0,1,1,1,1,0,1,0,0,0,1,0,1,1,0,1,1,0,0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,0,1,1,0,1,1,1,1,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,1,0,1,1,0,0,0,0,1,1,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,0,1,0,0,1,1,1,0,0,1,0,1,0,1,0,1,1,0,1,0,0,1,0,0,0,0,1,1,0,1,1,1,0,1,0,0,0,0,0,0,1,0,0,1,1,0,0,0,1,0,0,0,0,0,1,1,0,1,1,1,0,1,1,1,0,0,1,1,1,1,0,1,0,1,1,0,0,0,0,0,0,0,1,1,0,0,1,1,0,1,1,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,1,1,1,0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1,1,1,0,1,0,0,0,1,1,1,0,1,0,0,1,1,0,0,1,0,1,1,1,0,0,1,1,1,1,1,0,0,1,1,0,1,1,1,1,1,0,0,1,1,1,1,0,0,0,1,0,1,1,1,1,1,1,1,0,0,1,0,0,1,0,0,0,1,0,0,1,0,0,1,0,0,1,0,1,1,0,1,1,1,1],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[33.0,50.0,52.0,56.0,35.0,58.0,66.0,38.0,53.0,43.0,39.0,58.0,45.0,52.0,36.0,83.0,57.0,39.0,58.0,54.0,65.0,69.0,41.0,43.0,64.0,55.0,46.0,40.0,70.0,36.0,62.0,71.0,38.0,67.0,50.0,68.0,58.0,63.0,60.0,24.0,44.0,55.0,42.0,61.0,49.0,66.0,51.0,65.0,53.0,52.0,60.0,46.0,69.0,62.0,64.0,72.0,66.0,32.0,54.0,59.0,74.0,37.0,32.0,68.0,62.0,58.0,54.0,75.0,48.0,54.0,57.0,31.0,74.0,40.0,54.0,82.0,48.0,53.0,61.0,27.0,62.0,66.0,39.0,51.0,41.0,52.0,46.0,57.0,47.0,82.0,43.0,55.0,57.0,46.0,56.0,49.0,52.0,46.0,56.0,60.0,49.0,67.0,39.0,59.0,67.0,55.0,68.0,44.0,47.0,45.0,70.0,62.0,68.0,46.0,74.0,60.0,52.0,58.0,42.0,50.0,43.0,57.0,51.0,49.0,46.0,47.0,40.0,66.0,48.0,45.0,39.0,47.0,54.0,55.0,66.0,47.0,62.0,51.0,70.0,51.0,48.0,32.0,60.0,50.0,48.0,42.0,51.0,44.0,71.0,57.0,34.0,58.0,31.0,71.0,46.0,69.0,82.0,54.0,59.0,47.0,56.0,54.0,42.0,53.0,77.0,37.0,68.0,66.0,62.0,43.0,48.0,44.0,54.0,39.0,65.0,51.0,30.0,53.0,48.0,51.0,64.0,34.0,43.0,67.0,46.0,46.0,44.0,79.0,59.0,69.0,35.0,49.0,32.0,60.0,41.0,38.0,40.0,35.0,56.0,48.0,36.0,51.0,43.0,52.0,41.0,67.0,61.0,34.0,63.0,62.0,64.0,45.0,53.0,46.0,51.0,51.0,33.0,48.0,50.0,63.0,48.0,51.0,34.0,46.0,56.0,54.0,46.0,66.0,57.0,38.0,34.0,55.0,41.0,49.0,60.0,56.0,66.0,65.0,56.0,52.0,48.0,71.0,54.0,52.0,57.0,38.0,58.0,56.0,46.0,56.0,53.0,61.0,45.0,53.0,46.0,64.0,47.0,46.0,68.0,70.0,41.0,50.0,62.0,43.0,53.0,46.0,52.0,53.0,34.0,40.0,43.0,40.0,50.0,58.0,48.0,39.0,49.0,51.0,47.0,59.0,42.0,44.0,65.0,40.0,43.0,65.0,50.0,49.0,70.0,49.0,52.0,39.0,31.0,64.0,44.0,46.0,32.0,36.0,30.0,68.0,49.0,50.0,35.0,37.0,65.0,61.0,37.0,76.0,48.0,36.0,55.0,65.0,39.0,34.0,25.0,59.0,42.0,54.0,51.0,49.0,59.0,72.0,61.0,41.0,50.0,52.0,34.0,66.0,40.0,37.0,58.0,58.0,50.0,52.0,55.0,36.0,45.0,31.0,57.0,49.0,52.0,75.0,57.0,57.0,38.0,56.0,56.0,60.0,47.0,57.0,59.0,61.0,48.0,78.0,46.0,72.0,48.0,44.0,52.0,76.0,72.0,53.0,47.0,44.0,34.0,45.0,64.0,59.0,68.0,62.0,49.0,40.0,59.0,48.0,40.0,48.0,39.0,51.0,40.0,55.0,41.0,38.0,42.0,66.0,66.0,58.0,43.0,46.0,55.0,54.0,43.0,57.0,40.0,42.0,64.0,72.0,39.0,52.0,43.0,62.0,43.0,77.0,58.0,49.0,44.0,49.0,58.0,40.0,74.0,73.0,44.0,43.0,45.0,40.0,65.0,55.0,55.0,52.0,68.0,56.0,53.0,43.0,64.0,55.0,76.0,46.0,56.0,44.0,38.0,43.0,53.0,81.0,50.0,63.0,30.0,47.0,25.0,55.0,48.0,48.0,50.0,37.0,72.0,47.0,65.0,53.0,82.0,35.0,38.0,37.0,47.0,54.0,39.0,59.0,22.0,56.0,56.0,42.0,58.0,64.0,62.0,64.0,50.0,58.0,52.0,60.0,31.0,42.0,38.0,57.0,41.0,39.0,40.0,56.0,68.0,48.0,66.0,41.0,63.0,49.0,41.0,40.0,55.0,55.0,48.0,41.0,50.0,41.0,32.0,59.0,42.0,54.0,48.0,49.0,60.0,43.0,39.0,48.0,46.0,45.0,53.0,39.0,52.0,33.0,53.0,42.0,67.0,50.0,78.0,58.0,43.0,43.0,46.0,56.0,62.0,35.0,60.0,77.0,58.0,39.0,39.0,48.0,44.0,48.0,74.0,67.0,33.0,41.0,45.0,62.0,65.0,39.0,77.0,63.0,71.0,44.0,58.0,69.0,48.0,64.0,62.0,40.0,69.0,40.0,44.0,48.0,60.0,61.0,40.0,57.0,54.0,63.0,42.0,59.0,41.0,66.0,53.0,36.0,46.0,51.0,45.0,33.0,46.0,75.0,47.0,48.0,47.0,51.0,48.0,38.0,40.0,67.0,72.0,52.0,51.0,63.0,35.0,33.0,62.0,43.0,47.0,70.0,51.0,40.0,39.0,32.0,60.0,33.0,57.0,68.0,69.0,54.0,60.0,57.0,18.0,55.0,46.0,54.0,46.0,54.0,47.0,35.0,48.0,45.0,47.0,41.0,42.0,41.0,41.0,52.0,31.0,41.0,55.0,73.0,64.0,29.0,63.0,54.0,63.0,45.0,65.0,47.0,49.0,57.0,44.0,53.0,29.0,56.0,52.0,44.0,25.0,54.0,40.0,46.0,67.0,45.0,45.0,47.0,65.0,54.0,41.0,43.0,54.0,52.0,68.0,82.0,42.0,75.0,74.0,43.0,65.0,35.0,42.0,55.0,42.0,51.0,71.0,41.0,47.0,28.0,42.0,55.0,70.0,67.0,49.0,55.0,37.0,48.0,37.0,46.0,34.0,63.0,53.0,54.0,76.0,50.0,69.0,48.0,45.0,42.0,39.0,55.0,43.0,38.0,51.0,60.0,70.0,71.0,62.0,69.0,34.0,52.0,56.0,37.0,43.0,67.0,53.0,49.0,44.0,51.0,60.0,37.0,50.0,31.0,45.0,53.0,45.0,66.0,68.0,44.0,50.0,51.0,66.0,48.0,45.0,61.0,43.0,47.0,58.0,33.0,55.0,56.0,54.0,52.0,52.0,64.0,39.0,56.0,73.0,56.0,64.0,43.0,39.0,59.0,52.0,43.0,48.0,48.0,46.0,53.0,59.0,49.0,31.0,72.0,76.0,54.0,39.0,60.0,59.0,42.0,49.0,32.0,41.0,68.0,60.0,76.0,43.0,42.0,74.0,68.0,43.0,53.0,71.0,48.0,37.0,78.0,42.0,47.0,60.0,50.0,41.0,77.0,67.0,64.0,49.0,62.0,46.0,48.0,34.0,66.0,50.0,47.0,71.0,51.0,44.0,64.0,55.0,65.0,62.0,54.0,51.0,57.0,39.0,50.0,52.0,40.0,42.0,46.0,47.0,53.0,51.0,52.0,44.0,43.0,52.0,49.0,53.0,48.0,50.0,71.0,43.0,53.0,53.0,61.0,56.0,47.0,68.0,32.0,40.0,46.0,73.0,56.0,74.0,55.0,74.0,50.0,66.0,42.0,41.0,51.0,42.0,46.0,38.0,46.0,41.0,59.0,62.0,64.0,54.0,54.0,61.0,62.0,38.0,48.0,56.0,73.0,26.0,34.0,50.0,44.0,62.0,32.0,44.0,68.0,45.0,74.0,47.0,36.0,48.0,66.0,56.0,64.0,61.0,49.0,57.0,54.0,66.0,47.0,65.0,63.0,44.0,53.0,35.0,62.0,49.0,64.0,39.0,55.0,67.0,54.0,41.0,57.0,67.0,59.0,38.0,36.0,28.0,31.0,72.0,52.0,49.0,50.0,43.0,49.0,58.0,68.0,49.0,39.0,54.0,63.0,51.0,61.0,62.0,77.0,31.0,70.0,42.0,55.0,42.0,38.0,52.0,55.0,46.0,56.0,71.0,48.0,38.0,50.0,76.0,60.0,68.0,73.0,36.0,66.0,43.0,42.0,61.0,53.0,28.0,34.0,55.0,41.0,44.0,34.0,55.0,63.0,51.0,44.0,45.0,48.0,45.0,46.0,40.0,39.0,51.0,43.0,41.0,67.0,63.0,46.0,78.0,58.0,51.0,62.0,42.0,36.0,70.0,41.0,65.0,44.0,39.0,50.0,47.0,41.0,48.0,74.0,48.0,49.0,58.0,49.0,61.0,61.0,51.0,37.0,49.0,63.0,54.0,50.0,46.0,60.0,50.0,67.0,67.0,47.0,57.0,30.0,62.0,47.0,48.0,42.0,42.0,35.0,54.0,49.0,46.0,61.0,69.0,40.0,30.0,46.0,47.0,77.0,54.0,50.0,51.0,26.0,39.0,52.0,49.0,52.0,27.0,45.0,55.0,67.0,41.0,56.0,66.0,67.0,52.0,57.0,73.0,60.0,44.0,45.0,66.0,60.0,69.0,50.0,78.0,46.0,48.0,41.0,60.0,39.0,64.0,46.0,43.0,37.0,42.0,44.0,40.0,58.0,46.0,57.0,54.0,36.0,66.0,30.0,37.0,58.0,56.0,47.0,61.0,51.0,24.0,35.0,60.0,64.0,40.0,57.0,53.0,50.0,53.0,38.0,56.0,59.0,57.0,39.0,45.0,69.0,49.0,42.0,58.0,50.0,68.0,71.0,44.0,34.0,41.0,48.0,68.0,48.0,55.0,49.0,63.0,37.0,44.0,63.0,42.0,44.0,65.0,44.0,63.0,55.0,47.0,55.0,51.0,54.0,52.0,60.0,71.0,44.0,38.0,41.0,44.0,55.0,42.0,41.0,38.0,58.0,39.0,46.0,39.0,60.0,41.0,44.0,60.0,62.0,64.0,60.0,59.0,65.0,50.0,61.0,44.0,40.0,58.0,46.0,54.0,63.0,37.0,45.0,41.0,58.0,65.0,56.0,44.0,63.0,55.0,47.0,47.0,39.0,52.0,32.0,41.0,48.0,41.0,46.0,55.0,48.0,47.0,38.0,69.0,70.0,60.0,45.0,50.0,44.0,44.0,50.0,49.0,72.0,37.0,68.0,46.0,57.0,54.0,36.0,78.0,52.0,40.0,49.0,81.0,64.0,44.0,43.0,50.0,69.0,54.0,62.0,64.0,46.0,57.0,40.0,52.0,34.0,50.0,21.0,43.0,46.0,41.0,74.0,50.0,38.0,39.0,76.0,60.0,37.0,56.0,66.0,68.0,49.0,39.0,56.0,47.0,65.0,42.0,36.0,57.0,57.0,37.0,54.0,32.0,54.0,54.0,62.0,68.0,37.0,42.0,48.0,66.0,43.0,59.0,59.0,54.0,50.0,52.0,33.0,44.0,53.0,42.0,74.0,54.0,46.0,52.0,52.0,43.0,33.0,60.0,61.0,54.0,57.0,62.0,60.0,64.0,69.0,73.0,47.0,44.0,47.0,44.0,58.0,65.0,32.0,46.0,52.0,58.0,62.0,66.0,77.0,35.0,52.0,40.0,72.0,46.0,51.0,48.0,43.0,65.0,49.0,48.0,38.0,45.0,58.0,62.0,48.0,34.0,38.0,40.0,50.0,59.0,56.0,51.0,80.0,39.0,55.0,46.0,45.0,48.0,68.0,53.0,42.0,34.0,44.0,59.0,45.0,66.0,57.0,44.0,53.0,83.0,72.0,69.0,62.0,50.0,48.0,60.0,63.0,66.0,53.0,80.0,68.0,36.0,32.0,59.0,69.0,51.0,50.0,51.0,44.0,50.0,57.0,44.0,52.0,43.0,33.0,41.0,30.0,61.0,59.0,61.0,49.0,57.0,64.0,47.0,54.0,48.0,47.0,45.0,65.0,49.0,76.0,67.0,56.0,42.0,48.0,58.0,51.0,68.0,54.0,65.0,67.0,46.0,62.0,55.0,57.0,47.0,36.0,57.0,52.0,68.0,65.0,63.0,54.0,43.0,35.0,36.0,74.0,41.0,42.0,39.0,64.0,28.0,52.0,52.0,46.0,58.0,70.0,48.0,57.0,54.0,54.0,68.0,54.0,38.0,74.0,35.0,49.0,59.0,40.0,41.0,62.0,66.0,65.0,71.0,47.0,47.0,65.0,49.0,61.0,81.0,60.0,47.0,69.0,34.0,78.0,34.0,59.0,42.0,46.0,46.0,55.0,31.0,47.0,45.0,50.0,55.0,54.0,62.0,50.0,34.0,62.0,42.0,49.0,42.0,47.0,56.0,49.0,73.0,47.0,53.0,58.0,61.0,49.0,38.0,33.0,57.0,71.0,55.0,43.0,63.0,42.0,60.0,62.0,55.0,55.0,56.0,65.0,50.0,47.0,63.0,46.0,39.0,29.0,45.0,50.0,62.0,38.0,47.0,54.0,49.0,63.0,51.0,43.0,42.0,45.0,54.0,55.0,35.0,30.0,50.0,40.0,43.0,43.0,38.0,57.0,50.0,49.0,58.0,44.0,58.0,53.0,46.0,47.0,44.0,38.0,42.0,56.0,40.0,60.0,31.0,53.0,62.0,37.0,77.0,56.0,55.0,24.0,50.0,55.0,68.0,55.0,58.0,37.0,51.0,40.0,47.0,64.0,51.0,61.0,53.0,64.0,32.0,46.0,68.0,36.0,54.0,46.0,51.0,64.0,30.0,51.0,56.0,43.0,54.0,46.0,44.0,34.0,63.0,61.0,42.0,63.0,57.0,66.0,37.0,59.0,42.0,48.0,60.0,39.0,59.0,36.0,43.0,54.0,57.0,47.0,41.0,83.0,43.0,53.0,70.0,60.0,42.0,48.0,34.0,68.0,44.0,61.0,55.0,71.0,54.0,38.0,49.0,52.0,60.0,70.0,55.0,40.0,36.0,70.0,47.0,57.0,42.0,51.0,44.0,66.0,82.0,48.0,53.0,61.0,54.0,48.0,37.0,84.0,47.0,33.0,63.0,60.0,44.0,37.0,36.0,42.0,61.0,46.0,60.0,37.0,41.0,68.0,54.0,66.0,69.0,68.0,72.0,48.0,62.0,42.0,56.0,51.0,36.0,56.0,43.0,49.0,46.0,69.0,40.0,39.0,52.0,46.0,55.0,41.0,48.0,58.0,71.0,46.0,58.0,71.0,79.0,33.0,46.0,46.0,65.0,57.0,38.0,70.0,46.0,62.0,31.0,42.0,57.0,54.0,56.0,67.0,51.0,49.0,37.0,49.0,42.0,58.0,62.0,60.0,54.0,40.0,51.0,58.0,43.0,33.0,62.0,59.0,49.0,50.0,42.0,56.0,35.0,45.0,44.0,67.0,52.0,52.0,62.0,71.0,54.0,47.0,49.0,54.0,52.0,39.0,51.0,49.0,65.0,55.0,44.0,51.0,59.0,70.0,53.0,49.0,45.0,41.0,55.0,43.0,51.0,59.0,60.0,68.0,60.0,45.0,51.0,37.0,60.0,52.0,50.0,46.0,50.0,64.0,45.0,41.0,54.0,40.0,55.0,38.0,40.0,70.0,60.0,43.0,59.0,40.0,55.0,81.0,39.0,53.0,80.0,61.0,53.0,54.0,63.0,58.0,46.0,38.0,55.0,63.0,43.0,68.0,50.0,50.0,59.0,57.0,55.0,50.0,61.0,55.0,63.0,49.0,56.0,71.0,40.0,84.0,43.0,61.0,46.0,55.0,33.0,65.0,68.0,57.0,76.0,58.0,56.0,39.0,29.0,54.0,47.0,62.0,52.0,47.0,64.0,34.0,59.0,71.0,47.0,67.0,59.0,57.0,58.0,39.0,41.0,41.0,52.0,55.0,46.0,73.0,59.0,39.0,49.0,43.0,47.0,64.0,46.0,46.0,62.0,47.0,32.0,61.0,68.0,66.0,46.0,35.0,45.0,32.0,41.0,29.0,65.0,43.0,43.0,59.0,70.0,41.0,39.0,41.0,45.0,53.0,44.0,52.0,47.0,62.0,50.0,63.0,56.0,45.0,42.0,59.0,39.0,47.0,84.0,52.0,49.0,63.0,38.0,53.0,65.0,45.0,42.0,43.0,44.0,40.0,49.0,37.0,54.0,44.0,63.0,34.0,50.0,55.0,67.0,40.0,48.0,50.0,49.0,64.0,50.0,42.0,40.0,51.0,60.0,70.0,31.0,57.0,38.0,44.0,64.0,38.0,48.0,43.0,43.0,69.0,66.0,47.0,67.0,42.0,64.0,66.0,43.0,41.0,42.0,76.0,46.0,53.0,64.0,49.0,48.0,37.0,39.0,37.0,57.0,40.0,62.0,50.0,54.0,46.0,39.0,45.0,67.0,62.0,44.0,56.0,31.0,48.0,63.0,50.0,37.0,56.0,62.0,53.0,37.0,36.0,47.0,51.0,57.0,59.0,46.0,38.0,39.0,42.0,38.0,47.0,40.0,42.0,57.0,45.0,48.0,66.0,53.0,58.0,49.0,42.0,47.0,51.0,44.0,55.0,48.0,57.0,37.0,42.0,52.0,41.0,48.0,52.0,52.0,48.0,71.0,43.0,41.0,60.0,75.0,40.0,67.0,66.0,68.0,54.0,52.0,45.0,29.0,54.0,59.0,53.0,64.0,53.0,41.0,52.0,57.0,51.0,54.0,51.0,47.0,57.0,51.0,68.0,46.0,41.0,68.0,33.0,45.0,29.0,64.0,58.0,42.0,48.0,36.0,37.0,51.0,67.0,46.0,56.0,66.0,55.0,55.0,53.0,52.0,39.0,49.0,39.0,34.0,40.0,60.0,28.0,58.0,59.0,41.0,63.0,42.0,45.0,53.0,57.0,74.0,41.0,42.0,24.0,65.0,56.0,49.0,60.0,71.0,55.0,47.0,58.0,58.0,55.0,39.0,70.0,69.0,43.0,49.0,48.0,56.0,47.0,41.0,56.0,33.0,60.0,48.0,66.0,70.0,52.0,56.0,37.0,38.0,58.0,49.0,79.0,54.0,67.0,61.0,42.0,44.0,48.0,47.0,65.0,37.0,36.0,48.0,42.0,38.0,46.0,74.0,53.0,64.0,70.0,33.0,39.0,53.0,58.0,58.0,57.0,34.0,40.0,53.0,39.0,46.0,46.0,43.0,68.0,41.0,38.0,46.0,58.0,35.0,60.0,63.0,41.0,49.0,47.0,59.0,45.0,50.0,39.0,66.0,47.0,59.0,80.0,59.0,77.0,33.0,42.0,43.0,37.0,56.0,69.0,46.0,69.0,38.0,64.0,56.0,48.0,56.0,57.0,83.0,36.0,71.0,56.0,48.0,29.0,73.0,38.0,67.0,35.0,47.0,53.0,32.0,47.0,56.0,50.0,50.0,69.0,42.0,39.0,61.0,56.0,44.0,45.0,43.0,54.0,42.0,41.0,53.0,55.0,43.0,47.0,35.0,38.0,46.0,56.0,55.0,40.0,60.0,49.0,63.0,65.0,40.0,36.0,45.0,46.0,61.0,68.0,47.0,47.0,48.0,37.0,45.0,38.0,39.0,56.0,77.0,53.0,34.0,44.0,52.0,45.0,49.0,68.0,39.0,46.0,49.0,64.0,51.0,43.0,28.0,52.0,61.0,37.0,56.0,74.0,70.0,51.0,37.0,53.0,63.0,61.0,44.0,63.0,42.0,48.0,51.0,55.0,57.0,59.0,73.0,49.0,69.0,66.0,42.0,58.0,49.0,63.0,82.0,45.0,51.0,60.0,78.0,37.0,45.0,66.0,37.0,67.0,38.0,47.0,47.0,22.0,44.0,50.0,35.0,67.0,56.0,44.0,61.0,41.0,45.0,64.0,50.0,57.0,53.0,45.0,62.0,41.0,51.0,31.0,42.0,47.0,71.0,47.0,63.0,65.0,43.0,79.0,66.0,45.0,48.0,39.0,66.0,60.0,39.0,73.0,42.0,48.0,46.0,54.0,52.0,52.0,38.0,55.0,50.0,59.0,71.0,54.0,47.0,32.0,54.0,37.0,50.0,56.0,22.0,36.0,41.0,53.0,41.0,44.0,40.0,54.0,40.0,47.0,83.0,36.0,47.0,43.0,41.0,54.0,55.0,49.0,35.0,47.0,37.0,58.0,36.0,47.0,59.0,64.0,55.0,30.0,50.0,40.0,55.0,57.0,80.0,62.0,34.0,56.0,67.0,35.0,55.0,58.0,37.0,68.0,57.0,66.0,47.0,51.0,41.0,37.0,35.0,55.0,44.0,47.0,51.0,54.0,61.0,33.0,60.0,55.0,46.0,34.0,41.0,60.0,39.0,38.0,36.0,45.0,53.0,39.0,48.0,58.0,62.0,55.0,56.0,29.0,35.0,77.0,71.0,57.0,57.0,53.0,43.0,59.0,60.0,34.0,51.0,48.0,50.0,49.0,57.0,66.0,60.0,66.0,44.0,39.0,53.0,32.0,51.0,52.0,71.0,47.0,39.0,57.0,49.0,46.0,57.0,43.0,53.0,38.0,47.0,44.0,45.0,60.0,47.0,45.0,50.0,39.0,52.0,35.0,52.0,54.0,66.0,30.0,38.0,39.0,52.0,52.0,43.0,49.0,58.0,39.0,59.0,60.0,63.0,38.0,61.0,70.0,45.0,44.0,52.0,58.0,45.0,40.0,75.0,44.0,37.0,53.0,54.0,58.0,52.0,58.0,34.0,56.0,60.0,68.0,68.0,60.0,43.0,44.0,75.0,50.0,45.0,60.0,51.0,64.0,45.0,62.0,55.0,71.0,38.0,72.0,67.0,55.0,56.0,52.0,38.0,43.0,48.0,69.0,37.0,63.0,71.0,44.0,67.0,48.0,61.0,44.0,62.0,68.0,36.0,62.0,44.0,60.0,62.0,75.0,33.0,56.0,40.0,46.0,43.0,64.0,51.0,63.0,59.0,41.0,40.0,47.0,45.0,41.0,53.0,58.0,40.0,69.0,46.0,65.0,48.0,41.0,42.0,71.0,65.0,56.0,33.0,68.0,47.0,43.0,53.0,56.0,60.0,54.0,49.0,38.0,38.0,44.0,28.0,54.0,39.0,48.0,50.0,41.0,33.0,50.0,41.0,45.0,52.0,45.0,47.0,38.0,51.0,56.0,44.0,48.0,46.0,60.0,41.0,40.0,59.0,61.0,52.0,53.0,65.0,35.0,62.0,46.0,42.0,44.0,63.0,40.0,36.0,52.0,32.0,79.0,48.0,49.0,37.0,52.0,43.0,50.0,41.0,49.0,42.0,45.0,55.0,71.0,61.0,54.0,43.0,65.0,45.0,40.0,38.0,53.0,62.0,58.0,64.0,62.0,52.0,32.0,35.0,39.0,50.0,51.0,50.0,49.0,51.0,50.0,53.0,44.0,54.0,54.0,54.0,53.0,53.0,63.0,39.0,50.0,56.0,42.0,58.0,44.0,59.0,54.0,41.0,63.0,52.0,63.0,50.0,36.0,42.0,57.0,47.0,71.0,56.0,62.0,77.0,72.0,64.0,58.0,71.0,42.0,46.0,40.0,63.0,76.0,41.0,49.0,51.0,44.0,44.0,62.0,40.0,60.0,44.0,53.0,22.0,55.0,67.0,60.0,51.0,46.0,55.0,52.0,81.0,55.0,74.0,54.0,76.0,41.0,33.0,67.0,40.0,46.0,53.0,59.0,63.0,60.0,55.0,48.0,65.0,52.0,43.0,67.0,53.0,44.0,48.0,31.0,54.0,42.0,52.0,45.0,37.0,36.0,70.0,49.0,45.0,46.0,46.0,53.0,55.0,46.0,63.0,35.0,36.0,61.0,50.0,48.0,80.0,34.0,47.0,65.0,31.0,61.0,58.0,40.0,49.0,46.0,67.0,47.0,77.0,40.0,43.0,58.0,56.0,53.0,56.0,59.0,71.0,73.0,54.0,54.0,46.0,69.0,45.0,31.0,39.0,51.0,37.0,61.0,50.0,60.0,34.0,41.0,57.0,63.0,35.0,74.0,64.0,35.0,54.0,36.0,49.0,39.0,47.0,47.0,46.0,43.0,48.0,72.0,57.0,28.0,47.0,53.0,66.0,67.0,64.0,60.0,59.0,66.0,65.0,68.0,51.0,52.0,44.0,43.0,53.0,53.0,45.0,62.0,72.0,47.0,48.0,49.0,51.0,67.0,37.0,50.0,46.0,41.0,45.0,68.0,42.0,31.0,55.0,37.0,42.0,46.0,32.0,50.0,43.0,25.0,42.0,41.0,44.0,39.0,49.0,58.0,35.0,45.0,64.0,61.0,42.0,52.0,69.0,44.0,58.0,51.0,55.0,70.0,59.0,39.0,46.0,68.0,49.0,42.0,46.0,47.0,57.0,46.0,67.0,39.0,35.0,46.0,64.0,60.0,48.0,41.0,41.0,57.0,61.0,45.0,30.0,52.0,28.0,50.0,61.0,31.0,34.0,41.0,68.0,43.0,42.0,45.0,57.0,40.0,65.0,53.0,41.0,66.0,57.0,25.0,43.0,51.0,58.0,52.0,44.0,58.0,65.0,34.0,48.0,62.0,41.0,75.0,39.0,51.0,45.0,64.0,73.0,56.0,77.0,68.0,62.0,48.0,48.0,45.0,32.0,48.0,56.0,51.0,48.0,48.0,41.0,53.0,48.0,64.0,49.0,58.0,70.0,62.0,44.0,52.0,53.0,40.0,46.0,58.0,50.0,53.0,57.0,49.0,55.0,42.0,59.0,27.0,40.0,69.0,38.0,38.0,70.0,57.0,54.0,66.0,49.0,53.0,38.0,45.0,48.0,63.0,55.0,45.0,56.0,52.0,66.0,45.0,48.0,41.0,51.0,45.0,48.0,52.0,48.0,54.0,35.0,41.0,59.0,53.0,59.0,43.0,66.0,52.0,42.0,56.0,57.0,47.0,76.0,58.0,35.0,40.0,32.0,63.0,48.0,32.0,69.0,41.0,59.0,54.0,43.0,69.0,60.0,54.0,57.0,53.0,39.0,43.0,56.0,50.0,31.0,28.0,53.0,43.0,48.0,44.0,58.0,52.0,62.0,44.0,53.0,38.0,39.0,37.0,68.0,66.0,70.0,49.0,35.0,49.0,44.0,41.0,57.0,41.0,35.0,43.0,65.0,61.0,48.0,38.0,42.0,50.0,57.0,63.0,64.0,70.0,57.0,55.0,34.0,37.0,54.0,39.0,55.0,53.0,38.0,37.0,50.0,70.0,34.0,40.0,46.0,45.0,61.0,69.0,44.0,54.0,58.0,60.0,50.0,42.0,63.0,47.0,49.0,43.0,48.0,45.0,66.0,34.0,48.0,55.0,50.0,36.0,44.0,54.0,45.0,58.0,55.0,63.0,39.0,52.0,44.0,58.0,42.0,59.0,32.0,53.0,58.0,49.0,62.0,48.0,31.0,67.0,44.0,29.0,70.0,36.0,49.0,43.0,62.0,64.0,56.0,29.0,72.0,47.0,60.0,42.0,56.0,42.0,52.0,59.0,45.0,55.0,65.0,69.0,43.0,56.0,44.0,59.0,69.0,57.0,30.0,41.0,41.0,50.0,45.0,62.0,60.0,48.0,66.0,48.0,58.0,37.0,62.0,34.0,32.0,48.0,74.0,35.0,61.0,56.0,41.0,65.0,70.0,64.0,62.0,53.0,63.0,57.0,59.0,59.0,52.0,49.0,72.0,40.0,61.0,52.0,62.0,46.0,46.0,55.0,68.0,43.0,71.0,51.0,52.0,41.0,64.0,58.0,63.0,47.0,50.0,69.0,43.0,65.0,52.0,54.0,47.0,53.0,47.0,38.0,75.0,47.0,46.0,54.0,42.0,50.0,61.0,40.0,64.0,50.0,62.0,62.0,49.0,68.0,37.0,45.0,33.0,51.0,47.0,42.0,76.0,65.0,40.0,32.0,47.0,63.0,46.0,38.0,43.0,63.0,55.0,56.0,36.0,45.0,42.0,60.0,36.0,36.0,46.0,63.0,48.0,50.0,44.0,61.0,51.0,42.0,44.0,35.0,47.0,62.0,55.0,32.0,60.0,48.0,43.0,41.0,60.0,46.0,36.0,46.0,52.0,44.0,51.0,49.0,68.0,47.0,48.0,60.0,70.0,50.0,54.0,54.0,56.0,55.0,44.0,49.0,21.0,66.0,62.0,62.0,60.0,46.0,45.0,48.0,55.0,49.0,61.0,41.0,48.0,61.0,53.0,49.0,41.0,33.0,52.0,49.0,56.0,39.0,48.0,69.0,36.0,69.0,48.0,69.0,67.0,42.0,45.0,60.0,38.0,52.0,67.0,38.0,50.0,52.0,24.0,36.0,41.0,45.0,47.0,73.0,60.0,44.0,66.0,54.0,44.0,25.0,50.0,37.0,69.0,58.0,37.0,42.0,71.0,61.0,65.0,52.0,65.0,54.0,61.0,55.0,32.0,57.0,56.0,44.0,47.0,56.0,37.0,31.0,29.0,45.0,44.0,53.0,34.0,40.0,63.0,52.0,59.0,51.0,69.0,46.0,57.0,27.0,66.0,51.0,38.0,54.0,45.0,68.0,52.0,41.0,67.0,52.0,42.0,44.0,58.0,63.0,35.0,47.0,54.0,44.0,44.0,49.0,47.0,50.0,45.0,39.0,42.0,43.0,54.0,40.0,47.0,59.0,60.0,52.0,61.0,46.0,53.0,45.0,80.0,32.0,53.0,75.0,44.0,62.0,50.0,44.0,46.0,66.0,49.0,57.0,57.0,56.0,64.0,53.0,58.0,54.0,46.0,37.0,33.0,67.0,55.0,44.0,66.0,54.0,55.0,59.0,68.0,49.0,49.0,64.0,40.0,61.0,70.0,57.0,73.0,46.0,48.0,63.0,49.0,57.0,59.0,50.0,39.0,50.0,50.0,50.0,44.0,48.0,45.0,36.0,39.0,56.0,51.0,47.0,40.0,72.0,54.0,30.0,45.0,60.0,44.0,39.0,67.0,68.0,55.0,55.0,42.0,47.0,74.0,57.0,59.0,39.0,41.0,61.0,28.0,79.0,68.0,34.0,37.0,37.0,36.0,60.0,44.0,49.0,28.0,38.0,43.0,68.0,50.0,48.0,44.0,37.0,40.0,61.0,41.0,70.0,53.0,59.0,53.0,46.0,80.0,45.0,59.0,41.0,38.0,50.0,48.0,60.0,45.0,65.0,66.0,62.0,68.0,54.0,45.0,70.0,66.0,57.0,50.0,51.0,36.0,68.0,51.0,64.0,44.0,50.0,43.0,51.0,50.0,75.0,31.0,58.0,57.0,57.0,47.0,68.0,38.0,65.0,42.0,54.0,55.0,45.0,42.0,33.0,61.0,48.0,45.0,36.0,57.0,63.0,64.0,38.0,37.0,46.0,28.0,51.0,68.0,79.0,51.0,43.0,63.0,44.0,55.0,38.0,36.0,58.0,39.0,59.0,47.0,49.0,70.0,51.0,57.0,44.0,55.0,52.0,53.0,70.0,53.0,60.0,56.0,45.0,64.0,66.0,38.0,38.0,57.0,55.0,51.0,72.0,70.0,54.0,55.0,38.0,66.0,38.0,66.0,43.0,46.0,40.0,50.0,38.0,52.0,60.0,54.0,62.0,72.0,84.0,44.0,66.0,41.0,47.0,44.0,67.0,36.0,48.0,62.0,30.0,42.0,51.0,44.0,45.0,72.0,62.0,57.0,47.0,60.0,54.0,43.0,36.0,37.0,38.0,49.0,55.0,64.0,66.0,46.0,49.0,36.0,45.0,30.0,52.0,53.0,64.0,67.0,61.0,54.0,45.0,61.0,56.0,35.0,38.0,30.0,49.0,38.0,42.0,42.0,55.0,53.0,36.0,58.0,29.0,42.0,47.0,41.0,39.0,49.0,35.0,45.0,73.0,39.0,53.0,38.0,38.0,44.0,61.0,41.0,58.0,39.0,50.0,44.0,56.0,64.0,37.0,66.0,53.0,54.0,53.0,73.0,33.0,57.0,49.0,47.0,56.0,32.0,61.0,52.0,43.0,65.0,39.0,68.0,48.0,44.0,50.0,43.0,61.0,56.0,49.0,39.0,36.0,45.0,45.0,53.0,40.0,45.0,32.0,61.0,30.0,47.0,67.0,46.0,30.0,47.0,55.0,39.0,44.0,71.0,45.0,51.0,56.0,40.0,51.0,46.0,55.0,76.0,56.0,58.0,74.0,56.0,56.0,27.0,44.0,54.0,62.0,55.0,65.0,49.0,39.0,56.0,62.0,66.0,53.0,51.0,42.0,42.0,51.0,70.0,46.0,42.0,58.0,55.0,39.0,59.0,58.0,53.0,47.0,34.0,43.0,72.0,79.0,34.0,46.0,58.0,71.0,65.0,49.0,70.0,59.0,39.0,38.0,43.0,37.0,61.0,39.0,38.0,73.0,63.0,46.0,41.0,51.0,59.0,50.0,59.0,80.0,48.0,67.0,42.0,64.0,35.0,46.0,51.0,60.0,45.0,58.0,52.0,29.0,63.0,43.0,72.0,29.0,57.0,57.0,29.0,46.0,29.0,48.0,52.0,61.0,58.0,42.0,55.0,59.0,49.0,77.0,39.0,70.0,56.0,24.0,64.0,37.0,49.0,65.0,57.0,51.0,49.0,57.0,51.0,60.0,66.0,41.0,55.0,75.0,38.0,44.0,51.0,25.0,58.0,44.0,63.0,44.0,29.0,35.0,38.0,54.0,70.0,54.0,48.0,43.0,52.0,58.0,61.0,45.0,65.0,49.0,36.0,55.0,54.0,68.0,36.0,34.0,62.0,48.0,60.0,44.0,49.0,63.0,61.0,52.0,47.0,57.0,72.0,68.0,42.0,52.0,61.0,47.0,44.0,41.0,49.0,57.0,46.0,76.0,55.0,43.0,46.0,44.0,45.0,45.0,46.0,60.0,67.0,34.0,38.0,44.0,57.0,65.0,50.0,40.0,66.0,27.0,64.0,45.0,58.0,78.0,57.0,77.0,60.0,68.0,46.0,53.0,40.0,48.0,62.0,54.0,36.0,40.0,69.0,36.0,49.0,48.0,28.0,68.0,41.0,35.0,70.0,46.0,50.0,77.0,60.0,47.0,69.0,67.0,60.0,46.0,39.0,41.0,42.0,53.0,46.0,47.0,37.0,49.0,52.0,43.0,73.0,63.0,42.0,54.0,58.0,66.0,60.0,90.0,42.0,65.0,45.0,48.0,40.0,43.0,61.0,43.0,48.0,36.0,54.0,45.0,54.0,68.0,56.0,51.0,35.0,46.0,71.0,64.0,49.0,43.0,60.0,66.0,64.0,56.0,56.0,70.0,40.0,41.0,54.0,51.0,43.0,66.0,58.0,48.0,36.0,49.0,50.0,51.0,30.0,46.0,52.0,68.0,34.0,77.0,58.0,50.0,49.0,49.0,64.0,52.0,41.0,56.0,48.0,58.0,51.0,63.0,50.0,54.0,61.0,39.0,63.0,37.0,46.0,49.0,53.0,57.0,69.0,45.0,71.0,48.0,43.0,43.0,41.0,35.0,53.0,49.0,52.0,38.0,53.0,55.0,55.0,48.0,47.0,71.0,37.0,59.0,51.0,40.0,36.0,54.0,58.0,59.0,45.0,38.0,45.0,69.0,57.0,42.0,55.0,38.0,60.0,37.0,53.0,46.0,51.0,57.0,49.0,40.0,64.0,45.0,43.0,49.0,42.0,61.0,74.0,60.0,29.0,67.0,69.0,41.0,59.0,51.0,46.0,49.0,55.0,55.0,33.0,65.0,58.0,39.0,64.0,67.0,53.0,45.0,49.0,49.0,51.0,51.0,54.0,49.0,53.0,45.0,50.0,37.0,51.0,67.0,56.0,52.0,36.0,65.0,30.0,69.0,33.0,55.0,50.0,63.0,54.0,50.0,48.0,38.0,74.0,57.0,58.0,61.0,55.0,55.0,56.0,73.0,55.0,40.0,54.0,61.0,33.0,50.0,48.0,48.0,41.0,35.0,68.0,42.0,49.0,50.0,63.0,56.0,55.0,41.0,37.0,47.0,50.0,64.0,44.0,41.0,47.0,39.0,41.0,41.0,75.0,37.0,58.0,30.0,36.0,60.0,49.0,52.0,35.0,54.0,38.0,49.0,51.0,60.0,54.0,39.0,41.0,36.0,39.0,47.0,33.0,62.0,73.0,49.0,48.0,36.0,50.0,62.0,46.0,44.0,48.0,42.0,61.0,55.0,71.0,34.0,40.0,41.0,39.0,54.0,50.0,43.0,56.0,43.0,38.0,50.0,28.0,57.0,58.0,72.0,47.0,87.0,62.0,52.0,67.0,50.0,54.0,51.0,53.0,56.0,54.0,55.0,41.0,65.0,37.0,46.0,37.0,60.0,60.0,42.0,47.0,49.0,49.0,66.0,41.0,59.0,58.0,44.0,46.0,53.0,43.0,32.0,33.0,40.0,50.0,48.0,53.0,54.0,53.0,57.0,36.0,71.0,52.0,43.0,29.0,61.0,35.0,49.0,48.0,55.0,70.0,43.0,42.0,47.0,59.0,44.0,57.0,36.0,34.0,53.0,73.0,45.0,59.0,43.0,68.0,45.0,64.0,59.0,57.0,57.0,67.0,60.0,65.0,59.0,52.0,47.0,71.0,60.0,68.0,67.0,55.0,38.0,55.0,63.0,40.0,46.0,49.0,45.0,41.0,71.0,72.0,41.0,64.0,32.0,51.0,48.0,57.0,39.0,49.0,81.0,57.0,64.0,46.0,62.0,42.0,40.0,45.0,65.0,59.0,55.0,53.0,67.0,48.0,41.0,59.0,57.0,69.0,64.0,49.0,64.0,37.0,49.0,40.0,41.0,58.0,56.0,54.0,37.0,42.0,63.0,54.0,55.0,50.0,55.0,52.0,31.0,44.0,71.0,40.0,42.0,52.0,62.0,31.0,58.0,43.0,58.0,68.0,38.0,43.0,57.0,71.0,36.0,46.0,42.0,63.0,50.0,38.0,48.0,63.0,63.0,55.0,60.0,63.0,52.0,55.0,48.0,42.0,61.0,36.0,60.0,69.0,46.0,51.0,56.0,42.0,54.0,60.0,62.0,59.0,42.0,67.0,55.0,31.0,44.0,52.0,29.0,38.0,57.0,47.0,39.0,63.0,64.0,63.0,49.0,64.0,81.0,55.0,46.0,41.0,60.0,50.0,58.0,47.0,58.0,58.0,42.0,39.0,53.0,61.0,52.0,31.0,40.0,45.0,64.0,58.0,61.0,62.0,42.0,35.0,70.0,38.0,42.0,44.0,53.0,36.0,42.0,57.0,65.0,47.0,49.0,41.0,52.0,57.0,62.0,67.0,60.0,53.0,59.0,52.0,50.0,67.0,62.0,66.0,48.0,39.0,40.0,41.0,63.0,36.0,59.0,58.0,48.0,38.0,48.0,60.0,50.0,37.0,62.0,63.0,50.0,56.0,44.0,43.0,66.0,65.0,49.0,34.0,42.0,54.0,62.0,59.0,69.0,57.0,70.0,56.0,46.0,31.0,70.0,49.0,56.0,60.0,55.0,52.0,61.0,69.0,44.0,49.0,47.0,36.0,51.0,42.0,42.0,34.0,48.0,48.0,51.0,72.0,71.0,69.0,50.0,65.0,48.0,66.0,36.0,45.0,43.0,75.0,53.0,50.0,55.0,50.0,51.0,49.0,64.0,23.0,48.0,75.0,47.0,62.0,33.0,56.0,53.0,38.0,63.0,64.0,63.0,64.0,45.0,47.0,76.0,69.0,50.0,44.0,45.0,53.0,43.0,62.0,61.0,41.0,43.0,62.0,58.0,42.0,48.0,50.0,64.0,78.0,52.0,44.0,61.0,63.0,42.0,45.0,62.0,62.0,55.0,47.0,58.0,61.0,50.0,46.0,63.0,40.0,62.0,74.0,35.0,67.0,48.0,61.0,36.0,65.0,56.0,44.0,60.0,73.0,68.0,62.0,38.0,28.0,64.0,34.0,48.0,42.0,50.0,53.0,60.0,56.0,57.0,48.0,38.0,59.0,67.0,59.0,62.0,64.0,50.0,40.0,71.0,69.0,63.0,53.0,44.0,45.0,59.0,54.0,51.0,51.0,59.0,74.0,38.0,48.0,35.0,64.0,58.0,54.0,44.0,46.0,29.0,58.0,69.0,64.0,63.0,76.0,53.0,45.0,50.0,64.0,39.0,65.0,50.0,52.0,54.0,58.0,40.0,63.0,60.0,70.0,59.0,61.0,48.0,60.0,50.0,46.0,60.0,48.0,61.0,61.0,55.0,33.0,58.0,63.0,44.0,44.0,58.0,70.0,46.0,37.0,57.0,56.0,39.0,53.0,63.0,41.0,48.0,50.0,61.0,48.0,64.0,46.0,35.0,36.0,35.0,69.0,43.0,44.0,48.0,48.0,54.0,43.0,46.0,51.0,40.0,61.0,47.0,44.0,66.0,45.0,56.0,52.0,58.0,50.0,47.0,55.0,45.0,54.0,29.0,39.0,58.0,45.0,74.0,53.0,53.0,66.0,46.0,65.0,76.0,48.0,49.0,60.0,47.0,53.0,41.0,53.0,35.0,57.0,43.0,49.0,66.0,45.0,47.0,58.0,37.0,83.0,47.0,45.0,58.0,57.0,63.0,52.0,61.0,55.0,52.0,44.0,63.0,55.0,59.0,39.0,75.0,42.0,65.0,66.0,48.0,49.0,70.0,66.0,34.0,58.0,56.0,49.0,50.0,65.0,62.0,47.0,85.0,61.0,62.0,72.0,55.0,61.0,46.0,46.0,75.0,63.0,59.0,69.0,61.0,57.0,49.0,61.0,53.0,49.0,32.0,52.0,42.0,46.0,78.0,60.0,61.0,41.0,52.0,40.0,63.0,66.0,51.0,57.0,63.0,51.0,27.0,31.0,37.0,35.0,66.0,71.0,31.0,52.0,41.0,54.0,39.0,43.0,43.0,57.0,36.0,51.0,44.0,41.0,74.0,42.0,48.0,50.0,44.0,56.0,52.0,61.0,47.0,61.0,41.0,39.0,75.0,37.0,54.0,47.0,76.0,43.0,49.0,45.0,62.0,41.0,60.0,77.0,56.0,63.0,68.0,36.0,49.0,47.0,71.0,68.0,43.0,51.0,47.0,46.0,46.0,45.0,42.0,41.0,51.0,48.0,42.0,35.0,39.0,49.0,65.0,46.0,50.0,52.0,51.0,66.0,58.0,45.0,55.0,44.0,72.0,57.0,45.0,60.0,42.0,57.0,44.0,50.0,50.0,39.0,57.0,61.0,58.0,77.0,37.0,68.0,67.0,62.0,62.0,47.0,52.0,47.0,40.0,41.0,41.0,59.0,31.0,60.0,52.0,66.0,52.0,55.0,60.0,31.0,60.0,68.0,27.0,39.0,60.0,61.0,70.0,42.0,56.0,46.0,57.0,57.0,65.0,29.0,53.0,59.0,53.0,51.0,46.0,64.0,55.0,54.0,43.0,49.0,68.0,57.0,44.0,49.0,51.0,53.0,53.0,55.0,41.0,32.0,49.0,58.0,61.0,57.0,65.0,66.0,59.0,49.0,47.0,57.0,64.0,38.0,64.0,70.0,37.0,49.0,59.0,63.0,55.0,50.0,79.0,65.0,50.0,62.0,64.0,53.0,46.0,40.0,53.0,55.0,37.0,39.0,57.0,30.0,44.0,55.0,42.0,51.0,35.0,53.0,66.0,47.0,74.0,54.0,47.0,48.0,45.0,44.0,75.0,58.0,43.0,34.0,69.0,62.0,49.0,41.0,52.0,36.0,65.0,46.0,77.0,68.0,60.0,47.0,44.0,58.0,46.0,49.0,61.0,86.0,41.0,53.0,59.0,61.0,47.0,78.0,31.0,45.0,56.0,54.0,66.0,33.0,51.0,54.0,44.0,51.0,50.0,61.0,50.0,45.0,47.0,42.0,36.0,48.0,46.0,38.0,70.0,62.0,50.0,59.0,30.0,43.0,76.0,53.0,76.0,50.0,63.0,40.0,45.0,39.0,42.0,54.0,49.0,55.0,51.0,70.0,47.0,83.0,62.0,36.0,59.0,59.0,59.0,46.0,55.0,56.0,40.0,59.0,53.0,36.0,50.0,57.0,50.0,53.0,62.0,41.0,73.0,57.0,49.0,38.0,48.0],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"test_result\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"age\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"boxmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('125511f1-26c5-4510-8dec-4c7f289432b8');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.box(df, x='test_result',y='age')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1daffe8-aff4-4b28-8bc9-d92a482a9d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "test_result=%{x}<br>physical_score=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa"
         },
         "name": "",
         "notched": false,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "box",
         "x": [
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          40.7,
          37.2,
          24.700000000000003,
          31,
          42.900000000000006,
          23,
          28.90000000000001,
          41.1,
          32,
          41.5,
          42.1,
          31.3,
          39.8,
          34.599999999999994,
          43,
          10.700000000000005,
          32.900000000000006,
          40.7,
          26.8,
          36.2,
          20.8,
          25.8,
          41.5,
          39.1,
          22.90000000000001,
          20.5,
          35.900000000000006,
          41,
          25.40000000000001,
          39.900000000000006,
          19,
          18.700000000000003,
          44.6,
          32.900000000000006,
          28.700000000000003,
          23.3,
          28.599999999999994,
          30.3,
          31.90000000000001,
          46.900000000000006,
          35.900000000000006,
          36.5,
          39.3,
          27.40000000000001,
          24.700000000000003,
          20.700000000000003,
          35.099999999999994,
          25.200000000000003,
          34.5,
          35.400000000000006,
          16.799999999999997,
          37.2,
          17.599999999999994,
          34.900000000000006,
          25.40000000000001,
          20.40000000000001,
          34.099999999999994,
          44.6,
          30.8,
          29.8,
          25.8,
          39.1,
          44.400000000000006,
          24.3,
          20,
          22.5,
          32.3,
          6.400000000000006,
          30.599999999999994,
          37.3,
          23.700000000000003,
          40.1,
          19.099999999999994,
          42.5,
          36.8,
          19.40000000000001,
          36.5,
          23,
          26.200000000000003,
          45.8,
          22.8,
          31.5,
          39.1,
          35.5,
          42.1,
          34.8,
          40,
          27.700000000000003,
          35.7,
          14.099999999999994,
          40.2,
          36.5,
          34.5,
          36.5,
          22.099999999999994,
          21.200000000000003,
          24.90000000000001,
          41.5,
          35.7,
          32.900000000000006,
          22.90000000000001,
          24.200000000000003,
          41.3,
          34.3,
          33.400000000000006,
          34.5,
          32.2,
          39.8,
          37.6,
          41.6,
          20.099999999999994,
          30,
          23,
          37.400000000000006,
          13.099999999999994,
          29.599999999999994,
          36.3,
          32.400000000000006,
          37.8,
          40,
          42.8,
          33.099999999999994,
          33.5,
          50,
          35.099999999999994,
          34.2,
          39,
          30.5,
          34.900000000000006,
          40.6,
          38.8,
          34.400000000000006,
          27.90000000000001,
          31.90000000000001,
          14.700000000000005,
          37.900000000000006,
          30.40000000000001,
          16.599999999999994,
          16.799999999999997,
          36.1,
          40.1,
          43,
          21.700000000000003,
          37.400000000000006,
          34.400000000000006,
          40.5,
          34.900000000000006,
          39.1,
          24.8,
          37.1,
          44.2,
          22.099999999999994,
          44.3,
          16.700000000000003,
          33.3,
          31.700000000000003,
          19.599999999999994,
          24.40000000000001,
          31.3,
          37.8,
          24.90000000000001,
          34.400000000000006,
          39.6,
          34.400000000000006,
          17.799999999999997,
          43.400000000000006,
          8.799999999999997,
          24,
          32.599999999999994,
          43.400000000000006,
          37.9,
          28.3,
          32.5,
          36.900000000000006,
          23.3,
          15.799999999999995,
          42.2,
          32.900000000000006,
          36.400000000000006,
          33.2,
          15.900000000000006,
          45.5,
          38.400000000000006,
          18.90000000000001,
          36.900000000000006,
          41.2,
          40,
          26.8,
          36.5,
          28.90000000000001,
          41.8,
          12.099999999999994,
          42.6,
          40.5,
          38.1,
          41.1,
          38.8,
          38.1,
          27.90000000000001,
          24.200000000000003,
          40.900000000000006,
          35.099999999999994,
          40.400000000000006,
          33.900000000000006,
          44.6,
          13.799999999999995,
          24,
          41.400000000000006,
          27.40000000000001,
          28.099999999999994,
          36.6,
          32.400000000000006,
          33.8,
          41,
          39.2,
          37.3,
          44.3,
          34.7,
          37.6,
          30,
          35.599999999999994,
          34,
          40.5,
          40.5,
          27.200000000000003,
          22.599999999999994,
          35.2,
          16.700000000000003,
          24.599999999999994,
          41,
          48.3,
          31.599999999999994,
          31.90000000000001,
          40.1,
          20.700000000000003,
          26.099999999999994,
          21.3,
          22.700000000000003,
          24.40000000000001,
          40.1,
          35.8,
          22.5,
          38.1,
          34.7,
          33.099999999999994,
          40.2,
          17.599999999999994,
          33,
          37,
          33.099999999999994,
          21.700000000000003,
          33.599999999999994,
          36.5,
          32.2,
          39.1,
          32.5,
          32.099999999999994,
          38.3,
          22.8,
          23.5,
          38.5,
          35.7,
          15.799999999999995,
          38.7,
          33.400000000000006,
          22.700000000000003,
          38,
          26.5,
          38.7,
          40.1,
          40.5,
          36.5,
          35.2,
          36.8,
          35.7,
          40.900000000000006,
          34.7,
          33.400000000000006,
          39.3,
          23.599999999999994,
          41.5,
          38.8,
          37.1,
          45,
          38.8,
          23.5,
          35.400000000000006,
          39.5,
          20.599999999999994,
          35.2,
          35.5,
          38.900000000000006,
          42.5,
          21.5,
          36.7,
          39.3,
          41.1,
          38.6,
          42.8,
          23.599999999999994,
          35.2,
          29.90000000000001,
          41.1,
          41.7,
          22.90000000000001,
          34.099999999999994,
          38.7,
          11.5,
          36.8,
          36.1,
          33.400000000000006,
          21.700000000000003,
          43.8,
          43.2,
          44.8,
          32.400000000000006,
          38.400000000000006,
          36.6,
          38.8,
          35.599999999999994,
          34,
          16.099999999999994,
          26,
          38.7,
          45,
          25.099999999999994,
          42.2,
          29.3,
          40.6,
          42.1,
          22.599999999999994,
          29.3,
          33.8,
          9.5,
          28.599999999999994,
          40.1,
          36.900000000000006,
          43.400000000000006,
          22.599999999999994,
          38.900000000000006,
          35.099999999999994,
          14.799999999999995,
          32.8,
          24.40000000000001,
          42.900000000000006,
          21.8,
          19.599999999999994,
          27.200000000000003,
          34,
          22.5,
          29.5,
          19.599999999999994,
          36.400000000000006,
          14.799999999999995,
          39.3,
          12.799999999999995,
          38,
          37.1,
          37.2,
          24.200000000000003,
          24.90000000000001,
          31.700000000000003,
          36.400000000000006,
          34.400000000000006,
          40.6,
          39,
          24.200000000000003,
          22.599999999999994,
          16.5,
          30.700000000000003,
          38.1,
          36.400000000000006,
          24.599999999999994,
          42,
          39.3,
          36.6,
          37.6,
          28.099999999999994,
          39.3,
          37.8,
          41.1,
          42.400000000000006,
          38.5,
          29.599999999999994,
          26.5,
          38.900000000000006,
          38.1,
          36.3,
          19.90000000000001,
          33.099999999999994,
          37.5,
          21.5,
          37.8,
          38.2,
          18.40000000000001,
          18.40000000000001,
          37.900000000000006,
          26.200000000000003,
          36,
          22.200000000000003,
          39.400000000000006,
          27.90000000000001,
          28.40000000000001,
          34.900000000000006,
          35.3,
          37.900000000000006,
          18.3,
          40.400000000000006,
          24.599999999999994,
          20.599999999999994,
          36.6,
          47.3,
          39.1,
          36.400000000000006,
          35.099999999999994,
          25.3,
          25.40000000000001,
          32.099999999999994,
          20.5,
          38.3,
          38.6,
          28.8,
          12.900000000000006,
          36.3,
          21.200000000000003,
          37.7,
          24.700000000000003,
          39.6,
          42.1,
          41.400000000000006,
          35.900000000000006,
          23.90000000000001,
          40.7,
          28.200000000000003,
          41.8,
          40.7,
          45.1,
          35.5,
          39.900000000000006,
          36.8,
          34.900000000000006,
          35.400000000000006,
          25,
          38.900000000000006,
          22.8,
          36.6,
          19.40000000000001,
          42.8,
          43,
          39.8,
          37.1,
          30.200000000000003,
          42.1,
          39.400000000000006,
          49.5,
          36.1,
          37.900000000000006,
          43.6,
          32.8,
          28.8,
          31,
          22.099999999999994,
          34.2,
          27.700000000000003,
          28.90000000000001,
          34.400000000000006,
          43.2,
          39.400000000000006,
          41.8,
          38.2,
          35.900000000000006,
          42,
          44.1,
          34.599999999999994,
          26.099999999999994,
          39,
          24.90000000000001,
          38.1,
          24.5,
          36.7,
          28.599999999999994,
          39.6,
          22.5,
          37.1,
          35.5,
          39.6,
          30.099999999999994,
          35.099999999999994,
          39.2,
          32,
          37.5,
          21.599999999999994,
          23.5,
          26.200000000000003,
          33.3,
          40.6,
          38.900000000000006,
          35.099999999999994,
          40.1,
          35.599999999999994,
          33.2,
          45.7,
          27.90000000000001,
          39.400000000000006,
          36.8,
          41.2,
          30.5,
          37.1,
          21.8,
          30.599999999999994,
          37.900000000000006,
          37.6,
          23.099999999999994,
          28.599999999999994,
          20.40000000000001,
          39.3,
          17.400000000000006,
          29.3,
          33.400000000000006,
          42.2,
          32.2,
          39.3,
          39.7,
          39.8,
          19.099999999999994,
          23.8,
          41.1,
          37.7,
          38.8,
          23.700000000000003,
          26.8,
          40.1,
          27.700000000000003,
          25.5,
          20.099999999999994,
          39.8,
          23.40000000000001,
          20.599999999999994,
          38.1,
          20,
          28.5,
          37,
          17.200000000000003,
          40.400000000000006,
          37.400000000000006,
          35.400000000000006,
          20.8,
          37.900000000000006,
          40.900000000000006,
          7.799999999999997,
          32,
          26.200000000000003,
          37.900000000000006,
          30.8,
          42.2,
          27.40000000000001,
          35.8,
          41.900000000000006,
          39,
          23.599999999999994,
          37.400000000000006,
          40.1,
          39.6,
          21.3,
          38.6,
          38,
          36,
          33.2,
          37.8,
          40.400000000000006,
          43.2,
          16.200000000000003,
          20.200000000000003,
          35.2,
          19.3,
          30.5,
          40.900000000000006,
          43.5,
          27.5,
          39.400000000000006,
          37.2,
          28.099999999999994,
          43.2,
          40.5,
          38.2,
          39.7,
          33.099999999999994,
          45.6,
          12.900000000000006,
          20.200000000000003,
          20.099999999999994,
          36,
          22.8,
          29.5,
          48.2,
          22.40000000000001,
          37.1,
          34.8,
          36.1,
          35.7,
          36.6,
          34.599999999999994,
          40.1,
          36.1,
          33.900000000000006,
          39.2,
          37.2,
          38.6,
          37.8,
          38,
          36.3,
          38.8,
          33.7,
          18.90000000000001,
          29.200000000000003,
          42.400000000000006,
          25.3,
          23.90000000000001,
          33.400000000000006,
          41.400000000000006,
          30.40000000000001,
          37.400000000000006,
          38.8,
          33.400000000000006,
          41.5,
          34.2,
          44.5,
          34.2,
          39.5,
          39.7,
          47.2,
          33.3,
          37.3,
          36.7,
          25,
          36.3,
          35.3,
          33.7,
          27.700000000000003,
          39.3,
          38,
          28.3,
          34.7,
          37.6,
          23.700000000000003,
          12,
          38.900000000000006,
          14.299999999999995,
          16.299999999999997,
          40.2,
          17.700000000000003,
          40.400000000000006,
          41.6,
          16,
          40.1,
          33.2,
          15.599999999999994,
          41.7,
          35.2,
          47.8,
          36.3,
          31.3,
          33.5,
          26.200000000000003,
          36.7,
          33,
          41.2,
          34.099999999999994,
          44.8,
          37.6,
          38.7,
          22.700000000000003,
          31.8,
          12.400000000000006,
          25,
          28.90000000000001,
          27.099999999999994,
          39.7,
          36.5,
          42,
          43,
          35.8,
          36.2,
          43.900000000000006,
          24,
          27.3,
          28.099999999999994,
          28.700000000000003,
          24.700000000000003,
          31.90000000000001,
          43.1,
          39.7,
          33.7,
          42,
          44.5,
          20.099999999999994,
          36.900000000000006,
          34.400000000000006,
          41.1,
          35.7,
          24.200000000000003,
          42.3,
          39.400000000000006,
          47.5,
          38.2,
          26.3,
          37.2,
          30.599999999999994,
          22.8,
          26.3,
          28.8,
          33.099999999999994,
          30,
          36.8,
          36.3,
          18,
          38.2,
          36.400000000000006,
          35.599999999999994,
          43.5,
          23.200000000000003,
          34.7,
          40,
          39.400000000000006,
          32.5,
          20.5,
          40.8,
          20.90000000000001,
          28.5,
          25.5,
          19.700000000000003,
          40.6,
          40.2,
          23.200000000000003,
          35.900000000000006,
          41.5,
          41.5,
          37,
          39,
          34.8,
          38.9,
          35.099999999999994,
          43.8,
          14.599999999999994,
          4.5,
          35.900000000000006,
          37.7,
          25.40000000000001,
          33,
          38.5,
          34.099999999999994,
          41.7,
          22.700000000000003,
          20.5,
          26.8,
          28.5,
          36.5,
          35.3,
          25.3,
          23.90000000000001,
          42.2,
          37.1,
          27.90000000000001,
          36.7,
          37.8,
          15.700000000000005,
          35.2,
          37.2,
          27.099999999999994,
          40.1,
          41.8,
          16.700000000000003,
          26,
          25.700000000000003,
          34.3,
          19.40000000000001,
          35.599999999999994,
          38.6,
          44.3,
          22.5,
          38.900000000000006,
          37.8,
          23,
          34.900000000000006,
          37.1,
          26.3,
          28.700000000000003,
          23.099999999999994,
          27.40000000000001,
          33.900000000000006,
          36.8,
          16.099999999999994,
          41,
          36.3,
          37.8,
          39.400000000000006,
          38.1,
          39.6,
          38.400000000000006,
          30.40000000000001,
          27.8,
          31.599999999999994,
          34.599999999999994,
          41.3,
          22.099999999999994,
          38.8,
          36.2,
          37.7,
          35.599999999999994,
          21.40000000000001,
          29.8,
          25,
          35.400000000000006,
          14.299999999999995,
          36.7,
          37.900000000000006,
          31.3,
          43.6,
          39.5,
          36.900000000000006,
          25.599999999999994,
          35,
          11.099999999999994,
          18.599999999999994,
          12.200000000000005,
          33.7,
          18.200000000000003,
          38.6,
          41.400000000000006,
          31,
          39.5,
          41.400000000000006,
          39.3,
          35.900000000000006,
          35.7,
          32.7,
          32.599999999999994,
          22.90000000000001,
          33.2,
          35.8,
          22.099999999999994,
          19.200000000000003,
          41.1,
          39,
          32.599999999999994,
          20.5,
          41.7,
          43.900000000000006,
          21.599999999999994,
          41.3,
          13.700000000000005,
          38,
          36,
          28.700000000000003,
          40.7,
          15.700000000000005,
          38.2,
          42.2,
          36.8,
          27,
          35.8,
          36.6,
          17.799999999999997,
          26,
          24.40000000000001,
          30.599999999999994,
          23.90000000000001,
          40.6,
          16.200000000000003,
          30,
          39.3,
          36.2,
          42,
          23.5,
          37.400000000000006,
          23.3,
          40.6,
          37,
          24.099999999999994,
          30.90000000000001,
          40.8,
          22.90000000000001,
          23.90000000000001,
          24.200000000000003,
          44.1,
          38.900000000000006,
          46.7,
          42.7,
          12.099999999999994,
          32.2,
          37.2,
          36.900000000000006,
          38.8,
          31.3,
          25.3,
          34.099999999999994,
          35.599999999999994,
          37.8,
          30.5,
          13.900000000000006,
          31.5,
          25,
          25,
          21,
          46.3,
          20.5,
          37.900000000000006,
          31.599999999999994,
          10.400000000000006,
          40.8,
          35.3,
          24.40000000000001,
          40.7,
          26.3,
          24.3,
          39.3,
          41.6,
          34.5,
          21,
          31.700000000000003,
          17.799999999999997,
          17.400000000000006,
          39,
          20,
          37.5,
          38.3,
          32.400000000000006,
          36.3,
          41,
          42,
          36.5,
          37,
          36.6,
          36.1,
          32.2,
          18.90000000000001,
          33.599999999999994,
          43.6,
          40.900000000000006,
          35.599999999999994,
          39,
          38.3,
          36.400000000000006,
          37.6,
          38,
          38,
          39.1,
          26.3,
          38.6,
          38.7,
          10.299999999999995,
          22.40000000000001,
          35.099999999999994,
          18,
          35,
          42.7,
          27.700000000000003,
          42.8,
          15,
          36.8,
          42.400000000000006,
          34.7,
          36.2,
          38.900000000000006,
          38.8,
          14.599999999999994,
          36.3,
          37.1,
          17.200000000000003,
          32.2,
          31.200000000000003,
          18.40000000000001,
          37,
          41.7,
          37.8,
          23.200000000000003,
          22.099999999999994,
          39.3,
          37.400000000000006,
          32.5,
          34.3,
          15.599999999999994,
          26.8,
          40.900000000000006,
          18.5,
          44.1,
          29.5,
          22.90000000000001,
          35.599999999999994,
          41.2,
          39.1,
          41,
          25.700000000000003,
          38.900000000000006,
          37.1,
          22.90000000000001,
          16.700000000000003,
          39.7,
          44.7,
          33.900000000000006,
          35.2,
          18.3,
          33.400000000000006,
          37.2,
          24.099999999999994,
          43.2,
          38,
          29.3,
          29.40000000000001,
          34.900000000000006,
          43.400000000000006,
          23.40000000000001,
          34.599999999999994,
          26.40000000000001,
          44.900000000000006,
          38.5,
          31.8,
          22.599999999999994,
          37.2,
          33,
          22.3,
          16.200000000000003,
          37.6,
          36.7,
          31.200000000000003,
          35.7,
          13.299999999999995,
          35,
          21.200000000000003,
          37.2,
          38,
          37.5,
          28.90000000000001,
          38.2,
          30.40000000000001,
          30.8,
          38.6,
          40.1,
          41.900000000000006,
          43.2,
          38.6,
          32.900000000000006,
          37.6,
          30.8,
          36,
          42.6,
          23.8,
          40.5,
          40.2,
          31.599999999999994,
          30.099999999999994,
          36.5,
          24.8,
          37.6,
          47.7,
          41.3,
          32.5,
          22.5,
          40.8,
          31.700000000000003,
          37,
          33.099999999999994,
          33.7,
          42,
          36.1,
          22.5,
          31.200000000000003,
          41.3,
          40.8,
          14,
          33.8,
          38.1,
          29,
          36.5,
          16,
          28.40000000000001,
          40.5,
          41.1,
          38.8,
          34.7,
          29.40000000000001,
          33.900000000000006,
          27.5,
          38.2,
          32.400000000000006,
          42.5,
          37.900000000000006,
          30.3,
          35.3,
          37.2,
          32.8,
          37.900000000000006,
          15.299999999999995,
          20.599999999999994,
          33.8,
          36.400000000000006,
          20.5,
          21.200000000000003,
          31.200000000000003,
          18.599999999999994,
          28.90000000000001,
          37.2,
          38.5,
          36.400000000000006,
          37.8,
          25.40000000000001,
          35.7,
          41.6,
          39.8,
          22.8,
          39.2,
          37.3,
          42.7,
          36.4,
          43.400000000000006,
          38.6,
          14.700000000000005,
          25.200000000000003,
          29.200000000000003,
          19.90000000000001,
          25.40000000000001,
          20.099999999999994,
          35.7,
          11.599999999999994,
          36.6,
          39.8,
          36.3,
          19.40000000000001,
          36.5,
          18.200000000000003,
          44.900000000000006,
          42.3,
          38.1,
          31.700000000000003,
          19.3,
          35,
          40.1,
          29.200000000000003,
          31.200000000000003,
          38.2,
          39.6,
          35.099999999999994,
          32.3,
          43.7,
          43.5,
          34.7,
          39.400000000000006,
          35.5,
          37.400000000000006,
          35.900000000000006,
          34.599999999999994,
          41.8,
          23.200000000000003,
          12.700000000000005,
          20.200000000000003,
          33.2,
          39.6,
          37.2,
          38.6,
          40,
          36.8,
          22.90000000000001,
          41.1,
          24.200000000000003,
          40.1,
          34.599999999999994,
          37.400000000000006,
          41.3,
          17.5,
          36.400000000000006,
          39.2,
          37.3,
          15.900000000000006,
          24.90000000000001,
          38.900000000000006,
          36.900000000000006,
          38.2,
          13.200000000000005,
          30.90000000000001,
          23.40000000000001,
          34.2,
          38.1,
          32.8,
          38.2,
          34.400000000000006,
          40.400000000000006,
          36.900000000000006,
          46.5,
          38.5,
          31.40000000000001,
          34.900000000000006,
          26.200000000000003,
          31,
          39.2,
          39.400000000000006,
          27.3,
          23.5,
          38.400000000000006,
          24.5,
          21,
          28.3,
          31.8,
          38.900000000000006,
          10.900000000000006,
          37.400000000000006,
          19.200000000000003,
          41.6,
          40.8,
          29.40000000000001,
          30.5,
          39.1,
          19.700000000000003,
          42.7,
          35.400000000000006,
          34.900000000000006,
          24.40000000000001,
          22.700000000000003,
          42.7,
          41.3,
          36.2,
          0,
          33.3,
          21.5,
          34.3,
          33.2,
          35,
          38.2,
          38.8,
          35.8,
          37,
          39.3,
          28,
          37.7,
          37.8,
          21.099999999999994,
          37.1,
          42.6,
          41.3,
          35.5,
          28.599999999999994,
          38.2,
          28.8,
          25,
          11.400000000000006,
          19.3,
          19,
          21.5,
          35.099999999999994,
          38.7,
          39.8,
          42.3,
          14.900000000000006,
          14.099999999999994,
          42.1,
          38.2,
          36.2,
          25.599999999999994,
          33.900000000000006,
          17.900000000000006,
          11.400000000000006,
          43.8,
          35.2,
          37.900000000000006,
          18.099999999999994,
          34.099999999999994,
          33.400000000000006,
          42,
          38.7,
          28.8,
          31.8,
          39.1,
          42.2,
          38.1,
          34.599999999999994,
          23.599999999999994,
          33.099999999999994,
          35.2,
          42.900000000000006,
          39.6,
          32.8,
          17.700000000000003,
          35.7,
          33.3,
          23,
          36.400000000000006,
          28.40000000000001,
          36.8,
          37.8,
          37,
          25.200000000000003,
          24.5,
          38.5,
          38.900000000000006,
          39.400000000000006,
          33.400000000000006,
          34.3,
          13.700000000000005,
          32.3,
          37.3,
          38.8,
          17.200000000000003,
          22,
          24.599999999999994,
          16.700000000000003,
          34.2,
          33.2,
          22.5,
          18.5,
          22.5,
          35.5,
          13.799999999999995,
          19.099999999999994,
          41.400000000000006,
          38.400000000000006,
          21,
          27.5,
          39,
          38.400000000000006,
          34.7,
          34.8,
          35.8,
          30.700000000000003,
          39.3,
          32.900000000000006,
          36.400000000000006,
          40.1,
          33.2,
          45.6,
          37.3,
          33.900000000000006,
          29.5,
          37.7,
          23,
          11.099999999999994,
          35.5,
          29.40000000000001,
          39.2,
          37.900000000000006,
          39.2,
          26.8,
          36,
          19.700000000000003,
          29.90000000000001,
          20.200000000000003,
          36.900000000000006,
          39.1,
          36.900000000000006,
          35.599999999999994,
          17.200000000000003,
          37.8,
          19.200000000000003,
          17.900000000000006,
          25.099999999999994,
          27.099999999999994,
          34.3,
          30.5,
          37.8,
          39.900000000000006,
          32.3,
          37,
          33.400000000000006,
          21.200000000000003,
          30.700000000000003,
          36.6,
          41.2,
          41.6,
          41.3,
          26.40000000000001,
          38.7,
          35.8,
          38.6,
          24.3,
          41.2,
          37.1,
          20.200000000000003,
          36.7,
          32.8,
          32,
          36.2,
          32.599999999999994,
          23.90000000000001,
          23.3,
          24.5,
          33.900000000000006,
          43.2,
          17.599999999999994,
          40.400000000000006,
          35.400000000000006,
          28.200000000000003,
          38.5,
          36.7,
          25.200000000000003,
          26.3,
          16.299999999999997,
          22.200000000000003,
          38.400000000000006,
          36.6,
          24.099999999999994,
          36.2,
          26.90000000000001,
          17.799999999999997,
          28.599999999999994,
          40.5,
          23.200000000000003,
          45,
          15.799999999999995,
          43.900000000000006,
          15.200000000000005,
          43.1,
          37.7,
          36,
          27.200000000000003,
          41.6,
          35.099999999999994,
          30.90000000000001,
          35.599999999999994,
          17.700000000000003,
          32.3,
          35.900000000000006,
          37,
          41.6,
          23.099999999999994,
          38.2,
          38.1,
          38.5,
          30,
          28.099999999999994,
          37.1,
          30.200000000000003,
          34.5,
          35.599999999999994,
          22,
          29.700000000000003,
          38.2,
          39.3,
          40.7,
          34.8,
          18.90000000000001,
          19.5,
          39,
          27,
          40.1,
          17.599999999999994,
          26.40000000000001,
          36.900000000000006,
          30.5,
          32.2,
          28.40000000000001,
          26.3,
          35,
          32.400000000000006,
          40.2,
          37.400000000000006,
          46.7,
          42.900000000000006,
          38,
          22.90000000000001,
          39.2,
          37,
          35.099999999999994,
          36.7,
          29.90000000000001,
          34,
          37.8,
          37.400000000000006,
          35.5,
          23,
          29.3,
          36.6,
          43.1,
          40.3,
          41.1,
          42.5,
          37.5,
          40.1,
          36.3,
          37.8,
          34.900000000000006,
          19.599999999999994,
          33.5,
          20.700000000000003,
          18.599999999999994,
          39.8,
          38.3,
          32.2,
          41.1,
          41.1,
          30.5,
          40.8,
          31,
          42.400000000000006,
          26.099999999999994,
          28.90000000000001,
          39.8,
          15.400000000000006,
          35.5,
          35.599999999999994,
          45.6,
          25.5,
          13.400000000000006,
          34.3,
          39.7,
          31.099999999999994,
          36.8,
          40,
          40.8,
          31.5,
          15.5,
          38.3,
          25,
          16.799999999999997,
          19.90000000000001,
          40.900000000000006,
          32.8,
          23.099999999999994,
          39,
          33.900000000000006,
          23.599999999999994,
          27.40000000000001,
          28.8,
          40.5,
          30,
          14.400000000000006,
          41.5,
          24.700000000000003,
          30.700000000000003,
          35.400000000000006,
          38.8,
          43.2,
          26.8,
          43.400000000000006,
          20.40000000000001,
          34.599999999999994,
          14.5,
          38.8,
          35.3,
          41.3,
          37.5,
          26.8,
          41.8,
          24.700000000000003,
          42.1,
          34.5,
          30.200000000000003,
          18.3,
          41.6,
          41,
          24.099999999999994,
          41.8,
          38.400000000000006,
          17.900000000000006,
          33.3,
          23.40000000000001,
          34.7,
          41.900000000000006,
          13.5,
          36.900000000000006,
          31.599999999999994,
          31.8,
          22.099999999999994,
          38.3,
          38.3,
          35.3,
          40.1,
          23.599999999999994,
          15.599999999999994,
          26.5,
          42.7,
          40,
          19.8,
          40.5,
          35.400000000000006,
          37.6,
          33.400000000000006,
          38,
          13.700000000000005,
          7.799999999999997,
          42.400000000000006,
          39.400000000000006,
          34.099999999999994,
          36.2,
          40.1,
          40.900000000000006,
          19.3,
          37.400000000000006,
          42.3,
          23.90000000000001,
          27.40000000000001,
          41.5,
          44.8,
          40.5,
          40.8,
          17.400000000000006,
          39.8,
          35,
          42,
          38.5,
          25.700000000000003,
          25.700000000000003,
          19.90000000000001,
          21.8,
          17.700000000000003,
          17.400000000000006,
          36.900000000000006,
          30.700000000000003,
          36.400000000000006,
          34.099999999999994,
          27.200000000000003,
          36.900000000000006,
          30.099999999999994,
          31.200000000000003,
          36.6,
          42.1,
          32.599999999999994,
          36.3,
          38.7,
          37.4,
          35.8,
          33.5,
          39.3,
          34.099999999999994,
          27.700000000000003,
          9.599999999999994,
          33,
          30.599999999999994,
          21.5,
          25,
          40.3,
          41,
          37.900000000000006,
          20.3,
          29.90000000000001,
          39.6,
          24.5,
          37.8,
          33.400000000000006,
          44.1,
          37.1,
          29.200000000000003,
          35.099999999999994,
          38.6,
          21.099999999999994,
          36.1,
          37.400000000000006,
          42.3,
          36.5,
          37.6,
          26.700000000000003,
          17.299999999999997,
          21.40000000000001,
          34,
          44,
          36.3,
          30.599999999999994,
          44.7,
          43.5,
          20.099999999999994,
          22,
          29.8,
          24.3,
          35.7,
          34.3,
          42.8,
          39.6,
          27.3,
          19.8,
          35.8,
          37.7,
          31.099999999999994,
          23.5,
          20.599999999999994,
          24,
          39.6,
          22.099999999999994,
          29.700000000000003,
          37.6,
          37.3,
          39.900000000000006,
          31.200000000000003,
          24.40000000000001,
          41.6,
          36.6,
          34.5,
          21.40000000000001,
          36,
          35.5,
          42.6,
          39.6,
          39.400000000000006,
          39.2,
          38.8,
          24.40000000000001,
          13.900000000000006,
          23.099999999999994,
          22.200000000000003,
          37.6,
          35.900000000000006,
          41.7,
          26.8,
          35.599999999999994,
          35.900000000000006,
          38.8,
          39.6,
          40.3,
          36.900000000000006,
          36.7,
          23.8,
          31.8,
          34.8,
          37.3,
          42.1,
          24.40000000000001,
          34.900000000000006,
          40.5,
          26.90000000000001,
          43.3,
          33.599999999999994,
          22,
          37.8,
          25.90000000000001,
          21.099999999999994,
          22.200000000000003,
          38.400000000000006,
          33.900000000000006,
          30.099999999999994,
          24.200000000000003,
          36.7,
          40,
          23.599999999999994,
          33.8,
          38.900000000000006,
          17.700000000000003,
          37.7,
          36.400000000000006,
          33.099999999999994,
          21.599999999999994,
          30,
          37.8,
          25.5,
          34.400000000000006,
          25.8,
          42,
          36.6,
          20.5,
          37.2,
          25.8,
          39.1,
          33,
          40.2,
          31.40000000000001,
          43.2,
          23.5,
          19.3,
          16.299999999999997,
          21.90000000000001,
          25,
          29.5,
          36.6,
          43,
          37.2,
          39,
          16.200000000000003,
          38.2,
          34.3,
          17,
          44.5,
          33.599999999999994,
          25.5,
          34.8,
          25.40000000000001,
          19.8,
          29,
          35.5,
          37.7,
          42.3,
          42.3,
          25.90000000000001,
          30.3,
          30.8,
          9.900000000000006,
          34,
          44,
          35.099999999999994,
          37.8,
          31.3,
          21.700000000000003,
          38.6,
          34.3,
          30,
          21.099999999999994,
          38.8,
          20.8,
          21.40000000000001,
          21.3,
          37.6,
          41.400000000000006,
          34.2,
          46.400000000000006,
          39.900000000000006,
          43.900000000000006,
          33.2,
          38.5,
          37.6,
          20.8,
          20.3,
          37.400000000000006,
          41.2,
          41.6,
          35.599999999999994,
          37.400000000000006,
          36.7,
          38.900000000000006,
          38.5,
          31.099999999999994,
          38.5,
          20.200000000000003,
          33.3,
          41.1,
          33.7,
          33.3,
          41.3,
          38.900000000000006,
          6.5,
          31.599999999999994,
          40.400000000000006,
          23.3,
          43.6,
          27.3,
          26,
          34.3,
          39.5,
          38.3,
          42.6,
          40.5,
          30.700000000000003,
          38,
          37.6,
          40.2,
          29.099999999999994,
          41,
          25.90000000000001,
          34.400000000000006,
          17.5,
          38.2,
          39.8,
          31.90000000000001,
          39.6,
          29.90000000000001,
          34.099999999999994,
          39.3,
          40.2,
          36.1,
          28.700000000000003,
          34,
          42.3,
          11,
          40,
          41.1,
          24.599999999999994,
          37.5,
          34.099999999999994,
          35.900000000000006,
          39.7,
          11.599999999999994,
          26.200000000000003,
          38.400000000000006,
          21.3,
          37.2,
          27.599999999999994,
          29.90000000000001,
          38.5,
          39,
          39.400000000000006,
          19.40000000000001,
          36.5,
          36.5,
          28,
          37.8,
          38.400000000000006,
          40.5,
          41.8,
          44.900000000000006,
          31.5,
          39.2,
          26.099999999999994,
          37.5,
          36,
          35.099999999999994,
          41,
          36,
          23,
          34,
          38,
          36.8,
          42,
          39.6,
          20.599999999999994,
          26.3,
          37.900000000000006,
          29.40000000000001,
          27,
          13.200000000000005,
          40.1,
          39.1,
          40,
          35.900000000000006,
          22.3,
          28,
          34.099999999999994,
          38.5,
          38,
          32.900000000000006,
          44.400000000000006,
          36.2,
          39.3,
          40.8,
          29.40000000000001,
          37.3,
          38.8,
          17.599999999999994,
          28.8,
          29.3,
          35.599999999999994,
          41.8,
          41,
          33.7,
          35.2,
          33.5,
          22.5,
          25.599999999999994,
          42.400000000000006,
          39.6,
          38,
          45.2,
          37,
          38.2,
          34.099999999999994,
          26.5,
          26.700000000000003,
          39.8,
          37.900000000000006,
          15,
          17.299999999999997,
          39.7,
          9.200000000000005,
          15.099999999999994,
          24.3,
          34,
          35.3,
          37.400000000000006,
          43,
          32.099999999999994,
          20.599999999999994,
          36.8,
          17.700000000000003,
          33,
          40.8,
          36.5,
          24.3,
          36,
          28,
          36.400000000000006,
          40.5,
          32.900000000000006,
          36.900000000000006,
          20,
          37.2,
          39.7,
          19.700000000000003,
          39.1,
          35.7,
          43.3,
          20.8,
          29.099999999999994,
          37.5,
          39.6,
          45.3,
          38.6,
          35.8,
          21.3,
          38.7,
          26.200000000000003,
          34.3,
          24.40000000000001,
          32.099999999999994,
          34.5,
          24.40000000000001,
          40.1,
          39,
          39.5,
          39.7,
          39.1,
          32,
          44.7,
          34.2,
          34.3,
          38.7,
          20.8,
          41.5,
          35.5,
          33.400000000000006,
          36.2,
          29.200000000000003,
          37.3,
          36.8,
          45.400000000000006,
          18,
          35.900000000000006,
          34.5,
          30.599999999999994,
          25.700000000000003,
          24.90000000000001,
          35,
          34,
          34.400000000000006,
          33.3,
          43.3,
          28.099999999999994,
          17.900000000000006,
          39.5,
          34.099999999999994,
          37.1,
          25.3,
          36.8,
          39.5,
          33.5,
          44.7,
          21.3,
          39.5,
          27.200000000000003,
          17.200000000000003,
          35.3,
          25.8,
          43.8,
          38.3,
          38.7,
          37.900000000000006,
          23.3,
          31.8,
          22.099999999999994,
          32.599999999999994,
          38,
          34.8,
          38.400000000000006,
          37.2,
          19.8,
          42.1,
          43.8,
          38.6,
          36.6,
          39.7,
          36.2,
          21.8,
          37.2,
          25.099999999999994,
          22.8,
          43.400000000000006,
          40.8,
          33,
          34.400000000000006,
          22.40000000000001,
          27.40000000000001,
          43.1,
          40.900000000000006,
          36.900000000000006,
          40,
          34.400000000000006,
          40.400000000000006,
          38,
          15.799999999999995,
          34.7,
          40.8,
          34.599999999999994,
          28.3,
          41.2,
          27.200000000000003,
          31.200000000000003,
          34.900000000000006,
          37.900000000000006,
          38.7,
          21.3,
          35.900000000000006,
          40.1,
          39.6,
          19.200000000000003,
          36,
          35.7,
          26.099999999999994,
          34.099999999999994,
          24.200000000000003,
          40.8,
          37.7,
          40.1,
          39.5,
          34.3,
          21.3,
          39.5,
          27.099999999999994,
          42.400000000000006,
          25.099999999999994,
          22.3,
          32.3,
          31.40000000000001,
          35,
          8.599999999999994,
          39.400000000000006,
          26.8,
          33.7,
          43,
          39.7,
          24.200000000000003,
          37,
          25,
          37.8,
          39.2,
          33.099999999999994,
          37.7,
          35.099999999999994,
          22.5,
          36,
          13.599999999999994,
          12.599999999999994,
          35.7,
          42.400000000000006,
          39.4,
          35.900000000000006,
          37.3,
          38.5,
          40.3,
          33,
          35.3,
          39.6,
          27.40000000000001,
          25,
          40.400000000000006,
          37.5,
          40.400000000000006,
          37.8,
          23.5,
          31.90000000000001,
          22,
          41.7,
          19.599999999999994,
          28.90000000000001,
          20,
          35.2,
          41.3,
          40.400000000000006,
          39.7,
          35.3,
          22.5,
          20.90000000000001,
          34,
          36.8,
          26.599999999999994,
          33.3,
          38.2,
          41.3,
          41.5,
          25.3,
          32,
          35.3,
          41.1,
          37.6,
          34.7,
          38.400000000000006,
          31.40000000000001,
          36,
          37.400000000000006,
          40.8,
          33.599999999999994,
          23,
          25,
          37.3,
          42.7,
          34.8,
          34.8,
          34.400000000000006,
          21.8,
          21.5,
          24.8,
          35,
          41,
          31.099999999999994,
          32.7,
          32.8,
          37.3,
          25.099999999999994,
          37.6,
          37.6,
          34.599999999999994,
          24.200000000000003,
          25,
          19.099999999999994,
          15.700000000000005,
          35.5,
          17.799999999999997,
          20.700000000000003,
          41,
          25.40000000000001,
          36,
          19.3,
          25,
          33.900000000000006,
          12.400000000000006,
          29.200000000000003,
          16.299999999999997,
          39.3,
          39.8,
          25.90000000000001,
          40.6,
          25.8,
          36.1,
          38.7,
          29,
          46.900000000000006,
          34.5,
          38,
          38.7,
          34.900000000000006,
          21,
          39.1,
          30.700000000000003,
          39.3,
          36.400000000000006,
          21.8,
          36.5,
          45.5,
          34.599999999999994,
          36.7,
          27.3,
          35.5,
          35.900000000000006,
          41.900000000000006,
          37.900000000000006,
          38.5,
          21.700000000000003,
          39.400000000000006,
          22,
          25.5,
          35.8,
          16.200000000000003,
          24.599999999999994,
          39.7,
          37.3,
          38.3,
          26.599999999999994,
          16.200000000000003,
          35.099999999999994,
          10.5,
          40.1,
          35.599999999999994,
          41.8,
          33.7,
          37.8,
          31,
          46,
          37,
          37,
          13.799999999999995,
          30.200000000000003,
          38.7,
          38.6,
          46.400000000000006,
          21.40000000000001,
          39.7,
          34.5,
          31.099999999999994,
          41.8,
          41.3,
          40.2,
          38.2,
          41.1,
          39.7,
          35.400000000000006,
          42,
          39.7,
          40.3,
          22.3,
          38.400000000000006,
          38.1,
          39,
          39.8,
          25.5,
          36,
          35.400000000000006,
          41.6,
          37.3,
          43,
          21.90000000000001,
          42.2,
          37.5,
          33.3,
          33,
          23.099999999999994,
          41.6,
          33.400000000000006,
          37.5,
          37.400000000000006,
          45.6,
          18.3,
          25.5,
          38.7,
          32.3,
          27.3,
          39,
          38.1,
          31.099999999999994,
          41.5,
          23.90000000000001,
          39.1,
          17.400000000000006,
          35.8,
          38.7,
          39.6,
          45.7,
          41.400000000000006,
          22.40000000000001,
          43.900000000000006,
          38.8,
          21.40000000000001,
          33.5,
          17.900000000000006,
          40.900000000000006,
          35.400000000000006,
          31.099999999999994,
          36.6,
          42.5,
          36.2,
          33.5,
          40.900000000000006,
          42.2,
          40.400000000000006,
          39,
          32.7,
          33.7,
          39.1,
          21.599999999999994,
          31.3,
          27.200000000000003,
          37.1,
          41.2,
          43.8,
          17,
          9.900000000000006,
          35.099999999999994,
          35.099999999999994,
          37.7,
          42.1,
          33.3,
          24.90000000000001,
          42.6,
          31.700000000000003,
          17.099999999999994,
          39.3,
          33.3,
          29.40000000000001,
          31,
          15.799999999999995,
          23.90000000000001,
          39.1,
          38.1,
          36.6,
          45.6,
          17.700000000000003,
          35.900000000000006,
          13.200000000000005,
          22.3,
          37.8,
          27.3,
          36.9,
          36.4,
          28.700000000000003,
          42.3,
          26.3,
          40,
          37.6,
          40.900000000000006,
          38.900000000000006,
          32.599999999999994,
          36.7,
          35.599999999999994,
          35.5,
          37.900000000000006,
          35.5,
          42.8,
          36.2,
          25.700000000000003,
          24.099999999999994,
          39.3,
          40.1,
          39.3,
          24.8,
          27.40000000000001,
          35.7,
          39.900000000000006,
          30.90000000000001,
          40.8,
          30.099999999999994,
          14.799999999999995,
          19.5,
          43.7,
          33.7,
          19.3,
          32.400000000000006,
          34,
          30.599999999999994,
          33.5,
          36.1,
          36.900000000000006,
          19.90000000000001,
          40.400000000000006,
          38.2,
          35.3,
          34.3,
          33.099999999999994,
          36.3,
          31.40000000000001,
          40.400000000000006,
          37.3,
          32.5,
          25.099999999999994,
          26.700000000000003,
          33.599999999999994,
          41,
          39.3,
          15.400000000000006,
          37.400000000000006,
          39.6,
          17.099999999999994,
          37.2,
          36.1,
          28.90000000000001,
          25.099999999999994,
          38.6,
          27.5,
          41.5,
          17.799999999999997,
          20.40000000000001,
          36,
          18.8,
          32.400000000000006,
          42.1,
          37.7,
          39.1,
          7.200000000000003,
          37.2,
          28.599999999999994,
          20.3,
          37.400000000000006,
          15.299999999999995,
          34.8,
          33.599999999999994,
          36.400000000000006,
          30,
          27.5,
          37,
          25.5,
          30.200000000000003,
          23.700000000000003,
          20.099999999999994,
          20.8,
          41.5,
          34.900000000000006,
          30.40000000000001,
          37,
          41.3,
          22.200000000000003,
          35.5,
          23,
          25.8,
          37.400000000000006,
          42.1,
          36.3,
          36.6,
          44.1,
          37.5,
          33,
          39.900000000000006,
          23,
          39.6,
          32.8,
          35.400000000000006,
          37.8,
          41.8,
          19.90000000000001,
          18.700000000000003,
          36.3,
          39.2,
          20.40000000000001,
          38.900000000000006,
          39.900000000000006,
          35.5,
          33.7,
          28.3,
          36.1,
          37.3,
          45.3,
          37.900000000000006,
          35.8,
          43,
          34.099999999999994,
          41.7,
          34.7,
          39.2,
          39.7,
          43.2,
          40.6,
          40.7,
          40.5,
          29.90000000000001,
          38.7,
          36.5,
          40.6,
          24.40000000000001,
          28.8,
          40.3,
          36.400000000000006,
          37.3,
          31.5,
          37.7,
          44,
          30.3,
          36,
          33.7,
          30.599999999999994,
          21.099999999999994,
          41.6,
          36.3,
          37.6,
          40.7,
          37.3,
          23.700000000000003,
          38.5,
          41.8,
          35.099999999999994,
          47.8,
          10.200000000000005,
          34.2,
          41.1,
          41.1,
          37.7,
          38,
          34.599999999999994,
          39.900000000000006,
          38.1,
          41.900000000000006,
          38.400000000000006,
          23.700000000000003,
          20.200000000000003,
          21.5,
          31.099999999999994,
          38.6,
          33.5,
          33.3,
          40.900000000000006,
          38.7,
          34.099999999999994,
          22.200000000000003,
          27.200000000000003,
          19.8,
          33.099999999999994,
          35.900000000000006,
          40.400000000000006,
          45.900000000000006,
          39.1,
          34.7,
          23.8,
          30.3,
          35.3,
          36.6,
          40.1,
          38.8,
          36,
          25,
          36.400000000000006,
          31.5,
          24.8,
          32.900000000000006,
          20,
          43.1,
          26.700000000000003,
          29.3,
          39.2,
          26.8,
          38,
          24.3,
          39.2,
          41.900000000000006,
          29.099999999999994,
          38,
          21.8,
          35.8,
          38.5,
          35.2,
          36.2,
          33.400000000000006,
          18.099999999999994,
          35.900000000000006,
          24.3,
          18.90000000000001,
          14.900000000000006,
          29,
          20.40000000000001,
          18.5,
          39.400000000000006,
          37.2,
          40.3,
          32,
          24.099999999999994,
          40.3,
          26.8,
          29.40000000000001,
          40.400000000000006,
          37.3,
          13.299999999999995,
          38.5,
          34.5,
          42.5,
          20.8,
          45.3,
          35.099999999999994,
          29,
          35,
          24.200000000000003,
          35.8,
          30,
          35.2,
          22.40000000000001,
          37.1,
          25,
          29.3,
          19,
          35.599999999999994,
          40.900000000000006,
          35.7,
          38.900000000000006,
          39,
          29.5,
          16,
          27.5,
          20.099999999999994,
          28.5,
          28.3,
          24,
          37.3,
          40.1,
          27.099999999999994,
          37.1,
          22.8,
          39.2,
          40.8,
          31.700000000000003,
          37.6,
          27.3,
          43.2,
          40.5,
          41.1,
          17.400000000000006,
          30.8,
          37.6,
          40.7,
          37.7,
          29.90000000000001,
          37.1,
          25.3,
          28.5,
          42.400000000000006,
          41.2,
          29.5,
          38.6,
          38.8,
          12.799999999999995,
          40.2,
          33.5,
          15.5,
          44.5,
          18,
          34.5,
          38.1,
          39.1,
          36.7,
          16.799999999999997,
          43.3,
          22.90000000000001,
          39,
          36.400000000000006,
          29.90000000000001,
          16,
          36.7,
          22.8,
          13.299999999999995,
          24.200000000000003,
          22.90000000000001,
          30.90000000000001,
          34.7,
          32.400000000000006,
          17.599999999999994,
          38.2,
          45.400000000000006,
          42,
          41.5,
          39.8,
          17.5,
          33.2,
          20.700000000000003,
          40.400000000000006,
          36.400000000000006,
          33.599999999999994,
          27.5,
          37.8,
          24.5,
          23.90000000000001,
          44.400000000000006,
          38.1,
          43,
          35.099999999999994,
          38.5,
          36.400000000000006,
          40.400000000000006,
          38.5,
          38.3,
          37.8,
          16.700000000000003,
          26.40000000000001,
          44.900000000000006,
          41,
          35.3,
          23,
          24.700000000000003,
          26.5,
          20.200000000000003,
          36.900000000000006,
          30.5,
          26.3,
          26.099999999999994,
          34.900000000000006,
          34.599999999999994,
          43.2,
          42,
          37.1,
          34.7,
          41.5,
          22.90000000000001,
          17.900000000000006,
          43.2,
          38.400000000000006,
          41,
          36.8,
          13.200000000000005,
          37.900000000000006,
          36.7,
          40,
          36.3,
          39.8,
          18.8,
          39,
          39.400000000000006,
          26.5,
          39.900000000000006,
          36.5,
          41.1,
          41.3,
          21.8,
          36.6,
          43.900000000000006,
          38.900000000000006,
          37,
          39,
          39.1,
          37.6,
          32,
          43.2,
          41.1,
          28.700000000000003,
          33.099999999999994,
          39.5,
          27.599999999999994,
          17.099999999999994,
          36,
          34,
          39.1,
          33.099999999999994,
          26.099999999999994,
          20.700000000000003,
          42.1,
          40.400000000000006,
          23.8,
          38.5,
          39.2,
          38.6,
          39.2,
          33.099999999999994,
          38.400000000000006,
          39.8,
          42.900000000000006,
          40,
          37,
          24.8,
          21.200000000000003,
          36,
          39.900000000000006,
          40.3,
          37.400000000000006,
          11.900000000000006,
          39.1,
          41.400000000000006,
          38.3,
          44.3,
          38,
          26.599999999999994,
          43.900000000000006,
          37.7,
          41.8,
          35.099999999999994,
          41.400000000000006,
          37.6,
          37,
          21.90000000000001,
          38,
          26.700000000000003,
          37.900000000000006,
          36.2,
          22,
          19.700000000000003,
          45.7,
          39.8,
          30,
          27.099999999999994,
          24.40000000000001,
          28.5,
          36.6,
          24.90000000000001,
          43.900000000000006,
          32.5,
          27.8,
          37.6,
          22,
          43.5,
          23.599999999999994,
          41.2,
          21.099999999999994,
          24.099999999999994,
          32.5,
          18.599999999999994,
          35.3,
          13.700000000000005,
          37.2,
          37.6,
          37.6,
          35.8,
          39.1,
          25.90000000000001,
          41.2,
          37.6,
          38.5,
          41.6,
          33.599999999999994,
          34.7,
          29.599999999999994,
          38,
          22.90000000000001,
          16,
          23.200000000000003,
          39.8,
          35.099999999999994,
          21.099999999999994,
          39.3,
          38.6,
          33.5,
          37.6,
          22.90000000000001,
          35.7,
          37.900000000000006,
          36.8,
          36.6,
          32.900000000000006,
          44.2,
          38.2,
          26.5,
          40.400000000000006,
          44.8,
          26.40000000000001,
          32,
          24.700000000000003,
          32.400000000000006,
          40.5,
          39.4,
          38,
          28,
          40.5,
          31.599999999999994,
          35.599999999999994,
          38.7,
          32.8,
          40.5,
          24,
          36.3,
          34.8,
          41.1,
          26.5,
          39.400000000000006,
          36,
          37.1,
          40.2,
          34.3,
          41.1,
          35.5,
          23.200000000000003,
          20.8,
          27.90000000000001,
          34.8,
          9.799999999999995,
          36.3,
          43.3,
          23.40000000000001,
          35.900000000000006,
          36.2,
          17.400000000000006,
          25.3,
          42.8,
          36.8,
          41.2,
          18.40000000000001,
          37.400000000000006,
          40.1,
          8.099999999999994,
          38.3,
          35,
          35.599999999999994,
          41.900000000000006,
          16.900000000000006,
          31.3,
          35.5,
          21.5,
          28.700000000000003,
          38.5,
          41.3,
          32.5,
          33.8,
          40.6,
          40.400000000000006,
          36.3,
          38,
          38.2,
          34.2,
          36,
          29.099999999999994,
          30.90000000000001,
          38.1,
          33.099999999999994,
          39.3,
          38.6,
          38.400000000000006,
          22.3,
          20.3,
          13.299999999999995,
          35.5,
          45.900000000000006,
          33.2,
          39.900000000000006,
          42.1,
          22.8,
          37.7,
          41.6,
          37.6,
          39.5,
          22.8,
          34.8,
          40,
          39.900000000000006,
          40,
          28.700000000000003,
          19.599999999999994,
          17.599999999999994,
          21.700000000000003,
          34.7,
          30.90000000000001,
          43.5,
          40.6,
          19.5,
          40.7,
          35.400000000000006,
          35,
          40.7,
          41.3,
          35.2,
          13.299999999999995,
          38.2,
          39,
          36.1,
          37.7,
          23.099999999999994,
          26.099999999999994,
          42.1,
          20.90000000000001,
          25,
          32.599999999999994,
          34.5,
          42.5,
          34,
          36.2,
          39.3,
          24.8,
          35.8,
          41.5,
          30.8,
          42.5,
          37.3,
          29.599999999999994,
          22.90000000000001,
          39.3,
          35.2,
          36.1,
          38.1,
          30.200000000000003,
          30.200000000000003,
          14.900000000000006,
          42.2,
          26.8,
          37.2,
          36.5,
          40,
          34.3,
          38.400000000000006,
          27.40000000000001,
          33.8,
          32.099999999999994,
          22.700000000000003,
          38.400000000000006,
          42.7,
          19,
          38.3,
          43.1,
          22.099999999999994,
          41.6,
          38.900000000000006,
          38.2,
          38.3,
          17.799999999999997,
          35.7,
          39.6,
          23.40000000000001,
          37.400000000000006,
          23.700000000000003,
          37.6,
          35.3,
          36.3,
          36.4,
          24.90000000000001,
          24,
          29.8,
          20.90000000000001,
          10.799999999999995,
          41.2,
          34.900000000000006,
          35.7,
          27.200000000000003,
          30,
          30.3,
          42.8,
          39.6,
          42.1,
          38.8,
          39,
          37.9,
          36,
          38.5,
          21.5,
          39.8,
          41.6,
          42.2,
          26.3,
          40,
          42.8,
          33,
          19.90000000000001,
          45.6,
          37.7,
          30.599999999999994,
          38.2,
          27.700000000000003,
          24.8,
          20.700000000000003,
          17.400000000000006,
          30,
          25.90000000000001,
          16.299999999999997,
          17.200000000000003,
          34.400000000000006,
          36.400000000000006,
          36.2,
          18.40000000000001,
          42.3,
          32.7,
          19.3,
          30.099999999999994,
          35.3,
          37.900000000000006,
          26.599999999999994,
          28.700000000000003,
          42.400000000000006,
          13.900000000000006,
          34.7,
          22.40000000000001,
          38.8,
          18.5,
          32.400000000000006,
          27.599999999999994,
          35.7,
          32.599999999999994,
          18.5,
          38.1,
          16,
          37.6,
          37.400000000000006,
          39.1,
          23.5,
          38.1,
          39.7,
          26,
          38.1,
          28.40000000000001,
          36.5,
          41.5,
          37.3,
          22.5,
          39.7,
          15.900000000000006,
          35.5,
          17.700000000000003,
          31.200000000000003,
          34.5,
          32.7,
          44.6,
          39,
          38.6,
          26.8,
          39.8,
          44.1,
          21.200000000000003,
          13.099999999999994,
          40.6,
          41.7,
          34.8,
          16,
          40.3,
          42.5,
          40.5,
          20,
          34.7,
          36.3,
          43.5,
          39.400000000000006,
          38.1,
          27.099999999999994,
          42.2,
          39.1,
          39.8,
          18.700000000000003,
          39.8,
          34.7,
          37.5,
          23.40000000000001,
          36.3,
          42.2,
          39.1,
          39.5,
          23.8,
          29.40000000000001,
          24.90000000000001,
          45,
          28.5,
          28.099999999999994,
          36.900000000000006,
          40.400000000000006,
          26.099999999999994,
          40.400000000000006,
          43.3,
          41.5,
          29.90000000000001,
          40.6,
          40,
          35.599999999999994,
          22.40000000000001,
          36.7,
          33.3,
          34,
          24.599999999999994,
          37.1,
          27.599999999999994,
          23.8,
          17,
          31.099999999999994,
          32.900000000000006,
          41.5,
          46.3,
          27.099999999999994,
          16.200000000000003,
          30.599999999999994,
          32.900000000000006,
          40,
          38.8,
          20.099999999999994,
          12,
          37,
          32.7,
          34.900000000000006,
          24.700000000000003,
          32.599999999999994,
          36.8,
          27,
          42.1,
          40.7,
          35.900000000000006,
          37.3,
          20.40000000000001,
          29.700000000000003,
          36.8,
          19.40000000000001,
          42.400000000000006,
          27.200000000000003,
          41.5,
          23.5,
          19.599999999999994,
          38.1,
          20.5,
          20.5,
          41.5,
          32.7,
          23.5,
          40.8,
          24,
          37.1,
          48.8,
          43.3,
          39.3,
          39.3,
          36.2,
          24,
          28.90000000000001,
          39.3,
          31.200000000000003,
          34.599999999999994,
          32.3,
          43.6,
          37.5,
          37.3,
          18.8,
          33.7,
          36.2,
          39.2,
          24.90000000000001,
          25.200000000000003,
          17.299999999999997,
          20.3,
          26.8,
          40,
          15.700000000000005,
          43.1,
          42.1,
          32.5,
          21.8,
          36.400000000000006,
          38.3,
          37,
          41.1,
          44,
          43.900000000000006,
          36,
          40,
          34.5,
          40.8,
          42.6,
          28.8,
          35.5,
          32,
          35.099999999999994,
          23.5,
          37.7,
          34.900000000000006,
          46.400000000000006,
          23.200000000000003,
          31.599999999999994,
          42.3,
          34.099999999999994,
          34.7,
          21,
          37.400000000000006,
          38.900000000000006,
          39.7,
          37.3,
          33.2,
          38.3,
          36.900000000000006,
          23.5,
          38.7,
          39,
          35.8,
          39.5,
          36.7,
          34.400000000000006,
          37.900000000000006,
          30.8,
          39.3,
          39.8,
          38.6,
          40.900000000000006,
          17.299999999999997,
          36,
          37.6,
          31.099999999999994,
          31.099999999999994,
          34.900000000000006,
          16,
          41,
          31.200000000000003,
          40.7,
          8.700000000000003,
          38.7,
          41.5,
          16.700000000000003,
          41.2,
          35.900000000000006,
          38.3,
          36.900000000000006,
          37,
          32.2,
          37,
          27,
          37,
          5.599999999999994,
          26.700000000000003,
          33.7,
          30.599999999999994,
          22.8,
          41,
          44.3,
          41,
          23.700000000000003,
          23.099999999999994,
          36.1,
          26.40000000000001,
          34.900000000000006,
          35.8,
          33.400000000000006,
          25.8,
          36.900000000000006,
          39.7,
          27.90000000000001,
          41.2,
          27.40000000000001,
          13,
          26.5,
          23.8,
          38.6,
          37.7,
          31.099999999999994,
          35,
          32.7,
          26.3,
          39.6,
          38.8,
          37.6,
          38.3,
          27.200000000000003,
          37.8,
          37.8,
          19.599999999999994,
          39,
          38.1,
          29.099999999999994,
          36.7,
          37.8,
          42.7,
          17.200000000000003,
          41.6,
          43.6,
          30.90000000000001,
          31.099999999999994,
          39.400000000000006,
          39.1,
          13.599999999999994,
          12.700000000000005,
          24.200000000000003,
          28,
          39.400000000000006,
          35.900000000000006,
          13.400000000000006,
          35.3,
          30.599999999999994,
          41.5,
          41.2,
          32.900000000000006,
          43.5,
          17.799999999999997,
          17.5,
          44.3,
          41.7,
          39.8,
          42.7,
          33.3,
          40.400000000000006,
          34.8,
          43,
          40.7,
          36.1,
          33,
          35,
          34.3,
          39.1,
          36.7,
          42.2,
          26.099999999999994,
          41.900000000000006,
          20.40000000000001,
          40.8,
          14.400000000000006,
          26.200000000000003,
          35.099999999999994,
          11.900000000000006,
          38.8,
          15.200000000000005,
          38.8,
          37.5,
          37.400000000000006,
          36.7,
          18.3,
          35.900000000000006,
          31.200000000000003,
          31,
          30,
          27.599999999999994,
          36.3,
          34.7,
          25.200000000000003,
          24.90000000000001,
          39.3,
          19.599999999999994,
          33,
          42.6,
          22.200000000000003,
          24.700000000000003,
          27,
          45.5,
          37.8,
          38.1,
          37.8,
          38,
          13.599999999999994,
          43.5,
          21.40000000000001,
          19,
          32.099999999999994,
          34.400000000000006,
          34.900000000000006,
          40.7,
          26.90000000000001,
          35.900000000000006,
          31.099999999999994,
          34.2,
          33.599999999999994,
          38.1,
          39,
          13.400000000000006,
          38.900000000000006,
          39.400000000000006,
          42.3,
          14.099999999999994,
          31.3,
          33.400000000000006,
          40.7,
          41.900000000000006,
          40.7,
          39.7,
          37.7,
          35.900000000000006,
          14.400000000000006,
          31,
          39.8,
          14.900000000000006,
          38.6,
          34.8,
          36.900000000000006,
          40.8,
          15.099999999999994,
          34,
          25.3,
          34.7,
          38.900000000000006,
          18.700000000000003,
          40.2,
          19.200000000000003,
          40,
          34.8,
          37.7,
          37.6,
          19.90000000000001,
          38.3,
          24.40000000000001,
          36,
          40.400000000000006,
          29.200000000000003,
          15.200000000000005,
          40.7,
          40.8,
          32.2,
          35.099999999999994,
          28.599999999999994,
          10.5,
          26.90000000000001,
          31.90000000000001,
          24.40000000000001,
          37.8,
          20.5,
          43.7,
          31.3,
          39,
          33.900000000000006,
          42.3,
          37.3,
          37.400000000000006,
          28.200000000000003,
          23.700000000000003,
          34.599999999999994,
          31,
          22.200000000000003,
          11.900000000000006,
          38.2,
          25.8,
          41.900000000000006,
          37.8,
          37.7,
          15.299999999999995,
          40.900000000000006,
          36.6,
          23.200000000000003,
          40.1,
          39,
          38.5,
          37.900000000000006,
          39.400000000000006,
          10.099999999999994,
          17,
          27.90000000000001,
          33.5,
          37.1,
          35.3,
          37.8,
          39,
          43.400000000000006,
          39.2,
          34.900000000000006,
          35.2,
          22,
          33,
          40.3,
          39.900000000000006,
          38.2,
          37.900000000000006,
          41.5,
          34.900000000000006,
          25.099999999999994,
          33.5,
          18.200000000000003,
          28.8,
          34.599999999999994,
          39.7,
          33.099999999999994,
          34.3,
          41.900000000000006,
          39.400000000000006,
          44.2,
          24,
          40.1,
          39.1,
          38.400000000000006,
          28.700000000000003,
          34.3,
          38.900000000000006,
          24.40000000000001,
          45.3,
          38.400000000000006,
          37.7,
          36.900000000000006,
          39.1,
          41.2,
          43,
          38.1,
          22.099999999999994,
          41.400000000000006,
          33.900000000000006,
          39.3,
          41.2,
          38.5,
          20.200000000000003,
          38.6,
          33.099999999999994,
          40.5,
          36.5,
          43.1,
          34.099999999999994,
          21.40000000000001,
          40.3,
          25.099999999999994,
          24,
          36.7,
          28.90000000000001,
          33.900000000000006,
          40.900000000000006,
          19.700000000000003,
          37.2,
          28.099999999999994,
          33.2,
          42,
          33.2,
          33.400000000000006,
          41,
          19.3,
          39.6,
          29.90000000000001,
          39.3,
          44,
          35.900000000000006,
          42,
          34,
          31.8,
          36.6,
          36.1,
          41.900000000000006,
          36.1,
          36.900000000000006,
          36.5,
          44.8,
          39,
          39.400000000000006,
          32.5,
          43,
          34.7,
          17.700000000000003,
          40,
          41.5,
          38,
          24.200000000000003,
          35.8,
          37,
          18,
          39.6,
          37.7,
          36.400000000000006,
          43.6,
          36.400000000000006,
          36.8,
          31.200000000000003,
          12.599999999999994,
          35.8,
          36.8,
          23.40000000000001,
          29.3,
          29.40000000000001,
          43,
          38.5,
          34.7,
          37.9,
          23.700000000000003,
          13.900000000000006,
          37,
          39.8,
          38.5,
          29.700000000000003,
          19.599999999999994,
          37.3,
          23.40000000000001,
          39.1,
          38.7,
          37.2,
          18.40000000000001,
          28.40000000000001,
          42.8,
          19.700000000000003,
          27,
          37.1,
          25.200000000000003,
          37.400000000000006,
          37.7,
          36.5,
          41.3,
          39.6,
          27.5,
          23.3,
          42.5,
          37.6,
          29.8,
          31.90000000000001,
          25.90000000000001,
          34.7,
          25.599999999999994,
          38.1,
          43,
          43.3,
          38.400000000000006,
          40.8,
          31,
          41.3,
          36.3,
          13.799999999999995,
          23.200000000000003,
          39.7,
          35.8,
          34.2,
          32,
          31.3,
          18.90000000000001,
          19.200000000000003,
          35.7,
          25.599999999999994,
          36.6,
          24.3,
          40.8,
          24,
          35.900000000000006,
          20.3,
          40.6,
          34.099999999999994,
          33.2,
          45.2,
          29.90000000000001,
          39.900000000000006,
          22.5,
          46.1,
          18.700000000000003,
          31.90000000000001,
          43.5,
          36.900000000000006,
          41,
          33.2,
          36.2,
          23.3,
          24.8,
          37.400000000000006,
          36.6,
          25.700000000000003,
          37.7,
          17.700000000000003,
          36.1,
          32.900000000000006,
          31.5,
          45.900000000000006,
          29,
          38.7,
          32.7,
          19.200000000000003,
          23.8,
          32.599999999999994,
          38,
          34.900000000000006,
          27.40000000000001,
          30.90000000000001,
          22.3,
          40,
          33.099999999999994,
          18.90000000000001,
          38.1,
          38.1,
          36.5,
          37.8,
          32.8,
          36,
          21.5,
          36.3,
          48.5,
          47.5,
          38.900000000000006,
          36.3,
          29.5,
          26.099999999999994,
          34.599999999999994,
          39,
          23.5,
          19.200000000000003,
          28.099999999999994,
          27.8,
          32.900000000000006,
          36.5,
          40.900000000000006,
          39.2,
          36.5,
          25,
          39.8,
          43,
          29.599999999999994,
          38.8,
          20.700000000000003,
          41.8,
          28,
          23.200000000000003,
          21.200000000000003,
          37.6,
          38.900000000000006,
          33.2,
          25.5,
          23,
          24.8,
          35.8,
          23.200000000000003,
          26.099999999999994,
          38.2,
          39.7,
          37.900000000000006,
          24.099999999999994,
          38.7,
          27.8,
          25.099999999999994,
          39.3,
          36.9,
          40.400000000000006,
          39,
          39.7,
          37.8,
          21.700000000000003,
          20.5,
          42.2,
          41,
          37.8,
          36.400000000000006,
          19,
          29.599999999999994,
          36.400000000000006,
          20.90000000000001,
          42.7,
          25.099999999999994,
          39.7,
          30.90000000000001,
          15.099999999999994,
          35.400000000000006,
          12.099999999999994,
          34.900000000000006,
          26,
          34.8,
          32,
          40.900000000000006,
          35.099999999999994,
          29,
          34.7,
          41.900000000000006,
          39,
          37.5,
          42.7,
          37.8,
          34.599999999999994,
          48.2,
          16.599999999999994,
          38.400000000000006,
          42.3,
          22.200000000000003,
          35.599999999999994,
          36.7,
          12.5,
          20.5,
          36.3,
          14.900000000000006,
          29.5,
          26.40000000000001,
          39,
          26.700000000000003,
          41.400000000000006,
          39.1,
          22.5,
          35.8,
          37.7,
          39.7,
          30.099999999999994,
          36.5,
          39.2,
          16.200000000000003,
          29.8,
          31.099999999999994,
          22.099999999999994,
          37.2,
          26.200000000000003,
          31.599999999999994,
          12.700000000000005,
          42,
          18.200000000000003,
          39.1,
          38.900000000000006,
          40.400000000000006,
          42.6,
          23.3,
          37.8,
          38.6,
          44.900000000000006,
          35.400000000000006,
          35.400000000000006,
          25.8,
          28.599999999999994,
          34.7,
          27.200000000000003,
          39.8,
          34.900000000000006,
          23.3,
          30.700000000000003,
          35.900000000000006,
          40.5,
          24.90000000000001,
          33.099999999999994,
          18.700000000000003,
          27.200000000000003,
          25.40000000000001,
          21.700000000000003,
          38.8,
          30.40000000000001,
          36.900000000000006,
          39.6,
          31.700000000000003,
          13.700000000000005,
          36.2,
          33.400000000000006,
          40.7,
          39.6,
          37.6,
          38.5,
          41.3,
          31.599999999999994,
          25.700000000000003,
          34.099999999999994,
          43.6,
          16.799999999999997,
          31.099999999999994,
          32.599999999999994,
          40,
          38.8,
          21.40000000000001,
          30.8,
          42.3,
          31.8,
          36.8,
          33.5,
          38.400000000000006,
          33.400000000000006,
          38.1,
          29.8,
          30.200000000000003,
          37.2,
          22.8,
          36.5,
          37,
          36.3,
          16.299999999999997,
          31.40000000000001,
          12.599999999999994,
          35.3,
          19.599999999999994,
          38.900000000000006,
          41.2,
          39.2,
          40.7,
          39.1,
          32.5,
          39.2,
          36.2,
          39.900000000000006,
          36.8,
          34,
          21.3,
          34.5,
          36.1,
          23.5,
          41.2,
          24.599999999999994,
          37.8,
          40.3,
          39,
          22.099999999999994,
          24.8,
          19.3,
          33.599999999999994,
          40.6,
          35.099999999999994,
          24.5,
          35.2,
          38,
          33.8,
          41,
          27.700000000000003,
          39.1,
          33.7,
          36.1,
          26.599999999999994,
          28.200000000000003,
          22.5,
          38.3,
          32.5,
          38.7,
          36.8,
          40.9,
          39.8,
          25.3,
          19,
          26.200000000000003,
          42.8,
          14.799999999999995,
          20.3,
          31.200000000000003,
          32.5,
          35.2,
          42.7,
          33.2,
          35.2,
          37.8,
          40.3,
          26.8,
          33.900000000000006,
          43.400000000000006,
          34.400000000000006,
          26.700000000000003,
          35.3,
          39.2,
          34.5,
          37.400000000000006,
          36.8,
          38,
          37.400000000000006,
          38.2,
          38.1,
          39.3,
          34.5,
          42.900000000000006,
          35.099999999999994,
          17.400000000000006,
          25.599999999999994,
          32.099999999999994,
          42.5,
          25,
          40.3,
          23.90000000000001,
          41,
          32.099999999999994,
          18.700000000000003,
          27.90000000000001,
          36,
          37.2,
          39.8,
          38.7,
          28.099999999999994,
          31.599999999999994,
          30.8,
          16.900000000000006,
          35.7,
          36.400000000000006,
          34.400000000000006,
          23.700000000000003,
          23.099999999999994,
          38.6,
          37.8,
          38.3,
          43.6,
          37,
          35.099999999999994,
          37.400000000000006,
          43.2,
          38.8,
          26.40000000000001,
          39.2,
          36.6,
          35.5,
          25.099999999999994,
          36.2,
          36.900000000000006,
          41.400000000000006,
          43.2,
          41.8,
          35.599999999999994,
          25.3,
          38.5,
          37.7,
          38,
          37.8,
          38.1,
          34.599999999999994,
          13.799999999999995,
          40.400000000000006,
          16.700000000000003,
          44.2,
          40.8,
          25.599999999999994,
          35,
          35,
          39.8,
          13.400000000000006,
          40.5,
          35.099999999999994,
          33.2,
          28.8,
          33,
          40.3,
          36.8,
          36.7,
          40.3,
          38.3,
          41.1,
          22.3,
          14.200000000000005,
          20.700000000000003,
          36.7,
          39,
          36,
          12.299999999999995,
          33.900000000000006,
          41.3,
          33.900000000000006,
          34.2,
          39.6,
          35.599999999999994,
          11.099999999999994,
          38.7,
          40.400000000000006,
          41.400000000000006,
          40.7,
          26.5,
          35.5,
          36.2,
          21.90000000000001,
          38.8,
          41.3,
          36.1,
          43.8,
          31.40000000000001,
          30.8,
          12.200000000000005,
          38,
          12.200000000000005,
          27.40000000000001,
          37.400000000000006,
          26.90000000000001,
          34.8,
          37.3,
          42.7,
          33.8,
          19,
          35.400000000000006,
          33.8,
          39.900000000000006,
          19.40000000000001,
          42,
          34.099999999999994,
          41.7,
          23,
          36.900000000000006,
          27.8,
          39.7,
          34.7,
          33,
          23,
          42.5,
          36.3,
          23.8,
          43.1,
          38.1,
          35.2,
          39.900000000000006,
          38.900000000000006,
          40.5,
          39.3,
          35.3,
          38.2,
          37.7,
          23,
          36.1,
          37,
          42,
          16.400000000000006,
          34.099999999999994,
          37.8,
          43.7,
          24.40000000000001,
          42,
          38.1,
          38.3,
          26.3,
          23,
          39.900000000000006,
          39.3,
          35.900000000000006,
          27.599999999999994,
          38.7,
          31,
          42,
          44.400000000000006,
          35.599999999999994,
          19.40000000000001,
          35.5,
          28.40000000000001,
          38.6,
          25.700000000000003,
          40,
          38.6,
          24.599999999999994,
          24.200000000000003,
          33.2,
          20.099999999999994,
          31.40000000000001,
          21.3,
          28.40000000000001,
          37.1,
          37.1,
          25.3,
          27.5,
          17.400000000000006,
          25.90000000000001,
          32.7,
          36.7,
          23.200000000000003,
          29.200000000000003,
          39,
          33.099999999999994,
          38,
          39.6,
          41.1,
          28.700000000000003,
          20.3,
          40.1,
          19.599999999999994,
          45.3,
          30,
          39.1,
          20,
          40.3,
          38.400000000000006,
          30.8,
          33.7,
          23.90000000000001,
          43.6,
          24.90000000000001,
          38.400000000000006,
          40.900000000000006,
          40.1,
          26.099999999999994,
          34.8,
          15.099999999999994,
          30.599999999999994,
          30.3,
          35.7,
          39.2,
          35.400000000000006,
          28.5,
          19.3,
          22.200000000000003,
          37.2,
          20.099999999999994,
          40.3,
          35.599999999999994,
          38.1,
          40.1,
          32.5,
          11.700000000000005,
          37.7,
          39.7,
          37.2,
          14,
          27.5,
          40.3,
          28.099999999999994,
          34,
          31.200000000000003,
          41.1,
          36.900000000000006,
          22.3,
          37.3,
          39.3,
          37.5,
          32.400000000000006,
          40.7,
          33.900000000000006,
          36.5,
          25.700000000000003,
          19.099999999999994,
          40.8,
          39.7,
          33.099999999999994,
          16.5,
          39.400000000000006,
          38.6,
          35.8,
          17.400000000000006,
          33.099999999999994,
          21.90000000000001,
          41.1,
          23,
          28.90000000000001,
          40.1,
          30.8,
          34.400000000000006,
          27.90000000000001,
          36.900000000000006,
          38,
          40.400000000000006,
          24.3,
          41.900000000000006,
          31.8,
          23.599999999999994,
          37.8,
          37.6,
          34.5,
          39.8,
          36.6,
          35.400000000000006,
          27.200000000000003,
          16.700000000000003,
          36.1,
          21,
          36.8,
          47.1,
          39.7,
          36.5,
          41.2,
          40.1,
          24.8,
          43.400000000000006,
          37.6,
          20.3,
          30.90000000000001,
          22.8,
          33.2,
          28,
          19.599999999999994,
          26.90000000000001,
          41.5,
          35.900000000000006,
          25.8,
          38.5,
          29.599999999999994,
          37.5,
          32.5,
          29.099999999999994,
          36.1,
          38.400000000000006,
          35.2,
          22.40000000000001,
          34.400000000000006,
          43.6,
          36.1,
          35.400000000000006,
          17.5,
          18.599999999999994,
          29.099999999999994,
          23.8,
          35.7,
          40.3,
          15.200000000000005,
          41.5,
          38.6,
          38.3,
          37.5,
          39.1,
          42.3,
          36.900000000000006,
          15.299999999999995,
          31.8,
          37.400000000000006,
          44.8,
          35.2,
          29.40000000000001,
          16.400000000000006,
          20.099999999999994,
          13.099999999999994,
          34.099999999999994,
          33.8,
          37.6,
          34.7,
          22.599999999999994,
          24.8,
          18.8,
          25.5,
          40,
          38.7,
          42.8,
          24.700000000000003,
          40.2,
          34.2,
          30.700000000000003,
          41.5,
          41.900000000000006,
          37,
          34.400000000000006,
          31.3,
          38.6,
          31.3,
          29.099999999999994,
          33.8,
          22.700000000000003,
          39.400000000000006,
          40.1,
          14.400000000000006,
          23.90000000000001,
          33.2,
          41.5,
          36.900000000000006,
          35.400000000000006,
          33.3,
          7.099999999999994,
          17.799999999999997,
          30.599999999999994,
          28,
          23,
          38,
          41.1,
          20.5,
          31,
          32.2,
          28.599999999999994,
          30.700000000000003,
          32.5,
          27.5,
          30.099999999999994,
          40.400000000000006,
          34.2,
          41.3,
          39.5,
          38.1,
          39.1,
          38.5,
          36.7,
          36,
          38.1,
          38,
          20.3,
          26.5,
          30.90000000000001,
          40.8,
          22.90000000000001,
          23,
          22,
          45.1,
          38.6,
          38.900000000000006,
          19.599999999999994,
          34.599999999999994,
          30.5,
          33.2,
          37.5,
          21.200000000000003,
          34.3,
          19.40000000000001,
          44.2,
          40.5,
          17.099999999999994,
          38,
          35.8,
          43.2,
          39.6,
          37.1,
          43.6,
          12.900000000000006,
          24.3,
          19.700000000000003,
          24.8,
          42.2,
          38.3,
          27.40000000000001,
          25.5,
          40.3,
          33.400000000000006,
          40.8,
          26.90000000000001,
          38,
          28.8,
          32.7,
          41.1,
          32.3,
          33.599999999999994,
          28.8,
          40.7,
          33.099999999999994,
          38,
          34.599999999999994,
          19.099999999999994,
          43.7,
          38.400000000000006,
          34.400000000000006,
          24.40000000000001,
          39.400000000000006,
          38.5,
          30.40000000000001,
          30.700000000000003,
          28.200000000000003,
          37.3,
          32.2,
          38.8,
          37,
          37.900000000000006,
          34.900000000000006,
          34.7,
          19.40000000000001,
          14.900000000000006,
          38.8,
          24.099999999999994,
          37.1,
          31.700000000000003,
          38.6,
          8.900000000000006,
          32.099999999999994,
          39.7,
          30.90000000000001,
          24.40000000000001,
          29.200000000000003,
          27.099999999999994,
          40.400000000000006,
          43.2,
          29.5,
          43,
          24.700000000000003,
          33.7,
          41.6,
          35.5,
          14.5,
          34.900000000000006,
          23.599999999999994,
          36.8,
          39.1,
          36,
          21.5,
          37,
          26,
          20.200000000000003,
          35.900000000000006,
          38.6,
          13,
          20.90000000000001,
          23.3,
          33.2,
          37.8,
          42.2,
          17.799999999999997,
          32.7,
          38.8,
          35.099999999999994,
          24.40000000000001,
          12.099999999999994,
          40.7,
          31.3,
          39.900000000000006,
          26.3,
          33.8,
          34.2,
          34.8,
          37.400000000000006,
          41.400000000000006,
          15,
          16.099999999999994,
          29.8,
          21.90000000000001,
          22.3,
          31.200000000000003,
          41.5,
          31,
          24.40000000000001,
          42.3,
          19.200000000000003,
          30.5,
          23.3,
          16.400000000000006,
          32.900000000000006,
          41.900000000000006,
          24.099999999999994,
          31,
          18.40000000000001,
          20,
          26.700000000000003,
          39.400000000000006,
          18.8,
          36.5,
          39.8,
          20.90000000000001,
          41.6,
          16,
          30.40000000000001,
          36.1,
          40.2,
          23.3,
          21.3,
          37.8,
          33.400000000000006,
          20.5,
          31.3,
          35.2,
          41.6,
          25.200000000000003,
          18.700000000000003,
          40.6,
          42.3,
          17.5,
          35.599999999999994,
          35.099999999999994,
          33.599999999999994,
          38.6,
          20.8,
          14.400000000000006,
          36.1,
          39.400000000000006,
          41.2,
          43.7,
          19.40000000000001,
          36.5,
          41.1,
          39.7,
          36.2,
          26.599999999999994,
          40.7,
          24.3,
          33.099999999999994,
          36,
          27.599999999999994,
          27.8,
          38.400000000000006,
          32.599999999999994,
          41.6,
          33.8,
          36.1,
          14.599999999999994,
          38.5,
          37.5,
          37,
          36.5,
          34,
          44.5,
          45.3,
          23.099999999999994,
          39.5,
          21.8,
          30.700000000000003,
          21,
          21.8,
          40.5,
          17.400000000000006,
          19.40000000000001,
          38.2,
          39.1,
          35.900000000000006,
          37.8,
          33.599999999999994,
          40.3,
          35.599999999999994,
          40.5,
          19.5,
          36.1,
          37.5,
          30,
          35.900000000000006,
          32,
          19.099999999999994,
          42.7,
          15.299999999999995,
          38.6,
          40.400000000000006,
          32.599999999999994,
          24.40000000000001,
          32.900000000000006,
          32.7,
          35.3,
          33.7,
          31.5,
          39.1,
          28.3,
          31.40000000000001,
          27.5,
          39.6,
          14.400000000000006,
          41.2,
          30.599999999999994,
          25.599999999999994,
          34.3,
          37.900000000000006,
          18.90000000000001,
          24.5,
          41.900000000000006,
          32.8,
          31.099999999999994,
          31.8,
          38.2,
          15.799999999999995,
          30.90000000000001,
          28.3,
          24.90000000000001,
          21.200000000000003,
          29.3,
          9.099999999999994,
          25.90000000000001,
          23.200000000000003,
          35.5,
          25.8,
          14.200000000000005,
          28.8,
          19.700000000000003,
          19.8,
          28.40000000000001,
          36.900000000000006,
          26.90000000000001,
          20.599999999999994,
          28.5,
          41.3,
          44.7,
          35.8,
          41.6,
          37.6,
          10.700000000000005,
          33.400000000000006,
          26,
          41.5,
          38,
          39.2,
          33.900000000000006,
          28.700000000000003,
          35.2,
          34.3,
          19.40000000000001,
          32.400000000000006,
          42.8,
          42.3,
          40.900000000000006,
          40.2,
          22.200000000000003,
          20.200000000000003,
          43.5,
          37.8,
          42.2,
          35,
          34.8,
          39.7,
          37.2,
          33.5,
          38.400000000000006,
          35.400000000000006,
          36.6,
          38.900000000000006,
          23.8,
          22.099999999999994,
          38.2,
          33.3,
          38.900000000000006,
          24.599999999999994,
          38.2,
          28.8,
          36.5,
          34.3,
          37.5,
          39.5,
          21.40000000000001,
          37.3,
          38.7,
          38.3,
          27.5,
          37.400000000000006,
          38.4,
          39.2,
          27.700000000000003,
          38.900000000000006,
          27.90000000000001,
          34.5,
          27.8,
          12.599999999999994,
          27.40000000000001,
          37.3,
          34.900000000000006,
          37.900000000000006,
          17.299999999999997,
          24.3,
          36.7,
          28.5,
          37.1,
          37.7,
          38.8,
          33.8,
          38.8,
          40.2,
          37.7,
          37.900000000000006,
          41.3,
          39.400000000000006,
          42.7,
          28.5,
          22.200000000000003,
          39.7,
          34.3,
          25.200000000000003,
          37.400000000000006,
          24,
          24.599999999999994,
          36.900000000000006,
          32.3,
          38.3,
          23.40000000000001,
          28.200000000000003,
          36.1,
          31.599999999999994,
          34.900000000000006,
          38.3,
          41.6,
          18,
          38.6,
          41.1,
          20.90000000000001,
          29.200000000000003,
          24.599999999999994,
          18.599999999999994,
          44.1,
          27.8,
          29.5,
          33.5,
          26.200000000000003,
          38.400000000000006,
          36.400000000000006,
          34.8,
          37.7,
          38.1,
          36.900000000000006,
          26.599999999999994,
          43.7,
          25.099999999999994,
          22.3,
          18.8,
          30.5,
          22.599999999999994,
          20.3,
          43.2,
          36.2,
          2.299999999999997,
          42.1,
          41.400000000000006,
          24.90000000000001,
          21.200000000000003,
          21.599999999999994,
          38.900000000000006,
          23.599999999999994,
          39.7,
          28.5,
          24.200000000000003,
          17,
          41.2,
          35.900000000000006,
          15.200000000000005,
          38.7,
          36,
          40.3,
          26.8,
          35.2,
          35.099999999999994,
          39.3,
          23.099999999999994,
          23.700000000000003,
          35.900000000000006,
          34.3,
          34.3,
          38.5,
          27.8,
          37.1,
          32.099999999999994,
          38.7,
          36.400000000000006,
          22.700000000000003,
          18.700000000000003,
          27.8,
          32.099999999999994,
          37.3,
          23.40000000000001,
          19.90000000000001,
          37.400000000000006,
          38.900000000000006,
          27.200000000000003,
          18,
          40.5,
          31.3,
          30.200000000000003,
          37.400000000000006,
          37.5,
          37.900000000000006,
          17.700000000000003,
          35.400000000000006,
          34.599999999999994,
          14.299999999999995,
          37.4,
          36.7,
          15,
          16.299999999999997,
          36,
          37,
          49.1,
          26.700000000000003,
          26,
          43.400000000000006,
          38,
          35.2,
          45.6,
          38.7,
          25.5,
          42,
          34.8,
          39,
          31.700000000000003,
          32.599999999999994,
          38.8,
          14.200000000000005,
          35.900000000000006,
          39.7,
          39,
          38.6,
          41.1,
          22.700000000000003,
          15.200000000000005,
          40.7,
          39.6,
          32,
          21.90000000000001,
          37.6,
          38.2,
          38.1,
          39.7,
          30.3,
          41.3,
          14.400000000000006,
          31.700000000000003,
          24.5,
          35.2,
          38.7,
          41,
          32.900000000000006,
          38.8,
          19.200000000000003,
          21.700000000000003,
          39.2,
          37.400000000000006,
          24.40000000000001,
          30,
          37.900000000000006,
          21.5,
          43.1,
          42.1,
          39.6,
          30.599999999999994,
          24.40000000000001,
          43.400000000000006,
          33.2,
          34.7,
          42.400000000000006,
          36.1,
          15.099999999999994,
          21,
          38,
          35.599999999999994,
          24.40000000000001,
          36.8,
          38.900000000000006,
          37.2,
          36.2,
          43,
          20.599999999999994,
          21.200000000000003,
          39.3,
          30.40000000000001,
          42.3,
          34.3,
          23.700000000000003,
          22.5,
          33.099999999999994,
          42,
          19.3,
          43,
          38,
          38.6,
          40.400000000000006,
          34.599999999999994,
          36.3,
          35,
          35.900000000000006,
          24.700000000000003,
          38.900000000000006,
          16,
          27,
          37,
          23.8,
          16,
          25.700000000000003,
          35.3,
          26,
          29.099999999999994,
          37.2,
          21.599999999999994,
          29.200000000000003,
          41.400000000000006,
          40.5,
          23.599999999999994,
          36.6,
          25.8,
          33,
          39.900000000000006,
          3.9000000000000057,
          33.900000000000006,
          34.5,
          46.400000000000006,
          38.5
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "boxmode": "group",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "test_result"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "physical_score"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"547d875c-ffb6-4548-8976-9e5f439edcfc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"547d875c-ffb6-4548-8976-9e5f439edcfc\")) {                    Plotly.newPlot(                        \"547d875c-ffb6-4548-8976-9e5f439edcfc\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"test_result=%{x}<br>physical_score=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"\",\"notched\":false,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[1,1,0,0,1,0,0,1,0,1,1,1,1,1,1,0,0,1,0,1,0,0,1,1,0,0,1,1,0,1,0,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,1,0,1,0,0,1,0,1,0,0,0,1,1,0,0,1,1,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0,0,1,1,1,1,1,0,1,0,1,1,1,1,0,0,0,1,1,0,0,0,1,0,0,1,1,1,1,1,0,0,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,0,0,1,1,1,0,0,0,1,1,0,0,1,1,1,0,1,1,1,1,1,0,1,1,0,1,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,1,1,0,0,1,1,0,0,1,1,1,1,0,1,1,0,1,1,1,0,1,0,1,0,1,0,1,1,1,1,0,0,1,1,1,1,1,0,0,1,0,0,0,1,1,1,1,1,1,1,1,0,1,0,1,1,0,0,1,0,0,1,1,1,0,1,0,0,0,0,0,0,1,0,0,1,1,1,0,1,1,0,0,1,1,1,1,0,0,1,0,0,1,1,0,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,1,0,0,0,1,1,0,1,1,1,1,1,0,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,1,1,1,1,0,0,1,0,0,1,1,1,0,1,1,0,1,0,1,0,0,0,1,0,1,0,1,0,1,0,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,0,1,1,1,1,0,1,0,1,1,1,0,0,1,1,1,0,1,1,0,1,1,0,0,1,0,1,0,1,0,0,1,1,1,0,1,0,0,1,1,1,1,1,0,0,1,0,1,1,0,0,1,0,1,0,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,0,1,0,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1,1,1,1,1,1,1,0,0,1,0,1,0,1,0,1,0,0,1,1,0,1,1,0,1,0,0,0,0,1,1,1,1,1,1,1,0,1,0,1,0,1,0,1,1,1,0,0,0,1,0,0,1,1,0,1,1,1,0,0,1,1,1,0,0,1,0,0,0,1,0,0,1,0,0,1,0,1,1,1,0,1,1,0,1,0,1,1,1,0,1,1,1,0,1,1,1,0,1,1,0,1,1,1,1,0,0,1,0,0,1,1,0,1,1,0,0,1,1,1,1,1,0,0,0,1,0,0,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,0,1,1,0,0,1,0,0,1,0,1,1,0,1,1,0,1,1,1,1,0,0,0,1,0,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,0,0,1,0,0,0,0,0,0,1,1,0,1,1,1,1,0,0,1,1,1,0,1,0,0,0,0,1,1,0,1,1,1,1,1,1,0,1,1,0,0,1,1,0,1,1,1,1,0,0,0,0,1,1,0,0,1,1,0,1,1,0,1,1,0,1,1,0,0,0,1,0,0,1,1,0,1,1,0,1,1,0,0,0,0,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,0,0,0,1,0,1,1,0,1,1,1,0,1,0,0,0,1,0,1,1,0,1,1,1,1,1,0,1,0,0,1,0,0,1,1,1,0,1,1,0,1,0,1,1,0,1,0,1,1,1,0,1,1,0,0,0,0,0,1,0,1,1,1,1,0,1,0,1,1,0,1,1,0,0,0,1,1,1,1,0,1,1,1,1,1,0,0,1,1,0,0,1,0,0,0,1,0,1,1,0,1,1,0,1,0,0,1,1,1,0,1,0,0,1,0,1,1,0,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,0,1,0,1,1,0,1,0,1,1,1,1,1,1,0,1,1,0,1,1,0,1,1,1,0,0,1,1,1,1,0,0,1,0,1,0,0,1,1,1,1,0,1,1,0,0,1,1,0,1,0,1,1,0,1,1,0,0,0,1,0,1,0,1,1,1,0,1,1,0,0,1,1,1,1,0,1,0,1,1,1,1,1,0,0,1,1,1,1,1,0,1,0,1,1,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,0,1,1,0,1,0,1,1,1,1,1,0,1,0,1,1,1,1,0,1,1,0,1,0,0,1,1,0,0,1,0,0,1,1,1,1,0,1,1,1,0,1,1,1,0,1,1,0,0,1,0,0,0,0,0,1,1,0,0,1,0,1,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,0,1,0,1,0,1,1,0,1,1,1,0,0,1,1,1,0,1,0,0,1,0,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,0,0,0,1,0,1,0,1,1,0,0,1,0,1,1,1,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,0,0,0,0,0,0,1,1,1,1,0,0,1,1,1,0,1,0,0,1,1,1,0,1,1,1,1,0,1,1,1,1,1,0,0,1,1,1,0,0,1,1,0,1,0,1,1,1,0,0,1,1,1,0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,1,0,0,1,1,0,0,1,1,1,1,1,0,1,1,1,1,0,1,0,1,0,1,0,0,1,0,1,1,1,0,1,0,0,0,1,1,1,0,0,1,0,0,0,0,1,0,1,1,0,1,0,0,0,1,1,1,1,0,1,1,1,1,1,1,0,1,0,0,1,0,0,0,0,1,1,0,1,1,0,1,1,0,0,0,0,1,1,0,1,0,0,0,0,0,1,0,1,0,1,1,1,0,1,1,0,1,0,1,1,1,1,0,1,1,1,0,0,1,0,1,1,0,0,1,1,1,1,0,0,1,0,1,0,0,1,0,0,0,0,1,1,1,1,1,1,1,0,1,1,0,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1,1,1,1,0,1,0,1,0,0,1,0,1,1,1,0,0,0,0,1,0,1,1,1,0,1,0,0,0,1,1,0,1,1,0,0,0,1,0,0,1,0,0,1,1,0,0,1,0,1,0,1,1,1,1,0,1,0,1,1,1,0,1,1,0,1,1,0,1,0,1,1,0,1,0,1,0,1,1,1,1,0,0,0,1,1,0,1,0,1,0,1,0,0,1,1,0,1,1,1,0,1,1,0,0,1,1,1,1,0,1,0,1,1,0,0,0,0,0,0,1,0,1,1,0,1,0,0,1,1,0,1,1,0,1,1,1,1,0,0,1,0,0,0,1,1,1,0,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,0,0,0,1,1,0,0,1,1,0,0,0,0,1,1,1,1,0,0,1,1,0,0,0,0,1,0,0,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,0,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,0,1,1,0,1,0,0,0,1,1,0,0,0,1,0,1,1,0,0,1,0,0,0,1,0,1,0,1,1,0,1,0,1,1,1,1,1,0,0,0,0,0,1,1,1,1,1,0,1,1,0,1,0,0,1,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,1,0,1,1,1,0,1,0,0,0,1,1,1,1,1,1,0,0,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,1,1,1,0,0,1,0,1,0,0,1,1,1,0,1,0,1,1,1,1,1,0,1,0,1,1,0,0,1,1,1,1,1,0,0,1,0,1,1,0,1,0,1,1,0,0,1,0,1,0,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,0,0,1,1,1,1,0,0,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,0,1,0,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,0,0,1,1,0,0,1,0,0,0,1,1,1,0,1,0,1,0,1,1,1,0,1,0,1,1,1,1,0,1,1,0,1,1,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,0,1,1,1,0,0,1,1,0,0,1,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,0,1,1,0,1,0,1,0,0,1,1,1,1,0,1,1,1,1,1,1,0,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,0,1,1,1,0,1,0,0,1,1,1,0,1,1,1,0,1,1,0,1,0,1,1,1,1,0,0,1,0,1,0,0,1,0,1,0,1,0,1,0,1,0,1,0,1,1,1,1,1,0,1,0,0,1,1,0,1,1,1,1,0,1,1,0,0,1,1,1,1,0,0,0,1,0,0,0,0,1,1,0,1,0,0,1,1,0,0,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,1,1,1,1,0,0,0,0,0,1,0,1,1,1,0,1,1,1,0,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,1,1,0,1,0,1,1,0,1,1,1,1,0,0,1,1,1,1,0,1,0,1,1,0,0,1,1,1,1,0,1,0,0,1,0,0,1,1,1,0,0,1,0,1,1,1,0,1,1,1,1,1,0,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,0,1,0,1,1,0,0,0,1,1,0,1,1,1,1,0,1,0,1,1,1,1,1,0,1,1,0,0,0,1,0,1,1,1,1,1,1,1,1,1,1,0,1,0,1,0,1,1,1,0,0,0,1,1,1,1,0,1,0,0,1,1,0,1,0,0,1,1,1,1,0,1,0,0,1,0,0,0,0,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,0,0,1,1,0,1,0,0,0,1,0,0,0,1,0,1,1,1,0,1,1,1,1,1,1,0,1,1,1,0,0,1,1,1,0,1,1,0,1,0,0,0,0,0,1,0,0,1,0,0,1,1,1,0,1,0,0,1,0,1,0,1,0,0,1,0,0,0,0,0,1,1,0,1,1,0,0,0,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,0,0,1,0,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,1,0,0,1,1,1,0,1,1,0,1,1,0,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,0,1,1,1,1,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,1,0,1,0,1,1,0,1,0,1,1,1,1,1,0,1,0,0,0,1,0,0,1,1,1,1,0,1,0,0,1,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,1,0,0,0,1,1,0,1,1,0,0,0,0,0,0,0,1,1,0,1,0,1,1,1,1,0,1,1,1,0,0,1,1,1,0,1,0,0,1,1,1,1,1,0,1,1,0,1,0,1,1,1,1,0,1,0,1,1,0,0,1,0,0,0,0,1,1,0,0,1,1,0,1,1,0,1,0,1,1,1,0,1,0,0,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,0,1,0,1,1,0,0,1,1,1,1,0,1,1,0,0,1,1,1,1,0,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,0,0,1,0,1,1,0,0,1,1,0,1,1,1,1,1,1,0,1,1,1,0,0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,1,1,0,1,0,1,1,0,0,1,1,0,0,0,0,1,0,1,0,0,1,0,1,0,1,0,0,1,0,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,0,0,1,1,0,1,1,1,1,0,1,1,0,1,1,1,1,0,1,1,0,1,0,0,1,0,1,0,1,0,1,1,1,1,0,1,1,1,0,1,1,1,1,0,1,1,0,0,0,1,0,1,1,0,1,1,0,0,1,1,1,0,1,1,0,1,1,1,1,0,1,1,0,0,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,0,0,1,1,0,1,1,0,1,1,1,0,0,1,1,1,1,1,0,0,0,0,0,1,1,0,1,1,1,1,1,0,0,1,1,1,1,0,0,1,0,0,0,1,1,0,0,1,0,1,1,0,1,1,0,0,1,1,1,1,1,0,0,1,0,1,1,1,1,1,0,1,0,0,1,1,0,1,1,0,1,1,1,0,0,1,1,0,1,0,1,1,1,0,0,0,0,0,0,1,1,1,0,0,0,1,1,1,1,1,0,0,1,0,1,0,1,0,1,1,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,1,1,0,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1,1,1,0,1,1,0,1,0,1,1,1,0,1,0,1,0,0,1,0,1,1,1,0,1,0,0,0,1,1,1,0,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,0,0,0,1,0,0,1,1,0,1,1,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,0,1,1,0,0,0,1,1,1,0,0,1,1,1,0,1,1,0,1,1,1,1,0,0,1,0,1,0,1,0,0,1,0,0,1,0,0,1,0,1,1,1,1,1,1,0,0,1,0,1,0,1,1,1,0,1,1,1,0,0,0,0,0,1,0,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,0,1,0,1,0,1,1,1,0,1,1,1,1,0,1,1,0,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,0,1,0,1,0,1,1,0,1,1,1,1,1,0,1,0,0,0,0,0,0,0,1,1,1,0,0,1,0,1,1,1,0,1,1,0,1,0,0,0,0,1,1,1,1,0,0,1,1,1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,0,0,1,1,0,0,0,0,1,1,0,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,0,0,1,0,1,0,1,1,1,1,0,1,1,0,0,0,1,1,0,0,1,0,1,1,0,0,0,1,1,1,1,1,0,1,0,0,1,1,0,1,0,1,0,1,1,1,1,0,1,1,1,0,0,0,1,1,1,1,1,0,0,1,1,0,1,1,1,1,0,0,0,1,1,0,1,0,1,1,1,1,0,1,0,1,1,0,0,1,1,1,1,0,0,0,1,0,1,0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,0,1,1,1,0,1,1,0,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,0,0,0,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,0,1,0,0,1,0,0,1,0,1,0,1,1,1,0,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,0,1,1,0,0,0,1,1,1,0,0,0,1,1,1,0,0,1,0,1,1,1,0,0,1,0,0,1,0,1,1,1,1,1,0,0,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,0,1,0,1,0,1,0,1,1,1,1,0,1,0,1,0,1,1,1,1,1,1,0,0,1,1,0,1,0,1,0,0,1,0,1,1,0,0,1,1,1,0,0,0,1,1,0,1,1,0,1,0,1,0,1,1,1,1,1,0,0,1,1,0,0,0,0,1,1,1,1,1,0,1,1,0,1,0,1,0,0,0,0,1,1,0,0,0,1,0,0,1,1,1,0,1,0,0,1,0,1,1,1,1,0,0,1,1,1,1,0,0,1,0,1,0,1,0,0,1,0,1,0,1,1,1,0,0,1,1,1,0,1,1,1,1,0,1,1,0,1,0,0,0,1,0,0,0,1,0,1,1,0,1,1,1,0,1,1,0,0,0,0,0,0,0,0,1,0,1,1,1,1,0,1,1,1,1,1,0,1,1,0,1,1,0,0,1,1,0,1,0,0,0,0,1,0,1,1,1,0,1,0,1,1,1,1,1,0,0,0,1,0,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,1,0,1,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,0,1,1,1,0,0,0,1,1,1,0,1,1,1,1,0,1,0,1,0,0,0,1,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,0,1,1,1,1,1,1,0,0,1,1,1,1,0,1,1,1,1,1,1,1,1,0,0,0,1,0,1,0,1,1,0,0,1,1,1,1,0,1,0,0,0,1,0,0,0,1,1,0,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,0,1,1,0,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,0,0,0,1,1,1,0,1,1,1,1,0,1,0,1,1,1,1,0,1,1,0,1,1,1,1,1,1,0,1,0,0,1,0,1,0,1,1,0,0,1,1,0,1,1,1,0,1,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,0,1,1,1,0,0,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,1,0,0,1,0,1,1,1,0,0,1,0,1,0,1,0,1,1,0,1,0,0,0,1,1,1,0,1,0,0,0,1,1,1,0,0,0,1,0,1,1,1,1,1,0,1,1,1,0,0,1,0,1,0,1,1,0,1,1,1,0,1,0,1,0,0,1,1,1,0,1,1,1,0,1,0,1,0,0,1,0,1,0,1,1,1,0,1,1,0,1,1,1,1,1,1,0,0,1,0,1,1,1,1,1,1,0,1,1,0,1,0,1,1,0,0,1,1,0,1,0,1,1,0,1,1,1,0,1,1,1,1,0,0,0,0,1,1,0,1,1,1,1,1,1,1,0,1,1,1,0,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,0,1,1,0,1,1,1,0,0,1,0,0,1,0,1,1,0,0,1,1,1,0,0,0,0,0,0,0,1,1,0,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,0,0,0,1,1,1,0,1,0,1,1,0,1,0,1,1,0,1,1,1,0,1,1,0,0,0,0,1,1,0,0,1,1,1,0,1,0,1,1,0,1,0,1,1,1,1,0,0,1,1,0,1,1,0,1,0,1,1,0,1,1,0,1,0,0,1,0,1,1,1,0,0,1,1,0,0,0,1,1,0,1,0,0,1,1,0,1,0,1,1,1,0,0,0,0,0,1,0,0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,1,1,1,1,1,0,0,0,0,0,0,1,1,0,1,0,0,0,0,1,1,0,0,0,0,0,1,0,1,1,0,1,0,0,1,1,0,0,1,0,0,0,1,1,0,0,1,1,0,1,1,1,0,0,0,1,1,1,1,0,1,1,1,1,0,1,0,1,1,0,0,1,0,1,0,1,0,0,1,0,1,1,1,1,0,1,0,1,0,0,1,0,0,1,1,1,1,1,1,1,1,0,1,1,0,1,0,0,1,0,1,1,1,0,1,1,1,1,0,1,0,0,0,1,0,1,1,0,1,1,0,0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,0,1,1,0,1,1,1,1,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,1,0,1,1,0,0,0,0,1,1,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,0,1,0,0,1,1,1,0,0,1,0,1,0,1,0,1,1,0,1,0,0,1,0,0,0,0,1,1,0,1,1,1,0,1,0,0,0,0,0,0,1,0,0,1,1,0,0,0,1,0,0,0,0,0,1,1,0,1,1,1,0,1,1,1,0,0,1,1,1,1,0,1,0,1,1,0,0,0,0,0,0,0,1,1,0,0,1,1,0,1,1,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,1,1,1,0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1,1,1,0,1,0,0,0,1,1,1,0,1,0,0,1,1,0,0,1,0,1,1,1,0,0,1,1,1,1,1,0,0,1,1,0,1,1,1,1,1,0,0,1,1,1,1,0,0,0,1,0,1,1,1,1,1,1,1,0,0,1,0,0,1,0,0,0,1,0,0,1,0,0,1,0,0,1,0,1,1,0,1,1,1,1],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[40.7,37.2,24.700000000000003,31.0,42.900000000000006,23.0,28.90000000000001,41.1,32.0,41.5,42.1,31.3,39.8,34.599999999999994,43.0,10.700000000000005,32.900000000000006,40.7,26.8,36.2,20.8,25.8,41.5,39.1,22.90000000000001,20.5,35.900000000000006,41.0,25.40000000000001,39.900000000000006,19.0,18.700000000000003,44.6,32.900000000000006,28.700000000000003,23.3,28.599999999999994,30.3,31.90000000000001,46.900000000000006,35.900000000000006,36.5,39.3,27.40000000000001,24.700000000000003,20.700000000000003,35.099999999999994,25.200000000000003,34.5,35.400000000000006,16.799999999999997,37.2,17.599999999999994,34.900000000000006,25.40000000000001,20.40000000000001,34.099999999999994,44.6,30.8,29.8,25.8,39.1,44.400000000000006,24.3,20.0,22.5,32.3,6.400000000000006,30.599999999999994,37.3,23.700000000000003,40.1,19.099999999999994,42.5,36.8,19.40000000000001,36.5,23.0,26.200000000000003,45.8,22.8,31.5,39.1,35.5,42.1,34.8,40.0,27.700000000000003,35.7,14.099999999999994,40.2,36.5,34.5,36.5,22.099999999999994,21.200000000000003,24.90000000000001,41.5,35.7,32.900000000000006,22.90000000000001,24.200000000000003,41.3,34.3,33.400000000000006,34.5,32.2,39.8,37.6,41.6,20.099999999999994,30.0,23.0,37.400000000000006,13.099999999999994,29.599999999999994,36.3,32.400000000000006,37.8,40.0,42.8,33.099999999999994,33.5,50.0,35.099999999999994,34.2,39.0,30.5,34.900000000000006,40.6,38.8,34.400000000000006,27.90000000000001,31.90000000000001,14.700000000000005,37.900000000000006,30.40000000000001,16.599999999999994,16.799999999999997,36.1,40.1,43.0,21.700000000000003,37.400000000000006,34.400000000000006,40.5,34.900000000000006,39.1,24.8,37.1,44.2,22.099999999999994,44.3,16.700000000000003,33.3,31.700000000000003,19.599999999999994,24.40000000000001,31.3,37.8,24.90000000000001,34.400000000000006,39.6,34.400000000000006,17.799999999999997,43.400000000000006,8.799999999999997,24.0,32.599999999999994,43.400000000000006,37.9,28.3,32.5,36.900000000000006,23.3,15.799999999999995,42.2,32.900000000000006,36.400000000000006,33.2,15.900000000000006,45.5,38.400000000000006,18.90000000000001,36.900000000000006,41.2,40.0,26.8,36.5,28.90000000000001,41.8,12.099999999999994,42.6,40.5,38.1,41.1,38.8,38.1,27.90000000000001,24.200000000000003,40.900000000000006,35.099999999999994,40.400000000000006,33.900000000000006,44.6,13.799999999999995,24.0,41.400000000000006,27.40000000000001,28.099999999999994,36.6,32.400000000000006,33.8,41.0,39.2,37.3,44.3,34.7,37.6,30.0,35.599999999999994,34.0,40.5,40.5,27.200000000000003,22.599999999999994,35.2,16.700000000000003,24.599999999999994,41.0,48.3,31.599999999999994,31.90000000000001,40.1,20.700000000000003,26.099999999999994,21.3,22.700000000000003,24.40000000000001,40.1,35.8,22.5,38.1,34.7,33.099999999999994,40.2,17.599999999999994,33.0,37.0,33.099999999999994,21.700000000000003,33.599999999999994,36.5,32.2,39.1,32.5,32.099999999999994,38.3,22.8,23.5,38.5,35.7,15.799999999999995,38.7,33.400000000000006,22.700000000000003,38.0,26.5,38.7,40.1,40.5,36.5,35.2,36.8,35.7,40.900000000000006,34.7,33.400000000000006,39.3,23.599999999999994,41.5,38.8,37.1,45.0,38.8,23.5,35.400000000000006,39.5,20.599999999999994,35.2,35.5,38.900000000000006,42.5,21.5,36.7,39.3,41.1,38.6,42.8,23.599999999999994,35.2,29.90000000000001,41.1,41.7,22.90000000000001,34.099999999999994,38.7,11.5,36.8,36.1,33.400000000000006,21.700000000000003,43.8,43.2,44.8,32.400000000000006,38.400000000000006,36.6,38.8,35.599999999999994,34.0,16.099999999999994,26.0,38.7,45.0,25.099999999999994,42.2,29.3,40.6,42.1,22.599999999999994,29.3,33.8,9.5,28.599999999999994,40.1,36.900000000000006,43.400000000000006,22.599999999999994,38.900000000000006,35.099999999999994,14.799999999999995,32.8,24.40000000000001,42.900000000000006,21.8,19.599999999999994,27.200000000000003,34.0,22.5,29.5,19.599999999999994,36.400000000000006,14.799999999999995,39.3,12.799999999999995,38.0,37.1,37.2,24.200000000000003,24.90000000000001,31.700000000000003,36.400000000000006,34.400000000000006,40.6,39.0,24.200000000000003,22.599999999999994,16.5,30.700000000000003,38.1,36.400000000000006,24.599999999999994,42.0,39.3,36.6,37.6,28.099999999999994,39.3,37.8,41.1,42.400000000000006,38.5,29.599999999999994,26.5,38.900000000000006,38.1,36.3,19.90000000000001,33.099999999999994,37.5,21.5,37.8,38.2,18.40000000000001,18.40000000000001,37.900000000000006,26.200000000000003,36.0,22.200000000000003,39.400000000000006,27.90000000000001,28.40000000000001,34.900000000000006,35.3,37.900000000000006,18.3,40.400000000000006,24.599999999999994,20.599999999999994,36.6,47.3,39.1,36.400000000000006,35.099999999999994,25.3,25.40000000000001,32.099999999999994,20.5,38.3,38.6,28.8,12.900000000000006,36.3,21.200000000000003,37.7,24.700000000000003,39.6,42.1,41.400000000000006,35.900000000000006,23.90000000000001,40.7,28.200000000000003,41.8,40.7,45.1,35.5,39.900000000000006,36.8,34.900000000000006,35.400000000000006,25.0,38.900000000000006,22.8,36.6,19.40000000000001,42.8,43.0,39.8,37.1,30.200000000000003,42.1,39.400000000000006,49.5,36.1,37.900000000000006,43.6,32.8,28.8,31.0,22.099999999999994,34.2,27.700000000000003,28.90000000000001,34.400000000000006,43.2,39.400000000000006,41.8,38.2,35.900000000000006,42.0,44.1,34.599999999999994,26.099999999999994,39.0,24.90000000000001,38.1,24.5,36.7,28.599999999999994,39.6,22.5,37.1,35.5,39.6,30.099999999999994,35.099999999999994,39.2,32.0,37.5,21.599999999999994,23.5,26.200000000000003,33.3,40.6,38.900000000000006,35.099999999999994,40.1,35.599999999999994,33.2,45.7,27.90000000000001,39.400000000000006,36.8,41.2,30.5,37.1,21.8,30.599999999999994,37.900000000000006,37.6,23.099999999999994,28.599999999999994,20.40000000000001,39.3,17.400000000000006,29.3,33.400000000000006,42.2,32.2,39.3,39.7,39.8,19.099999999999994,23.8,41.1,37.7,38.8,23.700000000000003,26.8,40.1,27.700000000000003,25.5,20.099999999999994,39.8,23.40000000000001,20.599999999999994,38.1,20.0,28.5,37.0,17.200000000000003,40.400000000000006,37.400000000000006,35.400000000000006,20.8,37.900000000000006,40.900000000000006,7.799999999999997,32.0,26.200000000000003,37.900000000000006,30.8,42.2,27.40000000000001,35.8,41.900000000000006,39.0,23.599999999999994,37.400000000000006,40.1,39.6,21.3,38.6,38.0,36.0,33.2,37.8,40.400000000000006,43.2,16.200000000000003,20.200000000000003,35.2,19.3,30.5,40.900000000000006,43.5,27.5,39.400000000000006,37.2,28.099999999999994,43.2,40.5,38.2,39.7,33.099999999999994,45.6,12.900000000000006,20.200000000000003,20.099999999999994,36.0,22.8,29.5,48.2,22.40000000000001,37.1,34.8,36.1,35.7,36.6,34.599999999999994,40.1,36.1,33.900000000000006,39.2,37.2,38.6,37.8,38.0,36.3,38.8,33.7,18.90000000000001,29.200000000000003,42.400000000000006,25.3,23.90000000000001,33.400000000000006,41.400000000000006,30.40000000000001,37.400000000000006,38.8,33.400000000000006,41.5,34.2,44.5,34.2,39.5,39.7,47.2,33.3,37.3,36.7,25.0,36.3,35.3,33.7,27.700000000000003,39.3,38.0,28.3,34.7,37.6,23.700000000000003,12.0,38.900000000000006,14.299999999999995,16.299999999999997,40.2,17.700000000000003,40.400000000000006,41.6,16.0,40.1,33.2,15.599999999999994,41.7,35.2,47.8,36.3,31.3,33.5,26.200000000000003,36.7,33.0,41.2,34.099999999999994,44.8,37.6,38.7,22.700000000000003,31.8,12.400000000000006,25.0,28.90000000000001,27.099999999999994,39.7,36.5,42.0,43.0,35.8,36.2,43.900000000000006,24.0,27.3,28.099999999999994,28.700000000000003,24.700000000000003,31.90000000000001,43.1,39.7,33.7,42.0,44.5,20.099999999999994,36.900000000000006,34.400000000000006,41.1,35.7,24.200000000000003,42.3,39.400000000000006,47.5,38.2,26.3,37.2,30.599999999999994,22.8,26.3,28.8,33.099999999999994,30.0,36.8,36.3,18.0,38.2,36.400000000000006,35.599999999999994,43.5,23.200000000000003,34.7,40.0,39.400000000000006,32.5,20.5,40.8,20.90000000000001,28.5,25.5,19.700000000000003,40.6,40.2,23.200000000000003,35.900000000000006,41.5,41.5,37.0,39.0,34.8,38.9,35.099999999999994,43.8,14.599999999999994,4.5,35.900000000000006,37.7,25.40000000000001,33.0,38.5,34.099999999999994,41.7,22.700000000000003,20.5,26.8,28.5,36.5,35.3,25.3,23.90000000000001,42.2,37.1,27.90000000000001,36.7,37.8,15.700000000000005,35.2,37.2,27.099999999999994,40.1,41.8,16.700000000000003,26.0,25.700000000000003,34.3,19.40000000000001,35.599999999999994,38.6,44.3,22.5,38.900000000000006,37.8,23.0,34.900000000000006,37.1,26.3,28.700000000000003,23.099999999999994,27.40000000000001,33.900000000000006,36.8,16.099999999999994,41.0,36.3,37.8,39.400000000000006,38.1,39.6,38.400000000000006,30.40000000000001,27.8,31.599999999999994,34.599999999999994,41.3,22.099999999999994,38.8,36.2,37.7,35.599999999999994,21.40000000000001,29.8,25.0,35.400000000000006,14.299999999999995,36.7,37.900000000000006,31.3,43.6,39.5,36.900000000000006,25.599999999999994,35.0,11.099999999999994,18.599999999999994,12.200000000000005,33.7,18.200000000000003,38.6,41.400000000000006,31.0,39.5,41.400000000000006,39.3,35.900000000000006,35.7,32.7,32.599999999999994,22.90000000000001,33.2,35.8,22.099999999999994,19.200000000000003,41.1,39.0,32.599999999999994,20.5,41.7,43.900000000000006,21.599999999999994,41.3,13.700000000000005,38.0,36.0,28.700000000000003,40.7,15.700000000000005,38.2,42.2,36.8,27.0,35.8,36.6,17.799999999999997,26.0,24.40000000000001,30.599999999999994,23.90000000000001,40.6,16.200000000000003,30.0,39.3,36.2,42.0,23.5,37.400000000000006,23.3,40.6,37.0,24.099999999999994,30.90000000000001,40.8,22.90000000000001,23.90000000000001,24.200000000000003,44.1,38.900000000000006,46.7,42.7,12.099999999999994,32.2,37.2,36.900000000000006,38.8,31.3,25.3,34.099999999999994,35.599999999999994,37.8,30.5,13.900000000000006,31.5,25.0,25.0,21.0,46.3,20.5,37.900000000000006,31.599999999999994,10.400000000000006,40.8,35.3,24.40000000000001,40.7,26.3,24.3,39.3,41.6,34.5,21.0,31.700000000000003,17.799999999999997,17.400000000000006,39.0,20.0,37.5,38.3,32.400000000000006,36.3,41.0,42.0,36.5,37.0,36.6,36.1,32.2,18.90000000000001,33.599999999999994,43.6,40.900000000000006,35.599999999999994,39.0,38.3,36.400000000000006,37.6,38.0,38.0,39.1,26.3,38.6,38.7,10.299999999999995,22.40000000000001,35.099999999999994,18.0,35.0,42.7,27.700000000000003,42.8,15.0,36.8,42.400000000000006,34.7,36.2,38.900000000000006,38.8,14.599999999999994,36.3,37.1,17.200000000000003,32.2,31.200000000000003,18.40000000000001,37.0,41.7,37.8,23.200000000000003,22.099999999999994,39.3,37.400000000000006,32.5,34.3,15.599999999999994,26.8,40.900000000000006,18.5,44.1,29.5,22.90000000000001,35.599999999999994,41.2,39.1,41.0,25.700000000000003,38.900000000000006,37.1,22.90000000000001,16.700000000000003,39.7,44.7,33.900000000000006,35.2,18.3,33.400000000000006,37.2,24.099999999999994,43.2,38.0,29.3,29.40000000000001,34.900000000000006,43.400000000000006,23.40000000000001,34.599999999999994,26.40000000000001,44.900000000000006,38.5,31.8,22.599999999999994,37.2,33.0,22.3,16.200000000000003,37.6,36.7,31.200000000000003,35.7,13.299999999999995,35.0,21.200000000000003,37.2,38.0,37.5,28.90000000000001,38.2,30.40000000000001,30.8,38.6,40.1,41.900000000000006,43.2,38.6,32.900000000000006,37.6,30.8,36.0,42.6,23.8,40.5,40.2,31.599999999999994,30.099999999999994,36.5,24.8,37.6,47.7,41.3,32.5,22.5,40.8,31.700000000000003,37.0,33.099999999999994,33.7,42.0,36.1,22.5,31.200000000000003,41.3,40.8,14.0,33.8,38.1,29.0,36.5,16.0,28.40000000000001,40.5,41.1,38.8,34.7,29.40000000000001,33.900000000000006,27.5,38.2,32.400000000000006,42.5,37.900000000000006,30.3,35.3,37.2,32.8,37.900000000000006,15.299999999999995,20.599999999999994,33.8,36.400000000000006,20.5,21.200000000000003,31.200000000000003,18.599999999999994,28.90000000000001,37.2,38.5,36.400000000000006,37.8,25.40000000000001,35.7,41.6,39.8,22.8,39.2,37.3,42.7,36.4,43.400000000000006,38.6,14.700000000000005,25.200000000000003,29.200000000000003,19.90000000000001,25.40000000000001,20.099999999999994,35.7,11.599999999999994,36.6,39.8,36.3,19.40000000000001,36.5,18.200000000000003,44.900000000000006,42.3,38.1,31.700000000000003,19.3,35.0,40.1,29.200000000000003,31.200000000000003,38.2,39.6,35.099999999999994,32.3,43.7,43.5,34.7,39.400000000000006,35.5,37.400000000000006,35.900000000000006,34.599999999999994,41.8,23.200000000000003,12.700000000000005,20.200000000000003,33.2,39.6,37.2,38.6,40.0,36.8,22.90000000000001,41.1,24.200000000000003,40.1,34.599999999999994,37.400000000000006,41.3,17.5,36.400000000000006,39.2,37.3,15.900000000000006,24.90000000000001,38.900000000000006,36.900000000000006,38.2,13.200000000000005,30.90000000000001,23.40000000000001,34.2,38.1,32.8,38.2,34.400000000000006,40.400000000000006,36.900000000000006,46.5,38.5,31.40000000000001,34.900000000000006,26.200000000000003,31.0,39.2,39.400000000000006,27.3,23.5,38.400000000000006,24.5,21.0,28.3,31.8,38.900000000000006,10.900000000000006,37.400000000000006,19.200000000000003,41.6,40.8,29.40000000000001,30.5,39.1,19.700000000000003,42.7,35.400000000000006,34.900000000000006,24.40000000000001,22.700000000000003,42.7,41.3,36.2,-0.0,33.3,21.5,34.3,33.2,35.0,38.2,38.8,35.8,37.0,39.3,28.0,37.7,37.8,21.099999999999994,37.1,42.6,41.3,35.5,28.599999999999994,38.2,28.8,25.0,11.400000000000006,19.3,19.0,21.5,35.099999999999994,38.7,39.8,42.3,14.900000000000006,14.099999999999994,42.1,38.2,36.2,25.599999999999994,33.900000000000006,17.900000000000006,11.400000000000006,43.8,35.2,37.900000000000006,18.099999999999994,34.099999999999994,33.400000000000006,42.0,38.7,28.8,31.8,39.1,42.2,38.1,34.599999999999994,23.599999999999994,33.099999999999994,35.2,42.900000000000006,39.6,32.8,17.700000000000003,35.7,33.3,23.0,36.400000000000006,28.40000000000001,36.8,37.8,37.0,25.200000000000003,24.5,38.5,38.900000000000006,39.400000000000006,33.400000000000006,34.3,13.700000000000005,32.3,37.3,38.8,17.200000000000003,22.0,24.599999999999994,16.700000000000003,34.2,33.2,22.5,18.5,22.5,35.5,13.799999999999995,19.099999999999994,41.400000000000006,38.400000000000006,21.0,27.5,39.0,38.400000000000006,34.7,34.8,35.8,30.700000000000003,39.3,32.900000000000006,36.400000000000006,40.1,33.2,45.6,37.3,33.900000000000006,29.5,37.7,23.0,11.099999999999994,35.5,29.40000000000001,39.2,37.900000000000006,39.2,26.8,36.0,19.700000000000003,29.90000000000001,20.200000000000003,36.900000000000006,39.1,36.900000000000006,35.599999999999994,17.200000000000003,37.8,19.200000000000003,17.900000000000006,25.099999999999994,27.099999999999994,34.3,30.5,37.8,39.900000000000006,32.3,37.0,33.400000000000006,21.200000000000003,30.700000000000003,36.6,41.2,41.6,41.3,26.40000000000001,38.7,35.8,38.6,24.3,41.2,37.1,20.200000000000003,36.7,32.8,32.0,36.2,32.599999999999994,23.90000000000001,23.3,24.5,33.900000000000006,43.2,17.599999999999994,40.400000000000006,35.400000000000006,28.200000000000003,38.5,36.7,25.200000000000003,26.3,16.299999999999997,22.200000000000003,38.400000000000006,36.6,24.099999999999994,36.2,26.90000000000001,17.799999999999997,28.599999999999994,40.5,23.200000000000003,45.0,15.799999999999995,43.900000000000006,15.200000000000005,43.1,37.7,36.0,27.200000000000003,41.6,35.099999999999994,30.90000000000001,35.599999999999994,17.700000000000003,32.3,35.900000000000006,37.0,41.6,23.099999999999994,38.2,38.1,38.5,30.0,28.099999999999994,37.1,30.200000000000003,34.5,35.599999999999994,22.0,29.700000000000003,38.2,39.3,40.7,34.8,18.90000000000001,19.5,39.0,27.0,40.1,17.599999999999994,26.40000000000001,36.900000000000006,30.5,32.2,28.40000000000001,26.3,35.0,32.400000000000006,40.2,37.400000000000006,46.7,42.900000000000006,38.0,22.90000000000001,39.2,37.0,35.099999999999994,36.7,29.90000000000001,34.0,37.8,37.400000000000006,35.5,23.0,29.3,36.6,43.1,40.3,41.1,42.5,37.5,40.1,36.3,37.8,34.900000000000006,19.599999999999994,33.5,20.700000000000003,18.599999999999994,39.8,38.3,32.2,41.1,41.1,30.5,40.8,31.0,42.400000000000006,26.099999999999994,28.90000000000001,39.8,15.400000000000006,35.5,35.599999999999994,45.6,25.5,13.400000000000006,34.3,39.7,31.099999999999994,36.8,40.0,40.8,31.5,15.5,38.3,25.0,16.799999999999997,19.90000000000001,40.900000000000006,32.8,23.099999999999994,39.0,33.900000000000006,23.599999999999994,27.40000000000001,28.8,40.5,30.0,14.400000000000006,41.5,24.700000000000003,30.700000000000003,35.400000000000006,38.8,43.2,26.8,43.400000000000006,20.40000000000001,34.599999999999994,14.5,38.8,35.3,41.3,37.5,26.8,41.8,24.700000000000003,42.1,34.5,30.200000000000003,18.3,41.6,41.0,24.099999999999994,41.8,38.400000000000006,17.900000000000006,33.3,23.40000000000001,34.7,41.900000000000006,13.5,36.900000000000006,31.599999999999994,31.8,22.099999999999994,38.3,38.3,35.3,40.1,23.599999999999994,15.599999999999994,26.5,42.7,40.0,19.8,40.5,35.400000000000006,37.6,33.400000000000006,38.0,13.700000000000005,7.799999999999997,42.400000000000006,39.400000000000006,34.099999999999994,36.2,40.1,40.900000000000006,19.3,37.400000000000006,42.3,23.90000000000001,27.40000000000001,41.5,44.8,40.5,40.8,17.400000000000006,39.8,35.0,42.0,38.5,25.700000000000003,25.700000000000003,19.90000000000001,21.8,17.700000000000003,17.400000000000006,36.900000000000006,30.700000000000003,36.400000000000006,34.099999999999994,27.200000000000003,36.900000000000006,30.099999999999994,31.200000000000003,36.6,42.1,32.599999999999994,36.3,38.7,37.4,35.8,33.5,39.3,34.099999999999994,27.700000000000003,9.599999999999994,33.0,30.599999999999994,21.5,25.0,40.3,41.0,37.900000000000006,20.3,29.90000000000001,39.6,24.5,37.8,33.400000000000006,44.1,37.1,29.200000000000003,35.099999999999994,38.6,21.099999999999994,36.1,37.400000000000006,42.3,36.5,37.6,26.700000000000003,17.299999999999997,21.40000000000001,34.0,44.0,36.3,30.599999999999994,44.7,43.5,20.099999999999994,22.0,29.8,24.3,35.7,34.3,42.8,39.6,27.3,19.8,35.8,37.7,31.099999999999994,23.5,20.599999999999994,24.0,39.6,22.099999999999994,29.700000000000003,37.6,37.3,39.900000000000006,31.200000000000003,24.40000000000001,41.6,36.6,34.5,21.40000000000001,36.0,35.5,42.6,39.6,39.400000000000006,39.2,38.8,24.40000000000001,13.900000000000006,23.099999999999994,22.200000000000003,37.6,35.900000000000006,41.7,26.8,35.599999999999994,35.900000000000006,38.8,39.6,40.3,36.900000000000006,36.7,23.8,31.8,34.8,37.3,42.1,24.40000000000001,34.900000000000006,40.5,26.90000000000001,43.3,33.599999999999994,22.0,37.8,25.90000000000001,21.099999999999994,22.200000000000003,38.400000000000006,33.900000000000006,30.099999999999994,24.200000000000003,36.7,40.0,23.599999999999994,33.8,38.900000000000006,17.700000000000003,37.7,36.400000000000006,33.099999999999994,21.599999999999994,30.0,37.8,25.5,34.400000000000006,25.8,42.0,36.6,20.5,37.2,25.8,39.1,33.0,40.2,31.40000000000001,43.2,23.5,19.3,16.299999999999997,21.90000000000001,25.0,29.5,36.6,43.0,37.2,39.0,16.200000000000003,38.2,34.3,17.0,44.5,33.599999999999994,25.5,34.8,25.40000000000001,19.8,29.0,35.5,37.7,42.3,42.3,25.90000000000001,30.3,30.8,9.900000000000006,34.0,44.0,35.099999999999994,37.8,31.3,21.700000000000003,38.6,34.3,30.0,21.099999999999994,38.8,20.8,21.40000000000001,21.3,37.6,41.400000000000006,34.2,46.400000000000006,39.900000000000006,43.900000000000006,33.2,38.5,37.6,20.8,20.3,37.400000000000006,41.2,41.6,35.599999999999994,37.400000000000006,36.7,38.900000000000006,38.5,31.099999999999994,38.5,20.200000000000003,33.3,41.1,33.7,33.3,41.3,38.900000000000006,6.5,31.599999999999994,40.400000000000006,23.3,43.6,27.3,26.0,34.3,39.5,38.3,42.6,40.5,30.700000000000003,38.0,37.6,40.2,29.099999999999994,41.0,25.90000000000001,34.400000000000006,17.5,38.2,39.8,31.90000000000001,39.6,29.90000000000001,34.099999999999994,39.3,40.2,36.1,28.700000000000003,34.0,42.3,11.0,40.0,41.1,24.599999999999994,37.5,34.099999999999994,35.900000000000006,39.7,11.599999999999994,26.200000000000003,38.400000000000006,21.3,37.2,27.599999999999994,29.90000000000001,38.5,39.0,39.400000000000006,19.40000000000001,36.5,36.5,28.0,37.8,38.400000000000006,40.5,41.8,44.900000000000006,31.5,39.2,26.099999999999994,37.5,36.0,35.099999999999994,41.0,36.0,23.0,34.0,38.0,36.8,42.0,39.6,20.599999999999994,26.3,37.900000000000006,29.40000000000001,27.0,13.200000000000005,40.1,39.1,40.0,35.900000000000006,22.3,28.0,34.099999999999994,38.5,38.0,32.900000000000006,44.400000000000006,36.2,39.3,40.8,29.40000000000001,37.3,38.8,17.599999999999994,28.8,29.3,35.599999999999994,41.8,41.0,33.7,35.2,33.5,22.5,25.599999999999994,42.400000000000006,39.6,38.0,45.2,37.0,38.2,34.099999999999994,26.5,26.700000000000003,39.8,37.900000000000006,15.0,17.299999999999997,39.7,9.200000000000005,15.099999999999994,24.3,34.0,35.3,37.400000000000006,43.0,32.099999999999994,20.599999999999994,36.8,17.700000000000003,33.0,40.8,36.5,24.3,36.0,28.0,36.400000000000006,40.5,32.900000000000006,36.900000000000006,20.0,37.2,39.7,19.700000000000003,39.1,35.7,43.3,20.8,29.099999999999994,37.5,39.6,45.3,38.6,35.8,21.3,38.7,26.200000000000003,34.3,24.40000000000001,32.099999999999994,34.5,24.40000000000001,40.1,39.0,39.5,39.7,39.1,32.0,44.7,34.2,34.3,38.7,20.8,41.5,35.5,33.400000000000006,36.2,29.200000000000003,37.3,36.8,45.400000000000006,18.0,35.900000000000006,34.5,30.599999999999994,25.700000000000003,24.90000000000001,35.0,34.0,34.400000000000006,33.3,43.3,28.099999999999994,17.900000000000006,39.5,34.099999999999994,37.1,25.3,36.8,39.5,33.5,44.7,21.3,39.5,27.200000000000003,17.200000000000003,35.3,25.8,43.8,38.3,38.7,37.900000000000006,23.3,31.8,22.099999999999994,32.599999999999994,38.0,34.8,38.400000000000006,37.2,19.8,42.1,43.8,38.6,36.6,39.7,36.2,21.8,37.2,25.099999999999994,22.8,43.400000000000006,40.8,33.0,34.400000000000006,22.40000000000001,27.40000000000001,43.1,40.900000000000006,36.900000000000006,40.0,34.400000000000006,40.400000000000006,38.0,15.799999999999995,34.7,40.8,34.599999999999994,28.3,41.2,27.200000000000003,31.200000000000003,34.900000000000006,37.900000000000006,38.7,21.3,35.900000000000006,40.1,39.6,19.200000000000003,36.0,35.7,26.099999999999994,34.099999999999994,24.200000000000003,40.8,37.7,40.1,39.5,34.3,21.3,39.5,27.099999999999994,42.400000000000006,25.099999999999994,22.3,32.3,31.40000000000001,35.0,8.599999999999994,39.400000000000006,26.8,33.7,43.0,39.7,24.200000000000003,37.0,25.0,37.8,39.2,33.099999999999994,37.7,35.099999999999994,22.5,36.0,13.599999999999994,12.599999999999994,35.7,42.400000000000006,39.4,35.900000000000006,37.3,38.5,40.3,33.0,35.3,39.6,27.40000000000001,25.0,40.400000000000006,37.5,40.400000000000006,37.8,23.5,31.90000000000001,22.0,41.7,19.599999999999994,28.90000000000001,20.0,35.2,41.3,40.400000000000006,39.7,35.3,22.5,20.90000000000001,34.0,36.8,26.599999999999994,33.3,38.2,41.3,41.5,25.3,32.0,35.3,41.1,37.6,34.7,38.400000000000006,31.40000000000001,36.0,37.400000000000006,40.8,33.599999999999994,23.0,25.0,37.3,42.7,34.8,34.8,34.400000000000006,21.8,21.5,24.8,35.0,41.0,31.099999999999994,32.7,32.8,37.3,25.099999999999994,37.6,37.6,34.599999999999994,24.200000000000003,25.0,19.099999999999994,15.700000000000005,35.5,17.799999999999997,20.700000000000003,41.0,25.40000000000001,36.0,19.3,25.0,33.900000000000006,12.400000000000006,29.200000000000003,16.299999999999997,39.3,39.8,25.90000000000001,40.6,25.8,36.1,38.7,29.0,46.900000000000006,34.5,38.0,38.7,34.900000000000006,21.0,39.1,30.700000000000003,39.3,36.400000000000006,21.8,36.5,45.5,34.599999999999994,36.7,27.3,35.5,35.900000000000006,41.900000000000006,37.900000000000006,38.5,21.700000000000003,39.400000000000006,22.0,25.5,35.8,16.200000000000003,24.599999999999994,39.7,37.3,38.3,26.599999999999994,16.200000000000003,35.099999999999994,10.5,40.1,35.599999999999994,41.8,33.7,37.8,31.0,46.0,37.0,37.0,13.799999999999995,30.200000000000003,38.7,38.6,46.400000000000006,21.40000000000001,39.7,34.5,31.099999999999994,41.8,41.3,40.2,38.2,41.1,39.7,35.400000000000006,42.0,39.7,40.3,22.3,38.400000000000006,38.1,39.0,39.8,25.5,36.0,35.400000000000006,41.6,37.3,43.0,21.90000000000001,42.2,37.5,33.3,33.0,23.099999999999994,41.6,33.400000000000006,37.5,37.400000000000006,45.6,18.3,25.5,38.7,32.3,27.3,39.0,38.1,31.099999999999994,41.5,23.90000000000001,39.1,17.400000000000006,35.8,38.7,39.6,45.7,41.400000000000006,22.40000000000001,43.900000000000006,38.8,21.40000000000001,33.5,17.900000000000006,40.900000000000006,35.400000000000006,31.099999999999994,36.6,42.5,36.2,33.5,40.900000000000006,42.2,40.400000000000006,39.0,32.7,33.7,39.1,21.599999999999994,31.3,27.200000000000003,37.1,41.2,43.8,17.0,9.900000000000006,35.099999999999994,35.099999999999994,37.7,42.1,33.3,24.90000000000001,42.6,31.700000000000003,17.099999999999994,39.3,33.3,29.40000000000001,31.0,15.799999999999995,23.90000000000001,39.1,38.1,36.6,45.6,17.700000000000003,35.900000000000006,13.200000000000005,22.3,37.8,27.3,36.9,36.4,28.700000000000003,42.3,26.3,40.0,37.6,40.900000000000006,38.900000000000006,32.599999999999994,36.7,35.599999999999994,35.5,37.900000000000006,35.5,42.8,36.2,25.700000000000003,24.099999999999994,39.3,40.1,39.3,24.8,27.40000000000001,35.7,39.900000000000006,30.90000000000001,40.8,30.099999999999994,14.799999999999995,19.5,43.7,33.7,19.3,32.400000000000006,34.0,30.599999999999994,33.5,36.1,36.900000000000006,19.90000000000001,40.400000000000006,38.2,35.3,34.3,33.099999999999994,36.3,31.40000000000001,40.400000000000006,37.3,32.5,25.099999999999994,26.700000000000003,33.599999999999994,41.0,39.3,15.400000000000006,37.400000000000006,39.6,17.099999999999994,37.2,36.1,28.90000000000001,25.099999999999994,38.6,27.5,41.5,17.799999999999997,20.40000000000001,36.0,18.8,32.400000000000006,42.1,37.7,39.1,7.200000000000003,37.2,28.599999999999994,20.3,37.400000000000006,15.299999999999995,34.8,33.599999999999994,36.400000000000006,30.0,27.5,37.0,25.5,30.200000000000003,23.700000000000003,20.099999999999994,20.8,41.5,34.900000000000006,30.40000000000001,37.0,41.3,22.200000000000003,35.5,23.0,25.8,37.400000000000006,42.1,36.3,36.6,44.1,37.5,33.0,39.900000000000006,23.0,39.6,32.8,35.400000000000006,37.8,41.8,19.90000000000001,18.700000000000003,36.3,39.2,20.40000000000001,38.900000000000006,39.900000000000006,35.5,33.7,28.3,36.1,37.3,45.3,37.900000000000006,35.8,43.0,34.099999999999994,41.7,34.7,39.2,39.7,43.2,40.6,40.7,40.5,29.90000000000001,38.7,36.5,40.6,24.40000000000001,28.8,40.3,36.400000000000006,37.3,31.5,37.7,44.0,30.3,36.0,33.7,30.599999999999994,21.099999999999994,41.6,36.3,37.6,40.7,37.3,23.700000000000003,38.5,41.8,35.099999999999994,47.8,10.200000000000005,34.2,41.1,41.1,37.7,38.0,34.599999999999994,39.900000000000006,38.1,41.900000000000006,38.400000000000006,23.700000000000003,20.200000000000003,21.5,31.099999999999994,38.6,33.5,33.3,40.900000000000006,38.7,34.099999999999994,22.200000000000003,27.200000000000003,19.8,33.099999999999994,35.900000000000006,40.400000000000006,45.900000000000006,39.1,34.7,23.8,30.3,35.3,36.6,40.1,38.8,36.0,25.0,36.400000000000006,31.5,24.8,32.900000000000006,20.0,43.1,26.700000000000003,29.3,39.2,26.8,38.0,24.3,39.2,41.900000000000006,29.099999999999994,38.0,21.8,35.8,38.5,35.2,36.2,33.400000000000006,18.099999999999994,35.900000000000006,24.3,18.90000000000001,14.900000000000006,29.0,20.40000000000001,18.5,39.400000000000006,37.2,40.3,32.0,24.099999999999994,40.3,26.8,29.40000000000001,40.400000000000006,37.3,13.299999999999995,38.5,34.5,42.5,20.8,45.3,35.099999999999994,29.0,35.0,24.200000000000003,35.8,30.0,35.2,22.40000000000001,37.1,25.0,29.3,19.0,35.599999999999994,40.900000000000006,35.7,38.900000000000006,39.0,29.5,16.0,27.5,20.099999999999994,28.5,28.3,24.0,37.3,40.1,27.099999999999994,37.1,22.8,39.2,40.8,31.700000000000003,37.6,27.3,43.2,40.5,41.1,17.400000000000006,30.8,37.6,40.7,37.7,29.90000000000001,37.1,25.3,28.5,42.400000000000006,41.2,29.5,38.6,38.8,12.799999999999995,40.2,33.5,15.5,44.5,18.0,34.5,38.1,39.1,36.7,16.799999999999997,43.3,22.90000000000001,39.0,36.400000000000006,29.90000000000001,16.0,36.7,22.8,13.299999999999995,24.200000000000003,22.90000000000001,30.90000000000001,34.7,32.400000000000006,17.599999999999994,38.2,45.400000000000006,42.0,41.5,39.8,17.5,33.2,20.700000000000003,40.400000000000006,36.400000000000006,33.599999999999994,27.5,37.8,24.5,23.90000000000001,44.400000000000006,38.1,43.0,35.099999999999994,38.5,36.400000000000006,40.400000000000006,38.5,38.3,37.8,16.700000000000003,26.40000000000001,44.900000000000006,41.0,35.3,23.0,24.700000000000003,26.5,20.200000000000003,36.900000000000006,30.5,26.3,26.099999999999994,34.900000000000006,34.599999999999994,43.2,42.0,37.1,34.7,41.5,22.90000000000001,17.900000000000006,43.2,38.400000000000006,41.0,36.8,13.200000000000005,37.900000000000006,36.7,40.0,36.3,39.8,18.8,39.0,39.400000000000006,26.5,39.900000000000006,36.5,41.1,41.3,21.8,36.6,43.900000000000006,38.900000000000006,37.0,39.0,39.1,37.6,32.0,43.2,41.1,28.700000000000003,33.099999999999994,39.5,27.599999999999994,17.099999999999994,36.0,34.0,39.1,33.099999999999994,26.099999999999994,20.700000000000003,42.1,40.400000000000006,23.8,38.5,39.2,38.6,39.2,33.099999999999994,38.400000000000006,39.8,42.900000000000006,40.0,37.0,24.8,21.200000000000003,36.0,39.900000000000006,40.3,37.400000000000006,11.900000000000006,39.1,41.400000000000006,38.3,44.3,38.0,26.599999999999994,43.900000000000006,37.7,41.8,35.099999999999994,41.400000000000006,37.6,37.0,21.90000000000001,38.0,26.700000000000003,37.900000000000006,36.2,22.0,19.700000000000003,45.7,39.8,30.0,27.099999999999994,24.40000000000001,28.5,36.6,24.90000000000001,43.900000000000006,32.5,27.8,37.6,22.0,43.5,23.599999999999994,41.2,21.099999999999994,24.099999999999994,32.5,18.599999999999994,35.3,13.700000000000005,37.2,37.6,37.6,35.8,39.1,25.90000000000001,41.2,37.6,38.5,41.6,33.599999999999994,34.7,29.599999999999994,38.0,22.90000000000001,16.0,23.200000000000003,39.8,35.099999999999994,21.099999999999994,39.3,38.6,33.5,37.6,22.90000000000001,35.7,37.900000000000006,36.8,36.6,32.900000000000006,44.2,38.2,26.5,40.400000000000006,44.8,26.40000000000001,32.0,24.700000000000003,32.400000000000006,40.5,39.4,38.0,28.0,40.5,31.599999999999994,35.599999999999994,38.7,32.8,40.5,24.0,36.3,34.8,41.1,26.5,39.400000000000006,36.0,37.1,40.2,34.3,41.1,35.5,23.200000000000003,20.8,27.90000000000001,34.8,9.799999999999995,36.3,43.3,23.40000000000001,35.900000000000006,36.2,17.400000000000006,25.3,42.8,36.8,41.2,18.40000000000001,37.400000000000006,40.1,8.099999999999994,38.3,35.0,35.599999999999994,41.900000000000006,16.900000000000006,31.3,35.5,21.5,28.700000000000003,38.5,41.3,32.5,33.8,40.6,40.400000000000006,36.3,38.0,38.2,34.2,36.0,29.099999999999994,30.90000000000001,38.1,33.099999999999994,39.3,38.6,38.400000000000006,22.3,20.3,13.299999999999995,35.5,45.900000000000006,33.2,39.900000000000006,42.1,22.8,37.7,41.6,37.6,39.5,22.8,34.8,40.0,39.900000000000006,40.0,28.700000000000003,19.599999999999994,17.599999999999994,21.700000000000003,34.7,30.90000000000001,43.5,40.6,19.5,40.7,35.400000000000006,35.0,40.7,41.3,35.2,13.299999999999995,38.2,39.0,36.1,37.7,23.099999999999994,26.099999999999994,42.1,20.90000000000001,25.0,32.599999999999994,34.5,42.5,34.0,36.2,39.3,24.8,35.8,41.5,30.8,42.5,37.3,29.599999999999994,22.90000000000001,39.3,35.2,36.1,38.1,30.200000000000003,30.200000000000003,14.900000000000006,42.2,26.8,37.2,36.5,40.0,34.3,38.400000000000006,27.40000000000001,33.8,32.099999999999994,22.700000000000003,38.400000000000006,42.7,19.0,38.3,43.1,22.099999999999994,41.6,38.900000000000006,38.2,38.3,17.799999999999997,35.7,39.6,23.40000000000001,37.400000000000006,23.700000000000003,37.6,35.3,36.3,36.4,24.90000000000001,24.0,29.8,20.90000000000001,10.799999999999995,41.2,34.900000000000006,35.7,27.200000000000003,30.0,30.3,42.8,39.6,42.1,38.8,39.0,37.9,36.0,38.5,21.5,39.8,41.6,42.2,26.3,40.0,42.8,33.0,19.90000000000001,45.6,37.7,30.599999999999994,38.2,27.700000000000003,24.8,20.700000000000003,17.400000000000006,30.0,25.90000000000001,16.299999999999997,17.200000000000003,34.400000000000006,36.400000000000006,36.2,18.40000000000001,42.3,32.7,19.3,30.099999999999994,35.3,37.900000000000006,26.599999999999994,28.700000000000003,42.400000000000006,13.900000000000006,34.7,22.40000000000001,38.8,18.5,32.400000000000006,27.599999999999994,35.7,32.599999999999994,18.5,38.1,16.0,37.6,37.400000000000006,39.1,23.5,38.1,39.7,26.0,38.1,28.40000000000001,36.5,41.5,37.3,22.5,39.7,15.900000000000006,35.5,17.700000000000003,31.200000000000003,34.5,32.7,44.6,39.0,38.6,26.8,39.8,44.1,21.200000000000003,13.099999999999994,40.6,41.7,34.8,16.0,40.3,42.5,40.5,20.0,34.7,36.3,43.5,39.400000000000006,38.1,27.099999999999994,42.2,39.1,39.8,18.700000000000003,39.8,34.7,37.5,23.40000000000001,36.3,42.2,39.1,39.5,23.8,29.40000000000001,24.90000000000001,45.0,28.5,28.099999999999994,36.900000000000006,40.400000000000006,26.099999999999994,40.400000000000006,43.3,41.5,29.90000000000001,40.6,40.0,35.599999999999994,22.40000000000001,36.7,33.3,34.0,24.599999999999994,37.1,27.599999999999994,23.8,17.0,31.099999999999994,32.900000000000006,41.5,46.3,27.099999999999994,16.200000000000003,30.599999999999994,32.900000000000006,40.0,38.8,20.099999999999994,12.0,37.0,32.7,34.900000000000006,24.700000000000003,32.599999999999994,36.8,27.0,42.1,40.7,35.900000000000006,37.3,20.40000000000001,29.700000000000003,36.8,19.40000000000001,42.400000000000006,27.200000000000003,41.5,23.5,19.599999999999994,38.1,20.5,20.5,41.5,32.7,23.5,40.8,24.0,37.1,48.8,43.3,39.3,39.3,36.2,24.0,28.90000000000001,39.3,31.200000000000003,34.599999999999994,32.3,43.6,37.5,37.3,18.8,33.7,36.2,39.2,24.90000000000001,25.200000000000003,17.299999999999997,20.3,26.8,40.0,15.700000000000005,43.1,42.1,32.5,21.8,36.400000000000006,38.3,37.0,41.1,44.0,43.900000000000006,36.0,40.0,34.5,40.8,42.6,28.8,35.5,32.0,35.099999999999994,23.5,37.7,34.900000000000006,46.400000000000006,23.200000000000003,31.599999999999994,42.3,34.099999999999994,34.7,21.0,37.400000000000006,38.900000000000006,39.7,37.3,33.2,38.3,36.900000000000006,23.5,38.7,39.0,35.8,39.5,36.7,34.400000000000006,37.900000000000006,30.8,39.3,39.8,38.6,40.900000000000006,17.299999999999997,36.0,37.6,31.099999999999994,31.099999999999994,34.900000000000006,16.0,41.0,31.200000000000003,40.7,8.700000000000003,38.7,41.5,16.700000000000003,41.2,35.900000000000006,38.3,36.900000000000006,37.0,32.2,37.0,27.0,37.0,5.599999999999994,26.700000000000003,33.7,30.599999999999994,22.8,41.0,44.3,41.0,23.700000000000003,23.099999999999994,36.1,26.40000000000001,34.900000000000006,35.8,33.400000000000006,25.8,36.900000000000006,39.7,27.90000000000001,41.2,27.40000000000001,13.0,26.5,23.8,38.6,37.7,31.099999999999994,35.0,32.7,26.3,39.6,38.8,37.6,38.3,27.200000000000003,37.8,37.8,19.599999999999994,39.0,38.1,29.099999999999994,36.7,37.8,42.7,17.200000000000003,41.6,43.6,30.90000000000001,31.099999999999994,39.400000000000006,39.1,13.599999999999994,12.700000000000005,24.200000000000003,28.0,39.400000000000006,35.900000000000006,13.400000000000006,35.3,30.599999999999994,41.5,41.2,32.900000000000006,43.5,17.799999999999997,17.5,44.3,41.7,39.8,42.7,33.3,40.400000000000006,34.8,43.0,40.7,36.1,33.0,35.0,34.3,39.1,36.7,42.2,26.099999999999994,41.900000000000006,20.40000000000001,40.8,14.400000000000006,26.200000000000003,35.099999999999994,11.900000000000006,38.8,15.200000000000005,38.8,37.5,37.400000000000006,36.7,18.3,35.900000000000006,31.200000000000003,31.0,30.0,27.599999999999994,36.3,34.7,25.200000000000003,24.90000000000001,39.3,19.599999999999994,33.0,42.6,22.200000000000003,24.700000000000003,27.0,45.5,37.8,38.1,37.8,38.0,13.599999999999994,43.5,21.40000000000001,19.0,32.099999999999994,34.400000000000006,34.900000000000006,40.7,26.90000000000001,35.900000000000006,31.099999999999994,34.2,33.599999999999994,38.1,39.0,13.400000000000006,38.900000000000006,39.400000000000006,42.3,14.099999999999994,31.3,33.400000000000006,40.7,41.900000000000006,40.7,39.7,37.7,35.900000000000006,14.400000000000006,31.0,39.8,14.900000000000006,38.6,34.8,36.900000000000006,40.8,15.099999999999994,34.0,25.3,34.7,38.900000000000006,18.700000000000003,40.2,19.200000000000003,40.0,34.8,37.7,37.6,19.90000000000001,38.3,24.40000000000001,36.0,40.400000000000006,29.200000000000003,15.200000000000005,40.7,40.8,32.2,35.099999999999994,28.599999999999994,10.5,26.90000000000001,31.90000000000001,24.40000000000001,37.8,20.5,43.7,31.3,39.0,33.900000000000006,42.3,37.3,37.400000000000006,28.200000000000003,23.700000000000003,34.599999999999994,31.0,22.200000000000003,11.900000000000006,38.2,25.8,41.900000000000006,37.8,37.7,15.299999999999995,40.900000000000006,36.6,23.200000000000003,40.1,39.0,38.5,37.900000000000006,39.400000000000006,10.099999999999994,17.0,27.90000000000001,33.5,37.1,35.3,37.8,39.0,43.400000000000006,39.2,34.900000000000006,35.2,22.0,33.0,40.3,39.900000000000006,38.2,37.900000000000006,41.5,34.900000000000006,25.099999999999994,33.5,18.200000000000003,28.8,34.599999999999994,39.7,33.099999999999994,34.3,41.900000000000006,39.400000000000006,44.2,24.0,40.1,39.1,38.400000000000006,28.700000000000003,34.3,38.900000000000006,24.40000000000001,45.3,38.400000000000006,37.7,36.900000000000006,39.1,41.2,43.0,38.1,22.099999999999994,41.400000000000006,33.900000000000006,39.3,41.2,38.5,20.200000000000003,38.6,33.099999999999994,40.5,36.5,43.1,34.099999999999994,21.40000000000001,40.3,25.099999999999994,24.0,36.7,28.90000000000001,33.900000000000006,40.900000000000006,19.700000000000003,37.2,28.099999999999994,33.2,42.0,33.2,33.400000000000006,41.0,19.3,39.6,29.90000000000001,39.3,44.0,35.900000000000006,42.0,34.0,31.8,36.6,36.1,41.900000000000006,36.1,36.900000000000006,36.5,44.8,39.0,39.400000000000006,32.5,43.0,34.7,17.700000000000003,40.0,41.5,38.0,24.200000000000003,35.8,37.0,18.0,39.6,37.7,36.400000000000006,43.6,36.400000000000006,36.8,31.200000000000003,12.599999999999994,35.8,36.8,23.40000000000001,29.3,29.40000000000001,43.0,38.5,34.7,37.9,23.700000000000003,13.900000000000006,37.0,39.8,38.5,29.700000000000003,19.599999999999994,37.3,23.40000000000001,39.1,38.7,37.2,18.40000000000001,28.40000000000001,42.8,19.700000000000003,27.0,37.1,25.200000000000003,37.400000000000006,37.7,36.5,41.3,39.6,27.5,23.3,42.5,37.6,29.8,31.90000000000001,25.90000000000001,34.7,25.599999999999994,38.1,43.0,43.3,38.400000000000006,40.8,31.0,41.3,36.3,13.799999999999995,23.200000000000003,39.7,35.8,34.2,32.0,31.3,18.90000000000001,19.200000000000003,35.7,25.599999999999994,36.6,24.3,40.8,24.0,35.900000000000006,20.3,40.6,34.099999999999994,33.2,45.2,29.90000000000001,39.900000000000006,22.5,46.1,18.700000000000003,31.90000000000001,43.5,36.900000000000006,41.0,33.2,36.2,23.3,24.8,37.400000000000006,36.6,25.700000000000003,37.7,17.700000000000003,36.1,32.900000000000006,31.5,45.900000000000006,29.0,38.7,32.7,19.200000000000003,23.8,32.599999999999994,38.0,34.900000000000006,27.40000000000001,30.90000000000001,22.3,40.0,33.099999999999994,18.90000000000001,38.1,38.1,36.5,37.8,32.8,36.0,21.5,36.3,48.5,47.5,38.900000000000006,36.3,29.5,26.099999999999994,34.599999999999994,39.0,23.5,19.200000000000003,28.099999999999994,27.8,32.900000000000006,36.5,40.900000000000006,39.2,36.5,25.0,39.8,43.0,29.599999999999994,38.8,20.700000000000003,41.8,28.0,23.200000000000003,21.200000000000003,37.6,38.900000000000006,33.2,25.5,23.0,24.8,35.8,23.200000000000003,26.099999999999994,38.2,39.7,37.900000000000006,24.099999999999994,38.7,27.8,25.099999999999994,39.3,36.9,40.400000000000006,39.0,39.7,37.8,21.700000000000003,20.5,42.2,41.0,37.8,36.400000000000006,19.0,29.599999999999994,36.400000000000006,20.90000000000001,42.7,25.099999999999994,39.7,30.90000000000001,15.099999999999994,35.400000000000006,12.099999999999994,34.900000000000006,26.0,34.8,32.0,40.900000000000006,35.099999999999994,29.0,34.7,41.900000000000006,39.0,37.5,42.7,37.8,34.599999999999994,48.2,16.599999999999994,38.400000000000006,42.3,22.200000000000003,35.599999999999994,36.7,12.5,20.5,36.3,14.900000000000006,29.5,26.40000000000001,39.0,26.700000000000003,41.400000000000006,39.1,22.5,35.8,37.7,39.7,30.099999999999994,36.5,39.2,16.200000000000003,29.8,31.099999999999994,22.099999999999994,37.2,26.200000000000003,31.599999999999994,12.700000000000005,42.0,18.200000000000003,39.1,38.900000000000006,40.400000000000006,42.6,23.3,37.8,38.6,44.900000000000006,35.400000000000006,35.400000000000006,25.8,28.599999999999994,34.7,27.200000000000003,39.8,34.900000000000006,23.3,30.700000000000003,35.900000000000006,40.5,24.90000000000001,33.099999999999994,18.700000000000003,27.200000000000003,25.40000000000001,21.700000000000003,38.8,30.40000000000001,36.900000000000006,39.6,31.700000000000003,13.700000000000005,36.2,33.400000000000006,40.7,39.6,37.6,38.5,41.3,31.599999999999994,25.700000000000003,34.099999999999994,43.6,16.799999999999997,31.099999999999994,32.599999999999994,40.0,38.8,21.40000000000001,30.8,42.3,31.8,36.8,33.5,38.400000000000006,33.400000000000006,38.1,29.8,30.200000000000003,37.2,22.8,36.5,37.0,36.3,16.299999999999997,31.40000000000001,12.599999999999994,35.3,19.599999999999994,38.900000000000006,41.2,39.2,40.7,39.1,32.5,39.2,36.2,39.900000000000006,36.8,34.0,21.3,34.5,36.1,23.5,41.2,24.599999999999994,37.8,40.3,39.0,22.099999999999994,24.8,19.3,33.599999999999994,40.6,35.099999999999994,24.5,35.2,38.0,33.8,41.0,27.700000000000003,39.1,33.7,36.1,26.599999999999994,28.200000000000003,22.5,38.3,32.5,38.7,36.8,40.9,39.8,25.3,19.0,26.200000000000003,42.8,14.799999999999995,20.3,31.200000000000003,32.5,35.2,42.7,33.2,35.2,37.8,40.3,26.8,33.900000000000006,43.400000000000006,34.400000000000006,26.700000000000003,35.3,39.2,34.5,37.400000000000006,36.8,38.0,37.400000000000006,38.2,38.1,39.3,34.5,42.900000000000006,35.099999999999994,17.400000000000006,25.599999999999994,32.099999999999994,42.5,25.0,40.3,23.90000000000001,41.0,32.099999999999994,18.700000000000003,27.90000000000001,36.0,37.2,39.8,38.7,28.099999999999994,31.599999999999994,30.8,16.900000000000006,35.7,36.400000000000006,34.400000000000006,23.700000000000003,23.099999999999994,38.6,37.8,38.3,43.6,37.0,35.099999999999994,37.400000000000006,43.2,38.8,26.40000000000001,39.2,36.6,35.5,25.099999999999994,36.2,36.900000000000006,41.400000000000006,43.2,41.8,35.599999999999994,25.3,38.5,37.7,38.0,37.8,38.1,34.599999999999994,13.799999999999995,40.400000000000006,16.700000000000003,44.2,40.8,25.599999999999994,35.0,35.0,39.8,13.400000000000006,40.5,35.099999999999994,33.2,28.8,33.0,40.3,36.8,36.7,40.3,38.3,41.1,22.3,14.200000000000005,20.700000000000003,36.7,39.0,36.0,12.299999999999995,33.900000000000006,41.3,33.900000000000006,34.2,39.6,35.599999999999994,11.099999999999994,38.7,40.400000000000006,41.400000000000006,40.7,26.5,35.5,36.2,21.90000000000001,38.8,41.3,36.1,43.8,31.40000000000001,30.8,12.200000000000005,38.0,12.200000000000005,27.40000000000001,37.400000000000006,26.90000000000001,34.8,37.3,42.7,33.8,19.0,35.400000000000006,33.8,39.900000000000006,19.40000000000001,42.0,34.099999999999994,41.7,23.0,36.900000000000006,27.8,39.7,34.7,33.0,23.0,42.5,36.3,23.8,43.1,38.1,35.2,39.900000000000006,38.900000000000006,40.5,39.3,35.3,38.2,37.7,23.0,36.1,37.0,42.0,16.400000000000006,34.099999999999994,37.8,43.7,24.40000000000001,42.0,38.1,38.3,26.3,23.0,39.900000000000006,39.3,35.900000000000006,27.599999999999994,38.7,31.0,42.0,44.400000000000006,35.599999999999994,19.40000000000001,35.5,28.40000000000001,38.6,25.700000000000003,40.0,38.6,24.599999999999994,24.200000000000003,33.2,20.099999999999994,31.40000000000001,21.3,28.40000000000001,37.1,37.1,25.3,27.5,17.400000000000006,25.90000000000001,32.7,36.7,23.200000000000003,29.200000000000003,39.0,33.099999999999994,38.0,39.6,41.1,28.700000000000003,20.3,40.1,19.599999999999994,45.3,30.0,39.1,20.0,40.3,38.400000000000006,30.8,33.7,23.90000000000001,43.6,24.90000000000001,38.400000000000006,40.900000000000006,40.1,26.099999999999994,34.8,15.099999999999994,30.599999999999994,30.3,35.7,39.2,35.400000000000006,28.5,19.3,22.200000000000003,37.2,20.099999999999994,40.3,35.599999999999994,38.1,40.1,32.5,11.700000000000005,37.7,39.7,37.2,14.0,27.5,40.3,28.099999999999994,34.0,31.200000000000003,41.1,36.900000000000006,22.3,37.3,39.3,37.5,32.400000000000006,40.7,33.900000000000006,36.5,25.700000000000003,19.099999999999994,40.8,39.7,33.099999999999994,16.5,39.400000000000006,38.6,35.8,17.400000000000006,33.099999999999994,21.90000000000001,41.1,23.0,28.90000000000001,40.1,30.8,34.400000000000006,27.90000000000001,36.900000000000006,38.0,40.400000000000006,24.3,41.900000000000006,31.8,23.599999999999994,37.8,37.6,34.5,39.8,36.6,35.400000000000006,27.200000000000003,16.700000000000003,36.1,21.0,36.8,47.1,39.7,36.5,41.2,40.1,24.8,43.400000000000006,37.6,20.3,30.90000000000001,22.8,33.2,28.0,19.599999999999994,26.90000000000001,41.5,35.900000000000006,25.8,38.5,29.599999999999994,37.5,32.5,29.099999999999994,36.1,38.400000000000006,35.2,22.40000000000001,34.400000000000006,43.6,36.1,35.400000000000006,17.5,18.599999999999994,29.099999999999994,23.8,35.7,40.3,15.200000000000005,41.5,38.6,38.3,37.5,39.1,42.3,36.900000000000006,15.299999999999995,31.8,37.400000000000006,44.8,35.2,29.40000000000001,16.400000000000006,20.099999999999994,13.099999999999994,34.099999999999994,33.8,37.6,34.7,22.599999999999994,24.8,18.8,25.5,40.0,38.7,42.8,24.700000000000003,40.2,34.2,30.700000000000003,41.5,41.900000000000006,37.0,34.400000000000006,31.3,38.6,31.3,29.099999999999994,33.8,22.700000000000003,39.400000000000006,40.1,14.400000000000006,23.90000000000001,33.2,41.5,36.900000000000006,35.400000000000006,33.3,7.099999999999994,17.799999999999997,30.599999999999994,28.0,23.0,38.0,41.1,20.5,31.0,32.2,28.599999999999994,30.700000000000003,32.5,27.5,30.099999999999994,40.400000000000006,34.2,41.3,39.5,38.1,39.1,38.5,36.7,36.0,38.1,38.0,20.3,26.5,30.90000000000001,40.8,22.90000000000001,23.0,22.0,45.1,38.6,38.900000000000006,19.599999999999994,34.599999999999994,30.5,33.2,37.5,21.200000000000003,34.3,19.40000000000001,44.2,40.5,17.099999999999994,38.0,35.8,43.2,39.6,37.1,43.6,12.900000000000006,24.3,19.700000000000003,24.8,42.2,38.3,27.40000000000001,25.5,40.3,33.400000000000006,40.8,26.90000000000001,38.0,28.8,32.7,41.1,32.3,33.599999999999994,28.8,40.7,33.099999999999994,38.0,34.599999999999994,19.099999999999994,43.7,38.400000000000006,34.400000000000006,24.40000000000001,39.400000000000006,38.5,30.40000000000001,30.700000000000003,28.200000000000003,37.3,32.2,38.8,37.0,37.900000000000006,34.900000000000006,34.7,19.40000000000001,14.900000000000006,38.8,24.099999999999994,37.1,31.700000000000003,38.6,8.900000000000006,32.099999999999994,39.7,30.90000000000001,24.40000000000001,29.200000000000003,27.099999999999994,40.400000000000006,43.2,29.5,43.0,24.700000000000003,33.7,41.6,35.5,14.5,34.900000000000006,23.599999999999994,36.8,39.1,36.0,21.5,37.0,26.0,20.200000000000003,35.900000000000006,38.6,13.0,20.90000000000001,23.3,33.2,37.8,42.2,17.799999999999997,32.7,38.8,35.099999999999994,24.40000000000001,12.099999999999994,40.7,31.3,39.900000000000006,26.3,33.8,34.2,34.8,37.400000000000006,41.400000000000006,15.0,16.099999999999994,29.8,21.90000000000001,22.3,31.200000000000003,41.5,31.0,24.40000000000001,42.3,19.200000000000003,30.5,23.3,16.400000000000006,32.900000000000006,41.900000000000006,24.099999999999994,31.0,18.40000000000001,20.0,26.700000000000003,39.400000000000006,18.8,36.5,39.8,20.90000000000001,41.6,16.0,30.40000000000001,36.1,40.2,23.3,21.3,37.8,33.400000000000006,20.5,31.3,35.2,41.6,25.200000000000003,18.700000000000003,40.6,42.3,17.5,35.599999999999994,35.099999999999994,33.599999999999994,38.6,20.8,14.400000000000006,36.1,39.400000000000006,41.2,43.7,19.40000000000001,36.5,41.1,39.7,36.2,26.599999999999994,40.7,24.3,33.099999999999994,36.0,27.599999999999994,27.8,38.400000000000006,32.599999999999994,41.6,33.8,36.1,14.599999999999994,38.5,37.5,37.0,36.5,34.0,44.5,45.3,23.099999999999994,39.5,21.8,30.700000000000003,21.0,21.8,40.5,17.400000000000006,19.40000000000001,38.2,39.1,35.900000000000006,37.8,33.599999999999994,40.3,35.599999999999994,40.5,19.5,36.1,37.5,30.0,35.900000000000006,32.0,19.099999999999994,42.7,15.299999999999995,38.6,40.400000000000006,32.599999999999994,24.40000000000001,32.900000000000006,32.7,35.3,33.7,31.5,39.1,28.3,31.40000000000001,27.5,39.6,14.400000000000006,41.2,30.599999999999994,25.599999999999994,34.3,37.900000000000006,18.90000000000001,24.5,41.900000000000006,32.8,31.099999999999994,31.8,38.2,15.799999999999995,30.90000000000001,28.3,24.90000000000001,21.200000000000003,29.3,9.099999999999994,25.90000000000001,23.200000000000003,35.5,25.8,14.200000000000005,28.8,19.700000000000003,19.8,28.40000000000001,36.900000000000006,26.90000000000001,20.599999999999994,28.5,41.3,44.7,35.8,41.6,37.6,10.700000000000005,33.400000000000006,26.0,41.5,38.0,39.2,33.900000000000006,28.700000000000003,35.2,34.3,19.40000000000001,32.400000000000006,42.8,42.3,40.900000000000006,40.2,22.200000000000003,20.200000000000003,43.5,37.8,42.2,35.0,34.8,39.7,37.2,33.5,38.400000000000006,35.400000000000006,36.6,38.900000000000006,23.8,22.099999999999994,38.2,33.3,38.900000000000006,24.599999999999994,38.2,28.8,36.5,34.3,37.5,39.5,21.40000000000001,37.3,38.7,38.3,27.5,37.400000000000006,38.4,39.2,27.700000000000003,38.900000000000006,27.90000000000001,34.5,27.8,12.599999999999994,27.40000000000001,37.3,34.900000000000006,37.900000000000006,17.299999999999997,24.3,36.7,28.5,37.1,37.7,38.8,33.8,38.8,40.2,37.7,37.900000000000006,41.3,39.400000000000006,42.7,28.5,22.200000000000003,39.7,34.3,25.200000000000003,37.400000000000006,24.0,24.599999999999994,36.900000000000006,32.3,38.3,23.40000000000001,28.200000000000003,36.1,31.599999999999994,34.900000000000006,38.3,41.6,18.0,38.6,41.1,20.90000000000001,29.200000000000003,24.599999999999994,18.599999999999994,44.1,27.8,29.5,33.5,26.200000000000003,38.400000000000006,36.400000000000006,34.8,37.7,38.1,36.900000000000006,26.599999999999994,43.7,25.099999999999994,22.3,18.8,30.5,22.599999999999994,20.3,43.2,36.2,2.299999999999997,42.1,41.400000000000006,24.90000000000001,21.200000000000003,21.599999999999994,38.900000000000006,23.599999999999994,39.7,28.5,24.200000000000003,17.0,41.2,35.900000000000006,15.200000000000005,38.7,36.0,40.3,26.8,35.2,35.099999999999994,39.3,23.099999999999994,23.700000000000003,35.900000000000006,34.3,34.3,38.5,27.8,37.1,32.099999999999994,38.7,36.400000000000006,22.700000000000003,18.700000000000003,27.8,32.099999999999994,37.3,23.40000000000001,19.90000000000001,37.400000000000006,38.900000000000006,27.200000000000003,18.0,40.5,31.3,30.200000000000003,37.400000000000006,37.5,37.900000000000006,17.700000000000003,35.400000000000006,34.599999999999994,14.299999999999995,37.4,36.7,15.0,16.299999999999997,36.0,37.0,49.1,26.700000000000003,26.0,43.400000000000006,38.0,35.2,45.6,38.7,25.5,42.0,34.8,39.0,31.700000000000003,32.599999999999994,38.8,14.200000000000005,35.900000000000006,39.7,39.0,38.6,41.1,22.700000000000003,15.200000000000005,40.7,39.6,32.0,21.90000000000001,37.6,38.2,38.1,39.7,30.3,41.3,14.400000000000006,31.700000000000003,24.5,35.2,38.7,41.0,32.900000000000006,38.8,19.200000000000003,21.700000000000003,39.2,37.400000000000006,24.40000000000001,30.0,37.900000000000006,21.5,43.1,42.1,39.6,30.599999999999994,24.40000000000001,43.400000000000006,33.2,34.7,42.400000000000006,36.1,15.099999999999994,21.0,38.0,35.599999999999994,24.40000000000001,36.8,38.900000000000006,37.2,36.2,43.0,20.599999999999994,21.200000000000003,39.3,30.40000000000001,42.3,34.3,23.700000000000003,22.5,33.099999999999994,42.0,19.3,43.0,38.0,38.6,40.400000000000006,34.599999999999994,36.3,35.0,35.900000000000006,24.700000000000003,38.900000000000006,16.0,27.0,37.0,23.8,16.0,25.700000000000003,35.3,26.0,29.099999999999994,37.2,21.599999999999994,29.200000000000003,41.400000000000006,40.5,23.599999999999994,36.6,25.8,33.0,39.900000000000006,3.9000000000000057,33.900000000000006,34.5,46.400000000000006,38.5],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"test_result\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"physical_score\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"boxmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('547d875c-ffb6-4548-8976-9e5f439edcfc');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.box(df, x='test_result',y='physical_score')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6beb31ea-c776-4428-9bda-52cf09db4b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "histfunc": "count",
         "histnorm": "",
         "marker": {
          "color": "rgba(255, 153, 51, 1.0)",
          "line": {
           "color": "#4D5663",
           "width": 1.3
          }
         },
         "name": "test_result",
         "opacity": 0.8,
         "orientation": "v",
         "type": "histogram",
         "x": [
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1
         ]
        }
       ],
       "layout": {
        "barmode": "overlay",
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"d0dc67de-3c10-4b5e-bb22-1f049fc053eb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';                                    if (document.getElementById(\"d0dc67de-3c10-4b5e-bb22-1f049fc053eb\")) {                    Plotly.newPlot(                        \"d0dc67de-3c10-4b5e-bb22-1f049fc053eb\",                        [{\"histfunc\":\"count\",\"histnorm\":\"\",\"marker\":{\"color\":\"rgba(255, 153, 51, 1.0)\",\"line\":{\"color\":\"#4D5663\",\"width\":1.3}},\"name\":\"test_result\",\"opacity\":0.8,\"orientation\":\"v\",\"x\":[1,1,0,0,1,0,0,1,0,1,1,1,1,1,1,0,0,1,0,1,0,0,1,1,0,0,1,1,0,1,0,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,1,0,1,0,0,1,0,1,0,0,0,1,1,0,0,1,1,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0,0,1,1,1,1,1,0,1,0,1,1,1,1,0,0,0,1,1,0,0,0,1,0,0,1,1,1,1,1,0,0,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,0,0,1,1,1,0,0,0,1,1,0,0,1,1,1,0,1,1,1,1,1,0,1,1,0,1,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,1,1,0,0,1,1,0,0,1,1,1,1,0,1,1,0,1,1,1,0,1,0,1,0,1,0,1,1,1,1,0,0,1,1,1,1,1,0,0,1,0,0,0,1,1,1,1,1,1,1,1,0,1,0,1,1,0,0,1,0,0,1,1,1,0,1,0,0,0,0,0,0,1,0,0,1,1,1,0,1,1,0,0,1,1,1,1,0,0,1,0,0,1,1,0,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,1,0,0,0,1,1,0,1,1,1,1,1,0,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,0,0,1,1,1,1,0,0,1,0,0,1,1,1,0,1,1,0,1,0,1,0,0,0,1,0,1,0,1,0,1,0,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,0,1,1,1,1,0,1,0,1,1,1,0,0,1,1,1,0,1,1,0,1,1,0,0,1,0,1,0,1,0,0,1,1,1,0,1,0,0,1,1,1,1,1,0,0,1,0,1,1,0,0,1,0,1,0,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,0,1,0,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1,1,1,1,1,1,1,0,0,1,0,1,0,1,0,1,0,0,1,1,0,1,1,0,1,0,0,0,0,1,1,1,1,1,1,1,0,1,0,1,0,1,0,1,1,1,0,0,0,1,0,0,1,1,0,1,1,1,0,0,1,1,1,0,0,1,0,0,0,1,0,0,1,0,0,1,0,1,1,1,0,1,1,0,1,0,1,1,1,0,1,1,1,0,1,1,1,0,1,1,0,1,1,1,1,0,0,1,0,0,1,1,0,1,1,0,0,1,1,1,1,1,0,0,0,1,0,0,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,0,1,1,0,0,1,0,0,1,0,1,1,0,1,1,0,1,1,1,1,0,0,0,1,0,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,0,0,1,0,0,0,0,0,0,1,1,0,1,1,1,1,0,0,1,1,1,0,1,0,0,0,0,1,1,0,1,1,1,1,1,1,0,1,1,0,0,1,1,0,1,1,1,1,0,0,0,0,1,1,0,0,1,1,0,1,1,0,1,1,0,1,1,0,0,0,1,0,0,1,1,0,1,1,0,1,1,0,0,0,0,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,0,0,0,1,0,1,1,0,1,1,1,0,1,0,0,0,1,0,1,1,0,1,1,1,1,1,0,1,0,0,1,0,0,1,1,1,0,1,1,0,1,0,1,1,0,1,0,1,1,1,0,1,1,0,0,0,0,0,1,0,1,1,1,1,0,1,0,1,1,0,1,1,0,0,0,1,1,1,1,0,1,1,1,1,1,0,0,1,1,0,0,1,0,0,0,1,0,1,1,0,1,1,0,1,0,0,1,1,1,0,1,0,0,1,0,1,1,0,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,0,1,0,1,1,0,1,0,1,1,1,1,1,1,0,1,1,0,1,1,0,1,1,1,0,0,1,1,1,1,0,0,1,0,1,0,0,1,1,1,1,0,1,1,0,0,1,1,0,1,0,1,1,0,1,1,0,0,0,1,0,1,0,1,1,1,0,1,1,0,0,1,1,1,1,0,1,0,1,1,1,1,1,0,0,1,1,1,1,1,0,1,0,1,1,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,0,1,1,0,1,0,1,1,1,1,1,0,1,0,1,1,1,1,0,1,1,0,1,0,0,1,1,0,0,1,0,0,1,1,1,1,0,1,1,1,0,1,1,1,0,1,1,0,0,1,0,0,0,0,0,1,1,0,0,1,0,1,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,0,1,0,1,0,1,1,0,1,1,1,0,0,1,1,1,0,1,0,0,1,0,1,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,0,0,0,1,0,1,0,1,1,0,0,1,0,1,1,1,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,0,0,0,0,0,0,1,1,1,1,0,0,1,1,1,0,1,0,0,1,1,1,0,1,1,1,1,0,1,1,1,1,1,0,0,1,1,1,0,0,1,1,0,1,0,1,1,1,0,0,1,1,1,0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,1,0,0,1,1,0,0,1,1,1,1,1,0,1,1,1,1,0,1,0,1,0,1,0,0,1,0,1,1,1,0,1,0,0,0,1,1,1,0,0,1,0,0,0,0,1,0,1,1,0,1,0,0,0,1,1,1,1,0,1,1,1,1,1,1,0,1,0,0,1,0,0,0,0,1,1,0,1,1,0,1,1,0,0,0,0,1,1,0,1,0,0,0,0,0,1,0,1,0,1,1,1,0,1,1,0,1,0,1,1,1,1,0,1,1,1,0,0,1,0,1,1,0,0,1,1,1,1,0,0,1,0,1,0,0,1,0,0,0,0,1,1,1,1,1,1,1,0,1,1,0,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1,1,1,1,0,1,0,1,0,0,1,0,1,1,1,0,0,0,0,1,0,1,1,1,0,1,0,0,0,1,1,0,1,1,0,0,0,1,0,0,1,0,0,1,1,0,0,1,0,1,0,1,1,1,1,0,1,0,1,1,1,0,1,1,0,1,1,0,1,0,1,1,0,1,0,1,0,1,1,1,1,0,0,0,1,1,0,1,0,1,0,1,0,0,1,1,0,1,1,1,0,1,1,0,0,1,1,1,1,0,1,0,1,1,0,0,0,0,0,0,1,0,1,1,0,1,0,0,1,1,0,1,1,0,1,1,1,1,0,0,1,0,0,0,1,1,1,0,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,0,0,0,1,1,0,0,1,1,0,0,0,0,1,1,1,1,0,0,1,1,0,0,0,0,1,0,0,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,0,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,0,1,1,0,1,0,0,0,1,1,0,0,0,1,0,1,1,0,0,1,0,0,0,1,0,1,0,1,1,0,1,0,1,1,1,1,1,0,0,0,0,0,1,1,1,1,1,0,1,1,0,1,0,0,1,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,1,0,1,1,1,0,1,0,0,0,1,1,1,1,1,1,0,0,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,1,1,1,0,0,1,0,1,0,0,1,1,1,0,1,0,1,1,1,1,1,0,1,0,1,1,0,0,1,1,1,1,1,0,0,1,0,1,1,0,1,0,1,1,0,0,1,0,1,0,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,0,0,1,1,1,1,0,0,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,0,1,0,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,0,0,1,1,0,0,1,0,0,0,1,1,1,0,1,0,1,0,1,1,1,0,1,0,1,1,1,1,0,1,1,0,1,1,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,0,1,1,1,0,0,1,1,0,0,1,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,0,1,1,0,1,0,1,0,0,1,1,1,1,0,1,1,1,1,1,1,0,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,0,1,1,1,0,1,0,0,1,1,1,0,1,1,1,0,1,1,0,1,0,1,1,1,1,0,0,1,0,1,0,0,1,0,1,0,1,0,1,0,1,0,1,0,1,1,1,1,1,0,1,0,0,1,1,0,1,1,1,1,0,1,1,0,0,1,1,1,1,0,0,0,1,0,0,0,0,1,1,0,1,0,0,1,1,0,0,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,1,1,1,1,0,0,0,0,0,1,0,1,1,1,0,1,1,1,0,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,1,1,0,1,0,1,1,0,1,1,1,1,0,0,1,1,1,1,0,1,0,1,1,0,0,1,1,1,1,0,1,0,0,1,0,0,1,1,1,0,0,1,0,1,1,1,0,1,1,1,1,1,0,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,0,1,0,1,1,0,0,0,1,1,0,1,1,1,1,0,1,0,1,1,1,1,1,0,1,1,0,0,0,1,0,1,1,1,1,1,1,1,1,1,1,0,1,0,1,0,1,1,1,0,0,0,1,1,1,1,0,1,0,0,1,1,0,1,0,0,1,1,1,1,0,1,0,0,1,0,0,0,0,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,0,0,1,1,0,1,0,0,0,1,0,0,0,1,0,1,1,1,0,1,1,1,1,1,1,0,1,1,1,0,0,1,1,1,0,1,1,0,1,0,0,0,0,0,1,0,0,1,0,0,1,1,1,0,1,0,0,1,0,1,0,1,0,0,1,0,0,0,0,0,1,1,0,1,1,0,0,0,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,0,0,1,0,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,1,0,0,1,1,1,0,1,1,0,1,1,0,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,0,1,1,1,1,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,1,0,1,0,1,1,0,1,0,1,1,1,1,1,0,1,0,0,0,1,0,0,1,1,1,1,0,1,0,0,1,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,1,0,0,0,1,1,0,1,1,0,0,0,0,0,0,0,1,1,0,1,0,1,1,1,1,0,1,1,1,0,0,1,1,1,0,1,0,0,1,1,1,1,1,0,1,1,0,1,0,1,1,1,1,0,1,0,1,1,0,0,1,0,0,0,0,1,1,0,0,1,1,0,1,1,0,1,0,1,1,1,0,1,0,0,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,0,1,0,1,1,0,0,1,1,1,1,0,1,1,0,0,1,1,1,1,0,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,0,0,1,0,1,1,0,0,1,1,0,1,1,1,1,1,1,0,1,1,1,0,0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,1,1,0,1,0,1,1,0,0,1,1,0,0,0,0,1,0,1,0,0,1,0,1,0,1,0,0,1,0,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,0,0,1,1,0,1,1,1,1,0,1,1,0,1,1,1,1,0,1,1,0,1,0,0,1,0,1,0,1,0,1,1,1,1,0,1,1,1,0,1,1,1,1,0,1,1,0,0,0,1,0,1,1,0,1,1,0,0,1,1,1,0,1,1,0,1,1,1,1,0,1,1,0,0,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,0,0,1,1,0,1,1,0,1,1,1,0,0,1,1,1,1,1,0,0,0,0,0,1,1,0,1,1,1,1,1,0,0,1,1,1,1,0,0,1,0,0,0,1,1,0,0,1,0,1,1,0,1,1,0,0,1,1,1,1,1,0,0,1,0,1,1,1,1,1,0,1,0,0,1,1,0,1,1,0,1,1,1,0,0,1,1,0,1,0,1,1,1,0,0,0,0,0,0,1,1,1,0,0,0,1,1,1,1,1,0,0,1,0,1,0,1,0,1,1,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,1,1,0,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1,1,1,0,1,1,0,1,0,1,1,1,0,1,0,1,0,0,1,0,1,1,1,0,1,0,0,0,1,1,1,0,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,0,0,0,1,0,0,1,1,0,1,1,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,0,1,1,0,0,0,1,1,1,0,0,1,1,1,0,1,1,0,1,1,1,1,0,0,1,0,1,0,1,0,0,1,0,0,1,0,0,1,0,1,1,1,1,1,1,0,0,1,0,1,0,1,1,1,0,1,1,1,0,0,0,0,0,1,0,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,0,1,0,1,0,1,1,1,0,1,1,1,1,0,1,1,0,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,0,1,0,1,0,1,1,0,1,1,1,1,1,0,1,0,0,0,0,0,0,0,1,1,1,0,0,1,0,1,1,1,0,1,1,0,1,0,0,0,0,1,1,1,1,0,0,1,1,1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,0,0,1,1,0,0,0,0,1,1,0,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,0,0,1,0,1,0,1,1,1,1,0,1,1,0,0,0,1,1,0,0,1,0,1,1,0,0,0,1,1,1,1,1,0,1,0,0,1,1,0,1,0,1,0,1,1,1,1,0,1,1,1,0,0,0,1,1,1,1,1,0,0,1,1,0,1,1,1,1,0,0,0,1,1,0,1,0,1,1,1,1,0,1,0,1,1,0,0,1,1,1,1,0,0,0,1,0,1,0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,0,1,1,1,0,1,1,0,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,0,0,0,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,0,1,0,0,1,0,0,1,0,1,0,1,1,1,0,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,0,1,1,0,0,0,1,1,1,0,0,0,1,1,1,0,0,1,0,1,1,1,0,0,1,0,0,1,0,1,1,1,1,1,0,0,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,0,1,0,1,0,1,0,1,1,1,1,0,1,0,1,0,1,1,1,1,1,1,0,0,1,1,0,1,0,1,0,0,1,0,1,1,0,0,1,1,1,0,0,0,1,1,0,1,1,0,1,0,1,0,1,1,1,1,1,0,0,1,1,0,0,0,0,1,1,1,1,1,0,1,1,0,1,0,1,0,0,0,0,1,1,0,0,0,1,0,0,1,1,1,0,1,0,0,1,0,1,1,1,1,0,0,1,1,1,1,0,0,1,0,1,0,1,0,0,1,0,1,0,1,1,1,0,0,1,1,1,0,1,1,1,1,0,1,1,0,1,0,0,0,1,0,0,0,1,0,1,1,0,1,1,1,0,1,1,0,0,0,0,0,0,0,0,1,0,1,1,1,1,0,1,1,1,1,1,0,1,1,0,1,1,0,0,1,1,0,1,0,0,0,0,1,0,1,1,1,0,1,0,1,1,1,1,1,0,0,0,1,0,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,1,0,1,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,0,1,1,1,0,0,0,1,1,1,0,1,1,1,1,0,1,0,1,0,0,0,1,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,0,1,1,1,1,1,1,0,0,1,1,1,1,0,1,1,1,1,1,1,1,1,0,0,0,1,0,1,0,1,1,0,0,1,1,1,1,0,1,0,0,0,1,0,0,0,1,1,0,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,0,1,1,0,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,0,0,0,1,1,1,0,1,1,1,1,0,1,0,1,1,1,1,0,1,1,0,1,1,1,1,1,1,0,1,0,0,1,0,1,0,1,1,0,0,1,1,0,1,1,1,0,1,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,0,1,1,1,0,0,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,1,0,0,1,0,1,1,1,0,0,1,0,1,0,1,0,1,1,0,1,0,0,0,1,1,1,0,1,0,0,0,1,1,1,0,0,0,1,0,1,1,1,1,1,0,1,1,1,0,0,1,0,1,0,1,1,0,1,1,1,0,1,0,1,0,0,1,1,1,0,1,1,1,0,1,0,1,0,0,1,0,1,0,1,1,1,0,1,1,0,1,1,1,1,1,1,0,0,1,0,1,1,1,1,1,1,0,1,1,0,1,0,1,1,0,0,1,1,0,1,0,1,1,0,1,1,1,0,1,1,1,1,0,0,0,0,1,1,0,1,1,1,1,1,1,1,0,1,1,1,0,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,0,1,1,0,1,1,1,0,0,1,0,0,1,0,1,1,0,0,1,1,1,0,0,0,0,0,0,0,1,1,0,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,0,0,0,1,1,1,0,1,0,1,1,0,1,0,1,1,0,1,1,1,0,1,1,0,0,0,0,1,1,0,0,1,1,1,0,1,0,1,1,0,1,0,1,1,1,1,0,0,1,1,0,1,1,0,1,0,1,1,0,1,1,0,1,0,0,1,0,1,1,1,0,0,1,1,0,0,0,1,1,0,1,0,0,1,1,0,1,0,1,1,1,0,0,0,0,0,1,0,0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,1,1,1,1,1,0,0,0,0,0,0,1,1,0,1,0,0,0,0,1,1,0,0,0,0,0,1,0,1,1,0,1,0,0,1,1,0,0,1,0,0,0,1,1,0,0,1,1,0,1,1,1,0,0,0,1,1,1,1,0,1,1,1,1,0,1,0,1,1,0,0,1,0,1,0,1,0,0,1,0,1,1,1,1,0,1,0,1,0,0,1,0,0,1,1,1,1,1,1,1,1,0,1,1,0,1,0,0,1,0,1,1,1,0,1,1,1,1,0,1,0,0,0,1,0,1,1,0,1,1,0,0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,0,1,1,0,1,1,1,1,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,1,0,1,1,0,0,0,0,1,1,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,0,1,0,0,1,1,1,0,0,1,0,1,0,1,0,1,1,0,1,0,0,1,0,0,0,0,1,1,0,1,1,1,0,1,0,0,0,0,0,0,1,0,0,1,1,0,0,0,1,0,0,0,0,0,1,1,0,1,1,1,0,1,1,1,0,0,1,1,1,1,0,1,0,1,1,0,0,0,0,0,0,0,1,1,0,0,1,1,0,1,1,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,1,1,1,1,0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1,1,1,0,1,0,0,0,1,1,1,0,1,0,0,1,1,0,0,1,0,1,1,1,0,0,1,1,1,1,1,0,0,1,1,0,1,1,1,1,1,0,0,1,1,1,1,0,0,0,1,0,1,1,1,1,1,1,1,0,0,1,0,0,1,0,0,0,1,0,0,1,0,0,1,0,0,1,0,1,1,0,1,1,1,1],\"type\":\"histogram\"}],                        {\"barmode\":\"overlay\",\"legend\":{\"bgcolor\":\"#F5F6F9\",\"font\":{\"color\":\"#4D5663\"}},\"paper_bgcolor\":\"#F5F6F9\",\"plot_bgcolor\":\"#F5F6F9\",\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"color\":\"#4D5663\"}},\"xaxis\":{\"gridcolor\":\"#E1E5ED\",\"showgrid\":true,\"tickfont\":{\"color\":\"#4D5663\"},\"title\":{\"font\":{\"color\":\"#4D5663\"},\"text\":\"\"},\"zerolinecolor\":\"#E1E5ED\"},\"yaxis\":{\"gridcolor\":\"#E1E5ED\",\"showgrid\":true,\"tickfont\":{\"color\":\"#4D5663\"},\"title\":{\"font\":{\"color\":\"#4D5663\"},\"text\":\"\"},\"zerolinecolor\":\"#E1E5ED\"}},                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d0dc67de-3c10-4b5e-bb22-1f049fc053eb');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['test_result'].iplot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21b4d733-aea7-44eb-b254-b27ea59b64f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3000\n",
       "0    2000\n",
       "Name: test_result, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['test_result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d75160ab-2556-46f1-b156-5a5e6b9c9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('test_result',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6138b6af-a9e3-4da2-893b-ef91965064c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['test_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2106c9c-cb8d-45df-bca3-feee4ded473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecc33cfa-0898-464a-b3a2-fd5bd5437e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a26c407-dd09-44bd-9fbc-da4bc0b843e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b06f37b-de28-4170-bcb0-d1d8d136ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05453ef0-bed6-4a1e-9b7c-743c5e7b0b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25f8c6d5-4619-400f-ad9f-aba588aea38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8e1ed19-8422-48e0-ab1d-5843b6df4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d47cc7f-232f-4dc2-8271-4b3e419f6ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba0a8279-49a3-4928-99d2-4eafe1e79f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adcba354-8add-4fc3-80e9-8d130412f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "103080a5-45ef-4595-951b-422427175e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.91653034,  3.4506941 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "944d9a50-542f-488a-a3b5-ac0e20d9c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c43da085-29dc-4e33-a1e2-3fc6728f1d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.90       597\n",
      "           1       0.91      0.96      0.94       903\n",
      "\n",
      "    accuracy                           0.92      1500\n",
      "   macro avg       0.92      0.91      0.92      1500\n",
      "weighted avg       0.92      0.92      0.92      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83157ab2-741f-409a-9e2b-336733826f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnf_mat = confusion_matrix(y_test,pred)\n",
    "sns.heatmap(cnf_mat,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f15a871-570f-44bc-8224-93595bacca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8ccb027-030f-4d33-bfb4-8b03ac987f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x1d9c6461340>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a54cb1b-d2c8-49e7-9552-1ea30543bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'C' : [100, 10, 1.0, 0.1, 0.01] , 'penalty' : ['l1', 'l2', 'elasticnet'] , 'l1_ratio' : [0.1,0.25,0.5,0.75,0.90,0.95,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5d7e1fd-a628-415c-8c40-15dcd195ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "505107f7-e113-422d-b542-d44e673fc808",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(model,param_grid,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47c512d7-fbb6-4d7e-a28d-79bddf3ccae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 525 candidates, totalling 2625 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "\n",
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning:\n",
      "\n",
      "One or more of the test scores are non-finite: [       nan        nan 0.91428571        nan 0.91428571 0.91428571\n",
      " 0.91428571 0.91428571 0.91428571 0.91428571        nan        nan\n",
      "        nan        nan 0.91428571        nan        nan 0.91428571\n",
      "        nan 0.91428571 0.91428571 0.91428571 0.91428571 0.91428571\n",
      " 0.91428571        nan        nan        nan        nan 0.91428571\n",
      "        nan        nan 0.91428571        nan 0.91428571 0.91428571\n",
      " 0.91428571 0.91428571 0.91428571 0.91428571        nan        nan\n",
      "        nan        nan 0.91428571        nan        nan 0.91428571\n",
      "        nan 0.91428571 0.91428571 0.91428571 0.91428571 0.91428571\n",
      " 0.91428571        nan        nan        nan        nan 0.91428571\n",
      "        nan        nan 0.91428571        nan 0.91428571 0.91428571\n",
      " 0.91428571 0.91428571 0.91428571 0.91428571        nan        nan\n",
      "        nan        nan 0.91428571        nan        nan 0.91428571\n",
      "        nan 0.91428571 0.91428571 0.91428571 0.91428571 0.91428571\n",
      " 0.91428571        nan        nan        nan        nan 0.91428571\n",
      "        nan        nan 0.91428571        nan 0.91428571 0.91428571\n",
      " 0.91428571 0.91428571 0.91428571 0.91428571        nan        nan\n",
      "        nan        nan 0.91428571        nan        nan 0.91428571\n",
      "        nan 0.91428571 0.91428571 0.91428571 0.91428571 0.91428571\n",
      " 0.91428571        nan        nan        nan        nan 0.91428571\n",
      "        nan        nan 0.91428571        nan 0.91428571 0.91428571\n",
      " 0.91428571 0.91428571 0.91428571 0.91428571        nan        nan\n",
      "        nan        nan 0.91428571        nan        nan 0.91428571\n",
      "        nan 0.91428571 0.91428571 0.91428571 0.91428571 0.91428571\n",
      " 0.91428571        nan        nan        nan        nan 0.91428571\n",
      "        nan        nan 0.91428571        nan 0.91428571 0.91428571\n",
      " 0.91428571 0.91428571 0.91428571 0.91428571        nan        nan\n",
      "        nan        nan 0.91428571        nan        nan 0.91428571\n",
      "        nan 0.91428571 0.91428571 0.91428571 0.91428571 0.91428571\n",
      " 0.91428571        nan        nan        nan        nan 0.91428571\n",
      "        nan        nan 0.91428571        nan 0.91428571 0.91428571\n",
      " 0.91428571 0.91428571 0.91428571 0.91428571        nan        nan\n",
      "        nan        nan 0.91428571        nan        nan 0.91428571\n",
      "        nan 0.91428571 0.91428571 0.91428571 0.91428571 0.91428571\n",
      " 0.91428571        nan        nan        nan        nan 0.91428571\n",
      "        nan        nan 0.91428571        nan 0.91428571 0.91485714\n",
      " 0.91485714 0.91457143 0.91485714 0.91485714        nan        nan\n",
      "        nan        nan 0.91485714        nan        nan 0.91428571\n",
      "        nan 0.91428571 0.91485714 0.91485714 0.91457143 0.91485714\n",
      " 0.91485714        nan        nan        nan        nan 0.91457143\n",
      "        nan        nan 0.91428571        nan 0.91428571 0.91485714\n",
      " 0.91485714 0.91457143 0.91485714 0.91485714        nan        nan\n",
      "        nan        nan 0.91457143        nan        nan 0.91457143\n",
      "        nan 0.91428571 0.91485714 0.91485714 0.91457143 0.91457143\n",
      " 0.91485714        nan        nan        nan        nan 0.91457143\n",
      "        nan        nan 0.91457143        nan 0.91428571 0.91485714\n",
      " 0.91485714 0.91457143 0.91485714 0.91485714        nan        nan\n",
      "        nan        nan 0.91457143        nan        nan 0.91457143\n",
      "        nan 0.91428571 0.91485714 0.91485714 0.91457143 0.91485714\n",
      " 0.91485714        nan        nan        nan        nan 0.91457143\n",
      "        nan        nan 0.91428571        nan 0.91428571 0.91485714\n",
      " 0.91485714 0.91457143 0.91485714 0.91485714        nan        nan\n",
      "        nan        nan 0.91428571        nan        nan 0.91457143\n",
      "        nan 0.91457143 0.91342857 0.91342857 0.914      0.91342857\n",
      " 0.91342857        nan        nan        nan        nan 0.91342857\n",
      "        nan        nan 0.91457143        nan 0.91457143 0.91342857\n",
      " 0.91342857 0.914      0.91371429 0.91342857        nan        nan\n",
      "        nan        nan 0.91371429        nan        nan 0.91457143\n",
      "        nan 0.91457143 0.91342857 0.91342857 0.914      0.91342857\n",
      " 0.91342857        nan        nan        nan        nan 0.914\n",
      "        nan        nan 0.91457143        nan 0.91457143 0.91342857\n",
      " 0.91342857 0.914      0.91371429 0.91342857        nan        nan\n",
      "        nan        nan 0.91428571        nan        nan 0.91457143\n",
      "        nan 0.91457143 0.91342857 0.91342857 0.914      0.91371429\n",
      " 0.91342857        nan        nan        nan        nan 0.91457143\n",
      "        nan        nan 0.91457143        nan 0.91457143 0.91342857\n",
      " 0.91342857 0.914      0.91371429 0.91342857        nan        nan\n",
      "        nan        nan 0.91457143        nan        nan 0.91457143\n",
      "        nan 0.91457143 0.91342857 0.91342857 0.914      0.91371429\n",
      " 0.91342857        nan        nan        nan        nan 0.91457143\n",
      "        nan        nan 0.916             nan 0.91514286 0.90971429\n",
      " 0.90971429 0.90771429 0.90971429 0.90971429        nan        nan\n",
      "        nan        nan 0.90942857        nan        nan 0.916\n",
      "        nan 0.91514286 0.90971429 0.90971429 0.90771429 0.90971429\n",
      " 0.90971429        nan        nan        nan        nan 0.91028571\n",
      "        nan        nan 0.916             nan 0.91514286 0.90971429\n",
      " 0.90971429 0.90771429 0.90942857 0.90971429        nan        nan\n",
      "        nan        nan 0.91085714        nan        nan 0.916\n",
      "        nan 0.91514286 0.90971429 0.90971429 0.90771429 0.90971429\n",
      " 0.90971429        nan        nan        nan        nan 0.91342857\n",
      "        nan        nan 0.916             nan 0.91542857 0.90971429\n",
      " 0.90971429 0.90771429 0.90971429 0.90971429        nan        nan\n",
      "        nan        nan 0.91342857        nan        nan 0.916\n",
      "        nan 0.91514286 0.90971429 0.90971429 0.90771429 0.90942857\n",
      " 0.90971429        nan        nan        nan        nan 0.91571429\n",
      "        nan        nan 0.916             nan 0.91514286 0.90971429\n",
      " 0.90971429 0.90771429 0.90971429 0.90971429        nan        nan\n",
      "        nan        nan 0.91514286]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nouman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning:\n",
      "\n",
      "l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                         'l1_ratio': [0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 1],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47574389-e20b-49be-be45-3719e2c1c73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecac36b8-c95a-4e34-b173-12634ea41612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'l1_ratio': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0650c8fc-da7b-430e-b075-15a9bcc805b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pred = grid_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dd6486c-2b67-407e-bd59-4b01b277e05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90       597\n",
      "           1       0.92      0.95      0.94       903\n",
      "\n",
      "    accuracy                           0.92      1500\n",
      "   macro avg       0.92      0.91      0.92      1500\n",
      "weighted avg       0.92      0.92      0.92      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19ea0325-e13c-4453-8989-d81c7fd97d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[515  82]\n",
      " [ 37 866]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a2de8d1-da53-4288-8c46-5170c9d3d25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[521  76]\n",
      " [ 43 860]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,grid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c88db-e4ad-482c-af9c-e8d497ffef93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
